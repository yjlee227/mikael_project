{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4a801c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Selenium ë²„ì „: 4.25.0\n",
      "âœ… UNIFIED_CITY_INFO ë¡œë“œ ì™„ë£Œ! 117ê°œ ë„ì‹œ ì§€ì›\n",
      "âœ… ê·¸ë£¹ 1 ì™„ë£Œ: ê¸°ë³¸ ì„¤ì • ë° í•µì‹¬ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "################ í˜ì´ì§€ë„¤ì´ì…˜ í…ŒìŠ¤íŠ¸ ì¤‘ #################\n",
    "# =============================================================================\n",
    "# ğŸš€ ê·¸ë£¹ 1: í†µì¼ëœ í•¨ìˆ˜ëª… - ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ í¬ë¡¤ë§ ì‹œìŠ¤í…œ (ë¦¬íŒ©í† ë§ ì™„ë£Œ)\n",
    "# - ë„ì‹œ ì •ë³´ë¥¼ UNIFIED_CITY_INFOë¡œ í†µí•©í•˜ì—¬ ë‹¨ì¼ ì†ŒìŠ¤ë¡œ ê´€ë¦¬\n",
    "#cd \"/mnt/c/Users/redsk/OneDrive/ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—/mikael_project/test_folder\"\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import warnings, os, time, shutil, urllib, random\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import platform\n",
    "import re                        # ê°€ê²©/í‰ì  ì •ì œìš© ì •ê·œì‹\n",
    "import json                      # ë©”íƒ€ë°ì´í„° JSON ì €ì¥ìš©\n",
    "from datetime import datetime    # íƒ€ì„ìŠ¤íƒ¬í”„ìš©\n",
    "import hashlib                   # URL ì¬ì‚¬ìš© ë°©ì§€ ì‹œìŠ¤í…œìš©\n",
    "\n",
    "from PIL import Image\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException\n",
    "\n",
    "import chromedriver_autoinstaller\n",
    "import undetected_chromedriver as uc\n",
    "from user_agents import parse\n",
    "import selenium\n",
    "\n",
    "print(f\"ğŸ”§ Selenium ë²„ì „: {selenium.__version__}\")\n",
    "\n",
    "# â­â­â­ ì¤‘ìš” ì„¤ì •: ì—¬ê¸°ì„œ ìˆ˜ì •í•˜ì„¸ìš”! â­â­â­\n",
    "CONFIG = {\n",
    "    \"WAIT_TIMEOUT\": 10,\n",
    "    \"RETRY_COUNT\": 3,\n",
    "    \"POPUP_WAIT\": 5,\n",
    "    \"SAVE_IMAGES\": True,\n",
    "    \n",
    "    # ğŸ†• í˜ì´ì§€ ìµœì í™” ì„¤ì • ì¶”ê°€\n",
    "    \"SMART_WAIT_MAX\": 8,          # smart_wait_for_page_load ìµœëŒ€ ëŒ€ê¸°\n",
    "    \"NEW_TAB_ENABLED\": False,      # ìƒˆ íƒ­ í¬ë¡¤ë§ í™œì„±í™”\n",
    "    \"PAGE_LOAD_TIMEOUT\": 6,       # í˜ì´ì§€ ë¡œë“œ íƒ€ì„ì•„ì›ƒ\n",
    "\n",
    "    \"SHORT_MIN_DELAY\": 0.2,    # íƒ€ì´í•‘ ê°„ê²© (0.2ì´ˆ ~ 0.5ì´ˆ)\n",
    "    \"SHORT_MAX_DELAY\": 0.5,\n",
    "\n",
    "    \"MEDIUM_MIN_DELAY\": 7,     # í˜ì´ì§€ ë¡œë“œ ë“± ì¼ë°˜ ëŒ€ê¸° (7ì´ˆ ~ 15ì´ˆ)\n",
    "    \"MEDIUM_MAX_DELAY\": 15,\n",
    "\n",
    "    \"LONG_MIN_DELAY\": 20,      # ê°€ë”ì”© ì‰¬ëŠ” ì‹œê°„ (20ì´ˆ ~ 40ì´ˆ)\n",
    "    \"LONG_MAX_DELAY\": 40,\n",
    "    \n",
    "    \"MAX_PRODUCTS_PER_CITY\": 1,     #â­â­â­â­â­â­â­â­â­#\n",
    "    \n",
    "    # ğŸ†• Gemini ì§€ì ì‚¬í•­ í•´ê²°: USER_AGENT ì¶”ê°€\n",
    "    \"USER_AGENT\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# ğŸ™ï¸ ê²€ìƒ‰í•  ë„ì‹œë“¤ (ì—¬ê¸°ì„œ ë³€ê²½!)\n",
    "CITIES_TO_SEARCH = [\"í›„ì¿ ì˜¤ì¹´\"]\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ“ [ìµœì¢… ìˆ˜ì •ë³¸] ë‹¨ì¼ ì •ë³´ ì†ŒìŠ¤ ë° ë¦¬íŒ©í† ë§ëœ í•¨ìˆ˜\n",
    "# =============================================================================\n",
    "\n",
    "# ëª¨ë“  ë„ì‹œì˜ ìƒì„¸ ì •ë³´ê°€ í¬í•¨ëœ ë”•ì…”ë„ˆë¦¬ (ìµœì¢… í™•ì¥ë³¸)\n",
    "UNIFIED_CITY_INFO = {\n",
    "    # ë™ë‚¨ì•„ì‹œì•„\n",
    "    \"ë°©ì½•\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"BKK\"},\n",
    "    \"íŒŒíƒ€ì•¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"PAT\"}, # ë°©ì½• ê³µí•­ ì‚¬ìš©\n",
    "    \"ì•„ìœ íƒ€ì•¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"BKK\"}, # ë°©ì½• ê³µí•­ ì‚¬ìš©\n",
    "    \"ì¹˜ì•™ë§ˆì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"CNX\"},\n",
    "    \"ë¹ ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"CNX\"}, # ì¹˜ì•™ë§ˆì´ ê³µí•­ ì‚¬ìš©\n",
    "    \"ì¹˜ì•™ë¼ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"CEI\"},\n",
    "    \"í‘¸ì¼“\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"HKT\"},\n",
    "    \"í”¼í”¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"KBV\"}, # í¬ë¼ë¹„ ê³µí•­ ì‚¬ìš©\n",
    "    \"í¬ë¼ë¹„\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"KBV\"},\n",
    "    \"í›„ì•„íŒ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"HHQ\"},\n",
    "    \"ì‹±ê°€í¬ë¥´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì‹±ê°€í¬ë¥´\", \"ì½”ë“œ\": \"SIN\"},\n",
    "    \"í™ì½©\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"í™ì½©\", \"ì½”ë“œ\": \"HKG\"},\n",
    "    \"ì¿ ì•Œë¼ë£¸í‘¸ë¥´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë§ë ˆì´ì‹œì•„\", \"ì½”ë“œ\": \"KUL\"},\n",
    "    \"ì½”íƒ€í‚¤ë‚˜ë°œë£¨\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë§ë ˆì´ì‹œì•„\", \"ì½”ë“œ\": \"BKI\"},\n",
    "    \"í˜ë‚­\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë§ë ˆì´ì‹œì•„\", \"ì½”ë“œ\": \"PEN\"},\n",
    "    \"ë‘ì¹´ìœ„\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë§ë ˆì´ì‹œì•„\", \"ì½”ë“œ\": \"LGK\"},\n",
    "    \"ì„¸ë¶€\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"í•„ë¦¬í•€\", \"ì½”ë“œ\": \"CEB\"},\n",
    "    \"ë³´í™€\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"í•„ë¦¬í•€\", \"ì½”ë“œ\": \"TAG\"},\n",
    "    \"ë§ˆë‹ë¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"í•„ë¦¬í•€\", \"ì½”ë“œ\": \"MNL\"},\n",
    "    \"ë³´ë¼ì¹´ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"í•„ë¦¬í•€\", \"ì½”ë“œ\": \"MPH\"}, # ì¹´í‹°í´ë€ ê³µí•­\n",
    "    \"ë‹¤ë‚­\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"DAD\"},\n",
    "    \"í˜¸ì´ì•ˆ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"DAD\"}, # ë‹¤ë‚­ ê³µí•­ ì‚¬ìš©\n",
    "    \"í›„ì—\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"HUI\"},\n",
    "    \"í˜¸ì¹˜ë¯¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"SGN\"},\n",
    "    \"ë¬´ì´ë„¤\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"SGN\"}, # í˜¸ì¹˜ë¯¼ ê³µí•­ ì‚¬ìš©\n",
    "    \"í‘¸ê¾¸ì˜¥\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"PQC\"},\n",
    "    \"ë‚˜íŠ¸ë‘\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"CXR\"},\n",
    "    \"í•˜ë…¸ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"HAN\"},\n",
    "    \"ë‹¬ë\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"DLI\"},\n",
    "    \"ë°œë¦¬\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¸ë„ë„¤ì‹œì•„\", \"ì½”ë“œ\": \"DPS\"},\n",
    "    \"í”„ë†ˆíœ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ìº„ë³´ë””ì•„\", \"ì½”ë“œ\": \"PNH\"}, #ì•„ì§ ìƒí’ˆì—†ìŒ 25.0723\n",
    "    \"ì‹œì— ë¦½\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ìº„ë³´ë””ì•„\", \"ì½”ë“œ\": \"REP\"}, #ì•„ì§ ìƒí’ˆì—†ìŒ 25.0723\n",
    "    \"ì”¨ì— ë¦½\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ìº„ë³´ë””ì•„\", \"ì½”ë“œ\": \"REP\"}, # ì‹œì— ë¦½ ë™ì˜ì–´, #ì•„ì§ ìƒí’ˆì—†ìŒ 25.0723\n",
    "    \"ë¹„ì—”í‹°ì•ˆ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë¼ì˜¤ìŠ¤\", \"ì½”ë“œ\": \"VTE\"},\n",
    "    \"ë°©ë¹„ì—¥\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë¼ì˜¤ìŠ¤\", \"ì½”ë“œ\": \"VTE\"}, # ë¹„ì—”í‹°ì•ˆ ê³µí•­ ì‚¬ìš©\n",
    "    \"ë£¨ì•™í”„ë¼ë°©\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë¼ì˜¤ìŠ¤\", \"ì½”ë“œ\": \"LPQ\"},\n",
    "\n",
    "    # ë™ë¶ì•„ì‹œì•„\n",
    "    \"ë„ì¿„\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"NRT\"},\n",
    "    \"ì˜¤ì‚¬ì¹´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"KIX\"},\n",
    "    \"êµí† \": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"KIX\"}, # ì˜¤ì‚¬ì¹´ ê³µí•­ ì‚¬ìš©\n",
    "    \"ë‚˜ê³ ì•¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"NGO\"},\n",
    "    \"í›„ì¿ ì˜¤ì¹´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"FUK\"},\n",
    "    \"ë²³í‘¸\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"OIT\"}, # ì˜¤ì´íƒ€ ê³µí•­ ì‚¬ìš©\n",
    "    \"ì˜¤ì´íƒ€\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"OIT\"},\n",
    "    \"êµ¬ë§ˆëª¨í† \": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"KMJ\"},\n",
    "    \"ì˜¤í‚¤ë‚˜ì™€\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"OKA\"},\n",
    "    \"ë¯¸ì•¼ì½”ì§€ë§ˆ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"MMY\"},\n",
    "    \"ì‚¿í¬ë¡œ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"CTS\"},\n",
    "    \"íƒ€ì´ë² ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€ë§Œ\", \"ì½”ë“œ\": \"TPE\"},\n",
    "    \"ìƒí•˜ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¤‘êµ­\", \"ì½”ë“œ\": \"PVG\"},\n",
    "    \"ë² ì´ì§•\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¤‘êµ­\", \"ì½”ë“œ\": \"PEK\"},\n",
    "    \"í•˜ì´ë‚œ(ì‹¼ì•¼)\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¤‘êµ­\", \"ì½”ë“œ\": \"SYX\"},\n",
    "    \"ë§ˆì¹´ì˜¤\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë§ˆì¹´ì˜¤\", \"ì½”ë“œ\": \"MFM\"},\n",
    "    \n",
    "    # ë‚¨ì•„ì‹œì•„\n",
    "    \"ë‰´ë¸ë¦¬\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¸ë„\", \"ì½”ë“œ\": \"DEL\"},\n",
    "    \"ë­„ë°”ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¸ë„\", \"ì½”ë“œ\": \"BOM\"},\n",
    "    \"ì¹´íŠ¸ë§Œë‘\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë„¤íŒ”\", \"ì½”ë“œ\": \"KTM\"},\n",
    "    \"í¬ì¹´ë¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë„¤íŒ”\", \"ì½”ë“œ\": \"PKR\"},\n",
    "\n",
    "    # í•œêµ­\n",
    "    \"ì„œìš¸\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"ICN\"},\n",
    "    \"ë¶€ì‚°\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"PUS\"},\n",
    "    \"ì œì£¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"CJU\"},\n",
    "    \"ëŒ€êµ¬\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"TAE\"},\n",
    "    \"ê´‘ì£¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"KWJ\"},\n",
    "    \"ì—¬ìˆ˜\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"RSU\"},\n",
    "    \"ì¸ì²œ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"ICN\"},\n",
    "    \"ê¹€í¬\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"GMP\"},\n",
    "\n",
    "    # ìœ ëŸ½\n",
    "    \"íŒŒë¦¬\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í”„ë‘ìŠ¤\", \"ì½”ë“œ\": \"CDG\"},\n",
    "    \"ëŸ°ë˜\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì˜êµ­\", \"ì½”ë“œ\": \"LHR\"},\n",
    "    \"ë”ë¸”ë¦°\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì•„ì¼ëœë“œ\", \"ì½”ë“œ\": \"DUB\"},\n",
    "    \"ë¡œë§ˆ\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"FCO\"},\n",
    "    \"í”¼ë Œì²´\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"FLR\"},\n",
    "    \"ë² ë„¤ì¹˜ì•„\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"VCE\"},\n",
    "    \"ë°€ë¼ë…¸\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"MXP\"},\n",
    "    \"ë°”ë¥´ì…€ë¡œë‚˜\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤í˜ì¸\", \"ì½”ë“œ\": \"BCN\"},\n",
    "    \"ë§ˆë“œë¦¬ë“œ\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤í˜ì¸\", \"ì½”ë“œ\": \"MAD\"},\n",
    "    \"ì„¸ë¹„ì•¼\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤í˜ì¸\", \"ì½”ë“œ\": \"SVQ\"},\n",
    "    \"ê·¸ë¼ë‚˜ë‹¤\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤í˜ì¸\", \"ì½”ë“œ\": \"GRX\"},\n",
    "    \"ì´ë¹„ì\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤í˜ì¸\", \"ì½”ë“œ\": \"IBZ\"},\n",
    "    \"ë¦¬ìŠ¤ë³¸\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í¬ë¥´íˆ¬ê°ˆ\", \"ì½”ë“œ\": \"LIS\"},\n",
    "    \"í¬ë¥´íˆ¬\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í¬ë¥´íˆ¬ê°ˆ\", \"ì½”ë“œ\": \"OPO\"},\n",
    "    \"í”„ë¼í•˜\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì²´ì½”\", \"ì½”ë“œ\": \"PRG\"},\n",
    "    \"ë¹„ì—”ë‚˜\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì˜¤ìŠ¤íŠ¸ë¦¬ì•„\", \"ì½”ë“œ\": \"VIE\"},\n",
    "    \"ì·¨ë¦¬íˆ\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤ìœ„ìŠ¤\", \"ì½”ë“œ\": \"ZRH\"},\n",
    "    \"ì¸í„°ë¼ì¼„\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤ìœ„ìŠ¤\", \"ì½”ë“œ\": \"ZRH\"}, # ì·¨ë¦¬íˆ ê³µí•­ ì‚¬ìš©\n",
    "    \"ì•”ìŠ¤í…Œë¥´ë‹´\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ë„¤ëœë€ë“œ\", \"ì½”ë“œ\": \"AMS\"},\n",
    "    \"ë¸Œë¤¼ì…€\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ë²¨ê¸°ì—\", \"ì½”ë“œ\": \"BRU\"},\n",
    "    \"ë®Œí—¨\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ë…ì¼\", \"ì½”ë“œ\": \"MUC\"},\n",
    "    \"ë² ë¥¼ë¦°\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ë…ì¼\", \"ì½”ë“œ\": \"BER\"},\n",
    "    \"í”„ë‘í¬í‘¸ë¥´íŠ¸\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ë…ì¼\", \"ì½”ë“œ\": \"FRA\"},\n",
    "    \"ë¶€ë‹¤í˜ìŠ¤íŠ¸\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í—ê°€ë¦¬\", \"ì½”ë“œ\": \"BUD\"},\n",
    "    \"ë°”ë¥´ìƒ¤ë°”\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í´ë€ë“œ\", \"ì½”ë“œ\": \"WAW\"},\n",
    "    \"í¬ë¼ì¿ í”„\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í´ë€ë“œ\", \"ì½”ë“œ\": \"KRK\"},\n",
    "    \"ì•„í…Œë„¤\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ê·¸ë¦¬ìŠ¤\", \"ì½”ë“œ\": \"ATH\"},\n",
    "    \"ì‚°í† ë¦¬ë‹ˆ\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ê·¸ë¦¬ìŠ¤\", \"ì½”ë“œ\": \"JTR\"},\n",
    "    \"ìê·¸ë ˆë¸Œ\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í¬ë¡œì•„í‹°ì•„\", \"ì½”ë“œ\": \"ZAG\"},\n",
    "    \"ë‘ë¸Œë¡œë¸Œë‹ˆí¬\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í¬ë¡œì•„í‹°ì•„\", \"ì½”ë“œ\": \"DBV\"},\n",
    "    \"ì½”íœí•˜ê²\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ë´ë§ˆí¬\", \"ì½”ë“œ\": \"CPH\"},\n",
    "    \"ìŠ¤í†¡í™€ë¦„\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤ì›¨ë´\", \"ì½”ë“œ\": \"ARN\"},\n",
    "    \"ì˜¤ìŠ¬ë¡œ\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ë…¸ë¥´ì›¨ì´\", \"ì½”ë“œ\": \"OSL\"},\n",
    "    \"í—¬ì‹±í‚¤\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í•€ë€ë“œ\", \"ì½”ë“œ\": \"HEL\"},\n",
    "    \"ì´ìŠ¤íƒ„ë¶ˆ\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í„°í‚¤\", \"ì½”ë“œ\": \"IST\"},\n",
    "\n",
    "    # ë¶ë¯¸\n",
    "    \"ë‰´ìš•\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"JFK\"},\n",
    "    \"ë¡œìŠ¤ì•¤ì ¤ë ˆìŠ¤\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"LAX\"},\n",
    "    \"ì‹œì¹´ê³ \": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"ORD\"},\n",
    "    \"í•˜ì™€ì´\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"HNL\"},\n",
    "    \"ìƒŒí”„ë€ì‹œìŠ¤ì½”\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"SFO\"},\n",
    "    \"ë¼ìŠ¤ë² ì´ê±°ìŠ¤\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"LAS\"},\n",
    "    \"ì›Œì‹±í„´ D.C.\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"IAD\"},\n",
    "    \"ë³´ìŠ¤í„´\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"BOS\"},\n",
    "    \"ì‹œì• í‹€\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"SEA\"},\n",
    "    \"ë°´ì¿ ë²„\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ìºë‚˜ë‹¤\", \"ì½”ë“œ\": \"YVR\"},\n",
    "    \"í† ë¡ í† \": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ìºë‚˜ë‹¤\", \"ì½”ë“œ\": \"YYZ\"},\n",
    "    \"ì¹¸ì¿¤\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë©•ì‹œì½”\", \"ì½”ë“œ\": \"CUN\"},\n",
    "\n",
    "    # ì˜¤ì„¸ì•„ë‹ˆì•„\n",
    "    \"ì‹œë“œë‹ˆ\": {\"ëŒ€ë¥™\": \"ì˜¤ì„¸ì•„ë‹ˆì•„\", \"êµ­ê°€\": \"í˜¸ì£¼\", \"ì½”ë“œ\": \"SYD\"},\n",
    "    \"ë©œë²„ë¥¸\": {\"ëŒ€ë¥™\": \"ì˜¤ì„¸ì•„ë‹ˆì•„\", \"êµ­ê°€\": \"í˜¸ì£¼\", \"ì½”ë“œ\": \"MEL\"},\n",
    "    \"ê´Œ\": {\"ëŒ€ë¥™\": \"ì˜¤ì„¸ì•„ë‹ˆì•„\", \"êµ­ê°€\": \"ê´Œ\", \"ì½”ë“œ\": \"GUM\"},\n",
    "    \"ì‚¬ì´íŒ\": {\"ëŒ€ë¥™\": \"ì˜¤ì„¸ì•„ë‹ˆì•„\", \"êµ­ê°€\": \"ë¶ë§ˆë¦¬ì•„ë‚˜ ì œë„\", \"ì½”ë“œ\": \"SPN\"},\n",
    "    \"ì˜¤í´ëœë“œ\": {\"ëŒ€ë¥™\": \"ì˜¤ì„¸ì•„ë‹ˆì•„\", \"êµ­ê°€\": \"ë‰´ì§ˆëœë“œ\", \"ì½”ë“œ\": \"AKL\"},\n",
    "    \n",
    "    # ì¤‘ë™\n",
    "    \"ë‘ë°”ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì•„ëì—ë¯¸ë¦¬íŠ¸\", \"ì½”ë“œ\": \"DXB\"},\n",
    "}\n",
    "\n",
    "print(f\"âœ… UNIFIED_CITY_INFO ë¡œë“œ ì™„ë£Œ! {len(UNIFIED_CITY_INFO)}ê°œ ë„ì‹œ ì§€ì›\")\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ”§ í•µì‹¬ í•¨ìˆ˜ë“¤ - ë‹¨ì¼ ì •ë³´ ì†ŒìŠ¤(UNIFIED_CITY_INFO) ì‚¬ìš©\n",
    "# =============================================================================\n",
    "\n",
    "def get_city_code(city_name):\n",
    "    \"\"\"ë„ì‹œëª…ìœ¼ë¡œ ê³µí•­ ì½”ë“œ ë°˜í™˜ (UNIFIED_CITY_INFO ì‚¬ìš©)\"\"\"\n",
    "    info = UNIFIED_CITY_INFO.get(city_name)\n",
    "    if info:\n",
    "        code = info.get(\"ì½”ë“œ\", city_name[:3].upper())\n",
    "        return code\n",
    "    return city_name[:3].upper()\n",
    "\n",
    "def get_city_info(city_name):\n",
    "    \"\"\"í†µí•©ëœ ë„ì‹œ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì‚¬ì „ ì •ì˜ëœ ê°’ë§Œ ì‚¬ìš©)\"\"\"\n",
    "    info = UNIFIED_CITY_INFO.get(city_name)\n",
    "    if info:\n",
    "        return info[\"ëŒ€ë¥™\"], info[\"êµ­ê°€\"]\n",
    "    else:\n",
    "        # ì •ì˜ë˜ì§€ ì•Šì€ ë„ì‹œì— ëŒ€í•œ ê¸°ë³¸ê°’\n",
    "        return \"ê¸°íƒ€\", \"ê¸°íƒ€\"\n",
    "\n",
    "def get_last_product_number(city_name):\n",
    "    \"\"\"ê¸°ì¡´ CSVì—ì„œ ë§ˆì§€ë§‰ ë²ˆí˜¸ í™•ì¸ (ë²ˆí˜¸ ì—°ì†ì„± í™•ë³´)\"\"\"\n",
    "    try:\n",
    "        continent, country = get_city_info(city_name)\n",
    "        \n",
    "        # ğŸ¯ ========== ë„ì‹œêµ­ê°€ íŠ¹ë³„ ì²˜ë¦¬ ì¶”ê°€ ==========\n",
    "        if city_name in [\"ë§ˆì¹´ì˜¤\", \"í™ì½©\", \"ì‹±ê°€í¬ë¥´\"]:\n",
    "            # ë„ì‹œêµ­ê°€: ëŒ€ë¥™ í´ë” ë°”ë¡œ ì•„ë˜ì—ì„œ ì°¾ê¸°\n",
    "            csv_path = os.path.join(\"data\", continent, f\"myrealtrip_{city_name}_products.csv\")\n",
    "        else:\n",
    "            # ì¼ë°˜ ë„ì‹œ: ê¸°ì¡´ êµ¬ì¡°\n",
    "            csv_path = os.path.join(\"data\", continent, country, city_name, f\"myrealtrip_{city_name}_products.csv\")\n",
    "        # ================================================\n",
    "        \n",
    "        if os.path.exists(csv_path):\n",
    "            df = pd.read_csv(csv_path, encoding='utf-8-sig')\n",
    "            if not df.empty and 'ë²ˆí˜¸' in df.columns:\n",
    "                last_number = df['ë²ˆí˜¸'].max()\n",
    "                print(f\"ğŸ“Š ê¸°ì¡´ CSV ë§ˆì§€ë§‰ ë²ˆí˜¸: {last_number}\")\n",
    "                return last_number\n",
    "        \n",
    "        print(f\"ğŸ“„ ê¸°ì¡´ CSV íŒŒì¼ ì—†ìŒ - 0ë¶€í„° ì‹œì‘\")\n",
    "        return 0   # íŒŒì¼ì´ ì—†ìœ¼ë©´ 0 ë°˜í™˜ (ë‹¤ìŒì€ 1ë¶€í„° ì‹œì‘)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ë§ˆì§€ë§‰ ë²ˆí˜¸ í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "        return 0   # 0 ë°˜í™˜í•˜ì—¬ ë‹¤ìŒì´ 1ë¶€í„° ì‹œì‘\n",
    "\n",
    "def get_product_name(driver, url_type=\"Product\"):\n",
    "    \"\"\"âœ… ìƒí’ˆëª… ìˆ˜ì§‘ (ê¸°ì¡´: get_product_name_by_type â†’ ìƒˆë¡œìš´: get_product_name)\"\"\"\n",
    "    print(f\"  ğŸ“Š {url_type} ìƒí’ˆëª… ìˆ˜ì§‘ ì¤‘...\")\n",
    "    \n",
    "    title_selectors = [\n",
    "        (By.CSS_SELECTOR, \"h1\"),\n",
    "        (By.CSS_SELECTOR, \".product-title\"),\n",
    "        (By.XPATH, \"//h1[contains(@class, 'title')]\"),\n",
    "        (By.XPATH, \"/html/body/div[1]/main/div[1]/section/div[1]/h1\")\n",
    "    ]\n",
    "\n",
    "    for selector_type, selector_value in title_selectors:\n",
    "        try:\n",
    "            title_element = WebDriverWait(driver, CONFIG[\"WAIT_TIMEOUT\"]).until(\n",
    "                EC.presence_of_element_located((selector_type, selector_value))\n",
    "            )\n",
    "            found_name = title_element.text\n",
    "            return found_name\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "    \n",
    "    raise NoSuchElementException(\"ìƒí’ˆëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "\n",
    "def get_price(driver):\n",
    "    \"\"\"âœ… ê°€ê²© ìˆ˜ì§‘ - ìˆ˜ì •ëœ ë²„ì „ (ì˜ëª»ëœ í…ìŠ¤íŠ¸ í•„í„°ë§ ê°•í™”)\"\"\"\n",
    "    print(f\"  ğŸ’° ê°€ê²© ì •ë³´ ìˆ˜ì§‘ ì¤‘...\")\n",
    "    \n",
    "    # ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ ì‹¤ì œ ê°€ê²© ì…€ë ‰í„°ë“¤\n",
    "    price_selectors = [\n",
    "        (By.CSS_SELECTOR, \"span[style*='color: rgb(255, 87, 87)']\"),\n",
    "        (By.CSS_SELECTOR, \"span[style*='color: rgb(255, 71, 71)']\"),\n",
    "        (By.CSS_SELECTOR, \"span[style*='color: red']\"),\n",
    "        (By.CSS_SELECTOR, \".text-red\"),\n",
    "        (By.CSS_SELECTOR, \".price\"),\n",
    "        (By.CSS_SELECTOR, \"[class*='price']\"),\n",
    "        # ë” êµ¬ì²´ì ì¸ XPath\n",
    "        (By.XPATH, \"//span[contains(text(), 'ì›~') and contains(text(), ',') and string-length(text()) < 30]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'ì›-') and contains(text(), ',') and string-length(text()) < 30]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), ',') and contains(text(), 'ì›') and not(contains(text(), 'ì¸ì›')) and not(contains(text(), 'ìµœì†Œ'))]\"),\n",
    "    ]\n",
    "\n",
    "    for selector_type, selector_value in price_selectors:\n",
    "        try:\n",
    "            price_elements = driver.find_elements(selector_type, selector_value)\n",
    "            \n",
    "            for price_element in price_elements:\n",
    "                found_price = price_element.text.strip()\n",
    "                \n",
    "                if not found_price:\n",
    "                    continue\n",
    "                \n",
    "                # ğŸ”¥ ê°•ë ¥í•œ í•„í„°ë§: ê°€ê²©ì´ ì•„ë‹Œ í…ìŠ¤íŠ¸ë“¤ ì œì™¸\n",
    "                invalid_keywords = [\n",
    "                    'ì¿ í°', 'ë°›ê¸°', 'ë‹¤ìš´', 'í• ì¸', 'ì ë¦½', 'í¬ì¸íŠ¸',\n",
    "                    'ìµœì†Œ', 'ì¸ì›', 'ëª…', 'ìµœëŒ€', 'ì„ íƒ', 'ì˜µì…˜',\n",
    "                    'ì˜ˆì•½', 'ì‹ ì²­', 'ë¬¸ì˜', 'ìƒë‹´', 'í™•ì¸', 'ëª…ë¶€í„°',\n",
    "                    'ì‹œê°„', 'ì¼ì •', 'ì½”ìŠ¤', 'íˆ¬ì–´', 'ì—¬í–‰', 'ë¶€í„°',\n",
    "                    'ì–¸ì–´', 'ê°€ì´ë“œ', 'í¬í•¨', 'ë¶ˆí¬í•¨', 'ì´ìƒ',\n",
    "                    'ì·¨ì†Œ', 'í™˜ë¶ˆ', 'ë³€ê²½', 'ì•ˆë‚´', 'ëª¨ì§‘'\n",
    "                ]\n",
    "                \n",
    "                if any(keyword in found_price for keyword in invalid_keywords):\n",
    "                    continue\n",
    "                \n",
    "                # ê¸¸ì´ ì œí•œ (ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ ì œì™¸)\n",
    "                if len(found_price) > 30:\n",
    "                    continue\n",
    "                \n",
    "                # ê°€ê²© íŒ¨í„´ í™•ì¸\n",
    "                import re\n",
    "                price_patterns = [\n",
    "                    r'\\d{1,3}(?:,\\d{3})+ì›[~-]?',  # 10,000ì›~ í˜•íƒœ\n",
    "                    r'\\d+,\\d+ì›[~-]?',             # ê°„ë‹¨í•œ ì²œë‹¨ìœ„ êµ¬ë¶„\n",
    "                    r'\\d{4,}ì›[~-]?',              # 10000ì›~ í˜•íƒœ\n",
    "                ]\n",
    "                \n",
    "                is_valid_price = any(re.search(pattern, found_price) for pattern in price_patterns)\n",
    "                \n",
    "                if is_valid_price and 'ì›' in found_price:\n",
    "                    print(f\"    âœ… ìœ íš¨í•œ ê°€ê²© ë°œê²¬: '{found_price}'\")\n",
    "                    return found_price\n",
    "                    \n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    print(f\"    âŒ ê°€ê²© ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "    return \"ì •ë³´ ì—†ìŒ\"\n",
    "\n",
    "def clean_price(price_text):\n",
    "    \"\"\"âœ… ê°€ê²© ì •ì œ (ê¸°ì¡´: extract_clean_price â†’ ìƒˆë¡œìš´: clean_price) (ê³µìš© í•¨ìˆ˜)\"\"\"\n",
    "    if not price_text or price_text == \"ì •ë³´ ì—†ìŒ\":\n",
    "        return \"ì •ë³´ ì—†ìŒ\"\n",
    "    \n",
    "    price_pattern = r'(\\d{1,3}(?:,\\d{3})*)\\s*ì›[~-]?'\n",
    "    match = re.search(price_pattern, price_text)\n",
    "    \n",
    "    if match:\n",
    "        return match.group(1) + \"ì›\"\n",
    "    else:\n",
    "        return price_text\n",
    "\n",
    "def clean_rating(rating_text):\n",
    "    \"\"\"âœ… í‰ì  ì •ì œ (ê¸°ì¡´: extract_clean_rating â†’ ìƒˆë¡œìš´: clean_rating) (ê³µìš© í•¨ìˆ˜)\"\"\"\n",
    "    if not rating_text or rating_text == \"ì •ë³´ ì—†ìŒ\":\n",
    "        return \"ì •ë³´ ì—†ìŒ\"\n",
    "    \n",
    "    rating_pattern = r'(\\d+\\.?\\d*)'\n",
    "    match = re.search(rating_pattern, rating_text)\n",
    "    \n",
    "    if match:\n",
    "        try:\n",
    "            return float(match.group(1))\n",
    "        except ValueError:\n",
    "            return rating_text\n",
    "    else:\n",
    "        return rating_text\n",
    "\n",
    "print(\"âœ… ê·¸ë£¹ 1 ì™„ë£Œ: ê¸°ë³¸ ì„¤ì • ë° í•µì‹¬ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1f698bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê·¸ë£¹ 2 ì™„ë£Œ: ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ë°ì´í„° ì €ì¥ í•¨ìˆ˜ë“¤ ì •ì˜ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ğŸš€ ê·¸ë£¹ 2: ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ë°ì´í„° ì €ì¥ í•¨ìˆ˜ë“¤\n",
    "# - ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ, ë°ì´í„° ì €ì¥, ê²°ê³¼ ì²˜ë¦¬ ê´€ë ¨ í•¨ìˆ˜ë“¤\n",
    "# =============================================================================\n",
    "\n",
    "def download_image(driver, product_name, city_name, product_number):\n",
    "    \"\"\"âœ… ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ - ê³„ì¸µ êµ¬ì¡° ì €ì¥ (ì „ì—­ ë²ˆí˜¸ ì‚¬ìš©ìœ¼ë¡œ ìˆ˜ì •)\"\"\"\n",
    "    if not CONFIG[\"SAVE_IMAGES\"]:\n",
    "        return {\n",
    "            'status': 'ì´ë¯¸ì§€ ì €ì¥ ë¹„í™œì„±í™”',\n",
    "            'filename': '',\n",
    "            'path': '',\n",
    "            'relative_path': '',\n",
    "            'size': 0\n",
    "        }\n",
    "        \n",
    "    print(f\"  ğŸ–¼ï¸ ëŒ€í‘œ ìƒí’ˆ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
    "    \n",
    "    # ë” ê´‘ë²”ìœ„í•œ ì´ë¯¸ì§€ ì…€ë ‰í„°ë“¤\n",
    "    image_selectors = [\n",
    "        (By.CSS_SELECTOR, \".main-image img\"),\n",
    "        (By.CSS_SELECTOR, \".hero-image img\"),\n",
    "        (By.CSS_SELECTOR, \".product-image img\"),\n",
    "        (By.CSS_SELECTOR, \".product-gallery img:first-child\"),\n",
    "        (By.CSS_SELECTOR, \".gallery img:first-child\"),\n",
    "        (By.CSS_SELECTOR, \".image-gallery img:first-child\"),\n",
    "        (By.CSS_SELECTOR, \".slider img:first-child\"),\n",
    "        (By.XPATH, \"//img[@width and @height and (@width > '200' or @height > '200')]\"),\n",
    "        (By.XPATH, \"//img[contains(@src, 'large') or contains(@src, 'big') or contains(@src, 'main')]\"),\n",
    "        (By.CSS_SELECTOR, \"img[src*='cdn']\"),\n",
    "        (By.CSS_SELECTOR, \"img[src*='cloudfront']\"),\n",
    "        (By.CSS_SELECTOR, \"img[src*='amazonaws']\"),\n",
    "        (By.XPATH, \"(//img[contains(@src, 'http') and not(contains(@src, 'icon')) and not(contains(@src, 'logo'))])[1]\"),\n",
    "        (By.XPATH, \"//img[contains(@alt, 'ìƒí’ˆ') or contains(@alt, 'íˆ¬ì–´') or contains(@alt, 'ì—¬í–‰')]\"),\n",
    "    ]\n",
    "\n",
    "    img_url = None\n",
    "    for selector_type, selector_value in image_selectors:\n",
    "        try:\n",
    "            img_elements = driver.find_elements(selector_type, selector_value)\n",
    "            for img_element in img_elements:\n",
    "                try:\n",
    "                    img_url = img_element.get_attribute('src')\n",
    "                    if not img_url or not img_url.startswith('http'):\n",
    "                        continue\n",
    "                    exclude_patterns = ['logo', 'icon', 'banner', 'ad', 'avatar', 'profile', 'button', 'arrow', 'star', 'thumb', 'small', 'mini']\n",
    "                    if any(pattern in img_url.lower() for pattern in exclude_patterns):\n",
    "                        continue\n",
    "                    try:\n",
    "                        size = img_element.size\n",
    "                        if size and (size.get('width', 0) < 100 or size.get('height', 0) < 100):\n",
    "                            continue\n",
    "                    except:\n",
    "                        pass\n",
    "                    print(f\"    âœ… ì´ë¯¸ì§€ URL ë°œê²¬: {img_url[:50]}...\")\n",
    "                    break\n",
    "                except Exception:\n",
    "                    continue\n",
    "            if img_url:\n",
    "                break\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    # â­ï¸ í•µì‹¬ ìˆ˜ì •: íŒŒì¼ëª…ì„ product_number ê¸°ì¤€ìœ¼ë¡œ ìƒì„± (1ë¶€í„° ì‹œì‘ ë³´ì¥)\n",
    "    city_code = get_city_code(city_name)\n",
    "    # ë²ˆí˜¸ê°€ 0ì´í•˜ë©´ 1ë¡œ ë³´ì •í•˜ì—¬ ì¼ê´€ì„± í™•ë³´\n",
    "    safe_number = max(1, product_number)\n",
    "    img_filename = f\"{city_code}_{safe_number:04d}.jpg\"\n",
    "\n",
    "    if not img_url:\n",
    "        print(f\"    âŒ ì´ë¯¸ì§€ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "        return {\n",
    "            'status': 'ì´ë¯¸ì§€ URL ì—†ìŒ',\n",
    "            'filename': img_filename,\n",
    "            'path': '',\n",
    "            'relative_path': '',\n",
    "            'size': 0\n",
    "        }\n",
    "\n",
    "    # ğŸ—ï¸ ê³„ì¸µ êµ¬ì¡° í´ë” ìƒì„± ë° ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ\n",
    "    try:\n",
    "        import urllib.request\n",
    "        import os\n",
    "        \n",
    "        # ë„ì‹œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "        continent, country = get_city_info(city_name)\n",
    "        \n",
    "        # ğŸ“ ê³„ì¸µ êµ¬ì¡° í´ë” ê²½ë¡œ ìƒì„±: myrealtripthumb_img/ëŒ€ë¥™/êµ­ê°€/ë„ì‹œ/\n",
    "        # ğŸ¯ ========== ë„ì‹œêµ­ê°€ íŠ¹ë³„ ì²˜ë¦¬ ==========\n",
    "        base_folder = \"myrealtripthumb_img\"\n",
    "\n",
    "        if city_name in [\"ë§ˆì¹´ì˜¤\", \"í™ì½©\", \"ì‹±ê°€í¬ë¥´\"]:\n",
    "            # ë„ì‹œêµ­ê°€: ëŒ€ë¥™/ë„ì‹œ/ êµ¬ì¡° (êµ­ê°€ í´ë” ìƒëµ)\n",
    "            hierarchical_folder = os.path.join(base_folder, continent, city_name)\n",
    "            relative_path = os.path.join(continent, city_name, img_filename)\n",
    "        else:\n",
    "            # ì¼ë°˜ ë„ì‹œ: ê¸°ì¡´ êµ¬ì¡° ìœ ì§€ (ëŒ€ë¥™/êµ­ê°€/ë„ì‹œ/)\n",
    "            hierarchical_folder = os.path.join(base_folder, continent, country, city_name)\n",
    "            relative_path = os.path.join(continent, country, city_name, img_filename)\n",
    "\n",
    "        # í´ë” ìƒì„± (ê³„ì¸µ êµ¬ì¡°)\n",
    "        os.makedirs(hierarchical_folder, exist_ok=True)\n",
    "        print(f\"    ğŸ“ ê³„ì¸µ í´ë” ìƒì„±: {hierarchical_folder}\")\n",
    "\n",
    "        # ì „ì²´ íŒŒì¼ ê²½ë¡œ\n",
    "        img_path = os.path.join(hierarchical_folder, img_filename)\n",
    "        \n",
    "        # User-Agent ì¶”ê°€ë¡œ ë‹¤ìš´ë¡œë“œ ì„±ê³µë¥  ë†’ì´ê¸°\n",
    "        req = urllib.request.Request(\n",
    "            img_url,\n",
    "            headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "        )\n",
    "        \n",
    "        with urllib.request.urlopen(req, timeout=10) as response:\n",
    "            with open(img_path, 'wb') as f:\n",
    "                f.write(response.read())\n",
    "        \n",
    "        file_size = os.path.getsize(img_path)\n",
    "        \n",
    "        if file_size < 1024:\n",
    "            os.remove(img_path)\n",
    "            print(f\"    âŒ ì´ë¯¸ì§€ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤ ({file_size} bytes)\")\n",
    "            return {\n",
    "                'status': 'íŒŒì¼ ë„ˆë¬´ ì‘ìŒ',\n",
    "                'filename': img_filename,\n",
    "                'path': '',\n",
    "                'relative_path': '',\n",
    "                'size': 0\n",
    "            }\n",
    "        \n",
    "        print(f\"    âœ… ê³„ì¸µ êµ¬ì¡° ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ! ({file_size:,} bytes)\")\n",
    "        print(f\"    ğŸ“ ì €ì¥ ìœ„ì¹˜: {relative_path}\")\n",
    "        \n",
    "        return {\n",
    "            'status': 'ë‹¤ìš´ë¡œë“œ ì™„ë£Œ',\n",
    "            'filename': img_filename,\n",
    "            'path': img_path,\n",
    "            'relative_path': relative_path,\n",
    "            'size': file_size\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    âš ï¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {type(e).__name__}: {e}\")\n",
    "        return {\n",
    "            'status': f'ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {type(e).__name__}',\n",
    "            'filename': img_filename,\n",
    "            'path': '',\n",
    "            'relative_path': '',\n",
    "            'size': 0\n",
    "        }\n",
    "\n",
    "def save_results(products_data):\n",
    "    \"\"\"âœ… ë°ì´í„° ì €ì¥ (ë„ì‹œIDëŠ” ì´ë¯¸ í¬í•¨ë¨)\"\"\"\n",
    "    print(\"ğŸ’¾ í•˜ì´ë¸Œë¦¬ë“œ êµ¬ì¡°ë¡œ ë°ì´í„° ì €ì¥ ì¤‘...\")\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    city_name = products_data[0]['ë„ì‹œ'] if products_data else 'unknown'\n",
    "    \n",
    "    # DataFrame ìƒì„± (ë„ì‹œIDëŠ” ì´ë¯¸ crawl_single_product_optimizedì—ì„œ ìƒì„±ë¨)\n",
    "    df = pd.DataFrame(products_data)\n",
    "    \n",
    "    csv_path = f\"myrealtrip_{city_name}_products_{len(products_data)}ê°œ_{timestamp}.csv\"\n",
    "    df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"ğŸ“ ê°œë³„ CSV ì €ì¥ ì™„ë£Œ: {csv_path}\")\n",
    "    \n",
    "    # ë„ì‹œID ì¡´ì¬ í™•ì¸ ë° ì¶œë ¥\n",
    "    if 'ë„ì‹œID' in df.columns and not df['ë„ì‹œID'].empty:\n",
    "        first_id = df['ë„ì‹œID'].iloc[0]\n",
    "        last_id = df['ë„ì‹œID'].iloc[-1]\n",
    "        print(f\"ğŸ†” ë„ì‹œID í™•ì¸: {first_id} ~ {last_id}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ ë„ì‹œID ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤ - crawl_single_product_optimized í™•ì¸ í•„ìš”\")\n",
    "    \n",
    "    city_code = get_city_code(city_name)\n",
    "    metadata = {\n",
    "        \"myrealtrip\": {\n",
    "            \"last_update\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            \"product_count\": len(products_data),\n",
    "            \"status\": \"success\",\n",
    "            \"csv_path\": csv_path,\n",
    "            \"city\": city_name,\n",
    "            \"city_id_pattern\": f\"{city_code}_X\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        os.makedirs('config', exist_ok=True)\n",
    "        with open('config/data_metadata.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"ğŸ“ ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: config/data_metadata.json\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    return csv_path\n",
    "\n",
    "def safe_csv_write(file_path, df, mode='w', header=True):\n",
    "    \"\"\"CSV íŒŒì¼ì„ ì•ˆì „í•˜ê²Œ ì‘ì„± (Permission denied ì˜¤ë¥˜ í•´ê²°)\"\"\"\n",
    "    max_retries = 5\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # ê¸°ì¡´ íŒŒì¼ì´ ìˆê³  ì“°ê¸° ëª¨ë“œì¸ ê²½ìš° ë°±ì—… ìƒì„±\n",
    "            if mode == 'a' and os.path.exists(file_path):\n",
    "                # íŒŒì¼ì´ ì ê²¨ìˆëŠ”ì§€ í™•ì¸\n",
    "                try:\n",
    "                    with open(file_path, 'a', encoding='utf-8-sig') as test_file:\n",
    "                        test_file.write('')  # ë¹ˆ ë¬¸ìì—´ ì“°ê¸° í…ŒìŠ¤íŠ¸\n",
    "                except PermissionError:\n",
    "                    print(f\"    âš ï¸ íŒŒì¼ì´ ì ê²¨ìˆìŒ, {attempt+1}ë²ˆì§¸ ì¬ì‹œë„...\")\n",
    "                    time.sleep(2)  # 2ì´ˆ ëŒ€ê¸°\n",
    "                    continue\n",
    "            \n",
    "            # CSV íŒŒì¼ ì‘ì„±\n",
    "            df.to_csv(file_path, mode=mode, header=header, index=False, encoding='utf-8-sig')\n",
    "            return True\n",
    "            \n",
    "        except PermissionError as e:\n",
    "            print(f\"    âš ï¸ ê¶Œí•œ ì˜¤ë¥˜ ({attempt+1}/{max_retries}): {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                # ì ê¹ ëŒ€ê¸° í›„ ì¬ì‹œë„\n",
    "                wait_time = (attempt + 1) * 2  # 2, 4, 6, 8ì´ˆ\n",
    "                print(f\"    â° {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                # ìµœì¢… ì‹œë„ - ë°±ì—… íŒŒì¼ë¡œ ì €ì¥\n",
    "                backup_path = file_path.replace('.csv', f'_backup_{datetime.now().strftime(\"%H%M%S\")}.csv')\n",
    "                try:\n",
    "                    df.to_csv(backup_path, mode='w', header=True, index=False, encoding='utf-8-sig')\n",
    "                    print(f\"    ğŸ’¾ ë°±ì—… íŒŒì¼ë¡œ ì €ì¥: {backup_path}\")\n",
    "                    return True\n",
    "                except Exception as backup_error:\n",
    "                    print(f\"    âŒ ë°±ì—… ì €ì¥ë„ ì‹¤íŒ¨: {backup_error}\")\n",
    "                    return False\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"    âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}\")\n",
    "            return False\n",
    "    \n",
    "    return False\n",
    "\n",
    "def save_batch_data(batch_results, city_name):\n",
    "    \"\"\"ë°°ì¹˜ ë°ì´í„° ì €ì¥ (ë„ì‹œID + êµ­ê°€ë³„ ì—°ì†ë²ˆí˜¸ ê°œì„  ë²„ì „)\"\"\"\n",
    "    if not batch_results:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        continent, country = get_city_info(city_name)\n",
    "        \n",
    "        # ğŸ†• 1ë‹¨ê³„: DataFrame ìƒì„± (ë„ì‹œIDëŠ” ì´ë¯¸ crawl_single_product_optimizedì—ì„œ ìƒì„±ë¨)\n",
    "        df = pd.DataFrame(batch_results)\n",
    "        \n",
    "        # ë„ì‹œID ì¡´ì¬ í™•ì¸\n",
    "        if 'ë„ì‹œID' not in df.columns or df['ë„ì‹œID'].empty:\n",
    "            # ë„ì‹œIDê°€ ì—†ëŠ” ê²½ìš°ë§Œ ìƒì„± (í•˜ìœ„ í˜¸í™˜ì„±)\n",
    "            city_code = get_city_code(city_name)\n",
    "            df['ë„ì‹œID'] = [f\"{city_code}_{i}\" for i in range(1, len(df) + 1)]\n",
    "            print(f\"âœ… ë„ì‹œID ì»¬ëŸ¼ ì¶”ê°€: {city_code}_1 ~ {city_code}_{len(df)}\")\n",
    "        else:\n",
    "            # ì´ë¯¸ ìˆëŠ” ê²½ìš° í™•ì¸ë§Œ\n",
    "            first_id = df['ë„ì‹œID'].iloc[0]\n",
    "            last_id = df['ë„ì‹œID'].iloc[-1] \n",
    "            print(f\"âœ… ë„ì‹œID í™•ì¸: {first_id} ~ {last_id}\")\n",
    "        \n",
    "        # ë²ˆí˜¸ ì»¬ëŸ¼ë„ ë™ì¼í•˜ê²Œ ì²˜ë¦¬\n",
    "        if 'ë²ˆí˜¸' not in df.columns:\n",
    "            df['ë²ˆí˜¸'] = range(1, len(df) + 1)\n",
    "            print(f\"âœ… ë²ˆí˜¸ ì»¬ëŸ¼ ì¶”ê°€: 1 ~ {len(df)}\")\n",
    "        \n",
    "        if city_name in [\"ë§ˆì¹´ì˜¤\", \"í™ì½©\", \"ì‹±ê°€í¬ë¥´\"]:\n",
    "            # ë„ì‹œêµ­ê°€: ëŒ€ë¥™ í´ë” ë°”ë¡œ ì•„ë˜ì— ì €ì¥\n",
    "            data_dir = os.path.join(\"data\", continent)\n",
    "            os.makedirs(data_dir, exist_ok=True)\n",
    "            \n",
    "            city_csv = os.path.join(data_dir, f\"myrealtrip_{city_name}_products.csv\")\n",
    "            \n",
    "            # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ì— ë”°ë¼ í—¤ë” ì„¤ì •\n",
    "            if os.path.exists(city_csv):\n",
    "                city_success = safe_csv_write(city_csv, df, mode='a', header=False)\n",
    "            else:\n",
    "                city_success = safe_csv_write(city_csv, df, mode='w', header=True)\n",
    "            \n",
    "            if city_success:\n",
    "                print(f\"âœ… ë„ì‹œêµ­ê°€ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {city_csv}\")\n",
    "                return {\n",
    "                    \"city_csv\": city_csv,\n",
    "                    \"country_csv\": \"ë„ì‹œêµ­ê°€ë¼ì„œ ë¶ˆí•„ìš”\",\n",
    "                    \"data_count\": len(batch_results)\n",
    "                }\n",
    "            else:\n",
    "                print(f\"âŒ ë„ì‹œêµ­ê°€ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨\")\n",
    "                return None\n",
    "\n",
    "        data_dir = os.path.join(\"data\", continent, country, city_name)\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "        # 1. ë„ì‹œë³„ CSV (ê¸°ì¡´ ë¡œì§ + ë„ì‹œID) + ì¤‘ë³µ ë°©ì§€ ê°•í™”\n",
    "        city_csv = os.path.join(data_dir, f\"myrealtrip_{city_name}_products.csv\")\n",
    "        if os.path.exists(city_csv):\n",
    "            # ğŸ”§ ìˆ˜ì •: ê¸°ì¡´ CSVì™€ ì¤‘ë³µ ì²´í¬ í›„ ì¶”ê°€\n",
    "            existing_df = pd.read_csv(city_csv, encoding='utf-8-sig')\n",
    "            existing_urls = set(existing_df['URL'].dropna())\n",
    "\n",
    "            # ìƒˆë¡œìš´ ë°ì´í„° ì¤‘ ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ê²ƒë§Œ í•„í„°ë§\n",
    "            new_df_filtered = df[~df['URL'].isin(existing_urls)]\n",
    "\n",
    "            if len(new_df_filtered) > 0:\n",
    "                city_success = safe_csv_write(city_csv, new_df_filtered, mode='a', header=False)\n",
    "                print(f\"âœ… ì¤‘ë³µ ì œê±° í›„ {len(new_df_filtered)}ê°œ ì¶”ê°€ ì €ì¥\")\n",
    "            else:\n",
    "                print(f\"âš ï¸ ëª¨ë“  ë°ì´í„°ê°€ ì¤‘ë³µìœ¼ë¡œ ì €ì¥ ìƒëµ\")\n",
    "                city_success = True\n",
    "        else:\n",
    "            city_success = safe_csv_write(city_csv, df, mode='w', header=True)\n",
    "\n",
    "        # ğŸ†• 2ë‹¨ê³„: êµ­ê°€ë³„ CSV ì—°ì† ë²ˆí˜¸ ì²˜ë¦¬\n",
    "        country_dir = os.path.join(\"data\", continent, country)\n",
    "        os.makedirs(country_dir, exist_ok=True)\n",
    "        country_csv = os.path.join(country_dir, f\"{country}_myrealtrip_products_all.csv\")\n",
    "        \n",
    "        # êµ­ê°€ë³„ CSVë¥¼ ìœ„í•œ DataFrame ë³µì‚¬ ë° ë²ˆí˜¸ ì¬í• ë‹¹\n",
    "        country_df = df.copy()\n",
    "        \n",
    "        if os.path.exists(country_csv):\n",
    "            # ê¸°ì¡´ íŒŒì¼ì—ì„œ ë§ˆì§€ë§‰ ë²ˆí˜¸ í™•ì¸ í›„ ì—°ì† ë²ˆí˜¸ í• ë‹¹\n",
    "            existing_df = pd.read_csv(country_csv, encoding='utf-8-sig')\n",
    "            if not existing_df.empty and 'ë²ˆí˜¸' in existing_df.columns:\n",
    "                last_number = existing_df['ë²ˆí˜¸'].max()\n",
    "                country_df['ë²ˆí˜¸'] = list(range(int(last_number) + 1, int(last_number) + 1 + len(country_df)))\n",
    "                print(f\"ğŸ”— êµ­ê°€ë³„ ì—°ì†ë²ˆí˜¸: {last_number + 1} ~ {last_number + len(country_df)}\")\n",
    "            country_success = safe_csv_write(country_csv, country_df, mode='a', header=False)\n",
    "        else:\n",
    "            # ìƒˆ íŒŒì¼ì´ë©´ 1ë¶€í„° ì‹œì‘\n",
    "            country_df['ë²ˆí˜¸'] = range(1, len(country_df) + 1)\n",
    "            print(f\"ğŸ†• êµ­ê°€ë³„ ì‹ ê·œíŒŒì¼: 1 ~ {len(country_df)}\")\n",
    "            country_success = safe_csv_write(country_csv, country_df, mode='w', header=True)\n",
    "\n",
    "        if city_success and country_success:\n",
    "            print(f\"âœ… ë°°ì¹˜ ë°ì´í„° ì €ì¥ ì™„ë£Œ:\")\n",
    "            print(f\"   ğŸ“ ë„ì‹œë³„: {city_csv}\")\n",
    "            print(f\"   ğŸ“ êµ­ê°€ë³„: {country_csv}\")\n",
    "            print(f\"   ğŸ†” ë„ì‹œID íŒ¨í„´: {city_code}_X\")\n",
    "            print(f\"   ğŸ”¢ êµ­ê°€ë³„ ë²ˆí˜¸: ì—°ì† ì²˜ë¦¬ë¨\")\n",
    "            \n",
    "            return {\n",
    "                \"city_csv\": city_csv,\n",
    "                \"country_csv\": country_csv,\n",
    "                \"data_count\": len(batch_results),\n",
    "                \"city_id_pattern\": f\"{city_code}_X\",\n",
    "                \"country_numbering\": \"ì—°ì†\"\n",
    "            }\n",
    "        else:\n",
    "            print(f\"âš ï¸ ì¼ë¶€ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨ (ë„ì‹œ:{city_success}, êµ­ê°€:{country_success})\")\n",
    "            return {\n",
    "                \"city_csv\": city_csv if city_success else \"ì €ì¥ì‹¤íŒ¨\",\n",
    "                \"country_csv\": country_csv if country_success else \"ì €ì¥ì‹¤íŒ¨\",\n",
    "                \"data_count\": len(batch_results)\n",
    "            }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë°°ì¹˜ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_rating(driver):\n",
    "    \"\"\"í‰ì  ì •ë³´ ìˆ˜ì§‘ (ê¸°ì¡´ í•¨ìˆ˜ ìœ ì§€)\"\"\"\n",
    "    rating_selectors = [\n",
    "        (By.CSS_SELECTOR, \".rating\"),\n",
    "        (By.CSS_SELECTOR, \"[class*='rating']\"),\n",
    "        (By.XPATH, \"//span[contains(@class, 'rating')]\"),\n",
    "        (By.XPATH, \"/html/body/div[1]/main/div[1]/section/div[1]/span/span[2]\")\n",
    "    ]\n",
    "\n",
    "    for selector_type, selector_value in rating_selectors:\n",
    "        try:\n",
    "            rating_element = WebDriverWait(driver, CONFIG[\"WAIT_TIMEOUT\"]).until(\n",
    "                EC.presence_of_element_located((selector_type, selector_value))\n",
    "            )\n",
    "            found_rating = rating_element.text\n",
    "            time.sleep(random.uniform(2, 4))\n",
    "            return found_rating\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "    \n",
    "    return \"ì •ë³´ ì—†ìŒ\"\n",
    "\n",
    "def get_review_count(driver):\n",
    "    \"\"\"ë¦¬ë·° ìˆ˜ ì •ë³´ ìˆ˜ì§‘\"\"\"\n",
    "    print(f\"  ğŸ“ ë¦¬ë·° ìˆ˜ ì •ë³´ ì°¾ëŠ” ì¤‘...\")\n",
    "    review_count_selectors = [\n",
    "        (By.XPATH, \"//span[contains(text(), 'ë¦¬ë·°')]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'review')]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'í›„ê¸°')]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'ê°œ')]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'ê±´')]\"),\n",
    "    ]\n",
    "\n",
    "    for selector_type, selector_value in review_count_selectors:\n",
    "        try:\n",
    "            review_element = WebDriverWait(driver, 3).until(\n",
    "                EC.presence_of_element_located((selector_type, selector_value))\n",
    "            )\n",
    "            review_text = review_element.text.strip()\n",
    "            \n",
    "            review_keywords = ['ë¦¬ë·°', 'í›„ê¸°', 'review', 'ê°œ', 'ê±´']\n",
    "            has_number = any(char.isdigit() for char in review_text)\n",
    "            has_keyword = any(keyword in review_text.lower() for keyword in review_keywords)\n",
    "            \n",
    "            if has_number and has_keyword and len(review_text) < 50:\n",
    "                print(f\"  âœ… ë¦¬ë·° ìˆ˜ ì •ë³´ ë°œê²¬: {review_text}\")\n",
    "                return review_text\n",
    "                \n",
    "        except TimeoutException:\n",
    "            continue\n",
    "\n",
    "    print(f\"  â„¹ï¸ ë¦¬ë·° ìˆ˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    return \"\"\n",
    "\n",
    "def get_language(driver):\n",
    "    \"\"\"ì–¸ì–´ ì •ë³´ ìˆ˜ì§‘ - ìˆ˜ì •ëœ ë²„ì „ (í›„ê¸° ë‚´ìš© ì œì™¸)\"\"\"\n",
    "    print(f\"  ğŸŒ ì–¸ì–´ ì •ë³´ ì°¾ëŠ” ì¤‘...\")\n",
    "    \n",
    "    # ì–¸ì–´ ì •ë³´ê°€ ìˆì„ ê°€ëŠ¥ì„±ì´ ë†’ì€ ì…€ë ‰í„°ë“¤\n",
    "    language_selectors = [\n",
    "        # ì–¸ì–´ ì„¹ì…˜ ì§ì ‘ íƒ€ê²ŸíŒ…\n",
    "        (By.XPATH, \"//dt[contains(text(), 'ì–¸ì–´')]/following-sibling::dd\"),\n",
    "        (By.XPATH, \"//span[contains(@class, 'language')]\"),\n",
    "        (By.XPATH, \"//div[contains(@class, 'language')]//span\"),\n",
    "        # ì§§ì€ ì–¸ì–´ í…ìŠ¤íŠ¸ë§Œ (í›„ê¸° ì œì™¸)\n",
    "        (By.XPATH, \"//span[contains(text(), 'í•œêµ­ì–´') and string-length(text()) < 20]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'ì˜ì–´') and string-length(text()) < 20]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'ì¤‘êµ­ì–´') and string-length(text()) < 20]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'ì¼ë³¸ì–´') and string-length(text()) < 20]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'Korean') and string-length(text()) < 20]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'English') and string-length(text()) < 20]\"),\n",
    "        # ì–¸ì–´ ì•„ì´ì½˜ ê·¼ì²˜ì˜ í…ìŠ¤íŠ¸\n",
    "        (By.XPATH, \"//i[contains(@class, 'language')]/following-sibling::span\"),\n",
    "    ]\n",
    "\n",
    "    for selector_type, selector_value in language_selectors:\n",
    "        try:\n",
    "            language_elements = driver.find_elements(selector_type, selector_value)\n",
    "            \n",
    "            for language_element in language_elements:\n",
    "                language_text = language_element.text.strip()\n",
    "                \n",
    "                if not language_text:\n",
    "                    continue\n",
    "                \n",
    "                # ğŸ”¥ ê°•ë ¥í•œ í•„í„°ë§: í›„ê¸°ë‚˜ ê¸´ í…ìŠ¤íŠ¸ ì œì™¸\n",
    "                # ê¸¸ì´ ì œí•œ (ì–¸ì–´ ì •ë³´ëŠ” ë³´í†µ ì§§ìŒ)\n",
    "                if len(language_text) > 50:\n",
    "                    continue\n",
    "                \n",
    "                # í›„ê¸° ê´€ë ¨ í‚¤ì›Œë“œ ì œì™¸\n",
    "                review_keywords = [\n",
    "                    'í›„ê¸°', 'ë¦¬ë·°', 'í‰ê°€', 'ë³„ì ', 'ì¶”ì²œ', 'ë§Œì¡±',\n",
    "                    'ì—¬í–‰', 'íˆ¬ì–´', 'ê²½í—˜', 'ì¢‹ì•˜', 'ë‚˜ë¹´', 'ìµœê³ ',\n",
    "                    'ë‹¤ìŒì—', 'ë˜', 'ì¬ë°©ë¬¸', 'ì¹œì ˆ', 'ì„œë¹„ìŠ¤',\n",
    "                    'ê°€ê²©', 'ì‹œê°„', 'ì¼ì •', 'ì½”ìŠ¤', 'ê°€ì´ë“œ',\n",
    "                    'ì˜ˆì•½', 'ì‹ ì²­', 'ë¬¸ì˜', 'í™•ì¸', 'ì·¨ì†Œ'\n",
    "                ]\n",
    "                \n",
    "                if any(keyword in language_text for keyword in review_keywords):\n",
    "                    continue\n",
    "                \n",
    "                # ì–¸ì–´ í‚¤ì›Œë“œ í™•ì¸\n",
    "                language_keywords = [\n",
    "                    'ì–¸ì–´', 'í•œêµ­ì–´', 'ì˜ì–´', 'ì¤‘êµ­ì–´', 'ì¼ë³¸ì–´', \n",
    "                    'Korean', 'English', 'Chinese', 'Japanese',\n",
    "                    'ê°€ëŠ¥', 'ì§€ì›', 'ì œê³µ'\n",
    "                ]\n",
    "                \n",
    "                if any(keyword in language_text for keyword in language_keywords):\n",
    "                    print(f\"    âœ… ì–¸ì–´ ì •ë³´ ë°œê²¬: {language_text}\")\n",
    "                    return language_text\n",
    "                    \n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    print(f\"    â„¹ï¸ ì–¸ì–´ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    return \"\"\n",
    "\n",
    "print(\"âœ… ê·¸ë£¹ 2 ì™„ë£Œ: ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ë°ì´í„° ì €ì¥ í•¨ìˆ˜ë“¤ ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4db7ff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ğŸ”„ ê·¸ë£¹ 3: ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶• (ë°ì´í„° ì—°ì†ì„± í™•ë³´) - url_history êµ¬ì¡° ì ìš©\n",
    "# - URL ì¬ì‚¬ìš© ë°©ì§€, ì„¸ì…˜ ì•ˆì „ì„±, í¬ë¡¤ë§ ìƒíƒœ ê´€ë¦¬, url history í´ë”ì™€ íŒŒì¼ ìƒì„±\n",
    "# =============================================================================\n",
    "\n",
    "# ğŸ”§ í•„ìˆ˜ Import ë¬¸ë“¤ (ìƒë‹¨ì— ëª¨ë‘ ì¶”ê°€)\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def ensure_config_directory():\n",
    "    \"\"\"config ë””ë ‰í† ë¦¬ ì•ˆì •ì„± í™•ë³´\"\"\"\n",
    "    # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ì˜ ì ˆëŒ€ ê²½ë¡œ í™•ë³´\n",
    "    current_dir = os.path.abspath(os.getcwd())\n",
    "    config_dir = os.path.join(current_dir, \"config\")\n",
    "    \n",
    "    # config ë””ë ‰í† ë¦¬ ìƒì„± ì‹œë„\n",
    "    try:\n",
    "        os.makedirs(config_dir, exist_ok=True)\n",
    "        \n",
    "        # ì“°ê¸° ê¶Œí•œ í…ŒìŠ¤íŠ¸\n",
    "        test_file = os.path.join(config_dir, \"write_test.tmp\")\n",
    "        with open(test_file, 'w') as f:\n",
    "            f.write(\"test\")\n",
    "        os.remove(test_file)\n",
    "        \n",
    "        return config_dir\n",
    "        \n",
    "    except (OSError, PermissionError) as e:\n",
    "        # ëŒ€ì²´ ê²½ë¡œ ì‹œë„ (ì„ì‹œ ë””ë ‰í† ë¦¬)\n",
    "        import tempfile\n",
    "        fallback_dir = os.path.join(tempfile.gettempdir(), \"myrealtrip_config\")\n",
    "        os.makedirs(fallback_dir, exist_ok=True)\n",
    "        print(f\"âš ï¸ ê¸°ë³¸ config ë””ë ‰í† ë¦¬ ì ‘ê·¼ ì‹¤íŒ¨, ëŒ€ì²´ ê²½ë¡œ ì‚¬ìš©: {fallback_dir}\")\n",
    "        return fallback_dir\n",
    "\n",
    "def validate_completed_urls(config_dir):\n",
    "    \"\"\"completed_urls.log íŒŒì¼ ìœ íš¨ì„± ê²€ì¦ ë° ì •ë¦¬\"\"\"\n",
    "    urls_file = os.path.join(config_dir, \"completed_urls.log\")\n",
    "    \n",
    "    if not os.path.exists(urls_file):\n",
    "        return set()\n",
    "    \n",
    "    try:\n",
    "        with open(urls_file, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        # URL ì •ë¦¬ ë° ì¤‘ë³µ ì œê±°\n",
    "        valid_urls = set()\n",
    "        for line in lines:\n",
    "            url = line.strip()\n",
    "            if url and url.startswith('http') and '/products/' in url:\n",
    "                valid_urls.add(url)\n",
    "        \n",
    "        # ì •ë¦¬ëœ URLë¡œ íŒŒì¼ ì¬ì‘ì„±\n",
    "        with open(urls_file, 'w', encoding='utf-8') as f:\n",
    "            for url in sorted(valid_urls):\n",
    "                f.write(url + '\\n')\n",
    "        \n",
    "        print(f\"âœ… completed_urls.log ì •ë¦¬ ì™„ë£Œ: {len(valid_urls)}ê°œ ê³ ìœ  URL\")\n",
    "        return valid_urls\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ URL íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {e}\")\n",
    "        return set()\n",
    "\n",
    "def verify_url_recorded(url, config_dir):\n",
    "    \"\"\"íŠ¹ì • URLì´ completed_urls.logì— ê¸°ë¡ë˜ì—ˆëŠ”ì§€ í™•ì¸\"\"\"\n",
    "    urls_file = os.path.join(config_dir, \"completed_urls.log\")\n",
    "    \n",
    "    if not os.path.exists(urls_file):\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        with open(urls_file, 'r', encoding='utf-8') as f:\n",
    "            recorded_urls = set(line.strip() for line in f if line.strip())\n",
    "        return url in recorded_urls\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def safe_url_record(url, config_dir):\n",
    "    \"\"\"URLì„ ì•ˆì „í•˜ê²Œ completed_urls.logì— ê¸°ë¡\"\"\"\n",
    "    urls_file = os.path.join(config_dir, \"completed_urls.log\")\n",
    "    \n",
    "    # ì¤‘ë³µ í™•ì¸\n",
    "    if verify_url_recorded(url, config_dir):\n",
    "        return True  # ì´ë¯¸ ê¸°ë¡ë¨\n",
    "    \n",
    "    try:\n",
    "        with open(urls_file, 'a', encoding='utf-8') as f:\n",
    "            f.write(url + '\\n')\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ URL ê¸°ë¡ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def load_crawler_state():\n",
    "    \"\"\"í¬ë¡¤ë§ ìƒíƒœ ë¡œë“œ (ì ˆëŒ€ ê²½ë¡œ ê¸°ë°˜)\"\"\"\n",
    "    config_dir = ensure_config_directory()\n",
    "    state_file = os.path.join(config_dir, \"crawler_meta.json\")\n",
    "    \n",
    "    # ê¸°ë³¸ ìƒíƒœ\n",
    "    default_state = {\n",
    "        \"total_collected_count\": 0,\n",
    "        \"last_crawled_page\": 1,\n",
    "        \"current_session_start\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"last_updated\": datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    \n",
    "    # ìƒíƒœ íŒŒì¼ ë¡œë“œ\n",
    "    if os.path.exists(state_file):\n",
    "        try:\n",
    "            with open(state_file, 'r', encoding='utf-8') as f:\n",
    "                state = json.load(f)\n",
    "            print(f\"âœ… ìƒíƒœ íŒŒì¼ ë¡œë“œ: {state['total_collected_count']}ê°œ ìˆ˜ì§‘ ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ìƒíƒœ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}, ê¸°ë³¸ê°’ ì‚¬ìš©\")\n",
    "            state = default_state\n",
    "    else:\n",
    "        state = default_state\n",
    "        print(\"ğŸ†• ìƒˆë¡œìš´ í¬ë¡¤ë§ ì„¸ì…˜ ì‹œì‘\")\n",
    "    \n",
    "    # ì™„ë£Œëœ URL ëª©ë¡ ê²€ì¦ ë° ë¡œë“œ\n",
    "    completed_urls = validate_completed_urls(config_dir)\n",
    "    print(f\"âœ… ì™„ë£Œëœ URL {len(completed_urls)}ê°œ ë¡œë“œ\")\n",
    "    \n",
    "    return state, completed_urls\n",
    "\n",
    "def save_crawler_state(state, new_url=None):\n",
    "    \"\"\"í¬ë¡¤ë§ ìƒíƒœ ì €ì¥ (ì ˆëŒ€ ê²½ë¡œ ê¸°ë°˜)\"\"\"\n",
    "    config_dir = ensure_config_directory()\n",
    "    state_file = os.path.join(config_dir, \"crawler_meta.json\")\n",
    "    \n",
    "    # ìƒíƒœ ì—…ë°ì´íŠ¸\n",
    "    state[\"last_updated\"] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    try:\n",
    "        # ìƒíƒœ íŒŒì¼ ì €ì¥\n",
    "        with open(state_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(state, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        # ìƒˆ URLì´ ìˆìœ¼ë©´ ì•ˆì „í•˜ê²Œ ê¸°ë¡\n",
    "        if new_url:\n",
    "            safe_url_record(new_url, config_dir)\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ìƒíƒœ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "def filter_new_urls(all_urls, completed_urls):\n",
    "    \"\"\"ì™„ë£Œë˜ì§€ ì•Šì€ ìƒˆë¡œìš´ URLë§Œ í•„í„°ë§\"\"\"\n",
    "    new_urls = [url for url in all_urls if url not in completed_urls]\n",
    "    \n",
    "    print(f\"ğŸ” URL í•„í„°ë§ ê²°ê³¼:\")\n",
    "    print(f\"   ğŸ“Š ì „ì²´ URL: {len(all_urls)}ê°œ\")\n",
    "    print(f\"   âœ… ì™„ë£Œëœ URL: {len(completed_urls)}ê°œ\")\n",
    "    print(f\"   ğŸ†• ìƒˆë¡œìš´ URL: {len(new_urls)}ê°œ\")\n",
    "    \n",
    "    return new_urls\n",
    "\n",
    "def collect_all_24_urls(driver):\n",
    "    \"\"\"í˜„ì¬ í˜ì´ì§€ì—ì„œ ìµœëŒ€ 24ê°œ ìƒí’ˆ URL ìˆ˜ì§‘\"\"\"\n",
    "    return collect_product_urls_from_page(driver)\n",
    "\n",
    "def collect_product_urls_from_page(driver):\n",
    "    \"\"\"\n",
    "    ğŸ†• [í†µí•© í•¨ìˆ˜] í˜„ì¬ í˜ì´ì§€ì˜ ëª¨ë“  ìƒí’ˆ URLì„ ê°€ì¥ í¬ê´„ì ì¸ ë°©ë²•ìœ¼ë¡œ ìˆ˜ì§‘\n",
    "    - ê¸°ì¡´ collect_all_24_urls, collect_page_urls ë“±ì„ ëŒ€ì²´í•˜ëŠ” ì™„ì „í•œ í†µí•© ì†”ë£¨ì…˜\n",
    "    - ëª¨ë“  ì…€ë ‰í„°ë¥¼ í†µí•©í•˜ì—¬ ëˆ„ë½ ë°©ì§€ ë° ìœ ì§€ë³´ìˆ˜ì„± ê·¹ëŒ€í™”\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“Š [í†µí•©] í˜„ì¬ í˜ì´ì§€ì˜ ëª¨ë“  URL ìˆ˜ì§‘ ì¤‘...\")\n",
    "\n",
    "    # ğŸ”§ ê¸°ì¡´ í•¨ìˆ˜ë“¤ì˜ ëª¨ë“  ì…€ë ‰í„°ë¥¼ í†µí•©í•˜ì—¬ íƒìƒ‰ ë²”ìœ„ ê·¹ëŒ€í™”\n",
    "    all_selectors = [\n",
    "        # Products & Offers (ê¸°ì¡´ collect_all_24_urls ì…€ë ‰í„°)\n",
    "        \"a[href*='/products/']\",\n",
    "        \"a[href*='/offers/']\",\n",
    "        \n",
    "        # Experiences (ê¸°ì¡´ collect_page_urls ì…€ë ‰í„°)\n",
    "        \"a[href*='/experiences/']\",\n",
    "        \"a[href*='/experience/']\",\n",
    "        \n",
    "        # í´ë˜ìŠ¤ ê¸°ë°˜ ì…€ë ‰í„° (ë” ì•ˆì •ì )\n",
    "        \".product-item a\",\n",
    "        \".experience-card a\",\n",
    "        \".product-gallery a\",\n",
    "        \n",
    "        # ì¶”ê°€ ì•ˆì „ì¥ì¹˜ ì…€ë ‰í„°\n",
    "        \"[class*='product'] a[href*='http']\",\n",
    "        \"[class*='experience'] a[href*='http']\",\n",
    "        \"[class*='offer'] a[href*='http']\"\n",
    "    ]\n",
    "\n",
    "    collected_urls = []\n",
    "    \n",
    "    # ğŸ”„ ê° ì…€ë ‰í„°ë³„ë¡œ URL ìˆ˜ì§‘\n",
    "    for selector_index, selector in enumerate(all_selectors):\n",
    "        try:\n",
    "            elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "            \n",
    "            for element in elements:\n",
    "                try:\n",
    "                    url = element.get_attribute('href')\n",
    "                    if url and url.startswith('http'):\n",
    "                        # ğŸ›¡ï¸ ìœ íš¨í•œ ìƒí’ˆ URLì¸ì§€ ê²€ì¦\n",
    "                        if any(pattern in url for pattern in ['/products/', '/offers/', '/experiences/', '/experience/']):\n",
    "                            collected_urls.append(url)\n",
    "                except Exception:\n",
    "                    continue\n",
    "                    \n",
    "        except Exception as e:\n",
    "            # íŠ¹ì • ì…€ë ‰í„° ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰\n",
    "            continue\n",
    "\n",
    "    # ğŸ”§ ì¤‘ë³µ ì œê±° (ìˆœì„œ ë³´ì¥)\n",
    "    seen = set()\n",
    "    unique_urls = []\n",
    "    for url in collected_urls:\n",
    "        if url not in seen:\n",
    "            seen.add(url)\n",
    "            unique_urls.append(url)\n",
    "    \n",
    "    print(f\"âœ… ì´ {len(unique_urls)}ê°œì˜ ê³ ìœ  URL ìˆ˜ì§‘ ì™„ë£Œ!\")\n",
    "\n",
    "    # ğŸ“Š URL íƒ€ì…ë³„ í†µê³„ ì œê³µ\n",
    "    products_count = sum(1 for url in unique_urls if '/products/' in url)\n",
    "    offers_count = sum(1 for url in unique_urls if '/offers/' in url)\n",
    "    experiences_count = sum(1 for url in unique_urls if '/experiences/' in url or '/experience/' in url)\n",
    "    \n",
    "    print(f\"   ğŸ›ï¸ Products: {products_count}ê°œ\")\n",
    "    print(f\"   ğŸ·ï¸ Offers: {offers_count}ê°œ\")\n",
    "    print(f\"   ğŸ¯ Experiences: {experiences_count}ê°œ\")\n",
    "\n",
    "    return unique_urls\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ”— URL ìºì‹œ ì‹œìŠ¤í…œ í™•ì¥ (ê·¸ë£¹ 3 í†µí•©)\n",
    "# =============================================================================\n",
    "\n",
    "def save_collected_urls(city_name, urls_list, sync_mode=True):\n",
    "    \"\"\"ìˆ˜ì§‘ëœ URLì„ íŒŒì¼ë¡œ ì €ì¥ (ê°œì„ ëœ ë²„ì „)\"\"\"\n",
    "    try:\n",
    "        os.makedirs(\"url_cache\", exist_ok=True)\n",
    "        cache_file = os.path.join(\"url_cache\", f\"{city_name}_collected.json\")\n",
    "        # ğŸ†• ê¸°ì¡´ ìºì‹œì™€ ë³‘í•©\n",
    "        existing_urls = []\n",
    "        if sync_mode and os.path.exists(cache_file):\n",
    "            try:\n",
    "                with open(cache_file, 'r', encoding='utf-8') as f:\n",
    "                    existing_data = json.load(f)\n",
    "                existing_urls = existing_data.get('urls', [])\n",
    "            except:\n",
    "                pass\n",
    "        # ì¤‘ë³µ ì œê±° í›„ ë³‘í•©\n",
    "        combined_urls = list(set(existing_urls + urls_list))\n",
    "        cache_data = {\n",
    "            \"city\": city_name,\n",
    "            \"urls\": combined_urls,\n",
    "            \"collected_time\": datetime.now().isoformat(),\n",
    "            \"total_count\": len(combined_urls),\n",
    "            \"session_urls\": len(urls_list),\n",
    "            \"sync_mode\": sync_mode\n",
    "        }\n",
    "        with open(cache_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(cache_data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"âœ… URL ìºì‹œ ì €ì¥: {len(combined_urls)}ê°œ (ì„¸ì…˜: +{len(urls_list)}ê°œ)\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ URL ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "def load_collected_urls(city_name):\n",
    "    \"\"\"\n",
    "    ì €ì¥ëœ URLì„ íŒŒì¼ì—ì„œ ë¡œë“œ\n",
    "    Args:\n",
    "        city_name (str): ë„ì‹œ ì´ë¦„\n",
    "    Returns:\n",
    "        list or None: URL ëª©ë¡ (ì‹¤íŒ¨ì‹œ None)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ìºì‹œ íŒŒì¼ ê²½ë¡œ ìƒì„±\n",
    "        cache_file = os.path.join(\"url_cache\", f\"{city_name}_collected.json\")\n",
    "        \n",
    "        # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "        if not os.path.exists(cache_file):\n",
    "            print(f\"â„¹ï¸ URL ìºì‹œ ì—†ìŒ: {cache_file}\")\n",
    "            return None\n",
    "        \n",
    "        # JSON íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ\n",
    "        with open(cache_file, 'r', encoding='utf-8') as f:\n",
    "            cache_data = json.load(f)\n",
    "        \n",
    "        # URL ëª©ë¡ ì¶”ì¶œ\n",
    "        urls = cache_data.get('urls', [])\n",
    "        collected_time = cache_data.get('collected_time', '')\n",
    "        \n",
    "        print(f\"âœ… URL ìºì‹œ ë¡œë“œ: {len(urls)}ê°œ ({collected_time})\")\n",
    "        return urls\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ URL ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "    \n",
    "def get_crawled_urls_from_csv(city_name):\n",
    "    \"\"\"CSV íŒŒì¼ì—ì„œ ì´ë¯¸ í¬ë¡¤ë§ëœ URL ëª©ë¡ ì¶”ì¶œ (ë²ˆí˜¸ ì‹œìŠ¤í…œì²˜ëŸ¼ ì•ˆì •ì )\"\"\"\n",
    "    try:\n",
    "        continent, country = get_city_info(city_name)\n",
    "        \n",
    "        # ë„ì‹œêµ­ê°€ íŠ¹ë³„ ì²˜ë¦¬\n",
    "        if city_name in [\"ë§ˆì¹´ì˜¤\", \"í™ì½©\", \"ì‹±ê°€í¬ë¥´\"]:\n",
    "            csv_path = os.path.join(\"data\", continent, f\"myrealtrip_{city_name}_products.csv\")\n",
    "        else:\n",
    "            csv_path = os.path.join(\"data\", continent, country, city_name,\n",
    "                                  f\"myrealtrip_{city_name}_products.csv\")\n",
    "        \n",
    "        if not os.path.exists(csv_path):\n",
    "            print(f\"ğŸ“„ CSV íŒŒì¼ ì—†ìŒ - ìƒˆë¡œìš´ í¬ë¡¤ë§ ì‹œì‘\")\n",
    "            return set()\n",
    "        \n",
    "        # URL ì»¬ëŸ¼ë§Œ ì½ê¸° (ì„±ëŠ¥ ìµœì í™”) + ì¤‘ë³µ ì œê±° ê°•í™”\n",
    "        df = pd.read_csv(csv_path, encoding='utf-8-sig', usecols=['URL'])\n",
    "        # ğŸ”§ ìˆ˜ì •: ì¤‘ë³µ ì œê±°ë¥¼ ë” í™•ì‹¤í•˜ê²Œ\n",
    "        unique_urls = df['URL'].dropna().drop_duplicates().tolist()\n",
    "        crawled_urls = set(unique_urls)\n",
    "        print(f\"âœ… CSVì—ì„œ í¬ë¡¤ë§ ì™„ë£Œ URL {len(crawled_urls)}ê°œ ë¡œë“œ (ì¤‘ë³µ ì œê±°ë¨)\")\n",
    "        return crawled_urls\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ CSV URL ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return set()\n",
    "\n",
    "def filter_new_urls_from_csv(all_urls, city_name):\n",
    "    \"\"\"CSV ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ URLë§Œ í•„í„°ë§\"\"\"\n",
    "    crawled_urls = get_crawled_urls_from_csv(city_name)\n",
    "    new_urls = [url for url in all_urls if url not in crawled_urls]\n",
    "    \n",
    "    print(f\"ğŸ” CSV ê¸°ë°˜ URL í•„í„°ë§:\")\n",
    "    print(f\"   ğŸ“Š ì „ì²´ URL: {len(all_urls)}ê°œ\")\n",
    "    print(f\"   âœ… ì´ë¯¸ ì™„ë£Œ: {len(crawled_urls)}ê°œ\")\n",
    "    print(f\"   ğŸ†• ìƒˆë¡œìš´ URL: {len(new_urls)}ê°œ\")\n",
    "    \n",
    "    return new_urls\n",
    "\n",
    "def collect_urls_with_csv_safety(driver, city_name):\n",
    "    \"\"\"CSV ê¸°ë°˜ ì„¸ì…˜ ì•ˆì „ URL ìˆ˜ì§‘ (JSON ìºì‹œ ëŒ€ì‹ )\"\"\"\n",
    "    print(f\"ğŸ“Š CSV ê¸°ë°˜ ì•ˆì „ URL ìˆ˜ì§‘ ì‹œì‘...\")\n",
    "    \n",
    "    # í˜„ì¬ í˜ì´ì§€ì˜ ëª¨ë“  URL ìˆ˜ì§‘\n",
    "    all_urls = collect_product_urls_from_page(driver)\n",
    "    \n",
    "    # CSV ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ URLë§Œ í•„í„°ë§\n",
    "    new_urls = filter_new_urls_from_csv(all_urls, city_name)\n",
    "    \n",
    "    return new_urls\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ”„ Group 3 ì¶”ê°€: ê°„ë‹¨í•œ URL ê´€ë¦¬ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ì½”ë“œ ë’¤ì— ì¶”ê°€)\n",
    "# - ê¸°ì¡´ Group 3ì˜ ë³µì¡í•œ ì‹œìŠ¤í…œì„ ë³´ì™„í•˜ëŠ” ê°„ë‹¨í•œ ìœ í‹¸ë¦¬í‹°\n",
    "# =============================================================================\n",
    "\n",
    "def sync_csv_and_log(city_name):\n",
    "    \"\"\"CSVì™€ completed_urls.log ê°„ë‹¨ ë™ê¸°í™”\"\"\"\n",
    "    print(f\"ğŸ”„ '{city_name}' CSV-Log ë™ê¸°í™” ì¤‘...\")\n",
    "    \n",
    "    try:\n",
    "        # CSV URLs ê°€ì ¸ì˜¤ê¸°\n",
    "        csv_urls = get_crawled_urls_from_csv(city_name)\n",
    "        \n",
    "        # completed_urls.log URLs ê°€ì ¸ì˜¤ê¸°\n",
    "        config_dir = ensure_config_directory()  # ê¸°ì¡´ Group 3 í•¨ìˆ˜ í™œìš©\n",
    "        log_urls = validate_completed_urls(config_dir)  # ê¸°ì¡´ Group 3 í•¨ìˆ˜ í™œìš©\n",
    "        \n",
    "        # CSVì— ìˆì§€ë§Œ logì— ì—†ëŠ” URLë“¤ì„ logì— ì¶”ê°€\n",
    "        missing_in_log = csv_urls - log_urls\n",
    "        synced_count = 0\n",
    "        \n",
    "        for url in missing_in_log:\n",
    "            if safe_url_record(url, config_dir):  # ê¸°ì¡´ Group 3 í•¨ìˆ˜ í™œìš©\n",
    "                synced_count += 1\n",
    "        \n",
    "        print(f\"âœ… ë™ê¸°í™” ì™„ë£Œ: {synced_count}ê°œ URL ì¶”ê°€\")\n",
    "        print(f\"ğŸ“Š CSV: {len(csv_urls)}ê°œ, Log: {len(log_urls) + synced_count}ê°œ\")\n",
    "        \n",
    "        return synced_count\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë™ê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "        return 0\n",
    "\n",
    "def check_system_consistency(city_name):\n",
    "    \"\"\"ê°„ë‹¨í•œ ì¼ê´€ì„± ì²´í¬\"\"\"\n",
    "    try:\n",
    "        # ê¸°ì¡´ Group 3 í•¨ìˆ˜ë“¤ í™œìš©\n",
    "        csv_urls = get_crawled_urls_from_csv(city_name)\n",
    "        config_dir = ensure_config_directory()\n",
    "        log_urls = validate_completed_urls(config_dir)\n",
    "        \n",
    "        # ì¼ê´€ì„± ê³„ì‚°\n",
    "        if len(csv_urls | log_urls) == 0:\n",
    "            consistency_rate = 100.0  # ë‘˜ ë‹¤ ë¹„ì–´ìˆìœ¼ë©´ 100% ì¼ê´€ì„±\n",
    "        else:\n",
    "            consistency_rate = len(csv_urls & log_urls) / len(csv_urls | log_urls) * 100\n",
    "        \n",
    "        # ê²°ê³¼ ì¶œë ¥\n",
    "        print(f\"ğŸ“Š '{city_name}' ì¼ê´€ì„±: {consistency_rate:.1f}%\")\n",
    "        print(f\"   CSV: {len(csv_urls)}ê°œ, Log: {len(log_urls)}ê°œ\")\n",
    "        print(f\"   ê³µí†µ: {len(csv_urls & log_urls)}ê°œ\")\n",
    "        \n",
    "        # ë¬¸ì œê°€ ìˆìœ¼ë©´ ê¶Œì¥ì‚¬í•­ ì¶œë ¥\n",
    "        if consistency_rate < 90:\n",
    "            print(f\"âš ï¸ ì¼ê´€ì„± ë‚®ìŒ - sync_csv_and_log('{city_name}') ì‹¤í–‰ ê¶Œì¥\")\n",
    "        \n",
    "        return consistency_rate > 90\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì¼ê´€ì„± ì²´í¬ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "def quick_cleanup_urls(city_name):\n",
    "    \"\"\"ê°„ë‹¨í•œ URL ì •ë¦¬\"\"\"\n",
    "    try:\n",
    "        config_dir = ensure_config_directory()  # ê¸°ì¡´ Group 3 í•¨ìˆ˜ í™œìš©\n",
    "        log_path = os.path.join(config_dir, \"completed_urls.log\")\n",
    "        \n",
    "        if not os.path.exists(log_path):\n",
    "            print(f\"â„¹ï¸ '{city_name}' ë¡œê·¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤\")\n",
    "            return 0\n",
    "        \n",
    "        # íŒŒì¼ ì½ê¸°\n",
    "        with open(log_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        print(f\"ğŸ” ì •ë¦¬ ì „: {len(lines)}ì¤„\")\n",
    "        \n",
    "        # ìœ íš¨í•œ URLë§Œ í•„í„°ë§ ë° ì¤‘ë³µ ì œê±°\n",
    "        valid_urls = set()\n",
    "        for line in lines:\n",
    "            url = line.strip()\n",
    "            if url and url.startswith('http') and ('/products/' in url or '/offers/' in url):\n",
    "                valid_urls.add(url)\n",
    "        \n",
    "        # ì •ë ¬ëœ ìƒíƒœë¡œ ì¬ì‘ì„±\n",
    "        with open(log_path, 'w', encoding='utf-8') as f:\n",
    "            for url in sorted(valid_urls):\n",
    "                f.write(f\"{url}\\n\")\n",
    "        \n",
    "        print(f\"âœ… '{city_name}' URL ì •ë¦¬ ì™„ë£Œ: {len(valid_urls)}ê°œ\")\n",
    "        print(f\"ğŸ§¹ ì œê±°ëœ í•­ëª©: {len(lines) - len(valid_urls)}ê°œ\")\n",
    "        \n",
    "        return len(valid_urls)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ URL ì •ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "        return 0\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ¯ ê°„í¸ í†µí•© í•¨ìˆ˜ (3ê°œ í•¨ìˆ˜ë¥¼ í•œ ë²ˆì— ì‹¤í–‰)\n",
    "# =============================================================================\n",
    "\n",
    "def maintain_url_system(city_name, auto_fix=True):\n",
    "    \"\"\"\n",
    "    URL ì‹œìŠ¤í…œ ê°„í¸ ìœ ì§€ë³´ìˆ˜ (3ë‹¨ê³„ í†µí•©)\n",
    "    1. ì¼ê´€ì„± ì²´í¬ â†’ 2. ë™ê¸°í™” â†’ 3. ì •ë¦¬\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ”§ '{city_name}' URL ì‹œìŠ¤í…œ ìœ ì§€ë³´ìˆ˜ ì‹œì‘...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    results = {\n",
    "        'consistency_check': False,\n",
    "        'sync_count': 0,\n",
    "        'cleanup_count': 0,\n",
    "        'status': 'failed'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # 1ë‹¨ê³„: ì¼ê´€ì„± ì²´í¬\n",
    "        print(\"1ï¸âƒ£ ì¼ê´€ì„± ì²´í¬...\")\n",
    "        is_consistent = check_system_consistency(city_name)\n",
    "        results['consistency_check'] = is_consistent\n",
    "        \n",
    "        # 2ë‹¨ê³„: í•„ìš”ì‹œ ë™ê¸°í™”\n",
    "        if not is_consistent and auto_fix:\n",
    "            print(\"\\n2ï¸âƒ£ ìë™ ë™ê¸°í™”...\")\n",
    "            sync_count = sync_csv_and_log(city_name)\n",
    "            results['sync_count'] = sync_count\n",
    "        elif not auto_fix:\n",
    "            print(\"\\nâ¸ï¸ ìë™ ìˆ˜ì • ë¹„í™œì„±í™” - ìˆ˜ë™ ì‹¤í–‰ í•„ìš”\")\n",
    "        else:\n",
    "            print(\"\\nâœ… ë™ê¸°í™” ë¶ˆí•„ìš”\")\n",
    "        \n",
    "        # 3ë‹¨ê³„: URL ì •ë¦¬\n",
    "        print(\"\\n3ï¸âƒ£ URL ì •ë¦¬...\")\n",
    "        cleanup_count = quick_cleanup_urls(city_name)\n",
    "        results['cleanup_count'] = cleanup_count\n",
    "        \n",
    "        # ìµœì¢… ìƒíƒœ í™•ì¸\n",
    "        print(\"\\nğŸ” ìµœì¢… ì¼ê´€ì„± ì¬í™•ì¸...\")\n",
    "        final_consistency = check_system_consistency(city_name)\n",
    "        \n",
    "        if final_consistency:\n",
    "            results['status'] = 'success'\n",
    "            print(\"\\nğŸ‰ URL ì‹œìŠ¤í…œ ìœ ì§€ë³´ìˆ˜ ì™„ë£Œ!\")\n",
    "        else:\n",
    "            results['status'] = 'partial'\n",
    "            print(\"\\nâš ï¸ ì¼ë¶€ ë¬¸ì œê°€ ë‚¨ì•„ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ ìœ ì§€ë³´ìˆ˜ ì‹¤íŒ¨: {e}\")\n",
    "        results['error'] = str(e)\n",
    "        return results\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ”„ ì‚¼ì¤‘ ë™ê¸°í™” ì‹œìŠ¤í…œ (URL ìºì‹œ ê°œì„ )\n",
    "# =============================================================================    \n",
    "def triple_sync_url_system(city_name):\n",
    "    \"\"\"ìˆ˜ì •ëœ ì‚¼ì¤‘ ë™ê¸°í™”: ì™„ë£Œëœ URLì€ ìºì‹œí•˜ì§€ ì•ŠìŒ\"\"\"\n",
    "    print(f\"ğŸ”„ '{city_name}' ì‚¼ì¤‘ ë™ê¸°í™” ì‹œì‘...\")\n",
    "    try:\n",
    "        # 1. ê° ì†ŒìŠ¤ì—ì„œ URL ìˆ˜ì§‘\n",
    "        csv_urls = get_crawled_urls_from_csv(city_name)\n",
    "        config_dir = ensure_config_directory()\n",
    "        log_urls = validate_completed_urls(config_dir)\n",
    "        print(f\"ğŸ“Š ë™ê¸°í™” ì „: CSV({len(csv_urls)}) Log({len(log_urls)}) Cache(X)\")\n",
    "        \n",
    "        # 2. CSVë¥¼ ë§ˆìŠ¤í„°ë¡œ Log ë™ê¸°í™”\n",
    "        missing_in_log = csv_urls - log_urls\n",
    "        for url in missing_in_log:\n",
    "            safe_url_record(url, config_dir)\n",
    "        \n",
    "        # ğŸ†• 3. URL ìºì‹œëŠ” í•­ìƒ ì‚­ì œ (ì™„ë£Œëœ URL ìºì‹œ ë°©ì§€)\n",
    "        cache_file = os.path.join(\"url_cache\", f\"{city_name}_collected.json\")\n",
    "        if os.path.exists(cache_file):\n",
    "            os.remove(cache_file)\n",
    "            print(f\"ğŸ—‘ï¸ URL ìºì‹œ ì •ë¦¬: ìƒˆë¡œìš´ ìˆ˜ì§‘ì„ ìœ„í•´ ì‚­ì œ\")\n",
    "        \n",
    "        print(f\"âœ… ì‚¼ì¤‘ ë™ê¸°í™” ì™„ë£Œ! Log ì¶”ê°€: {len(missing_in_log)}ê°œ\")\n",
    "        print(f\"ğŸ’¡ ë‹¤ìŒ ì„¸ì…˜ì€ ìƒˆë¡œìš´ URL ìˆ˜ì§‘ë¶€í„° ì‹œì‘ë©ë‹ˆë‹¤\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì‚¼ì¤‘ ë™ê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "        return False   \n",
    "\n",
    "# =============================================================================\n",
    "# ğŸš€ ì‚¬ìš© ì˜ˆì‹œ ë° ë„ì›€ë§\n",
    "# =============================================================================\n",
    "\n",
    "def show_url_management_help():\n",
    "    \"\"\"URL ê´€ë¦¬ í•¨ìˆ˜ ì‚¬ìš©ë²• ë„ì›€ë§\"\"\"\n",
    "    print(\"ğŸ¯ ê°„ë‹¨í•œ URL ê´€ë¦¬ í•¨ìˆ˜ ì‚¬ìš©ë²•\")\n",
    "    print(\"=\" * 40)\n",
    "    print()\n",
    "    print(\"ğŸ“‹ ê°œë³„ í•¨ìˆ˜:\")\n",
    "    print(\"   sync_csv_and_log('í›„ì¿ ì˜¤ì¹´')        # CSV â†’ Log ë™ê¸°í™”\")\n",
    "    print(\"   check_system_consistency('í›„ì¿ ì˜¤ì¹´')  # ì¼ê´€ì„± ì²´í¬\")\n",
    "    print(\"   quick_cleanup_urls('í›„ì¿ ì˜¤ì¹´')       # URL ì •ë¦¬\")\n",
    "    print()\n",
    "    print(\"ğŸ¯ í†µí•© í•¨ìˆ˜ (ê¶Œì¥):\")\n",
    "    print(\"   maintain_url_system('í›„ì¿ ì˜¤ì¹´')      # 3ë‹¨ê³„ í•œë²ˆì—\")\n",
    "    print(\"   maintain_url_system('í›„ì¿ ì˜¤ì¹´', auto_fix=False)  # ì²´í¬ë§Œ\")\n",
    "    print()\n",
    "    print(\"ğŸ’¡ ì–¸ì œ ì‚¬ìš©í•˜ë‚˜ìš”?\")\n",
    "    print(\"   - í¬ë¡¤ë§ ì „/í›„ ì‹œìŠ¤í…œ ì ê²€\")\n",
    "    print(\"   - CSVì™€ Log íŒŒì¼ ë¶ˆì¼ì¹˜ ì˜ì‹¬ì‹œ\")  \n",
    "    print(\"   - completed_urls.log íŒŒì¼ì´ ë„ˆë¬´ í´ ë•Œ\")\n",
    "    print(\"   - ë‹¤ë¥¸ ë„ì‹œë¡œ ì „í™˜í•˜ê¸° ì „\")\n",
    "    print()\n",
    "    print(\"âš¡ ë¹ ë¥¸ ì ê²€:\")\n",
    "    print(\"   if not check_system_consistency('ë„ì‹œëª…'):\")\n",
    "    print(\"       maintain_url_system('ë„ì‹œëª…')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cb292a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ ê·¸ë£¹ 4: í™•ì¥ì„± ê°œì„  ì‹œìŠ¤í…œ ì´ˆê¸°í™”...\n",
      "âš™ï¸ CONFIG í™•ì¥ì„± ì„¤ì • ì—…ë°ì´íŠ¸ ì™„ë£Œ!\n",
      "âœ… config/city_codes.json ë¡œë“œ ë° ë™ê¸°í™” ì™„ë£Œ! (117ê°œ ë„ì‹œ)\n",
      "ğŸ“… ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: 2025-07-23 19:08:54\n",
      "âœ… ê·¸ë£¹ 4 ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!\n",
      "   - create_city_codes_file(): ë„ì‹œ ì½”ë“œ JSON íŒŒì¼ ìƒì„±\n",
      "   - add_new_city(): ìƒˆ ë„ì‹œ ì¶”ê°€\n",
      "   - show_supported_cities(): ì§€ì› ë„ì‹œ ëª©ë¡ í‘œì‹œ\n",
      "   - validate_city(): ë„ì‹œëª… ìœ íš¨ì„± ê²€ì‚¬\n",
      "   - analyze_pagination(): í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„\n",
      "   - check_next_button(): ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ í™•ì¸\n",
      "   - generate_crawling_plan(): í¬ë¡¤ë§ ê³„íš ìˆ˜ë¦½\n",
      "   - report_reconnaissance_results(): ì •ì°° ê²°ê³¼ ë³´ê³ \n",
      "ğŸ¯ í˜ì´ì§€ë„¤ì´ì…˜ ìë™í™”ë¥¼ ìœ„í•œ ì¤€ë¹„ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ğŸš€ ê·¸ë£¹ 4: í™•ì¥ì„± ê°œì„  ì‹œìŠ¤í…œ (ë¦¬íŒ©í† ë§ëœ ë²„ì „)\n",
    "# - ë„ì‹œ ê´€ë¦¬, í˜ì´ì§€ë„¤ì´ì…˜ ë¶„ì„, ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "# =============================================================================\n",
    "\n",
    "def create_city_codes_file():\n",
    "    \"\"\"ë„ì‹œ ì½”ë“œë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥ (UNIFIED_CITY_INFO ê¸°ë°˜)\"\"\"\n",
    "    enhanced_city_data = {\n",
    "        \"version\": \"3.0\",\n",
    "        \"last_updated\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"cities\": {},\n",
    "        \"total_cities\": len(UNIFIED_CITY_INFO)\n",
    "    }\n",
    "\n",
    "    for city_name, info in UNIFIED_CITY_INFO.items():\n",
    "        enhanced_city_data[\"cities\"][city_name] = {\n",
    "            \"code\": info.get(\"ì½”ë“œ\", \"N/A\"),\n",
    "            \"continent\": info.get(\"ëŒ€ë¥™\", \"ê¸°íƒ€\"),\n",
    "            \"country\": info.get(\"êµ­ê°€\", \"ê¸°íƒ€\")\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        with open('config/city_codes.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(enhanced_city_data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"âœ… config/city_codes.json íŒŒì¼ ìƒì„± ì™„ë£Œ! ({len(UNIFIED_CITY_INFO)}ê°œ ë„ì‹œ)\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "def load_city_codes_from_file():\n",
    "    \"\"\"JSON íŒŒì¼ì—ì„œ ë„ì‹œ ì½”ë“œ ë¡œë“œ (UNIFIED_CITY_INFOì™€ ë™ê¸°í™”)\"\"\"\n",
    "    if not os.path.exists('config/city_codes.json'):\n",
    "        print(\"ğŸ“ config/city_codes.json íŒŒì¼ì´ ì—†ì–´ì„œ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...\")\n",
    "        create_city_codes_file()\n",
    "    \n",
    "    try:\n",
    "        with open('config/city_codes.json', 'r', encoding='utf-8') as f:\n",
    "            city_data = json.load(f)\n",
    "        \n",
    "        loaded_cities = city_data.get(\"cities\", {})\n",
    "        \n",
    "        for city, info in loaded_cities.items():\n",
    "            if city not in UNIFIED_CITY_INFO:\n",
    "                 UNIFIED_CITY_INFO[city] = {\n",
    "                     \"ëŒ€ë¥™\": info.get(\"continent\"),\n",
    "                     \"êµ­ê°€\": info.get(\"country\"),\n",
    "                     \"ì½”ë“œ\": info.get(\"code\")\n",
    "                 }\n",
    "        \n",
    "        print(f\"âœ… config/city_codes.json ë¡œë“œ ë° ë™ê¸°í™” ì™„ë£Œ! ({len(UNIFIED_CITY_INFO)}ê°œ ë„ì‹œ)\")\n",
    "        print(f\"ğŸ“… ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {city_data.get('last_updated', 'ì•Œ ìˆ˜ ì—†ìŒ')}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        print(\"ğŸ’¡ ì½”ë“œì˜ UNIFIED_CITY_INFOë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "def add_new_city(city_name, airport_code, continent=\"ê¸°íƒ€\", country=\"ê¸°íƒ€\", update_file=True):\n",
    "    \"\"\"ìƒˆë¡œìš´ ë„ì‹œë¥¼ UNIFIED_CITY_INFOì— ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    global UNIFIED_CITY_INFO\n",
    "    \n",
    "    if city_name not in UNIFIED_CITY_INFO:\n",
    "        UNIFIED_CITY_INFO[city_name] = {\n",
    "            \"ëŒ€ë¥™\": continent,\n",
    "            \"êµ­ê°€\": country,\n",
    "            \"ì½”ë“œ\": airport_code\n",
    "        }\n",
    "        print(f\"âœ… ë©”ëª¨ë¦¬ì— ì¶”ê°€: {city_name} â†’ {airport_code} ({continent}, {country})\")\n",
    "        if update_file:\n",
    "            create_city_codes_file()\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ë„ì‹œì…ë‹ˆë‹¤: {city_name}\")\n",
    "        return False\n",
    "\n",
    "def show_supported_cities():\n",
    "    \"\"\"ì§€ì›í•˜ëŠ” ë„ì‹œ ëª©ë¡ í‘œì‹œ (UNIFIED_CITY_INFO ê¸°ë°˜)\"\"\"\n",
    "    print(\"\\nğŸŒ ì§€ì›í•˜ëŠ” ë„ì‹œ ëª©ë¡:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    cities_by_continent = {}\n",
    "    for city, info in UNIFIED_CITY_INFO.items():\n",
    "        continent = info.get(\"ëŒ€ë¥™\", \"ê¸°íƒ€\")\n",
    "        if continent not in cities_by_continent:\n",
    "            cities_by_continent[continent] = []\n",
    "        cities_by_continent[continent].append(city)\n",
    "\n",
    "    for continent, cities in sorted(cities_by_continent.items()):\n",
    "        print(f\"\\nğŸ“ {continent}:\")\n",
    "        for city in sorted(cities):\n",
    "            code = UNIFIED_CITY_INFO[city].get(\"ì½”ë“œ\", \"N/A\")\n",
    "            print(f\"   {city} â†’ {code}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ì´ {len(UNIFIED_CITY_INFO)}ê°œ ë„ì‹œ ì§€ì›\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "def validate_city(city_name):\n",
    "    \"\"\"ë„ì‹œëª… ìœ íš¨ì„± ê²€ì‚¬ (UNIFIED_CITY_INFO ê¸°ë°˜)\"\"\"\n",
    "    if not city_name or len(city_name.strip()) == 0:\n",
    "        return False, \"ë„ì‹œëª…ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    if city_name in UNIFIED_CITY_INFO:\n",
    "        code = UNIFIED_CITY_INFO[city_name].get(\"ì½”ë“œ\", \"N/A\")\n",
    "        return True, f\"ì§€ì›í•˜ëŠ” ë„ì‹œì…ë‹ˆë‹¤. ({code})\"\n",
    "    \n",
    "    similar_cities = [c for c in UNIFIED_CITY_INFO if city_name.lower() in c.lower() or c.lower() in city_name.lower()]\n",
    "    \n",
    "    if similar_cities:\n",
    "        return False, f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë„ì‹œì…ë‹ˆë‹¤. ë¹„ìŠ·í•œ ë„ì‹œ: {', '.join(similar_cities)}\"\n",
    "    else:\n",
    "        return False, f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë„ì‹œì…ë‹ˆë‹¤. ìƒˆë¡œ ì¶”ê°€í•˜ì‹œë ¤ë©´ add_new_city() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\"\n",
    "\n",
    "def update_config_for_scalability():\n",
    "    \"\"\"í™•ì¥ì„±ì„ ìœ„í•œ CONFIG ì—…ë°ì´íŠ¸\"\"\"\n",
    "    global CONFIG\n",
    "    \n",
    "    scalability_config = {\n",
    "        \"AUTO_LOAD_CITIES\": True,\n",
    "        \"AUTO_SAVE_NEW_CITIES\": True,\n",
    "        \"ENABLE_MULTI_CITY\": False,\n",
    "        \"CITY_PROCESSING_ORDER\": \"sequential\",\n",
    "        \"BACKUP_OLD_DATA\": True,\n",
    "        \"DATA_RETENTION_DAYS\": 30,\n",
    "        \"ENABLE_CITY_VALIDATION\": True,\n",
    "        \"ENABLE_DUPLICATE_CHECK\": True,\n",
    "    }\n",
    "    \n",
    "    CONFIG.update(scalability_config)\n",
    "    print(\"âš™ï¸ CONFIG í™•ì¥ì„± ì„¤ì • ì—…ë°ì´íŠ¸ ì™„ë£Œ!\")\n",
    "\n",
    "def analyze_pagination(driver):\n",
    "    \"\"\"í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„ - ì´ í˜ì´ì§€ ìˆ˜, ìƒí’ˆ ìˆ˜ íŒŒì•…\"\"\"\n",
    "    print(f\"  ğŸ” í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„ ì¤‘...\")\n",
    "    \n",
    "    try:\n",
    "        # í˜ì´ì§€ ë¡œë”© ì™„ë£Œ ëŒ€ê¸°\n",
    "        time.sleep(3)\n",
    "        \n",
    "        # ì´ ìƒí’ˆ ìˆ˜ ì°¾ê¸°\n",
    "        total_products = 0\n",
    "        total_selectors = [\n",
    "            \"//span[contains(text(), 'ì´') and contains(text(), 'ê°œ')]\",\n",
    "            \"//span[contains(text(), 'ì „ì²´') and contains(text(), 'ê°œ')]\", \n",
    "            \"//div[contains(@class, 'total') or contains(@class, 'count')]//span\",\n",
    "            \"//span[contains(text(), 'ê²°ê³¼')]\",\n",
    "        ]\n",
    "        \n",
    "        for selector in total_selectors:\n",
    "            try:\n",
    "                elements = driver.find_elements(By.XPATH, selector)\n",
    "                for element in elements:\n",
    "                    text = element.text.strip()\n",
    "                    if 'ê°œ' in text and any(char.isdigit() for char in text):\n",
    "                        # ìˆ«ì ì¶”ì¶œ\n",
    "                        import re\n",
    "                        numbers = re.findall(r'\\d+', text)\n",
    "                        if numbers:\n",
    "                            total_products = int(numbers[0])\n",
    "                            print(f\"    âœ… ì´ ìƒí’ˆ ìˆ˜ ë°œê²¬: {total_products}ê°œ\")\n",
    "                            break\n",
    "                if total_products > 0:\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ì°¾ê¸°\n",
    "        total_pages = 1\n",
    "        has_next_button = False\n",
    "        \n",
    "        # ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ì°¾ê¸°\n",
    "        next_button_selectors = [\n",
    "            \"//button[contains(@aria-label, 'ë‹¤ìŒ')]\",\n",
    "            \"//button[contains(text(), 'ë‹¤ìŒ')]\",\n",
    "            \"//a[contains(@aria-label, 'ë‹¤ìŒ')]\", \n",
    "            \"//a[contains(text(), 'ë‹¤ìŒ')]\",\n",
    "            \"//button[contains(@class, 'next')]\",\n",
    "            \"//a[contains(@class, 'next')]\",\n",
    "            \".pagination .next\",\n",
    "            \".pager .next\"\n",
    "        ]\n",
    "        \n",
    "        for selector in next_button_selectors:\n",
    "            try:\n",
    "                if selector.startswith('//'):\n",
    "                    elements = driver.find_elements(By.XPATH, selector)\n",
    "                else:\n",
    "                    elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                    \n",
    "                for element in elements:\n",
    "                    if element.is_enabled() and element.is_displayed():\n",
    "                        has_next_button = True\n",
    "                        print(f\"    âœ… 'ë‹¤ìŒ í˜ì´ì§€' ë²„íŠ¼ ë°œê²¬!\")\n",
    "                        break\n",
    "                if has_next_button:\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # í˜ì´ì§€ ë²ˆí˜¸ ì°¾ê¸° (ì´ í˜ì´ì§€ ìˆ˜ ì¶”ì •)\n",
    "        page_number_selectors = [\n",
    "            \"//button[contains(@class, 'page') or contains(@class, 'pagination')]//span\",\n",
    "            \"//a[contains(@class, 'page') or contains(@class, 'pagination')]//span\",\n",
    "            \".pagination button span\",\n",
    "            \".pager a span\"\n",
    "        ]\n",
    "        \n",
    "        max_page = 1\n",
    "        for selector in page_number_selectors:\n",
    "            try:\n",
    "                if selector.startswith('//'):\n",
    "                    elements = driver.find_elements(By.XPATH, selector)\n",
    "                else:\n",
    "                    elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                    \n",
    "                for element in elements:\n",
    "                    text = element.text.strip()\n",
    "                    if text.isdigit():\n",
    "                        page_num = int(text)\n",
    "                        max_page = max(max_page, page_num)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        total_pages = max_page\n",
    "\n",
    "        # 495ê°œ ìƒí’ˆì´ 1í˜ì´ì§€ ë¬¸ì œ í•´ê²° ë¡œì§\n",
    "        if total_products > 100 and total_pages == 1:\n",
    "            estimated_pages = (total_products + 23) // 24  # ë…¼ë¦¬ì  ê³„ì‚° (24ê°œì”©)\n",
    "            if has_next_button:\n",
    "                total_pages = estimated_pages  # ì¶”ì •ê°’ ì ìš©\n",
    "                print(f\"    ğŸ”§ í˜ì´ì§€ ìˆ˜ ë³´ì •: {total_products}ê°œ ìƒí’ˆ â†’ {total_pages}í˜ì´ì§€ë¡œ ìˆ˜ì •\")\n",
    "                print(f\"    ğŸ“Š ì˜ˆìƒ í˜ì´ì§€ë‹¹ ìƒí’ˆ ìˆ˜: ~{total_products // total_pages}ê°œ\")\n",
    "            else:\n",
    "                print(f\"    âš ï¸ ë‹¤ìŒ ë²„íŠ¼ ì—†ìŒ: ì‹¤ì œë¡œ 1í˜ì´ì§€ì¼ ìˆ˜ ìˆìŒ (ìƒí’ˆ {total_products}ê°œ)\")\n",
    "                # ì‹¤ì œë¡œ 1í˜ì´ì§€ì¸ì§€ í™•ì¸í•˜ê¸° ìœ„í•œ ì¶”ê°€ ë¡œì§ í•„ìš”í•  ìˆ˜ ìˆìŒ\n",
    "                \n",
    "                # í˜ì´ì§€ë‹¹ ìƒí’ˆ ìˆ˜ ì¶”ì • (í˜„ì¬ í˜ì´ì§€ ê¸°ì¤€)\n",
    "                products_per_page = 24  # ê¸°ë³¸ê°’\n",
    "                if total_products > 0 and total_pages > 0:\n",
    "                    products_per_page = min(24, total_products // total_pages + (1 if total_products % total_pages > 0 else 0))\n",
    "                \n",
    "                return {\n",
    "                    'total_products': total_products,\n",
    "                    'total_pages': total_pages, \n",
    "                    'products_per_page': products_per_page,\n",
    "                    'has_next_button': has_next_button,\n",
    "                    'is_pagination_available': has_next_button or total_pages > 1\n",
    "                }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    âŒ í˜ì´ì§€ë„¤ì´ì…˜ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "        return {\n",
    "            'total_products': 0,\n",
    "            'total_pages': 1,\n",
    "            'products_per_page': 24,\n",
    "            'has_next_button': False,\n",
    "            'is_pagination_available': False\n",
    "        }\n",
    "\n",
    "def check_next_button(driver):\n",
    "    \"\"\"ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ì‘ë™ í™•ì¸\"\"\"\n",
    "    print(f\"  ğŸ” ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ì‘ë™ì„± í™•ì¸ ì¤‘...\")\n",
    "    \n",
    "    next_button_selectors = [\n",
    "        \"//button[contains(@aria-label, 'ë‹¤ìŒ') and not(@disabled)]\",\n",
    "        \"//button[contains(text(), 'ë‹¤ìŒ') and not(@disabled)]\",\n",
    "        \"//a[contains(@aria-label, 'ë‹¤ìŒ')]\",\n",
    "        \"//a[contains(text(), 'ë‹¤ìŒ')]\",\n",
    "        \"//button[contains(@class, 'next') and not(@disabled)]\",\n",
    "        \"//a[contains(@class, 'next')]\"\n",
    "    ]\n",
    "    \n",
    "    for selector in next_button_selectors:\n",
    "        try:\n",
    "            element = driver.find_element(By.XPATH, selector)\n",
    "            if element.is_enabled() and element.is_displayed():\n",
    "                # í´ë¦­ ê°€ëŠ¥í•œì§€ í™•ì¸ (ì‹¤ì œë¡œ í´ë¦­í•˜ì§€ëŠ” ì•ŠìŒ)\n",
    "                try:\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView(true);\", element)\n",
    "                    print(f\"    âœ… ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì´ ì‘ë™ ê°€ëŠ¥í•©ë‹ˆë‹¤!\")\n",
    "                    return True\n",
    "                except:\n",
    "                    continue\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    print(f\"    âŒ ì‘ë™ ê°€ëŠ¥í•œ ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    return False\n",
    "\n",
    "def generate_crawling_plan(pagination_info, city_name):\n",
    "    \"\"\"í¬ë¡¤ë§ ê³„íš ìƒì„± ë° ë³´ê³ \"\"\"\n",
    "    print(f\"\\nğŸ“‹ í¬ë¡¤ë§ ê³„íš ìˆ˜ë¦½ ì¤‘...\")\n",
    "    \n",
    "    plan = {\n",
    "        'city': city_name,\n",
    "        'total_products': pagination_info['total_products'],\n",
    "        'total_pages': pagination_info['total_pages'],\n",
    "        'products_per_page': pagination_info['products_per_page'],\n",
    "        'pagination_available': pagination_info['is_pagination_available'],\n",
    "        'estimated_time_minutes': 0,\n",
    "        'recommended_batch_size': CONFIG['MAX_PRODUCTS_PER_CITY'],\n",
    "        'strategy': 'ë‹¨ì¼ í˜ì´ì§€'\n",
    "    }\n",
    "    \n",
    "    # ì˜ˆìƒ ì†Œìš” ì‹œê°„ ê³„ì‚° (ìƒí’ˆë‹¹ ì•½ 30ì´ˆ ì¶”ì •)\n",
    "    products_to_crawl = min(pagination_info['total_products'], CONFIG['MAX_PRODUCTS_PER_CITY'])\n",
    "    plan['estimated_time_minutes'] = products_to_crawl * 0.5  # ìƒí’ˆë‹¹ 30ì´ˆ\n",
    "    \n",
    "    # ì „ëµ ê²°ì •\n",
    "    if pagination_info['is_pagination_available'] and pagination_info['total_pages'] > 1:\n",
    "        plan['strategy'] = 'ë‹¤ì¤‘ í˜ì´ì§€ ìˆœíšŒ'\n",
    "        if pagination_info['total_products'] > CONFIG['MAX_PRODUCTS_PER_CITY']:\n",
    "            plan['strategy'] += f\" (ìµœëŒ€ {CONFIG['MAX_PRODUCTS_PER_CITY']}ê°œ ì œí•œ)\"\n",
    "    \n",
    "    return plan\n",
    "\n",
    "def report_reconnaissance_results(plan):\n",
    "    \"\"\"ì •ì°° ê²°ê³¼ ë³´ê³ \"\"\"\n",
    "    print(f\"\\nğŸ” === ì •ì°° ì™„ë£Œ ë³´ê³ ì„œ ===\")\n",
    "    print(f\"ğŸ“ ë„ì‹œ: {plan['city']}\")\n",
    "    print(f\"ğŸ“Š ë°œê²¬ëœ ì´ ìƒí’ˆ ìˆ˜: {plan['total_products']}ê°œ\")\n",
    "    print(f\"ğŸ“„ ì´ í˜ì´ì§€ ìˆ˜: {plan['total_pages']}í˜ì´ì§€\")\n",
    "    print(f\"ğŸ“‹ í˜ì´ì§€ë‹¹ ìƒí’ˆ ìˆ˜: {plan['products_per_page']}ê°œ\")\n",
    "    print(f\"ğŸ”„ í˜ì´ì§€ë„¤ì´ì…˜ ê°€ëŠ¥: {'âœ… ì˜ˆ' if plan['pagination_available'] else 'âŒ ì•„ë‹ˆì˜¤'}\")\n",
    "    print(f\"â±ï¸ ì˜ˆìƒ ì†Œìš” ì‹œê°„: {plan['estimated_time_minutes']:.1f}ë¶„\")\n",
    "    print(f\"ğŸ¯ í¬ë¡¤ë§ ì „ëµ: {plan['strategy']}\")\n",
    "    print(f\"ğŸ“¦ ì‹¤ì œ ìˆ˜ì§‘ ì˜ˆì •: {min(plan['total_products'], plan['recommended_batch_size'])}ê°œ\")\n",
    "    print(f\"=\" * 50)\n",
    "    \n",
    "    if plan['pagination_available']:\n",
    "        print(f\"ğŸš€ í˜ì´ì§€ë„¤ì´ì…˜ì„ í™œìš©í•œ ì „ì²´ í¬ë¡¤ë§ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"âš ï¸ í˜ì´ì§€ë„¤ì´ì…˜ì´ ì œí•œì ì…ë‹ˆë‹¤. í˜„ì¬ í˜ì´ì§€ë§Œ í¬ë¡¤ë§ ê°€ëŠ¥í•©ë‹ˆë‹¤.\")\n",
    "        return False\n",
    "\n",
    "def initialize_file_system():\n",
    "    \"\"\"íŒŒì¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ì„¤ì • (ë¦¬íŒ©í† ë§ëœ ë²„ì „)\"\"\"\n",
    "    print(\"ğŸ”§ ê·¸ë£¹ 4: í™•ì¥ì„± ê°œì„  ì‹œìŠ¤í…œ ì´ˆê¸°í™”...\")\n",
    "    \n",
    "    update_config_for_scalability()\n",
    "    \n",
    "    if CONFIG.get(\"AUTO_LOAD_CITIES\", True):\n",
    "        load_city_codes_from_file()\n",
    "    \n",
    "    print(\"âœ… ê·¸ë£¹ 4 ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
    "    return True\n",
    "\n",
    "# ìë™ ì´ˆê¸°í™” ì‹¤í–‰\n",
    "try:\n",
    "    initialize_file_system()\n",
    "    print(\"   - create_city_codes_file(): ë„ì‹œ ì½”ë“œ JSON íŒŒì¼ ìƒì„±\")\n",
    "    print(\"   - add_new_city(): ìƒˆ ë„ì‹œ ì¶”ê°€\")\n",
    "    print(\"   - show_supported_cities(): ì§€ì› ë„ì‹œ ëª©ë¡ í‘œì‹œ\")\n",
    "    print(\"   - validate_city(): ë„ì‹œëª… ìœ íš¨ì„± ê²€ì‚¬\")\n",
    "    print(\"   - analyze_pagination(): í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„\")\n",
    "    print(\"   - check_next_button(): ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ í™•ì¸\")\n",
    "    print(\"   - generate_crawling_plan(): í¬ë¡¤ë§ ê³„íš ìˆ˜ë¦½\")\n",
    "    print(\"   - report_reconnaissance_results(): ì •ì°° ê²°ê³¼ ë³´ê³ \")\n",
    "    print(\"ğŸ¯ í˜ì´ì§€ë„¤ì´ì…˜ ìë™í™”ë¥¼ ìœ„í•œ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ê·¸ë£¹ 4 ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ’¡ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ê³„ì† ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c5fe0af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê·¸ë£¹ 5 ì™„ë£Œ: ë¸Œë¼ìš°ì € ì œì–´ ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ì •ì˜ ì™„ë£Œ!\n",
      "   - setup_driver(): í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì •\n",
      "   - go_to_main_page(): ë©”ì¸ í˜ì´ì§€ ì´ë™\n",
      "   - find_and_fill_search(): ê²€ìƒ‰ì°½ ì…ë ¥\n",
      "   - click_search_button(): ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­\n",
      "   - handle_popup(): íŒì—… ì²˜ë¦¬\n",
      "   - click_view_all(): ì „ì²´ ìƒí’ˆ ë³´ê¸°\n",
      "   - safe_browser_restart(): ì•ˆì „í•œ ë¸Œë¼ìš°ì € ì¬ì‹œì‘\n",
      "   - return_to_current_page(): í˜ì´ì§€ ë³µê·€\n",
      "   - human_like_scroll_patterns(): ìì—°ìŠ¤ëŸ¬ìš´ ìŠ¤í¬ë¡¤\n",
      "   - smart_scroll_selector(): ìŠ¤ë§ˆíŠ¸ ìŠ¤í¬ë¡¤ ì„ íƒ\n",
      "   âš¡ smart_wait_for_page_load(): ë™ì  ëŒ€ê¸°ì‹œê°„\n",
      "   âš¡ crawl_single_product_with_new_tab(): ìƒˆ íƒ­ í™œìš© í¬ë¡¤ë§\n",
      "   âš¡ crawl_single_product_new_tab_method(): ìµœì í™”ëœ í¬ë¡¤ë§ (ì¶©ëŒë°©ì§€)\n",
      "   âš¡ wait_for_page_ready(): í˜ì´ì§€ ì¤€ë¹„ ëŒ€ê¸°\n",
      "   âš¡ adaptive_wait(): ì ì‘í˜• ëŒ€ê¸° ì‹œê°„\n",
      "   âš¡ safe_tab_operation(): ì•ˆì „í•œ íƒ­ ì‘ì—…\n",
      "   - print_progress(): ì§„í–‰ë¥  í‘œì‹œ\n",
      "   - retry_operation(): ì¬ì‹œë„ ë¡œì§\n",
      "   - make_safe_filename(): ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ğŸ› ï¸ ê·¸ë£¹ 5: ë¸Œë¼ìš°ì € ì œì–´ ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤\n",
    "# - ë“œë¼ì´ë²„ ì„¤ì •, í˜ì´ì§€ ë„¤ë¹„ê²Œì´ì…˜, ìœ í‹¸ë¦¬í‹° ê¸°ëŠ¥ë“¤\n",
    "# =============================================================================\n",
    "\n",
    "def make_user_agent(ua, is_mobile):\n",
    "    \"\"\"User Agent ìƒì„± í•¨ìˆ˜\"\"\"\n",
    "    user_agent = parse(ua)\n",
    "    model = user_agent.device.model\n",
    "    platform = user_agent.os.family\n",
    "    platform_version = user_agent.os.version_string + \".0.0\"\n",
    "    version = user_agent.browser.version[0]\n",
    "    ua_full_version = user_agent.browser.version_string\n",
    "    architecture = \"x86\"\n",
    "    print(platform)\n",
    "    if is_mobile:\n",
    "        platform_info = \"Linux armv8l\"\n",
    "        architecture= \"\"\n",
    "    else:\n",
    "        platform_info = \"Win32\"\n",
    "        model = \"\"\n",
    "    RET_USER_AGENT = {\n",
    "        \"appVersion\" : ua.replace(\"Mozilla/\", \"\"),\n",
    "        \"userAgent\": ua,\n",
    "        \"platform\" : f\"{platform_info}\",\n",
    "        \"acceptLanguage\" : \"ko-KR, kr, en-US, en\",\n",
    "        \"userAgentMetadata\":{\n",
    "            \"brands\" : [\n",
    "                {\"brand\":\"Google Chrome\", \"version\":f\"{version}\"},\n",
    "                {\"brand\":\"Chromium\", \"version\":f\"{version}\"},\n",
    "                {\"brand\":\" Not A;Brand\", \"version\":\"99\"}\n",
    "            ],\n",
    "            \"fullVersionList\" : [\n",
    "                {\"brand\":\"Google Chrome\", \"version\":f\"{version}\"},\n",
    "                {\"brand\":\"Chromium\", \"version\":f\"{version}\"},\n",
    "                {\"brand\":\" Not A;Brand\", \"version\":\"99\"}\n",
    "            ],\n",
    "            \"fullVersion\":f\"{ua_full_version}\",\n",
    "            \"platform\" :platform,\n",
    "            \"platformVersion\":platform_version,\n",
    "            \"architecture\":architecture,\n",
    "            \"model\" : model,\n",
    "            \"mobile\":is_mobile\n",
    "        }\n",
    "    }\n",
    "    return RET_USER_AGENT\n",
    "\n",
    "def generate_random_geolocation():\n",
    "    \"\"\"ëœë¤ ì§€ë¦¬ì  ìœ„ì¹˜ ìƒì„±\"\"\"\n",
    "    ltop_lat = 37.75415601640249\n",
    "    ltop_long = 126.86767642302573\n",
    "    rbottom_lat = 37.593829172663945\n",
    "    rbottom_long = 127.15276051439332\n",
    "\n",
    "    targetLat = random.uniform(rbottom_lat, ltop_lat)\n",
    "    targetLong = random.uniform(ltop_long,rbottom_long)\n",
    "    return {\"latitude\":targetLat, \"longitude\" : targetLong, \"accuracy\":100}\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì • ë° ì‹¤í–‰\"\"\"\n",
    "    chromedriver_autoinstaller.install()\n",
    "    \n",
    "    options = uc.ChromeOptions()\n",
    "    \n",
    "    UA = CONFIG[\"USER_AGENT\"]\n",
    "    options.add_argument(f\"--user-agent={UA}\")\n",
    "    \n",
    "    rand_user_folder = random.randrange(1,100)\n",
    "    raw_path = os.path.abspath(\"cookies\")\n",
    "    try:\n",
    "        # shutil.rmtree(raw_path) # í´ë” ì‚­ì œ ë°©ì§€ë¥¼ ìœ„í•´ ì´ ì¤„ì„ ì£¼ì„ ì²˜ë¦¬\n",
    "        pass\n",
    "    except:\n",
    "        pass\n",
    "    os.makedirs(raw_path, exist_ok=True)\n",
    "    user_cookie_name = f\"{raw_path}/{rand_user_folder}\"\n",
    "    if os.path.exists(user_cookie_name) == False:\n",
    "        os.makedirs(user_cookie_name, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        driver = uc.Chrome(user_data_dir=user_cookie_name, options=options)\n",
    "        print(\"âœ… í¬ë¡¬ ë“œë¼ì´ë²„ ì‹¤í–‰ ì„±ê³µ!\")\n",
    "        print(platform.system())\n",
    "    except Exception as e:\n",
    "        print('\\n',\"-\"*50,'\\n',\"-\"*50,'\\n')\n",
    "        print(\"# í‚¤í™ˆ ë©”ì„¸ì§€ : í˜¹ì‹œ ì—¬ê¸°ì„œ ì—ëŸ¬ ë°œìƒì‹œ [ì•„ë˜ ë¸”ë¡œê·¸ ì°¸ê³  -> ì¬ë¶€íŒ… -> ë‹¤ì‹œ ì½”ë“œì‹¤í–‰] í•´ë³´ì‹œê¸¸ ë°”ëë‹ˆë‹¤! \\n (êµ¬ê¸€í¬ë¡¬ ë²„ì ¼ ì—…ê·¸ë ˆì´ë“œ ë¬¸ì œ)\")\n",
    "        print('https://appfollow.tistory.com/102')\n",
    "        print('\\n',\"-\"*50,'\\n',\"-\"*50,'\\n')\n",
    "        raise RuntimeError\n",
    "        \n",
    "    UA_Data = make_user_agent(UA,False)\n",
    "    driver.execute_cdp_cmd(\"Network.setUserAgentOverride\",UA_Data)\n",
    "    \n",
    "    GEO_DATA = generate_random_geolocation()\n",
    "    driver.execute_cdp_cmd(\"Emulation.setGeolocationOverride\", GEO_DATA)\n",
    "    driver.execute_cdp_cmd(\"Emulation.setUserAgentOverride\", UA_Data)\n",
    "    driver.execute_cdp_cmd(\"Emulation.setNavigatorOverrides\",{\"platform\":\"Linux armv8l\"})\n",
    "    \n",
    "    return driver\n",
    "\n",
    "def go_to_main_page(driver):\n",
    "    \"\"\"ë©”ì¸ í˜ì´ì§€ë¡œ ì´ë™\"\"\"\n",
    "    driver.get(\"https://www.myrealtrip.com/experiences/\")\n",
    "    # ğŸ‘‡ ìƒˆë¡œìš´ 'MEDIUM' í”„ë¡œí•„ì„ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •í•©ë‹ˆë‹¤.\n",
    "    time.sleep(random.uniform(CONFIG[\"MEDIUM_MIN_DELAY\"], CONFIG[\"MEDIUM_MAX_DELAY\"]))\n",
    "    return True\n",
    "\n",
    "def find_and_fill_search(driver, city_name):\n",
    "    \"\"\"ê²€ìƒ‰ì°½ ì°¾ê¸° ë° ì¸ê°„ì ì¸ íƒ€ì´í•‘ ì ìš©\"\"\"\n",
    "    print(f\"  ğŸ” '{city_name}' ê²€ìƒ‰ì°½ ì°¾ëŠ” ì¤‘...\")\n",
    "    search_selectors = [\n",
    "        (By.CSS_SELECTOR, \"input[placeholder*='ì–´ë””ë¡œ']\"),\n",
    "        (By.CSS_SELECTOR, \"input[type='text']\"),\n",
    "        (By.XPATH, \"//input[contains(@placeholder, 'ì–´ë””ë¡œ')]\"),\n",
    "        (By.XPATH, \"/html/body/main/div/div[2]/section[1]/div[1]/div/div/input\")\n",
    "    ]\n",
    "\n",
    "    search_input = None\n",
    "    for selector_type, selector_value in search_selectors:\n",
    "        try:\n",
    "            search_input = WebDriverWait(driver, CONFIG[\"WAIT_TIMEOUT\"]).until(\n",
    "                EC.presence_of_element_located((selector_type, selector_value))\n",
    "            )\n",
    "            print(f\"  âœ… ê²€ìƒ‰ì°½ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!\")\n",
    "            break\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "\n",
    "    if not search_input:\n",
    "        raise NoSuchElementException(\"ê²€ìƒ‰ì°½ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "\n",
    "    # [ìˆ˜ì •] ì‚¬ëŒì²˜ëŸ¼ í•œ ê¸€ìì”© íƒ€ì´í•‘í•˜ëŠ” ë¡œì§\n",
    "    search_input.clear()\n",
    "    for char in city_name:\n",
    "        search_input.send_keys(char)\n",
    "        # ê° ê¸€ì ì‚¬ì´ì— ì•„ì£¼ ì§§ì€ ë¬´ì‘ìœ„ ë”œë ˆì´ ì¶”ê°€\n",
    "        time.sleep(random.uniform(CONFIG[\"SHORT_MIN_DELAY\"], CONFIG[\"SHORT_MAX_DELAY\"]))\n",
    "    \n",
    "    # ë‹¨ì–´ ì…ë ¥ í›„ ì ì‹œ ìƒê°í•˜ëŠ” ê²ƒì²˜ëŸ¼ ëŒ€ê¸°\n",
    "    time.sleep(random.uniform(1, 2))\n",
    "    print(f\"  ğŸ“ '{city_name}' í‚¤ì›Œë“œ ì…ë ¥ ì™„ë£Œ\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def click_search_button(driver):\n",
    "    \"\"\"ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­\"\"\"\n",
    "    print(f\"  ğŸ” ê²€ìƒ‰ ë²„íŠ¼ ì°¾ëŠ” ì¤‘...\")\n",
    "    search_button_selectors = [\n",
    "        (By.CSS_SELECTOR, \"button[type='submit']\"),\n",
    "        (By.CSS_SELECTOR, \".search-btn\"),\n",
    "        (By.XPATH, \"//button[contains(@class, 'search')]\"),\n",
    "        (By.XPATH, \"//img[contains(@alt, 'ê²€ìƒ‰')]//parent::*\"),\n",
    "        (By.XPATH, \"/html/body/main/div/div[2]/section[1]/div[1]/div/div/div/img\")\n",
    "    ]\n",
    "\n",
    "    search_clicked = False\n",
    "    for selector_type, selector_value in search_button_selectors:\n",
    "        try:\n",
    "            search_button = WebDriverWait(driver, CONFIG[\"WAIT_TIMEOUT\"]).until(\n",
    "                EC.element_to_be_clickable((selector_type, selector_value))\n",
    "            )\n",
    "            search_button.click()\n",
    "            print(f\"  âœ… ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­ ì„±ê³µ!\")\n",
    "            search_clicked = True\n",
    "            time.sleep(random.uniform(CONFIG[\"MEDIUM_MIN_DELAY\"], CONFIG[\"MEDIUM_MAX_DELAY\"]))\n",
    "            break\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "\n",
    "    if not search_clicked:\n",
    "        raise NoSuchElementException(\"ê²€ìƒ‰ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "    return True\n",
    "\n",
    "def handle_popup(driver):\n",
    "    \"\"\"íŒì—… ì²˜ë¦¬\"\"\"\n",
    "    popup_selectors = [\n",
    "        (By.CSS_SELECTOR, \".popup-close\"),\n",
    "        (By.CSS_SELECTOR, \".modal-close\"),\n",
    "        (By.XPATH, \"//button[contains(@aria-label, 'ë‹«ê¸°')]\"),\n",
    "        (By.XPATH, \"//button[contains(text(), 'ë‹«ê¸°')]\"),\n",
    "        (By.XPATH, \"/html/body/div[15]/div[2]/button\")\n",
    "    ]\n",
    "\n",
    "    popup_closed = False\n",
    "    for selector_type, selector_value in popup_selectors:\n",
    "        try:\n",
    "            popup_button = WebDriverWait(driver, CONFIG[\"POPUP_WAIT\"]).until(\n",
    "                EC.element_to_be_clickable((selector_type, selector_value))\n",
    "            )\n",
    "            popup_button.click()\n",
    "            print(f\"  âœ… íŒì—…ì°½ì„ ë‹«ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "            popup_closed = True\n",
    "            time.sleep(random.uniform(1, 4))\n",
    "            break\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "\n",
    "    if not popup_closed:\n",
    "        print(f\"  â„¹ï¸ íŒì—…ì°½ì´ ì—†ê±°ë‚˜ ì´ë¯¸ ë‹«í˜€ìˆìŠµë‹ˆë‹¤.\")\n",
    "    return True\n",
    "\n",
    "def click_view_all(driver):\n",
    "    \"\"\"ì „ì²´ ìƒí’ˆ ë³´ê¸° ë²„íŠ¼ í´ë¦­ (ì•ˆì •ì„± ê°•í™”)\"\"\"\n",
    "    print(f\"  ğŸ“‹ ì „ì²´ ìƒí’ˆ ë³´ê¸° ë²„íŠ¼ ì°¾ëŠ” ì¤‘...\")\n",
    "    \n",
    "    view_all_selectors = [\n",
    "        (By.XPATH, \"//button[contains(text(), 'ì „ì²´')]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'ì „ì²´')]//parent::button\"),\n",
    "        (By.CSS_SELECTOR, \"button[aria-label*='ì „ì²´']\"),\n",
    "        (By.XPATH, \"/html/body/div[4]/div[2]/div/div/div/span[21]/button\")\n",
    "    ]\n",
    "\n",
    "    view_all_clicked = False\n",
    "    for selector_type, selector_value in view_all_selectors:\n",
    "        try:\n",
    "            view_all_button = WebDriverWait(driver, CONFIG[\"WAIT_TIMEOUT\"]).until(\n",
    "                EC.element_to_be_clickable((selector_type, selector_value))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_all_button)\n",
    "            \n",
    "            print(f\"  âœ… ì „ì²´ ìƒí’ˆ ë³´ê¸° í´ë¦­ ì„±ê³µ!\")\n",
    "            view_all_clicked = True\n",
    "            time.sleep(random.uniform(CONFIG[\"MEDIUM_MIN_DELAY\"], CONFIG[\"MEDIUM_MAX_DELAY\"]))\n",
    "            break\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "\n",
    "    if not view_all_clicked:\n",
    "        print(f\"  âš ï¸ ì „ì²´ ìƒí’ˆ ë³´ê¸° ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ìƒí’ˆìœ¼ë¡œ ì§„í–‰...\")\n",
    "        \n",
    "    return True\n",
    "\n",
    "def safe_browser_restart():\n",
    "    \"\"\"ì•ˆì „í•œ ë¸Œë¼ìš°ì € ì¬ì‹œì‘ with 3ë²ˆ ì¬ì‹œë„\"\"\"\n",
    "    global driver\n",
    "    \n",
    "    for attempt in range(3):  # 3ë²ˆ ì‹œë„\n",
    "        try:\n",
    "            print(f\"ğŸ”„ ë¸Œë¼ìš°ì € ì¬ì‹œì‘ ì‹œë„ {attempt+1}/3...\")\n",
    "            \n",
    "            # 1ë‹¨ê³„: ì•ˆì „í•œ ì¢…ë£Œ\n",
    "            if 'driver' in globals() and driver:\n",
    "                driver.quit()\n",
    "                driver = None\n",
    "            \n",
    "            # 2ë‹¨ê³„: ëŒ€ê¸° ë° ì •ë¦¬\n",
    "            wait_time = random.uniform(5, 10)\n",
    "            print(f\"â° {wait_time:.1f}ì´ˆ ëŒ€ê¸° ì¤‘...\")\n",
    "            time.sleep(wait_time)\n",
    "            \n",
    "            # 3ë‹¨ê³„: ìƒˆ ë¸Œë¼ìš°ì € ì‹œì‘\n",
    "            print(\"ğŸš€ ìƒˆ ë¸Œë¼ìš°ì € ì‹œì‘ ì¤‘...\")\n",
    "            driver = setup_driver()\n",
    "            \n",
    "            # 4ë‹¨ê³„: ë™ì‘ ê²€ì¦\n",
    "            print(\"ğŸ” ë¸Œë¼ìš°ì € ë™ì‘ ê²€ì¦ ì¤‘...\")\n",
    "            driver.get(\"https://www.myrealtrip.com/\")\n",
    "            time.sleep(2)\n",
    "            \n",
    "            print(\"âœ… ë¸Œë¼ìš°ì € ì¬ì‹œì‘ ì„±ê³µ!\")\n",
    "            return True, \"ì¬ì‹œì‘ ì„±ê³µ\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì¬ì‹œì‘ ì‹œë„ {attempt+1} ì‹¤íŒ¨: {type(e).__name__}: {e}\")\n",
    "            if attempt == 2:  # ë§ˆì§€ë§‰ ì‹œë„\n",
    "                print(\"ğŸš¨ ë¸Œë¼ìš°ì € ì¬ì‹œì‘ ìµœì¢… ì‹¤íŒ¨!\")\n",
    "                return False, f\"ì¬ì‹œì‘ ë¶ˆê°€: {e}\"\n",
    "            print(f\"ğŸ”„ {3-attempt-1}ì´ˆ í›„ ì¬ì‹œë„...\")\n",
    "            time.sleep(3)  # ë‹¤ìŒ ì‹œë„ ì „ ëŒ€ê¸°\n",
    "    \n",
    "    return False, \"ìµœì¢… ì‹¤íŒ¨\"\n",
    "\n",
    "def return_to_current_page():\n",
    "    \"\"\"í˜„ì¬ ì„¤ì •ëœ ë„ì‹œ ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ë¡œ ë³µê·€ (ìˆ˜ì •ë¨)\"\"\"\n",
    "    try:\n",
    "        current_city = CITIES_TO_SEARCH[0] if CITIES_TO_SEARCH else \"ë°”ë¥´ì…€ë¡œë‚˜\"\n",
    "        print(f\"ğŸ”„ {current_city} ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ë¡œ ë³µê·€ ì¤‘...\")\n",
    "        \n",
    "        # ë™ì  URL ìƒì„± (ë°”ë¥´ì…€ë¡œë‚˜ ê¸°ì¤€)\n",
    "        if current_city == \"ë°”ë¥´ì…€ë¡œë‚˜\":\n",
    "            search_url = \"https://www.myrealtrip.com/experiences/?destination=%EB%B0%94%EB%A5%B4%EC%85%80%EB%A1%9C%EB%82%98\"\n",
    "        else:\n",
    "            # ë‹¤ë¥¸ ë„ì‹œì˜ ê²½ìš° ê²€ìƒ‰ í˜ì´ì§€ë¡œ ì´ë™\n",
    "            search_url = f\"https://www.myrealtrip.com/experiences/?destination={current_city}\"\n",
    "        \n",
    "        driver.get(search_url)\n",
    "        time.sleep(random.uniform(3, 5))\n",
    "        print(\"âœ… í˜ì´ì§€ ë³µê·€ ì™„ë£Œ\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í˜ì´ì§€ ë³µê·€ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ› ï¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (ì§„í–‰ë¥  í‘œì‹œ, ì¬ì‹œë„ ë¡œì§ ë“±)\n",
    "# =============================================================================\n",
    "\n",
    "def print_progress(current, total, city_name, status=\"ì§„í–‰ì¤‘\"):\n",
    "    \"\"\"ì§„í–‰ë¥ ì„ ì‹œê°ì ìœ¼ë¡œ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    percentage = (current / total) * 100\n",
    "    bar_length = 30\n",
    "    filled_length = int(bar_length * current // total)\n",
    "    bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)\n",
    "    \n",
    "    emoji = \"ğŸ”\" if status == \"ì§„í–‰ì¤‘\" else \"âœ…\" if status == \"ì™„ë£Œ\" else \"âŒ\"\n",
    "    \n",
    "    print(f\"\\n{emoji} ì§„í–‰ë¥ : [{bar}] {percentage:.1f}% ({current}/{total})\")\n",
    "    print(f\"ğŸ“ í˜„ì¬ ì‘ì—…: {city_name} - {status}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "def print_product_progress(current, total, product_name):\n",
    "    \"\"\"ìƒí’ˆë³„ ì§„í–‰ë¥  í‘œì‹œ í•¨ìˆ˜\"\"\"\n",
    "    percentage = (current / total) * 100\n",
    "    bar_length = 20\n",
    "    filled_length = int(bar_length * current // total)\n",
    "    bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)\n",
    "    \n",
    "    safe_name = str(product_name)[:30] + \"...\" if len(str(product_name)) > 30 else str(product_name)\n",
    "    print(f\"    ğŸ¯ ìƒí’ˆ ì§„í–‰ë¥ : [{bar}] {percentage:.1f}% ({current}/{total})\")\n",
    "    print(f\"    ğŸ“¦ í˜„ì¬ ìƒí’ˆ: {safe_name}\")\n",
    "\n",
    "def save_intermediate_results(results, city_name):\n",
    "    \"\"\"ì¤‘ê°„ ê²°ê³¼ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    if results and CONFIG.get(\"SAVE_INTERMEDIATE\", False):\n",
    "        try:\n",
    "            timestamp = time.strftime('%Y%m%d_%H%M%S')\n",
    "            temp_filename = f\"temp_ì¤‘ê°„ì €ì¥_{city_name}_{timestamp}.csv\"\n",
    "            pd.DataFrame(results).to_csv(temp_filename, index=False, encoding='utf-8-sig')\n",
    "            print(f\"  ğŸ’¾ ì¤‘ê°„ ê²°ê³¼ ì €ì¥: {temp_filename}\")\n",
    "            return temp_filename\n",
    "        except Exception as e:\n",
    "            print(f\"  âš ï¸ ì¤‘ê°„ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def retry_operation(func, operation_name, max_retries=None):\n",
    "    \"\"\"ì‹¤íŒ¨í•œ ì‘ì—…ì„ ì¬ì‹œë„í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    if max_retries is None:\n",
    "        max_retries = CONFIG[\"RETRY_COUNT\"]\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return func()\n",
    "        except (TimeoutException, NoSuchElementException, WebDriverException) as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                print(f\"  âŒ {operation_name} ìµœì¢… ì‹¤íŒ¨: {type(e).__name__}\")\n",
    "                raise e\n",
    "            print(f\"  ğŸ”„ {operation_name} ì¬ì‹œë„ {attempt + 1}/{max_retries} (ì˜¤ë¥˜: {type(e).__name__})\")\n",
    "            time.sleep(2)\n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ {operation_name} ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {type(e).__name__}: {e}\")\n",
    "            raise e\n",
    "\n",
    "def make_safe_filename(filename):\n",
    "    \"\"\"íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°\"\"\"\n",
    "    if not filename:\n",
    "        return \"ê¸°ë³¸íŒŒì¼ëª…\"\n",
    "    \n",
    "    safe_filename = str(filename)\n",
    "    unsafe_chars = ['/', '\\\\', ':', '*', '?', '\"', '<', '>', '|', '\\n', '\\r', '\\t']\n",
    "    for char in unsafe_chars:\n",
    "        safe_filename = safe_filename.replace(char, '_')\n",
    "    \n",
    "    if len(safe_filename) > 200:\n",
    "        safe_filename = safe_filename[:200]\n",
    "    \n",
    "    if safe_filename.startswith('.'):\n",
    "        safe_filename = '_' + safe_filename[1:]\n",
    "    \n",
    "    return safe_filename\n",
    "\n",
    "# =============================================================================\n",
    "# âš¡ í˜ì´ì§€ ë¡œë”© ìµœì í™” ì‹œìŠ¤í…œ (ê·¸ë£¹ 5 í™•ì¥)\n",
    "# =============================================================================\n",
    "\n",
    "def smart_wait_for_page_load(driver, max_wait=None):\n",
    "    \"\"\"ë™ì  ëŒ€ê¸°ì‹œê°„ - í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ ê°ì§€\"\"\"\n",
    "    if max_wait is None:\n",
    "        max_wait = CONFIG.get(\"SMART_WAIT_MAX\", 8)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < max_wait:\n",
    "        try:\n",
    "            if driver.execute_script(\"return document.readyState\") == \"complete\":\n",
    "                # í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ í›„ ìµœì†Œ ëŒ€ê¸°\n",
    "                time.sleep(random.uniform(0.5, 1.5))\n",
    "                return True\n",
    "        except (WebDriverException, Exception):\n",
    "            pass\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    # ìµœëŒ€ ëŒ€ê¸°ì‹œê°„ ì´ˆê³¼ ì‹œì—ë„ ìµœì†Œ ëŒ€ê¸°\n",
    "    time.sleep(random.uniform(1, 2))\n",
    "    return False\n",
    "\n",
    "\n",
    "def crawl_single_product_with_new_tab(driver, product_url, product_number, city_name,\n",
    "                                    continent, country, page_num):\n",
    "    \"\"\"ìƒˆ íƒ­ í™œìš© ë‹¨ì¼ ìƒí’ˆ í¬ë¡¤ë§ (ìµœì í™”ëœ ë²„ì „)\"\"\"\n",
    "    main_tab = driver.current_window_handle\n",
    "\n",
    "    try:\n",
    "        # ğŸš€ ìƒˆ íƒ­ì—ì„œ ìƒí’ˆ í˜ì´ì§€ ì—´ê¸° (ë’¤ë¡œê°€ê¸° ëŒ€ì‹ )\n",
    "        driver.execute_script(\"window.open('');\")\n",
    "        driver.switch_to.window(driver.window_handles[-1])\n",
    "\n",
    "        # ìƒí’ˆ í˜ì´ì§€ ì´ë™\n",
    "        driver.get(product_url)\n",
    "\n",
    "        # ğŸš€ ë™ì  ëŒ€ê¸°ì‹œê°„ ì ìš© (ê¸°ì¡´ 7-15ì´ˆ â†’ 2-4ì´ˆ)\n",
    "        timeout = CONFIG.get(\"PAGE_LOAD_TIMEOUT\", 6)\n",
    "        if not smart_wait_for_page_load(driver, max_wait=timeout):\n",
    "            print(f\"      âš ï¸ í˜ì´ì§€ ë¡œë”© ì‹œê°„ ì´ˆê³¼, ê³„ì† ì§„í–‰\")\n",
    "\n",
    "        # URL íƒ€ì… íŒë³„\n",
    "        url_type = \"Product\" if \"/products/\" in product_url else \"Offer\"\n",
    "\n",
    "        # ì •ë³´ ìˆ˜ì§‘ (ê¸°ì¡´ í•¨ìˆ˜ë“¤ í™œìš©)\n",
    "        product_name = get_product_name(driver, url_type)\n",
    "        price_raw = get_price(driver)\n",
    "        price_clean = clean_price(price_raw)\n",
    "        rating_raw = get_rating(driver)\n",
    "        rating_clean = clean_rating(rating_raw)\n",
    "        review_count = get_review_count(driver)\n",
    "        language = get_language(driver)\n",
    "\n",
    "        # ë„ì‹œID ìƒì„±\n",
    "        city_code = get_city_code(city_name)\n",
    "        city_id = f\"{city_code}_{product_number}\"\n",
    "\n",
    "        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ\n",
    "        if CONFIG.get(\"SAVE_IMAGES\", False):\n",
    "            img_info = download_image(driver, product_name, city_name, product_number)\n",
    "        else:\n",
    "            img_info = {\n",
    "                'filename': '', 'relative_path': '', 'path': '',\n",
    "                'status': 'skipped', 'size': 0\n",
    "            }\n",
    "\n",
    "        # ê²°ê³¼ ë°ì´í„° ìƒì„±\n",
    "        result = {\n",
    "            'ë²ˆí˜¸': product_number,\n",
    "            'ë„ì‹œID': city_id,\n",
    "            'í˜ì´ì§€': page_num,\n",
    "            'ëŒ€ë¥™': continent,\n",
    "            'êµ­ê°€': country,\n",
    "            'ë„ì‹œ': city_name,\n",
    "            'ê³µí•­ì½”ë“œ': city_code,\n",
    "            'ìƒí’ˆíƒ€ì…': url_type,\n",
    "            'ìƒí’ˆëª…': product_name,\n",
    "            'ê°€ê²©_ì›ë³¸': price_raw,\n",
    "            'ê°€ê²©_ì •ì œ': price_clean,\n",
    "            'í‰ì _ì›ë³¸': rating_raw,\n",
    "            'í‰ì _ì •ì œ': rating_clean,\n",
    "            'ë¦¬ë·°ìˆ˜': review_count,\n",
    "            'ì–¸ì–´': language,\n",
    "            'ì´ë¯¸ì§€_íŒŒì¼ëª…': img_info.get('filename', ''),\n",
    "            'ì´ë¯¸ì§€_ìƒëŒ€ê²½ë¡œ': img_info.get('relative_path', ''),\n",
    "            'ì´ë¯¸ì§€_ì „ì²´ê²½ë¡œ': img_info.get('path', ''),\n",
    "            'ì´ë¯¸ì§€_ìƒíƒœ': img_info.get('status', ''),\n",
    "            'ì´ë¯¸ì§€_í¬ê¸°': img_info.get('size', 0),\n",
    "            'URL': product_url,\n",
    "            'ìˆ˜ì§‘_ì‹œê°„': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'ìƒíƒœ': 'ì™„ì „ìˆ˜ì§‘'\n",
    "        }\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"      âŒ ìƒí’ˆ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "    finally:\n",
    "        # ğŸš€ ìƒˆ íƒ­ ë‹«ê¸° ë° ë©”ì¸ íƒ­ìœ¼ë¡œ ë³µê·€ (ë’¤ë¡œê°€ê¸° ëŒ€ì‹ )\n",
    "        try:\n",
    "            driver.close()\n",
    "            driver.switch_to.window(main_tab)\n",
    "            # ì¶”ê°€ ëŒ€ê¸° ì—†ì´ ë°”ë¡œ ë‹¤ìŒ ìƒí’ˆ ì§„í–‰ (ì‹œê°„ ì ˆì•½)\n",
    "        except Exception:\n",
    "            try:\n",
    "                driver.switch_to.window(main_tab)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "def crawl_single_product_with_stable_new_tab(driver, product_url, product_number, city_name,\n",
    "                                             continent, country, page_num):\n",
    "      \"\"\"ğŸ›¡ï¸ ì„¸ì…˜ ì•ˆì •ì„±ì´ ê°•í™”ëœ ìƒˆ íƒ­ í¬ë¡¤ë§ í•¨ìˆ˜ (ê¸°ì¡´ ì½”ë“œ 100% í˜¸í™˜)\"\"\"\n",
    "      main_tab = driver.current_window_handle\n",
    "      new_tab = None\n",
    "\n",
    "      try:\n",
    "          # ğŸ”¹ 1ë‹¨ê³„: ì„¸ì…˜ ìœ íš¨ì„± ì‚¬ì „ ê²€ì¦\n",
    "          try:\n",
    "              driver.current_url  # ì„¸ì…˜ ìƒíƒœ í™•ì¸\n",
    "              driver.title       # ì¶”ê°€ ê²€ì¦\n",
    "          except Exception as e:\n",
    "              print(f\"      ğŸš¨ ì„¸ì…˜ ë¬´íš¨: {e}\")\n",
    "              return None\n",
    "\n",
    "          # ğŸ”¹ 2ë‹¨ê³„: ì•ˆì „í•œ ìƒˆ íƒ­ ìƒì„± (3íšŒ ì‹œë„)\n",
    "          for tab_attempt in range(3):\n",
    "              try:\n",
    "                  driver.execute_script(\"window.open('');\")\n",
    "                  all_tabs = driver.window_handles\n",
    "\n",
    "                  if len(all_tabs) > 1:  # ê°œì„ : ë‹¨ìˆœí™”\n",
    "                      new_tab = all_tabs[-1]\n",
    "                      driver.switch_to.window(new_tab)\n",
    "                      print(f\"      âœ… ìƒˆ íƒ­ ìƒì„± ì„±ê³µ (ì‹œë„ {tab_attempt + 1})\")\n",
    "                      break\n",
    "                  else:\n",
    "                      print(f\"      âš ï¸ ìƒˆ íƒ­ ìƒì„± ì‹¤íŒ¨ (ì‹œë„ {tab_attempt + 1})\")\n",
    "\n",
    "              except Exception as e:\n",
    "                  print(f\"      âŒ íƒ­ ìƒì„± ì˜¤ë¥˜ {tab_attempt + 1}: {e}\")\n",
    "                  if tab_attempt < 2:\n",
    "                      time.sleep(1)\n",
    "                      continue\n",
    "                  else:\n",
    "                      return None\n",
    "\n",
    "          if not new_tab:\n",
    "              print(f\"      ğŸš¨ ìƒˆ íƒ­ ìƒì„± ìµœì¢… ì‹¤íŒ¨\")\n",
    "              return None\n",
    "\n",
    "          # ğŸ”¹ 3ë‹¨ê³„: ìƒí’ˆ í˜ì´ì§€ ë¡œë“œ (ì•ˆì •ì„± ê°•í™”)\n",
    "          load_success = False\n",
    "          for load_attempt in range(3):\n",
    "              try:\n",
    "                  driver.get(product_url)\n",
    "\n",
    "                  # í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ ëŒ€ê¸° (ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ í˜¸í™˜)\n",
    "                  timeout = CONFIG.get(\"PAGE_LOAD_TIMEOUT\", 6)\n",
    "                  if not smart_wait_for_page_load(driver, max_wait=timeout):\n",
    "                      print(f\"      âš ï¸ í˜ì´ì§€ ë¡œë”© ì‹œê°„ ì´ˆê³¼, ê³„ì† ì§„í–‰\")\n",
    "\n",
    "                  # í˜ì´ì§€ ì•ˆì •í™” ëŒ€ê¸° ì¶”ê°€\n",
    "                  time.sleep(random.uniform(1, 2))\n",
    "\n",
    "                  # ì„¸ì…˜ ìœ íš¨ì„± ì¬í™•ì¸ (offers í¬í•¨)\n",
    "                  current_url = driver.current_url\n",
    "                  if (product_url in current_url or\n",
    "                      \"products\" in current_url or\n",
    "                      \"offers\" in current_url):\n",
    "                      load_success = True\n",
    "                      print(f\"      âœ… í˜ì´ì§€ ë¡œë“œ ì„±ê³µ (ì‹œë„ {load_attempt + 1})\")\n",
    "                      break\n",
    "                  else:\n",
    "                      print(f\"      âš ï¸ í˜ì´ì§€ ë¡œë“œ ì˜ì‹¬ (ì‹œë„ {load_attempt + 1}): {current_url}\")\n",
    "\n",
    "              except Exception as e:\n",
    "                  print(f\"      âŒ í˜ì´ì§€ ë¡œë“œ ì˜¤ë¥˜ {load_attempt + 1}: {e}\")\n",
    "                  if load_attempt < 2:\n",
    "                      time.sleep(2)\n",
    "                      continue\n",
    "\n",
    "          if not load_success:\n",
    "              print(f\"      ğŸš¨ í˜ì´ì§€ ë¡œë“œ ìµœì¢… ì‹¤íŒ¨\")\n",
    "              return None\n",
    "\n",
    "          # ğŸ”¹ 4ë‹¨ê³„: ë°ì´í„° ìˆ˜ì§‘ (ê¸°ì¡´ ë¡œì§ 100% í™œìš©)\n",
    "          try:\n",
    "              # URL íƒ€ì… íŒë³„ (ê¸°ì¡´ê³¼ ë™ì¼)\n",
    "              url_type = \"Product\" if \"/products/\" in product_url else \"Offer\"\n",
    "\n",
    "              # ì •ë³´ ìˆ˜ì§‘ (ê¸°ì¡´ í•¨ìˆ˜ë“¤ ê·¸ëŒ€ë¡œ ì‚¬ìš©)\n",
    "              product_name = get_product_name(driver, url_type)\n",
    "              price_raw = get_price(driver)\n",
    "              price_clean = clean_price(price_raw)\n",
    "              rating_raw = get_rating(driver)\n",
    "              rating_clean = clean_rating(rating_raw)\n",
    "              review_count = get_review_count(driver)\n",
    "              language = get_language(driver)\n",
    "\n",
    "              # ë„ì‹œID ìƒì„± (ê¸°ì¡´ê³¼ ë™ì¼)\n",
    "              city_code = get_city_code(city_name)\n",
    "              city_id = f\"{city_code}_{product_number}\"\n",
    "\n",
    "              # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ê¸°ì¡´ ì‹œìŠ¤í…œ í˜¸í™˜)\n",
    "              if CONFIG.get(\"SAVE_IMAGES\", False):\n",
    "                  img_info = download_image(driver, product_name, city_name, product_number)\n",
    "              else:\n",
    "                  img_info = {\n",
    "                      'filename': '', 'relative_path': '', 'path': '',\n",
    "                      'status': 'skipped', 'size': 0\n",
    "                  }\n",
    "\n",
    "              print(f\"      âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {product_name[:30]}...\")\n",
    "\n",
    "          except Exception as e:\n",
    "              print(f\"      âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}\")\n",
    "              return None\n",
    "\n",
    "          # ğŸ”¹ 5ë‹¨ê³„: ê²°ê³¼ ë°ì´í„° ìƒì„± (ê¸°ì¡´ êµ¬ì¡° 100% ìœ ì§€)\n",
    "          result = {\n",
    "              'ë²ˆí˜¸': product_number,\n",
    "              'ë„ì‹œID': city_id,\n",
    "              'í˜ì´ì§€': page_num,\n",
    "              'ëŒ€ë¥™': continent,\n",
    "              'êµ­ê°€': country,\n",
    "              'ë„ì‹œ': city_name,\n",
    "              'ê³µí•­ì½”ë“œ': city_code,\n",
    "              'ìƒí’ˆíƒ€ì…': url_type,\n",
    "              'ìƒí’ˆëª…': product_name,\n",
    "              'ê°€ê²©_ì›ë³¸': price_raw,\n",
    "              'ê°€ê²©_ì •ì œ': price_clean,\n",
    "              'í‰ì _ì›ë³¸': rating_raw,\n",
    "              'í‰ì _ì •ì œ': rating_clean,\n",
    "              'ë¦¬ë·°ìˆ˜': review_count,\n",
    "              'ì–¸ì–´': language,\n",
    "              'ì´ë¯¸ì§€_íŒŒì¼ëª…': img_info.get('filename', ''),\n",
    "              'ì´ë¯¸ì§€_ìƒëŒ€ê²½ë¡œ': img_info.get('relative_path', ''),\n",
    "              'ì´ë¯¸ì§€_ì „ì²´ê²½ë¡œ': img_info.get('path', ''),\n",
    "              'ì´ë¯¸ì§€_ìƒíƒœ': img_info.get('status', ''),\n",
    "              'ì´ë¯¸ì§€_í¬ê¸°': img_info.get('size', 0),\n",
    "              'URL': product_url,\n",
    "              'ìˆ˜ì§‘_ì‹œê°„': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "              'ìƒíƒœ': 'ì™„ì „ìˆ˜ì§‘'\n",
    "          }\n",
    "\n",
    "          return result\n",
    "\n",
    "      except Exception as e:\n",
    "          print(f\"      ğŸš¨ í¬ë¡¤ë§ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}\")\n",
    "          return None\n",
    "\n",
    "      finally:\n",
    "          # ğŸ”¹ 6ë‹¨ê³„: ì•ˆì „í•œ íƒ­ ì •ë¦¬ ë° ë©”ì¸ íƒ­ ë³µê·€\n",
    "          try:\n",
    "              if new_tab:\n",
    "                  # ìƒˆ íƒ­ì´ ì—¬ì „íˆ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "                  current_tabs = driver.window_handles\n",
    "                  if new_tab in current_tabs:\n",
    "                      try:\n",
    "                          driver.switch_to.window(new_tab)\n",
    "                          driver.close()\n",
    "                          print(f\"      ğŸ—‘ï¸ ìƒˆ íƒ­ ì •ë¦¬ ì™„ë£Œ\")\n",
    "                      except Exception:\n",
    "                          print(f\"      âš ï¸ ìƒˆ íƒ­ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ)\")\n",
    "\n",
    "              # ë©”ì¸ íƒ­ìœ¼ë¡œ ì•ˆì „ ë³µê·€\n",
    "              if main_tab in driver.window_handles:\n",
    "                  driver.switch_to.window(main_tab)\n",
    "                  print(f\"      ğŸ”™ ë©”ì¸ íƒ­ ë³µê·€ ì™„ë£Œ\")\n",
    "              else:\n",
    "                  # ë©”ì¸ íƒ­ì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ íƒ­ìœ¼ë¡œ\n",
    "                  remaining_tabs = driver.window_handles\n",
    "                  if remaining_tabs:\n",
    "                      driver.switch_to.window(remaining_tabs[0])\n",
    "                      print(f\"      ğŸ”„ ì²« ë²ˆì§¸ íƒ­ìœ¼ë¡œ ë³µê·€\")\n",
    "\n",
    "              # ë©”ëª¨ë¦¬ ì •ë¦¬ë¥¼ ìœ„í•œ ì§§ì€ ëŒ€ê¸° (ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ í˜¸í™˜)\n",
    "              time.sleep(0.5)\n",
    "\n",
    "          except Exception as cleanup_error:\n",
    "              print(f\"      âš ï¸ íƒ­ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {cleanup_error}\")\n",
    "              # ì •ë¦¬ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰ (ê¸°ì¡´ ë™ì‘ ìœ ì§€)            \n",
    "\n",
    "\n",
    "def crawl_single_product_new_tab_method(driver, product_url, product_number, city_name, \n",
    "                                      continent, country, page_num):\n",
    "    \"\"\"ìµœì í™”ëœ ë‹¨ì¼ ìƒí’ˆ í¬ë¡¤ë§ - ìƒˆ íƒ­ ë°©ì‹ ì‚¬ìš© (ê¸°ì¡´ í•¨ìˆ˜ëª… ì¶©ëŒ ë°©ì§€)\"\"\"\n",
    "    return crawl_single_product_with_new_tab(\n",
    "        driver, product_url, product_number, city_name, continent, country, page_num\n",
    "    )\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ”§ í˜ì´ì§€ ë¡œë”© ìµœì í™” ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤\n",
    "# =============================================================================\n",
    "\n",
    "def wait_for_page_ready(driver, timeout=10):\n",
    "    \"\"\"í˜ì´ì§€ê°€ ì™„ì „íˆ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°\"\"\"\n",
    "    try:\n",
    "        WebDriverWait(driver, timeout).until(\n",
    "            lambda d: d.execute_script(\"return document.readyState\") == \"complete\"\n",
    "        )\n",
    "        return True\n",
    "    except TimeoutException:\n",
    "        print(f\"      âš ï¸ í˜ì´ì§€ ì¤€ë¹„ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼ ({timeout}ì´ˆ)\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"      âŒ í˜ì´ì§€ ì¤€ë¹„ í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def adaptive_wait(base_time=2):\n",
    "    \"\"\"ì ì‘í˜• ëŒ€ê¸° ì‹œê°„ (ì‹œìŠ¤í…œ ë¶€í•˜ì— ë”°ë¼ ì¡°ì •)\"\"\"\n",
    "    # CONFIGì—ì„œ ì„¤ì •ëœ ë²”ìœ„ ë‚´ì—ì„œ ëœë¤ ëŒ€ê¸°\n",
    "    min_delay = CONFIG.get(\"SHORT_MIN_DELAY\", 0.2)\n",
    "    max_delay = CONFIG.get(\"SHORT_MAX_DELAY\", 0.5)\n",
    "    \n",
    "    # ê¸°ë³¸ ì‹œê°„ì— ëœë¤ ìš”ì†Œ ì¶”ê°€\n",
    "    wait_time = base_time + random.uniform(min_delay, max_delay)\n",
    "    time.sleep(wait_time)\n",
    "    return wait_time\n",
    "\n",
    "\n",
    "def safe_tab_operation(driver, operation_func, *args, **kwargs):\n",
    "    \"\"\"ì•ˆì „í•œ íƒ­ ì‘ì—… ìˆ˜í–‰ (ì—ëŸ¬ ë³µêµ¬ í¬í•¨)\"\"\"\n",
    "    main_tab = driver.current_window_handle\n",
    "    \n",
    "    try:\n",
    "        result = operation_func(*args, **kwargs)\n",
    "        return True, result\n",
    "    except Exception as e:\n",
    "        print(f\"      âŒ íƒ­ ì‘ì—… ì‹¤íŒ¨: {e}\")\n",
    "        try:\n",
    "            # ë©”ì¸ íƒ­ìœ¼ë¡œ ë³µê·€ ì‹œë„\n",
    "            driver.switch_to.window(main_tab)\n",
    "            return False, f\"íƒ­ ì‘ì—… ì‹¤íŒ¨: {e}\"\n",
    "        except Exception as recovery_error:\n",
    "            print(f\"      ğŸš¨ íƒ­ ë³µêµ¬ë„ ì‹¤íŒ¨: {recovery_error}\")\n",
    "            return False, f\"íƒ­ ë³µêµ¬ ì‹¤íŒ¨: {recovery_error}\"\n",
    "        \n",
    "def human_like_scroll_patterns(driver):\n",
    "    \"\"\"ğŸ­ ìˆœìˆ˜ ìŠ¤í¬ë¡¤ íŒ¨í„´ë§Œ (ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ì¤‘ë³µ ì—†ìŒ)\"\"\"\n",
    "    patterns = [\"smooth_reading\", \"comparison_scroll\", \"quick_scan\"]\n",
    "    selected = random.choice(patterns)\n",
    "    print(f\"  ğŸ­ ìŠ¤í¬ë¡¤ íŒ¨í„´: {selected}\")\n",
    "\n",
    "    try:\n",
    "        if selected == \"smooth_reading\":\n",
    "            for i in range(3, 6):\n",
    "                scroll_amount = random.randint(250, 500)\n",
    "                driver.execute_script(f\"window.scrollBy(0, {scroll_amount});\")\n",
    "                time.sleep(random.uniform(0.5, 2.0))\n",
    "\n",
    "        elif selected == \"comparison_scroll\":\n",
    "            for i in range(2, 4):\n",
    "                down_amount = random.randint(400, 700)\n",
    "                driver.execute_script(f\"window.scrollBy(0, {down_amount});\")\n",
    "                time.sleep(random.uniform(0.5, 2.0))\n",
    "\n",
    "                up_amount = random.randint(100, 300)\n",
    "                driver.execute_script(f\"window.scrollBy(0, -{up_amount});\")\n",
    "                time.sleep(random.uniform(0.5, 2.0))\n",
    "\n",
    "        elif selected == \"quick_scan\":\n",
    "            for i in range(4, 8):\n",
    "                scroll_amount = random.randint(300, 600)\n",
    "                driver.execute_script(f\"window.scrollBy(0, {scroll_amount});\")\n",
    "                time.sleep(random.uniform(0.25, 1.0))\n",
    "\n",
    "        print(f\"  âœ… ìŠ¤í¬ë¡¤ ì™„ë£Œ\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸ ìŠ¤í¬ë¡¤ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "\n",
    "def enhanced_scroll_patterns(driver):\n",
    "    \"\"\"ğŸ­ í–¥ìƒëœ 5ê°€ì§€ ìŠ¤í¬ë¡¤ íŒ¨í„´ (í˜¸í™˜ì„± ê°œì„  ë²„ì „)\"\"\"\n",
    "    patterns = [\n",
    "        \"natural_reading\",      # ìì—°ìŠ¤ëŸ¬ìš´ ì½ê¸°\n",
    "        \"search_and_compare\",   # ê²€ìƒ‰í•˜ê³  ë¹„êµí•˜ê¸°\n",
    "        \"rapid_overview\",       # ë¹ ë¥¸ ê°œìš” íŒŒì•…\n",
    "        \"detailed_inspection\",  # ìì„¸í•œ ê²€ì‚¬\n",
    "        \"hesitant_browsing\"     # ë§ì„¤ì´ë©° íƒìƒ‰\n",
    "    ]\n",
    "\n",
    "    selected = random.choice(patterns)\n",
    "    print(f\"  ğŸ­ í–¥ìƒëœ ìŠ¤í¬ë¡¤ íŒ¨í„´: {selected}\")\n",
    "\n",
    "    try:\n",
    "        if selected == \"natural_reading\":\n",
    "            # ìì—°ìŠ¤ëŸ¬ìš´ ì½ê¸° íŒ¨í„´ - ì¼ì •í•œ ì†ë„ë¡œ ì•„ë˜ë¡œ\n",
    "            for i in range(4, 7):\n",
    "                scroll_amount = random.randint(200, 400)\n",
    "                driver.execute_script(f\"window.scrollBy(0, {scroll_amount});\")\n",
    "\n",
    "                # ì½ê¸° ì‹œê°„ - ë‚´ìš©ì— ë”°ë¼ ë‹¤ë¦„\n",
    "                reading_time = random.uniform(1.5, 3.5)\n",
    "                time.sleep(reading_time)\n",
    "\n",
    "                # ê°€ë” ì¡°ê¸ˆ ìœ„ë¡œ ë˜ëŒì•„ê°€ê¸° (ì¬í™•ì¸)\n",
    "                if random.random() < 0.3:\n",
    "                    back_scroll = random.randint(50, 150)\n",
    "                    driver.execute_script(f\"window.scrollBy(0, -{back_scroll});\")\n",
    "                    time.sleep(random.uniform(0.5, 1.0))\n",
    "\n",
    "        elif selected == \"search_and_compare\":\n",
    "            # íŠ¹ì • í•­ëª©ì„ ì°¾ê³  ë¹„êµí•˜ëŠ” íŒ¨í„´\n",
    "            for i in range(3, 6):\n",
    "                # ë¹ ë¥´ê²Œ ìŠ¤í¬ë¡¤í•´ì„œ í›‘ì–´ë³´ê¸°\n",
    "                fast_scroll = random.randint(500, 800)\n",
    "                driver.execute_script(f\"window.scrollBy(0, {fast_scroll});\")\n",
    "                time.sleep(random.uniform(0.8, 1.5))\n",
    "\n",
    "                # ê´€ì‹¬ ìˆëŠ” ë¶€ë¶„ì—ì„œ ë©ˆì¶°ì„œ ìì„¸íˆ ë³´ê¸°\n",
    "                if random.random() < 0.6:\n",
    "                    # ìœ„ë¡œ ì¡°ê¸ˆ ë˜ëŒì•„ê°€ì„œ ë‹¤ì‹œ ë³´ê¸°\n",
    "                    back_amount = random.randint(200, 400)\n",
    "                    driver.execute_script(f\"window.scrollBy(0, -{back_amount});\")\n",
    "                    time.sleep(random.uniform(2.0, 4.0))  # ë¹„êµ ê²€í†  ì‹œê°„\n",
    "\n",
    "                    # ë‹¤ì‹œ ì•„ë˜ë¡œ ì¡°ê¸ˆ\n",
    "                    forward_amount = random.randint(100, 300)\n",
    "                    driver.execute_script(f\"window.scrollBy(0, {forward_amount});\")\n",
    "                    time.sleep(random.uniform(1.0, 2.0))\n",
    "\n",
    "        elif selected == \"rapid_overview\":\n",
    "            # ë¹ ë¥¸ ê°œìš” íŒŒì•… - ì „ì²´ì ìœ¼ë¡œ í›‘ì–´ë³´ê¸°\n",
    "            for i in range(6, 10):\n",
    "                scroll_amount = random.randint(400, 700)\n",
    "                driver.execute_script(f\"window.scrollBy(0, {scroll_amount});\")\n",
    "                time.sleep(random.uniform(0.3, 0.8))  # ì§§ì€ ì •ì§€\n",
    "\n",
    "        elif selected == \"detailed_inspection\":\n",
    "            # ìì„¸í•œ ê²€ì‚¬ - ì²œì²œíˆ ê¼¼ê¼¼íˆ\n",
    "            for i in range(3, 5):\n",
    "                small_scroll = random.randint(150, 300)\n",
    "                driver.execute_script(f\"window.scrollBy(0, {small_scroll});\")\n",
    "\n",
    "                # ê¸´ ê²€í†  ì‹œê°„\n",
    "                inspection_time = random.uniform(3.0, 6.0)\n",
    "                time.sleep(inspection_time)\n",
    "\n",
    "                # ğŸ”§ í˜¸í™˜ì„± ê°œì„ : ë³µì¡í•œ ë§ˆìš°ìŠ¤ ì´ë²¤íŠ¸ ì œê±°\n",
    "                # ê°„ë‹¨í•œ ë§ˆìš°ìŠ¤ ì›€ì§ì„ë§Œ ì‹œë®¬ë ˆì´ì…˜\n",
    "                if random.random() < 0.5:  # 50%ë¡œ í™•ë¥  ë‚®ì¶¤\n",
    "                    try:\n",
    "                        driver.execute_script(\"\"\"\n",
    "                            var event = new MouseEvent('mousemove', {\n",
    "                                clientX: Math.random() * 500,\n",
    "                                clientY: Math.random() * 300\n",
    "                            });\n",
    "                            document.dispatchEvent(event);\n",
    "                        \"\"\")\n",
    "                        time.sleep(random.uniform(0.5, 1.0))\n",
    "                    except:\n",
    "                        pass  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¬´ì‹œ\n",
    "\n",
    "        elif selected == \"hesitant_browsing\":\n",
    "            # ë§ì„¤ì´ë©° íƒìƒ‰í•˜ëŠ” íŒ¨í„´\n",
    "            for i in range(4, 8):\n",
    "                # ì¡°ê¸ˆ ìŠ¤í¬ë¡¤\n",
    "                hesitant_scroll = random.randint(200, 400)\n",
    "                driver.execute_script(f\"window.scrollBy(0, {hesitant_scroll});\")\n",
    "                time.sleep(random.uniform(1.0, 2.0))\n",
    "\n",
    "                # 50% í™•ë¥ ë¡œ ë˜ëŒì•„ê°€ê¸°\n",
    "                if random.random() < 0.5:\n",
    "                    back_amount = random.randint(100, 200)\n",
    "                    driver.execute_script(f\"window.scrollBy(0, -{back_amount});\")\n",
    "                    time.sleep(random.uniform(0.8, 1.5))\n",
    "\n",
    "                    # ë‹¤ì‹œ ì•ìœ¼ë¡œ ì§„í–‰\n",
    "                    forward_again = random.randint(150, 350)\n",
    "                    driver.execute_script(f\"window.scrollBy(0, {forward_again});\")\n",
    "                    time.sleep(random.uniform(1.2, 2.5))\n",
    "\n",
    "        print(f\"  âœ… í–¥ìƒëœ ìŠ¤í¬ë¡¤ ì™„ë£Œ\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸ í–¥ìƒëœ ìŠ¤í¬ë¡¤ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "\n",
    "def smart_scroll_selector(driver):\n",
    "    \"\"\"ğŸ¯ ìŠ¤ë§ˆíŠ¸ ìŠ¤í¬ë¡¤ ì„ íƒê¸° - ë‘ í•¨ìˆ˜ ì¤‘ ëœë¤ ì„ íƒ\"\"\"\n",
    "    scroll_functions = [\n",
    "        (\"ê¸°ë³¸ íŒ¨í„´\", human_like_scroll_patterns),\n",
    "        (\"í–¥ìƒëœ íŒ¨í„´\", enhanced_scroll_patterns)\n",
    "    ]\n",
    "\n",
    "    selected_name, selected_function = random.choice(scroll_functions)\n",
    "    print(f\"  ğŸ² ì„ íƒëœ ìŠ¤í¬ë¡¤: {selected_name}\")\n",
    "    selected_function(driver)\n",
    "\n",
    "\n",
    "print(\"âœ… ê·¸ë£¹ 5 ì™„ë£Œ: ë¸Œë¼ìš°ì € ì œì–´ ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ì •ì˜ ì™„ë£Œ!\")\n",
    "print(\"   - setup_driver(): í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì •\")\n",
    "print(\"   - go_to_main_page(): ë©”ì¸ í˜ì´ì§€ ì´ë™\")\n",
    "print(\"   - find_and_fill_search(): ê²€ìƒ‰ì°½ ì…ë ¥\")\n",
    "print(\"   - click_search_button(): ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­\")\n",
    "print(\"   - handle_popup(): íŒì—… ì²˜ë¦¬\")\n",
    "print(\"   - click_view_all(): ì „ì²´ ìƒí’ˆ ë³´ê¸°\")\n",
    "print(\"   - safe_browser_restart(): ì•ˆì „í•œ ë¸Œë¼ìš°ì € ì¬ì‹œì‘\")\n",
    "print(\"   - return_to_current_page(): í˜ì´ì§€ ë³µê·€\")\n",
    "print(\"   - human_like_scroll_patterns(): ìì—°ìŠ¤ëŸ¬ìš´ ìŠ¤í¬ë¡¤\")  # ğŸ†• ì¶”ê°€\n",
    "print(\"   - smart_scroll_selector(): ìŠ¤ë§ˆíŠ¸ ìŠ¤í¬ë¡¤ ì„ íƒ\")     # ğŸ†• ì¶”ê°€\n",
    "\n",
    "# ğŸ†• í˜ì´ì§€ ìµœì í™” í•¨ìˆ˜ë“¤ ì¶”ê°€\n",
    "print(\"   âš¡ smart_wait_for_page_load(): ë™ì  ëŒ€ê¸°ì‹œê°„\")\n",
    "print(\"   âš¡ crawl_single_product_with_new_tab(): ìƒˆ íƒ­ í™œìš© í¬ë¡¤ë§\")\n",
    "print(\"   âš¡ crawl_single_product_new_tab_method(): ìµœì í™”ëœ í¬ë¡¤ë§ (ì¶©ëŒë°©ì§€)\")\n",
    "print(\"   âš¡ wait_for_page_ready(): í˜ì´ì§€ ì¤€ë¹„ ëŒ€ê¸°\")\n",
    "print(\"   âš¡ adaptive_wait(): ì ì‘í˜• ëŒ€ê¸° ì‹œê°„\")\n",
    "print(\"   âš¡ safe_tab_operation(): ì•ˆì „í•œ íƒ­ ì‘ì—…\")\n",
    "# ê¸°ì¡´ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤\n",
    "print(\"   - print_progress(): ì§„í–‰ë¥  í‘œì‹œ\")\n",
    "print(\"   - retry_operation(): ì¬ì‹œë„ ë¡œì§\")\n",
    "print(\"   - make_safe_filename(): ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "86fa1b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ í¬ë¡¤ë§ ì‹œìŠ¤í…œ ì‹œì‘!\n",
      "================================================================================\n",
      "ğŸ”„ ê²°ê³¼ ì €ì¥ì†Œ ì´ˆê¸°í™” ì™„ë£Œ\n",
      "ğŸ†• ìƒˆë¡œìš´ ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì¤‘...\n",
      "âœ… í¬ë¡¬ ë“œë¼ì´ë²„ ì‹¤í–‰ ì„±ê³µ!\n",
      "Windows\n",
      "Windows\n",
      "âœ… ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì™„ë£Œ!\n",
      "ğŸ“ ì´ë¯¸ì§€ í´ë” í™•ì¸ ì™„ë£Œ (ê¸°ì¡´ ì´ë¯¸ì§€ ì—°ì†ì„± ë³´ì¥): c:\\Users\\redsk\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\mikael_project\\test_folder\\myrealtripthumb_img\n",
      "============================================================\n",
      "ğŸŒ ì„¤ì •ëœ ê²€ìƒ‰ ë„ì‹œ: í›„ì¿ ì˜¤ì¹´\n",
      "  ğŸŒ ëŒ€ë¥™: ì•„ì‹œì•„\n",
      "  ğŸ›ï¸ êµ­ê°€: ì¼ë³¸\n",
      "  âœˆï¸ ê³µí•­ ì½”ë“œ: FUK\n",
      "âš™ï¸ í¬ë¡¤ë§ ì„¤ì •:\n",
      "  ğŸ“Š ìµœëŒ€ ìƒí’ˆ ìˆ˜: 1ê°œ\n",
      "  â±ï¸ ì¬ì‹œë„ íšŸìˆ˜: 3íšŒ\n",
      "  ğŸ”„ ëŒ€ê¸° ì‹œê°„: 7-15ì´ˆ\n",
      "  ğŸ–¼ï¸ ì´ë¯¸ì§€ ì €ì¥: âœ… í™œì„±í™”\n",
      "============================================================\n",
      "âœ… ë„ì‹œ ìœ íš¨ì„± ê²€ì¦: ì§€ì›í•˜ëŠ” ë„ì‹œì…ë‹ˆë‹¤. (FUK)\n",
      "ğŸ“ ë°ì´í„° ì €ì¥ ê²½ë¡œ ìƒì„± ì™„ë£Œ: data\\ì•„ì‹œì•„\\ì¼ë³¸\\í›„ì¿ ì˜¤ì¹´\n",
      "ğŸ“ êµ­ê°€ë³„ í†µí•© ê²½ë¡œ ìƒì„± ì™„ë£Œ: data\\ì•„ì‹œì•„\\ì¼ë³¸\n",
      "\n",
      "ğŸ”„ ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...\n",
      "âœ… ìƒíƒœ íŒŒì¼ ë¡œë“œ: 0ê°œ ìˆ˜ì§‘ ì™„ë£Œ\n",
      "âœ… completed_urls.log ì •ë¦¬ ì™„ë£Œ: 4ê°œ ê³ ìœ  URL\n",
      "âœ… ì™„ë£Œëœ URL 4ê°œ ë¡œë“œ\n",
      "âœ… ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ\n",
      "  ğŸ“Š ì´ì „ ìˆ˜ì§‘ ì™„ë£Œ: 0ê°œ\n",
      "  ğŸ“ ì™„ë£Œëœ URL: 4ê°œ\n",
      "ğŸ“„ ê¸°ì¡´ CSV íŒŒì¼ ì—†ìŒ - 0ë¶€í„° ì‹œì‘\n",
      "ğŸ”¢ ë²ˆí˜¸ ì—°ì†ì„± ì„¤ì • (1ë¶€í„° ì‹œì‘):\n",
      "  ğŸ“Š ê¸°ì¡´ ë§ˆì§€ë§‰ ë²ˆí˜¸: 0\n",
      "  ğŸ†• ì‹œì‘ ë²ˆí˜¸: 1\n",
      "ğŸ“ ì´ë¯¸ì§€ ì €ì¥ ê¸°ë³¸ ê²½ë¡œ: myrealtripthumb_img/ì•„ì‹œì•„/ì¼ë³¸/í›„ì¿ ì˜¤ì¹´/\n",
      "ğŸ“ ë°ì´í„° ì €ì¥ ê²½ë¡œ: data/ì•„ì‹œì•„/ì¼ë³¸/í›„ì¿ ì˜¤ì¹´/\n",
      "ğŸ”¢ ë²ˆí˜¸ ì‹œì‘ì : 1\n",
      "ğŸš€ ë‹¤ìŒ: ê·¸ë£¹ 7ì„ ì‹¤í–‰í•˜ì—¬ ì›¹ì‚¬ì´íŠ¸ ê²€ìƒ‰ì„ ì‹œì‘í•˜ì„¸ìš”!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ğŸš€ ê·¸ë£¹ 6: ë“œë¼ì´ë²„ ì´ˆê¸°í™” ë° ê¸°ë³¸ ì„¤ì •\n",
    "# - ë“œë¼ì´ë²„ ì‹œì‘, ì´ë¯¸ì§€ í´ë” ì„¤ì •, ê¸°ë³¸ í™˜ê²½ êµ¬ì¶•\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸš€ ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ í¬ë¡¤ë§ ì‹œìŠ¤í…œ ì‹œì‘!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥ì†Œ ì´ˆê¸°í™”\n",
    "all_results = []\n",
    "print(\"ğŸ”„ ê²°ê³¼ ì €ì¥ì†Œ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "\n",
    "# ë“œë¼ì´ë²„ ì´ˆê¸°í™”\n",
    "try:\n",
    "    # ê¸°ì¡´ ë“œë¼ì´ë²„ê°€ ìˆë‹¤ë©´ ìƒíƒœ í™•ì¸\n",
    "    try:\n",
    "        current_url = driver.current_url\n",
    "        print(\"âœ… ê¸°ì¡´ ë“œë¼ì´ë²„ ê°ì§€ë¨ - ì¬ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸ ì¤‘...\")\n",
    "        \n",
    "        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¡œ ë“œë¼ì´ë²„ ì‘ë™ í™•ì¸\n",
    "        driver.execute_script(\"return document.readyState;\")\n",
    "        print(\"âœ… ê¸°ì¡´ ë“œë¼ì´ë²„ ì •ìƒ ì‘ë™ ì¤‘! ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "        \n",
    "    except (NameError, WebDriverException):\n",
    "        print(\"ğŸ†• ìƒˆë¡œìš´ ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì¤‘...\")\n",
    "        driver = setup_driver()\n",
    "        print(\"âœ… ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ”„ ë“œë¼ì´ë²„ ì¬ìƒì„± ì‹œë„...\")\n",
    "    try:\n",
    "        driver = setup_driver()\n",
    "        print(\"âœ… ë“œë¼ì´ë²„ ì¬ìƒì„± ì„±ê³µ!\")\n",
    "    except Exception as retry_error:\n",
    "        print(f\"âŒ ë“œë¼ì´ë²„ ì¬ìƒì„±ë„ ì‹¤íŒ¨: {retry_error}\")\n",
    "        raise\n",
    "\n",
    "# âœ… ìˆ˜ì •: ì´ë¯¸ì§€ í´ë” ì—°ì†ì„± í™•ë³´ - ê¸°ì¡´ ì´ë¯¸ì§€ ë³´ì¡´\n",
    "if CONFIG[\"SAVE_IMAGES\"]:\n",
    "    img_folder_path = os.path.join(os.path.abspath(\"\"), \"myrealtripthumb_img\")\n",
    "    # âœ… í•µì‹¬ ìˆ˜ì •: ì´ë¯¸ì§€ í´ë” ì‚­ì œ ì½”ë“œ ì™„ì „ ì œê±° (ë°ì´í„° ì—°ì†ì„± í™•ë³´)\n",
    "    # shutil.rmtree(img_folder_path)  # ì´ ì¤„ì„ ì œê±°í•˜ì—¬ ê¸°ì¡´ ì´ë¯¸ì§€ ë³´ì¡´\n",
    "    os.makedirs(img_folder_path, exist_ok=True)\n",
    "    print(f\"ğŸ“ ì´ë¯¸ì§€ í´ë” í™•ì¸ ì™„ë£Œ (ê¸°ì¡´ ì´ë¯¸ì§€ ì—°ì†ì„± ë³´ì¥): {img_folder_path}\")\n",
    "\n",
    "# ğŸ†• ê·¸ë£¹ 1 ì„¤ì •ì—ì„œ ë„ì‹œ ê°€ì ¸ì˜¤ê¸°\n",
    "if not CITIES_TO_SEARCH:\n",
    "    print(\"âŒ CITIES_TO_SEARCHê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!\")\n",
    "    print(\"ğŸ’¡ ê·¸ë£¹ 1ì—ì„œ CITIES_TO_SEARCH = ['ë„ì‹œëª…']ì„ ì„¤ì •í•˜ì„¸ìš”!\")\n",
    "    raise ValueError(\"ê²€ìƒ‰í•  ë„ì‹œê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤\")\n",
    "\n",
    "city_name = CITIES_TO_SEARCH[0]  # ğŸ†• ì²« ë²ˆì§¸ ë„ì‹œ ì‚¬ìš©\n",
    "continent, country = get_city_info(city_name)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"ğŸŒ ì„¤ì •ëœ ê²€ìƒ‰ ë„ì‹œ: {city_name}\")\n",
    "print(f\"  ğŸŒ ëŒ€ë¥™: {continent}\")\n",
    "print(f\"  ğŸ›ï¸ êµ­ê°€: {country}\")  \n",
    "print(f\"  âœˆï¸ ê³µí•­ ì½”ë“œ: {get_city_code(city_name)}\")\n",
    "print(f\"âš™ï¸ í¬ë¡¤ë§ ì„¤ì •:\")\n",
    "print(f\"  ğŸ“Š ìµœëŒ€ ìƒí’ˆ ìˆ˜: {CONFIG['MAX_PRODUCTS_PER_CITY']}ê°œ\")\n",
    "print(f\"  â±ï¸ ì¬ì‹œë„ íšŸìˆ˜: {CONFIG['RETRY_COUNT']}íšŒ\")\n",
    "print(f\"  ğŸ”„ ëŒ€ê¸° ì‹œê°„: {CONFIG['MEDIUM_MIN_DELAY']}-{CONFIG['MEDIUM_MAX_DELAY']}ì´ˆ\")\n",
    "print(f\"  ğŸ–¼ï¸ ì´ë¯¸ì§€ ì €ì¥: {'âœ… í™œì„±í™”' if CONFIG['SAVE_IMAGES'] else 'âŒ ë¹„í™œì„±í™”'}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ë„ì‹œ ìœ íš¨ì„± ê²€ì¦\n",
    "is_valid, message = validate_city(city_name)\n",
    "if is_valid:\n",
    "    print(f\"âœ… ë„ì‹œ ìœ íš¨ì„± ê²€ì¦: {message}\")\n",
    "else:\n",
    "    print(f\"âš ï¸ ë„ì‹œ ìœ íš¨ì„± ê²½ê³ : {message}\")\n",
    "    print(\"ğŸ’¡ ê³„ì† ì§„í–‰í•˜ì§€ë§Œ ì˜ˆìƒì¹˜ ëª»í•œ ê²°ê³¼ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ë°ì´í„° ì €ì¥ ê²½ë¡œ ë¯¸ë¦¬ ìƒì„±\n",
    "try:\n",
    "    if city_name in [\"ë§ˆì¹´ì˜¤\", \"í™ì½©\", \"ì‹±ê°€í¬ë¥´\"]:\n",
    "        # ë„ì‹œêµ­ê°€: ëŒ€ë¥™ í´ë”ë§Œ ìƒì„±\n",
    "        data_dir = os.path.join(\"data\", continent)\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "        print(f\"ğŸ“ ë„ì‹œêµ­ê°€ ë°ì´í„° ê²½ë¡œ ìƒì„±: {data_dir}\")\n",
    "    else:\n",
    "        # ì¼ë°˜ ë„ì‹œ: ê¸°ì¡´ êµ¬ì¡°\n",
    "        data_dir = os.path.join(\"data\", continent, country, city_name)\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "        print(f\"ğŸ“ ë°ì´í„° ì €ì¥ ê²½ë¡œ ìƒì„± ì™„ë£Œ: {data_dir}\")\n",
    "        \n",
    "        # êµ­ê°€ë³„ í†µí•© í´ë”ë„ ìƒì„±\n",
    "        country_dir = os.path.join(\"data\", continent, country)\n",
    "        os.makedirs(country_dir, exist_ok=True)\n",
    "        print(f\"ğŸ“ êµ­ê°€ë³„ í†µí•© ê²½ë¡œ ìƒì„± ì™„ë£Œ: {country_dir}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ë°ì´í„° í´ë” ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ’¡ í¬ë¡¤ë§ì€ ê³„ì† ì§„í–‰ë˜ì§€ë§Œ ì €ì¥ ì‹œ ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "print(f\"\\nğŸ”„ ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...\")\n",
    "try:\n",
    "    crawler_state, completed_urls = load_crawler_state()\n",
    "    print(f\"âœ… ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ\")\n",
    "    print(f\"  ğŸ“Š ì´ì „ ìˆ˜ì§‘ ì™„ë£Œ: {crawler_state.get('total_collected_count', 0)}ê°œ\")\n",
    "    print(f\"  ğŸ“ ì™„ë£Œëœ URL: {len(completed_urls)}ê°œ\")\n",
    "    \n",
    "    # ğŸ†• ë²ˆí˜¸ ì—°ì†ì„± í™•ë³´: ê¸°ì¡´ CSV ë§ˆì§€ë§‰ ë²ˆí˜¸ í™•ì¸ (1ë¶€í„° ì‹œì‘ ë³´ì¥)\n",
    "    last_product_number = get_last_product_number(city_name)\n",
    "    start_number = max(1, last_product_number + 1)  # ë‹¤ìŒ ë²ˆí˜¸ë¶€í„°, ìµœì†Œ 1 ë³´ì¥\n",
    "\n",
    "    print(f\"ğŸ”¢ ë²ˆí˜¸ ì—°ì†ì„± ì„¤ì • (1ë¶€í„° ì‹œì‘):\")\n",
    "    print(f\"  ğŸ“Š ê¸°ì¡´ ë§ˆì§€ë§‰ ë²ˆí˜¸: {last_product_number}\")\n",
    "    print(f\"  ğŸ†• ì‹œì‘ ë²ˆí˜¸: {start_number}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ’¡ ê¸°ë³¸ ìƒíƒœë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
    "    crawler_state = {\n",
    "        \"total_collected_count\": 0,\n",
    "        \"last_crawled_page\": 1,\n",
    "        \"current_session_start\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"last_updated\": datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    completed_urls = set()\n",
    "    start_number = 0\n",
    "\n",
    "if city_name in [\"ë§ˆì¹´ì˜¤\", \"í™ì½©\", \"ì‹±ê°€í¬ë¥´\"]:\n",
    "    print(f\"ğŸ“ ì´ë¯¸ì§€ ì €ì¥ ê¸°ë³¸ ê²½ë¡œ: myrealtripthumb_img/{continent}/{city_name}/\")\n",
    "    print(f\"ğŸ“ ë°ì´í„° ì €ì¥ ê²½ë¡œ: data/{continent}/\")\n",
    "else:\n",
    "    print(f\"ğŸ“ ì´ë¯¸ì§€ ì €ì¥ ê¸°ë³¸ ê²½ë¡œ: myrealtripthumb_img/{continent}/{country}/{city_name}/\")\n",
    "    print(f\"ğŸ“ ë°ì´í„° ì €ì¥ ê²½ë¡œ: data/{continent}/{country}/{city_name}/\")\n",
    "print(f\"ğŸ”¢ ë²ˆí˜¸ ì‹œì‘ì : {start_number}\")\n",
    "print(\"ğŸš€ ë‹¤ìŒ: ê·¸ë£¹ 7ì„ ì‹¤í–‰í•˜ì—¬ ì›¹ì‚¬ì´íŠ¸ ê²€ìƒ‰ì„ ì‹œì‘í•˜ì„¸ìš”!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cd99f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ê·¸ë£¹ 7: ì›¹ì‚¬ì´íŠ¸ ê²€ìƒ‰ ë° í˜ì´ì§€ ì´ë™ ì‹œì‘!\n",
      "============================================================\n",
      "ğŸ“‹ í˜„ì¬ ì„¤ì • í™•ì¸:\n",
      "  ğŸ™ï¸ ê²€ìƒ‰ ë„ì‹œ: í›„ì¿ ì˜¤ì¹´\n",
      "  ğŸŒ ìœ„ì¹˜: ì•„ì‹œì•„ > ì¼ë³¸\n",
      "  âœˆï¸ ê³µí•­ ì½”ë“œ: FUK\n",
      "  ğŸ”¢ ì‹œì‘ ë²ˆí˜¸: 1\n",
      "\n",
      "ğŸ” ì§„í–‰ë¥ : [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0% (0/1)\n",
      "ğŸ“ í˜„ì¬ ì‘ì—…: í›„ì¿ ì˜¤ì¹´ - ì›¹ì‚¬ì´íŠ¸ ì ‘ì† ì¤‘\n",
      "--------------------------------------------------\n",
      "  ğŸ“± ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ ë©”ì¸ í˜ì´ì§€ ì´ë™ ì¤‘...\n",
      "  âœ… ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ í˜ì´ì§€ ì—´ê¸° ì™„ë£Œ\n",
      "\n",
      "ğŸ” ì§„í–‰ë¥ : [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 25.0% (1/4)\n",
      "ğŸ“ í˜„ì¬ ì‘ì—…: í›„ì¿ ì˜¤ì¹´ - ê²€ìƒ‰ì°½ ì…ë ¥ ì¤‘\n",
      "--------------------------------------------------\n",
      "  ğŸ” 'í›„ì¿ ì˜¤ì¹´' ê²€ìƒ‰ì°½ ì°¾ëŠ” ì¤‘...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ğŸš€ ê·¸ë£¹ 7: ì›¹ì‚¬ì´íŠ¸ ê²€ìƒ‰ ë° í˜ì´ì§€ ì´ë™\n",
    "# - ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ ì‚¬ì´íŠ¸ ì ‘ì†, ë„ì‹œ ê²€ìƒ‰, ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ ë„ë‹¬\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ” ê·¸ë£¹ 7: ì›¹ì‚¬ì´íŠ¸ ê²€ìƒ‰ ë° í˜ì´ì§€ ì´ë™ ì‹œì‘!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ê·¸ë£¹ 6ì—ì„œ ì„¤ì •ëœ ë³€ìˆ˜ë“¤ í™•ì¸\n",
    "try:\n",
    "    print(f\"ğŸ“‹ í˜„ì¬ ì„¤ì • í™•ì¸:\")\n",
    "    print(f\"  ğŸ™ï¸ ê²€ìƒ‰ ë„ì‹œ: {city_name}\")\n",
    "    print(f\"  ğŸŒ ìœ„ì¹˜: {continent} > {country}\")\n",
    "    print(f\"  âœˆï¸ ê³µí•­ ì½”ë“œ: {get_city_code(city_name)}\")\n",
    "    print(f\"  ğŸ”¢ ì‹œì‘ ë²ˆí˜¸: {start_number}\")\n",
    "except NameError as e:\n",
    "    print(f\"âŒ ê·¸ë£¹ 6ì´ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}\")\n",
    "    print(\"ğŸ’¡ ê·¸ë£¹ 6ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”!\")\n",
    "    raise\n",
    "\n",
    "print(f\"\\nğŸ” ì§„í–‰ë¥ : [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0% (0/1)\")\n",
    "print(f\"ğŸ“ í˜„ì¬ ì‘ì—…: {city_name} - ì›¹ì‚¬ì´íŠ¸ ì ‘ì† ì¤‘\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "try:\n",
    "    # 1. ë©”ì¸ í˜ì´ì§€ë¡œ ì´ë™\n",
    "    print(\"  ğŸ“± ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ ë©”ì¸ í˜ì´ì§€ ì´ë™ ì¤‘...\")\n",
    "    retry_operation(\n",
    "        lambda: go_to_main_page(driver), \n",
    "        \"ë©”ì¸ í˜ì´ì§€ ì´ë™\"\n",
    "    )\n",
    "    print(f\"  âœ… ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ í˜ì´ì§€ ì—´ê¸° ì™„ë£Œ\")\n",
    "    \n",
    "    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸\n",
    "    print(f\"\\nğŸ” ì§„í–‰ë¥ : [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 25.0% (1/4)\")\n",
    "    print(f\"ğŸ“ í˜„ì¬ ì‘ì—…: {city_name} - ê²€ìƒ‰ì°½ ì…ë ¥ ì¤‘\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # 2. ê²€ìƒ‰ì°½ ì°¾ê¸° ë° ì…ë ¥ (ğŸ†• ë™ì  ë„ì‹œëª… ì‚¬ìš©)\n",
    "    retry_operation(\n",
    "        lambda: find_and_fill_search(driver, city_name), \n",
    "        f\"{city_name} ê²€ìƒ‰ì°½ ì…ë ¥\"\n",
    "    )\n",
    "    \n",
    "    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸\n",
    "    print(f\"\\nğŸ” ì§„í–‰ë¥ : [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 50.0% (2/4)\")\n",
    "    print(f\"ğŸ“ í˜„ì¬ ì‘ì—…: {city_name} - ê²€ìƒ‰ ì‹¤í–‰ ì¤‘\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # 3. ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­\n",
    "    retry_operation(\n",
    "        lambda: click_search_button(driver), \n",
    "        \"ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­\"\n",
    "    )\n",
    "    \n",
    "    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸\n",
    "    print(f\"\\nğŸ” ì§„í–‰ë¥ : [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 75.0% (3/4)\")\n",
    "    print(f\"ğŸ“ í˜„ì¬ ì‘ì—…: {city_name} - í˜ì´ì§€ ìµœì í™” ì¤‘\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # 4. íŒì—… ì²˜ë¦¬ (ì„ íƒì‚¬í•­)\n",
    "    try:\n",
    "        handle_popup(driver)\n",
    "    except Exception as e:\n",
    "        print(f\"  â„¹ï¸ íŒì—… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {type(e).__name__}\")\n",
    "\n",
    "    # 5. ì „ì²´ ìƒí’ˆ ë³´ê¸° í´ë¦­ (ì„ íƒì‚¬í•­)\n",
    "    try:\n",
    "        click_view_all(driver)\n",
    "    except Exception as e:\n",
    "        print(f\"  â„¹ï¸ ì „ì²´ ìƒí’ˆ ë³´ê¸° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {type(e).__name__}\")\n",
    "    \n",
    "    # ì§„í–‰ë¥  ì™„ë£Œ\n",
    "    print(f\"\\nâœ… ì§„í–‰ë¥ : [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100.0% (4/4)\")\n",
    "    print(f\"ğŸ“ í˜„ì¬ ì‘ì—…: {city_name} - ì™„ë£Œ\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    print(f\"\\nğŸ‰ ê·¸ë£¹ 7 ì™„ë£Œ: {city_name} ê²€ìƒ‰ ì„±ê³µ!\")\n",
    "    print(f\"ğŸ¯ í˜„ì¬ ìƒíƒœ: {city_name} ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤\")\n",
    "    \n",
    "    # í˜„ì¬ í˜ì´ì§€ URL í™•ì¸\n",
    "    try:\n",
    "        current_url = driver.current_url\n",
    "        print(f\"ğŸ”— í˜„ì¬ í˜ì´ì§€: {current_url[:80]}...\")\n",
    "        \n",
    "        # URLì—ì„œ ë„ì‹œëª… í™•ì¸\n",
    "        if city_name in current_url or get_city_code(city_name).lower() in current_url.lower():\n",
    "            print(\"âœ… URL ê²€ì¦: ì˜¬ë°”ë¥¸ ë„ì‹œ í˜ì´ì§€ì— ìˆìŠµë‹ˆë‹¤\")\n",
    "        else:\n",
    "            print(\"âš ï¸ URL ê²€ì¦: ì˜ˆìƒê³¼ ë‹¤ë¥¸ í˜ì´ì§€ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ í˜„ì¬ URL í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # í˜ì´ì§€ ë¡œë“œ ìƒíƒœ í™•ì¸\n",
    "    try:\n",
    "        page_state = driver.execute_script(\"return document.readyState;\")\n",
    "        if page_state == \"complete\":\n",
    "            print(\"âœ… í˜ì´ì§€ ë¡œë“œ: ì™„ì „íˆ ë¡œë“œë¨\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ í˜ì´ì§€ ë¡œë“œ: {page_state} ìƒíƒœ\")\n",
    "            print(\"  â° ì¶”ê°€ ë¡œë”© ëŒ€ê¸° ì¤‘...\")\n",
    "            time.sleep(3)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ í˜ì´ì§€ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    print(\"ğŸš€ ë‹¤ìŒ: ê·¸ë£¹ 8ì„ ì‹¤í–‰í•˜ì—¬ URL ìˆ˜ì§‘ ë° ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”!\")\n",
    "    \n",
    "except TimeoutException as e:\n",
    "    print(f\"\\nâ° {city_name}: í˜ì´ì§€ ë¡œë”© ì‹œê°„ ì´ˆê³¼\")\n",
    "    print(f\"ğŸ“ ìœ„ì¹˜: {continent} > {country} > {city_name}\")\n",
    "    print(\"âŒ ê·¸ë£¹ 7 ì‹¤íŒ¨: ì‹œê°„ ì´ˆê³¼\")\n",
    "    print(\"ğŸ’¡ í•´ê²° ë°©ë²•:\")\n",
    "    print(\"   1. ì¸í„°ë„· ì—°ê²° ìƒíƒœ í™•ì¸\")\n",
    "    print(\"   2. ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ ì‚¬ì´íŠ¸ ì ‘ì† ìƒíƒœ í™•ì¸\")\n",
    "    print(\"   3. ë“œë¼ì´ë²„ ì¬ì‹œì‘ í›„ ì¬ì‹œë„\")\n",
    "    \n",
    "except NoSuchElementException as e:\n",
    "    print(f\"\\nğŸ” {city_name}: í•„ìš”í•œ ì›¹ ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ\")\n",
    "    print(f\"ğŸ“ ìœ„ì¹˜: {continent} > {country} > {city_name}\")\n",
    "    print(\"âŒ ê·¸ë£¹ 7 ì‹¤íŒ¨: ìš”ì†Œ ì—†ìŒ\")\n",
    "    print(\"ğŸ’¡ í•´ê²° ë°©ë²•:\")\n",
    "    print(\"   1. ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½ í™•ì¸\")\n",
    "    print(\"   2. ê²€ìƒ‰í•˜ëŠ” ë„ì‹œëª…ì´ ì •í™•í•œì§€ í™•ì¸\")\n",
    "    print(\"   3. ë¸Œë¼ìš°ì €ë¥¼ ìˆ˜ë™ìœ¼ë¡œ í™•ì¸\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ {city_name}: ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ - {type(e).__name__}: {e}\")\n",
    "    print(\"âŒ ê·¸ë£¹ 7 ì‹¤íŒ¨: ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜\")\n",
    "    print(\"ğŸ’¡ í•´ê²° ë°©ë²•:\")\n",
    "    print(\"   1. ê·¸ë£¹ 6ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸\")\n",
    "    print(f\"   2. CITIES_TO_SEARCHì— '{city_name}'ì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸\")\n",
    "    print(\"   3. ë“œë¼ì´ë²„ ìƒíƒœ í™•ì¸\")\n",
    "    print(\"   4. ë¸Œë¼ìš°ì € ì¬ì‹œì‘ í›„ ì¬ì‹œë„\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… ê·¸ë£¹ 7 ì›¹ì‚¬ì´íŠ¸ ê²€ìƒ‰ ë‹¨ê³„ ì™„ë£Œ!\")\n",
    "print(\"ğŸ”§ ìˆ˜í–‰ëœ ì‘ì—…:\")\n",
    "print(\"   - ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ ë©”ì¸ í˜ì´ì§€ ì ‘ì†\")\n",
    "print(\"   - ë„ì‹œëª… ê²€ìƒ‰ì°½ ì…ë ¥\")\n",
    "print(\"   - ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­\")\n",
    "print(\"   - íŒì—… ë° UI ìµœì í™”\")\n",
    "print(\"   - ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ ë„ë‹¬\")\n",
    "print(\"ğŸ¯ ë‹¤ìŒ ë‹¨ê³„: ê·¸ë£¹ 8ì—ì„œ URL ìˆ˜ì§‘ ë° í˜ì´ì§€ë„¤ì´ì…˜ ë¶„ì„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f1247f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ê·¸ë£¹ 8: URL ìˆ˜ì§‘ ë° í˜ì´ì§€ë„¤ì´ì…˜ ë¶„ì„ ì‹œì‘!\n",
      "============================================================\n",
      "ğŸ“‹ í˜„ì¬ ìƒíƒœ í™•ì¸:\n",
      "  ğŸ™ï¸ ëŒ€ìƒ ë„ì‹œ: í›„ì¿ ì˜¤ì¹´\n",
      "  ğŸ“Š ì™„ë£Œëœ URL: 4ê°œ\n",
      "  ğŸ”¢ ì‹œì‘ ë²ˆí˜¸: 1\n",
      "  ğŸ“± ë“œë¼ì´ë²„ ìƒíƒœ: í™œì„±\n",
      "\n",
      "ğŸ” === 1ë‹¨ê³„: í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„ ===\n",
      "ğŸ” í›„ì¿ ì˜¤ì¹´ í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„ ì¤‘...\n",
      "  ğŸ” í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„ ì¤‘...\n",
      "    âœ… ì´ ìƒí’ˆ ìˆ˜ ë°œê²¬: 542ê°œ\n",
      "    âš ï¸ ë‹¤ìŒ ë²„íŠ¼ ì—†ìŒ: ì‹¤ì œë¡œ 1í˜ì´ì§€ì¼ ìˆ˜ ìˆìŒ (ìƒí’ˆ 542ê°œ)\n",
      "\n",
      "ğŸ“‹ í¬ë¡¤ë§ ê³„íš ìˆ˜ë¦½ ì¤‘...\n",
      "\n",
      "ğŸ” === ì •ì°° ì™„ë£Œ ë³´ê³ ì„œ ===\n",
      "ğŸ“ ë„ì‹œ: í›„ì¿ ì˜¤ì¹´\n",
      "ğŸ“Š ë°œê²¬ëœ ì´ ìƒí’ˆ ìˆ˜: 542ê°œ\n",
      "ğŸ“„ ì´ í˜ì´ì§€ ìˆ˜: 1í˜ì´ì§€\n",
      "ğŸ“‹ í˜ì´ì§€ë‹¹ ìƒí’ˆ ìˆ˜: 24ê°œ\n",
      "ğŸ”„ í˜ì´ì§€ë„¤ì´ì…˜ ê°€ëŠ¥: âŒ ì•„ë‹ˆì˜¤\n",
      "â±ï¸ ì˜ˆìƒ ì†Œìš” ì‹œê°„: 0.5ë¶„\n",
      "ğŸ¯ í¬ë¡¤ë§ ì „ëµ: ë‹¨ì¼ í˜ì´ì§€\n",
      "ğŸ“¦ ì‹¤ì œ ìˆ˜ì§‘ ì˜ˆì •: 1ê°œ\n",
      "==================================================\n",
      "âš ï¸ í˜ì´ì§€ë„¤ì´ì…˜ì´ ì œí•œì ì…ë‹ˆë‹¤. í˜„ì¬ í˜ì´ì§€ë§Œ í¬ë¡¤ë§ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
      "  ğŸ” ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ì‘ë™ì„± í™•ì¸ ì¤‘...\n",
      "    âŒ ì‘ë™ ê°€ëŠ¥í•œ ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "âš ï¸ í˜ì´ì§€ë„¤ì´ì…˜ ì œí•œìœ¼ë¡œ í˜„ì¬ í˜ì´ì§€ë§Œ í¬ë¡¤ë§ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ” === 2ë‹¨ê³„: CSV ê¸°ë°˜ ì•ˆì „ URL ìˆ˜ì§‘ ===\n",
      "ğŸ“Š í›„ì¿ ì˜¤ì¹´ì—ì„œ CSV ê¸°ë°˜ ì•ˆì „ URL ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "ğŸ“Š CSV ê¸°ë°˜ ì•ˆì „ URL ìˆ˜ì§‘ ì‹œì‘...\n",
      "ğŸ“Š [í†µí•©] í˜„ì¬ í˜ì´ì§€ì˜ ëª¨ë“  URL ìˆ˜ì§‘ ì¤‘...\n",
      "âœ… ì´ 24ê°œì˜ ê³ ìœ  URL ìˆ˜ì§‘ ì™„ë£Œ!\n",
      "   ğŸ›ï¸ Products: 15ê°œ\n",
      "   ğŸ·ï¸ Offers: 9ê°œ\n",
      "   ğŸ¯ Experiences: 0ê°œ\n",
      "ğŸ“„ CSV íŒŒì¼ ì—†ìŒ - ìƒˆë¡œìš´ í¬ë¡¤ë§ ì‹œì‘\n",
      "ğŸ” CSV ê¸°ë°˜ URL í•„í„°ë§:\n",
      "   ğŸ“Š ì „ì²´ URL: 24ê°œ\n",
      "   âœ… ì´ë¯¸ ì™„ë£Œ: 0ê°œ\n",
      "   ğŸ†• ìƒˆë¡œìš´ URL: 24ê°œ\n",
      "\n",
      "ğŸ‰ ìƒˆë¡œìš´ URL ìˆ˜ì§‘ ì„±ê³µ!\n",
      "ğŸ“ˆ ì´ 24ê°œì˜ ìƒˆë¡œìš´ URLì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!\n",
      "ğŸ”¢ ì„¤ì •ëœ í¬ë¡¤ë§ ê°œìˆ˜: 1ê°œ\n",
      "ğŸ¯ ì‹¤ì œ í¬ë¡¤ë§í•  ê°œìˆ˜: 1ê°œ\n",
      "\n",
      "ğŸ“‹ ìˆ˜ì§‘ëœ ìƒˆë¡œìš´ URL ëª©ë¡:\n",
      "--------------------------------------------------------------------------------\n",
      "   1. ğŸ›ï¸ Product: https://experiences.myrealtrip.com/products/3153599\n",
      "\n",
      "ğŸ” URL ìœ íš¨ì„± ì²´í¬:\n",
      "  âœ… Products: 15ê°œ\n",
      "  âœ… Offers: 9ê°œ\n",
      "  ğŸ¯ ì´ ìƒˆë¡œìš´ URL: 24ê°œ\n",
      "\n",
      "ğŸš€ CSV ê¸°ë°˜ ì•ˆì „ URL ìˆ˜ì§‘ ì„±ê³µ! ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤!\n",
      "\n",
      "ğŸ” === 3ë‹¨ê³„: ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½ ===\n",
      "ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½:\n",
      "  ğŸ™ï¸ ëŒ€ìƒ ë„ì‹œ: í›„ì¿ ì˜¤ì¹´\n",
      "  ğŸ“„ í˜ì´ì§€ë„¤ì´ì…˜ ì „ëµ: ë‹¨ì¼ í˜ì´ì§€\n",
      "  ğŸ”¢ ìˆ˜ì§‘ëœ ì‹ ê·œ URL: 1ê°œ\n",
      "  ğŸ“Š ì„¤ì •ëœ ìµœëŒ€ í¬ë¡¤ë§: 1ê°œ\n",
      "  ğŸ”¢ ë²ˆí˜¸ ì‹œì‘ì : 1\n",
      "  ğŸ“ˆ ì˜ˆìƒ ë²ˆí˜¸ ë²”ìœ„: 1 ~ 1\n",
      "  ğŸ“ ì´ë¯¸ì§€ ì €ì¥ ìœ„ì¹˜: myrealtripthumb_img/ì•„ì‹œì•„/ì¼ë³¸/í›„ì¿ ì˜¤ì¹´/\n",
      "  ğŸ“ ë°ì´í„° ì €ì¥ ìœ„ì¹˜: data/ì•„ì‹œì•„/ì¼ë³¸/í›„ì¿ ì˜¤ì¹´/\n",
      "\n",
      "âœ… ê·¸ë£¹ 8 ì™„ë£Œ: URL ìˆ˜ì§‘ ë° ë¶„ì„ ì„±ê³µ!\n",
      "ğŸš€ ë‹¤ìŒ: ê·¸ë£¹ 9ë¥¼ ì‹¤í–‰í•˜ì—¬ ì‹¤ì œ í¬ë¡¤ë§ì„ ì‹œì‘í•˜ì„¸ìš”!\n",
      "\n",
      "============================================================\n",
      "âœ… ê·¸ë£¹ 8 URL ìˆ˜ì§‘ ë° í˜ì´ì§€ë„¤ì´ì…˜ ë¶„ì„ ì™„ë£Œ!\n",
      "ğŸ”§ ìˆ˜í–‰ëœ ì‘ì—…:\n",
      "   - í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„\n",
      "   - í¬ë¡¤ë§ ê³„íš ìˆ˜ë¦½\n",
      "   - CSV ê¸°ë°˜ ì•ˆì „ URL ìˆ˜ì§‘\n",
      "   - URL ì¤‘ë³µ ë°©ì§€ ë° í•„í„°ë§\n",
      "   - ìˆ˜ì§‘ ê²°ê³¼ ê²€ì¦\n",
      "ğŸ›¡ï¸ ë³´ì•ˆ ê¸°ëŠ¥:\n",
      "   - CSV ê¸°ë°˜ URL ì¤‘ë³µ ë°©ì§€ (íŒŒì¼ ì „í™˜ì— ì•ˆì •ì )\n",
      "   - ì™„ë£Œëœ ì‘ì—… ìë™ ì œì™¸\n",
      "   - ë²ˆí˜¸ ì—°ì†ì„± ë³´ì¥\n",
      "âœ… URL ìºì‹œ ì €ì¥: 1ê°œ (ì„¸ì…˜: +1ê°œ)\n",
      "ğŸ’¾ í›„ì¿ ì˜¤ì¹´ URL ìºì‹œ ì €ì¥ ì™„ë£Œ: 1ê°œ\n",
      "ğŸ¯ ë‹¤ìŒ ë‹¨ê³„: ê·¸ë£¹ 9ì—ì„œ 1ê°œ ìƒí’ˆ í¬ë¡¤ë§ ì‹œì‘\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ğŸš€ ê·¸ë£¹ 8: URL ìˆ˜ì§‘ ë° í˜ì´ì§€ë„¤ì´ì…˜ ë¶„ì„\n",
    "# - CSV ê¸°ë°˜ ì•ˆì „ URL ìˆ˜ì§‘, ì¤‘ë³µ ë°©ì§€, í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ” ê·¸ë£¹ 8: URL ìˆ˜ì§‘ ë° í˜ì´ì§€ë„¤ì´ì…˜ ë¶„ì„ ì‹œì‘!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ê·¸ë£¹ 6, 7ì—ì„œ ì„¤ì •ëœ ë³€ìˆ˜ë“¤ í™•ì¸\n",
    "try:\n",
    "    print(f\"ğŸ“‹ í˜„ì¬ ìƒíƒœ í™•ì¸:\")\n",
    "    print(f\"  ğŸ™ï¸ ëŒ€ìƒ ë„ì‹œ: {city_name}\")\n",
    "    print(f\"  ğŸ“Š ì™„ë£Œëœ URL: {len(completed_urls)}ê°œ\")\n",
    "    print(f\"  ğŸ”¢ ì‹œì‘ ë²ˆí˜¸: {start_number}\")\n",
    "    print(f\"  ğŸ“± ë“œë¼ì´ë²„ ìƒíƒœ: í™œì„±\")\n",
    "except NameError as e:\n",
    "    print(f\"âŒ í•„ìˆ˜ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}\")\n",
    "    print(\"ğŸ’¡ ê·¸ë£¹ 6ê³¼ ê·¸ë£¹ 7ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”!\")\n",
    "    raise\n",
    "\n",
    "print(\"\\nğŸ” === 1ë‹¨ê³„: í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„ ===\")\n",
    "\n",
    "try:\n",
    "    # í˜ì´ì§€ë„¤ì´ì…˜ ë¶„ì„ ì‹¤í–‰\n",
    "    print(f\"ğŸ” {city_name} í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„ ì¤‘...\")\n",
    "    pagination_info = analyze_pagination(driver)\n",
    "    \n",
    "    # í¬ë¡¤ë§ ê³„íš ìˆ˜ë¦½\n",
    "    plan = generate_crawling_plan(pagination_info, city_name)\n",
    "    can_proceed = report_reconnaissance_results(plan)\n",
    "    \n",
    "    # ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ì‘ë™ì„± í™•ì¸\n",
    "    button_working = check_next_button(driver)\n",
    "    \n",
    "    if can_proceed and button_working:\n",
    "        print(\"\\nğŸš€ í˜ì´ì§€ë„¤ì´ì…˜ì„ í™œìš©í•œ ì „ì²´ í¬ë¡¤ë§ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!\")\n",
    "        pagination_strategy = \"ë‹¤ì¤‘ í˜ì´ì§€\"\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ í˜ì´ì§€ë„¤ì´ì…˜ ì œí•œìœ¼ë¡œ í˜„ì¬ í˜ì´ì§€ë§Œ í¬ë¡¤ë§ ê°€ëŠ¥í•©ë‹ˆë‹¤.\")\n",
    "        pagination_strategy = \"ë‹¨ì¼ í˜ì´ì§€\"\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ í˜ì´ì§€ë„¤ì´ì…˜ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ’¡ ê¸°ë³¸ ì „ëµìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
    "    pagination_strategy = \"ê¸°ë³¸\"\n",
    "    pagination_info = {\n",
    "        'total_products': 0,\n",
    "        'total_pages': 1,\n",
    "        'products_per_page': 24,\n",
    "        'has_next_button': False,\n",
    "        'is_pagination_available': False\n",
    "    }\n",
    "\n",
    "print(f\"\\nğŸ” === 2ë‹¨ê³„: CSV ê¸°ë°˜ ì•ˆì „ URL ìˆ˜ì§‘ ===\")\n",
    "\n",
    "try:\n",
    "    # ì„¸ì…˜ ì•ˆì „ URL ìˆ˜ì§‘ ì‹¤í–‰\n",
    "    print(f\"ğŸ“Š {city_name}ì—ì„œ CSV ê¸°ë°˜ ì•ˆì „ URL ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "        \n",
    "    collected_urls = collect_urls_with_csv_safety(driver, city_name)\n",
    "    \n",
    "    if collected_urls:\n",
    "        print(f\"\\nğŸ‰ ìƒˆë¡œìš´ URL ìˆ˜ì§‘ ì„±ê³µ!\")\n",
    "        print(f\"ğŸ“ˆ ì´ {len(collected_urls)}ê°œì˜ ìƒˆë¡œìš´ URLì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!\")\n",
    "        \n",
    "        # ì„¤ì •ëœ ê°œìˆ˜ì™€ ë¹„êµ\n",
    "        max_products = CONFIG['MAX_PRODUCTS_PER_CITY']\n",
    "        will_crawl = min(len(collected_urls), max_products)\n",
    "        \n",
    "        print(f\"ğŸ”¢ ì„¤ì •ëœ í¬ë¡¤ë§ ê°œìˆ˜: {max_products}ê°œ\")\n",
    "        print(f\"ğŸ¯ ì‹¤ì œ í¬ë¡¤ë§í•  ê°œìˆ˜: {will_crawl}ê°œ\")\n",
    "        \n",
    "        print(f\"\\nğŸ“‹ ìˆ˜ì§‘ëœ ìƒˆë¡œìš´ URL ëª©ë¡:\")\n",
    "        print(\"-\" * 80)\n",
    "        for i, url in enumerate(collected_urls[:max_products], 1):\n",
    "            url_type = \"ğŸ›ï¸ Product\" if \"/products/\" in url else \"ğŸ·ï¸ Offer\"\n",
    "            print(f\"  {i:2d}. {url_type}: {url}\")\n",
    "        \n",
    "        # URL ìœ íš¨ì„± ì²´í¬\n",
    "        print(f\"\\nğŸ” URL ìœ íš¨ì„± ì²´í¬:\")\n",
    "        products_count = sum(1 for url in collected_urls if '/products/' in url)\n",
    "        offers_count = sum(1 for url in collected_urls if '/offers/' in url)\n",
    "        \n",
    "        print(f\"  âœ… Products: {products_count}ê°œ\")\n",
    "        print(f\"  âœ… Offers: {offers_count}ê°œ\")\n",
    "        print(f\"  ğŸ¯ ì´ ìƒˆë¡œìš´ URL: {products_count + offers_count}ê°œ\")\n",
    "        \n",
    "        # ì „ì—­ ë³€ìˆ˜ë¡œ URL ì €ì¥ (ê·¸ë£¹ 9ì—ì„œ ì‚¬ìš©)\n",
    "        urls_to_crawl = collected_urls[:max_products]\n",
    "        total_products_to_crawl = len(urls_to_crawl)\n",
    "        \n",
    "        print(\"\\nğŸš€ CSV ê¸°ë°˜ ì•ˆì „ URL ìˆ˜ì§‘ ì„±ê³µ! ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"\\nâŒ ìƒˆë¡œìš´ URL ìˆ˜ì§‘ ì‹¤íŒ¨ ë˜ëŠ” ëª¨ë“  URLì´ ì´ë¯¸ ì²˜ë¦¬ë¨\")\n",
    "        print(\"ğŸ’¡ ì¶”ê°€ ë¶„ì„:\")\n",
    "        \n",
    "        # ê¸°ë³¸ URL ìˆ˜ì§‘ìœ¼ë¡œ ì „ì²´ ìƒí™© íŒŒì•…\n",
    "        try:\n",
    "            basic_urls = collect_all_24_urls(driver)\n",
    "            print(f\"   ğŸ“„ í˜ì´ì§€ì˜ ì „ì²´ URL: {len(basic_urls)}ê°œ\")\n",
    "            print(f\"   ğŸ“„ ì´ë¯¸ ì™„ë£Œëœ URL: {len(completed_urls)}ê°œ\")\n",
    "            \n",
    "            overlap_count = len([url for url in basic_urls if url in completed_urls])\n",
    "            print(f\"   ğŸ”„ ì¤‘ë³µ URL: {overlap_count}ê°œ\")\n",
    "            \n",
    "            if overlap_count == len(basic_urls):\n",
    "                print(\"   âœ… ëª¨ë“  URLì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì–´ ì¤‘ë³µ ë°©ì§€ê°€ ì •ìƒ ì‘ë™í–ˆìŠµë‹ˆë‹¤!\")\n",
    "                urls_to_crawl = []\n",
    "                total_products_to_crawl = 0\n",
    "            else:\n",
    "                print(\"   âš ï¸ ì¤‘ë³µ ë°©ì§€ ì‹œìŠ¤í…œì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "                # ê¸°ë³¸ URLì´ë¼ë„ ìƒˆë¡œìš´ ê²ƒë“¤ ì‚¬ìš©\n",
    "                new_basic_urls = [url for url in basic_urls if url not in completed_urls]\n",
    "                urls_to_crawl = new_basic_urls[:CONFIG['MAX_PRODUCTS_PER_CITY']]\n",
    "                total_products_to_crawl = len(urls_to_crawl)\n",
    "                print(f\"   ğŸ”„ ê¸°ë³¸ ìˆ˜ì§‘ìœ¼ë¡œ {total_products_to_crawl}ê°œ URL í™•ë³´\")\n",
    "                \n",
    "        except Exception as debug_error:\n",
    "            print(f\"   âŒ ë¶„ì„ ì‹¤íŒ¨: {debug_error}\")\n",
    "            urls_to_crawl = []\n",
    "            total_products_to_crawl = 0\n",
    "        \n",
    "        if total_products_to_crawl == 0:\n",
    "            print(\"ğŸ”„ ìƒˆë¡œìš´ í˜ì´ì§€ë¡œ ì´ë™í•˜ê±°ë‚˜ ë‹¤ë¥¸ ë„ì‹œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ CSV ê¸°ë°˜ ì•ˆì „ URL ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {type(e).__name__}: {e}\")\n",
    "    print(\"ğŸ’¡ ê°€ëŠ¥í•œ í•´ê²°ì±…:\")\n",
    "    print(\"   1. ê·¸ë£¹ 7ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸\")\n",
    "    print(\"   2. ë¸Œë¼ìš°ì €ê°€ ì˜¬ë°”ë¥¸ ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ì— ìˆëŠ”ì§€ í™•ì¸\")\n",
    "    print(\"   3. ì¸í„°ë„· ì—°ê²° ìƒíƒœ í™•ì¸\")\n",
    "    \n",
    "    # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ URL ìˆ˜ì§‘ ì‹œë„\n",
    "    try:\n",
    "        print(\"\\nğŸ”„ ê¸°ë³¸ URL ìˆ˜ì§‘ ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„...\")\n",
    "        basic_urls = collect_all_24_urls(driver)\n",
    "        new_urls = filter_new_urls(basic_urls, completed_urls)\n",
    "        urls_to_crawl = new_urls[:CONFIG['MAX_PRODUCTS_PER_CITY']]\n",
    "        total_products_to_crawl = len(urls_to_crawl)\n",
    "        print(f\"âœ… ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ {total_products_to_crawl}ê°œ URL í™•ë³´\")\n",
    "    except Exception as fallback_error:\n",
    "        print(f\"âŒ ê¸°ë³¸ ë°©ì‹ë„ ì‹¤íŒ¨: {fallback_error}\")\n",
    "        urls_to_crawl = []\n",
    "        total_products_to_crawl = 0\n",
    "\n",
    "print(f\"\\nğŸ” === 3ë‹¨ê³„: ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½ ===\")\n",
    "\n",
    "try:\n",
    "    print(f\"ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½:\")\n",
    "    print(f\"  ğŸ™ï¸ ëŒ€ìƒ ë„ì‹œ: {city_name}\")\n",
    "    print(f\"  ğŸ“„ í˜ì´ì§€ë„¤ì´ì…˜ ì „ëµ: {pagination_strategy}\")\n",
    "    print(f\"  ğŸ”¢ ìˆ˜ì§‘ëœ ì‹ ê·œ URL: {total_products_to_crawl}ê°œ\")\n",
    "    print(f\"  ğŸ“Š ì„¤ì •ëœ ìµœëŒ€ í¬ë¡¤ë§: {CONFIG['MAX_PRODUCTS_PER_CITY']}ê°œ\")\n",
    "    print(f\"  ğŸ”¢ ë²ˆí˜¸ ì‹œì‘ì : {start_number}\")\n",
    "    \n",
    "    if total_products_to_crawl > 0:\n",
    "        print(f\"  ğŸ“ˆ ì˜ˆìƒ ë²ˆí˜¸ ë²”ìœ„: {start_number} ~ {start_number + total_products_to_crawl - 1}\")\n",
    "        print(f\"  ğŸ“ ì´ë¯¸ì§€ ì €ì¥ ìœ„ì¹˜: myrealtripthumb_img/{continent}/{country}/{city_name}/\")\n",
    "        print(f\"  ğŸ“ ë°ì´í„° ì €ì¥ ìœ„ì¹˜: data/{continent}/{country}/{city_name}/\")\n",
    "        \n",
    "        print(f\"\\nâœ… ê·¸ë£¹ 8 ì™„ë£Œ: URL ìˆ˜ì§‘ ë° ë¶„ì„ ì„±ê³µ!\")\n",
    "        print(\"ğŸš€ ë‹¤ìŒ: ê·¸ë£¹ 9ë¥¼ ì‹¤í–‰í•˜ì—¬ ì‹¤ì œ í¬ë¡¤ë§ì„ ì‹œì‘í•˜ì„¸ìš”!\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ ê·¸ë£¹ 8 ì™„ë£Œ: í¬ë¡¤ë§í•  ìƒˆë¡œìš´ URLì´ ì—†ìŒ\")\n",
    "        print(\"ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "        print(\"   1. ë‹¤ë¥¸ ë„ì‹œë¡œ ë³€ê²½\")\n",
    "        print(\"   2. config/completed_urls.log ì´ˆê¸°í™”\")\n",
    "        print(\"   3. í˜ì´ì§€ë„¤ì´ì…˜ì„ í†µí•œ ë‹¤ìŒ í˜ì´ì§€ ì´ë™\")\n",
    "        \n",
    "except NameError:\n",
    "    print(\"âŒ í•„ìˆ˜ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ’¡ URL ìˆ˜ì§‘ì— ì‹¤íŒ¨í–ˆì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.\")\n",
    "    total_products_to_crawl = 0\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… ê·¸ë£¹ 8 URL ìˆ˜ì§‘ ë° í˜ì´ì§€ë„¤ì´ì…˜ ë¶„ì„ ì™„ë£Œ!\")\n",
    "print(\"ğŸ”§ ìˆ˜í–‰ëœ ì‘ì—…:\")\n",
    "print(\"   - í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„\")\n",
    "print(\"   - í¬ë¡¤ë§ ê³„íš ìˆ˜ë¦½\")\n",
    "print(\"   - CSV ê¸°ë°˜ ì•ˆì „ URL ìˆ˜ì§‘\")\n",
    "print(\"   - URL ì¤‘ë³µ ë°©ì§€ ë° í•„í„°ë§\")\n",
    "print(\"   - ìˆ˜ì§‘ ê²°ê³¼ ê²€ì¦\")\n",
    "print(\"ğŸ›¡ï¸ ë³´ì•ˆ ê¸°ëŠ¥:\")\n",
    "print(\"   - CSV ê¸°ë°˜ URL ì¤‘ë³µ ë°©ì§€ (íŒŒì¼ ì „í™˜ì— ì•ˆì •ì )\")\n",
    "print(\"   - ì™„ë£Œëœ ì‘ì—… ìë™ ì œì™¸\")\n",
    "print(\"   - ë²ˆí˜¸ ì—°ì†ì„± ë³´ì¥\")\n",
    "\n",
    "if 'total_products_to_crawl' in locals() and total_products_to_crawl > 0:\n",
    "    # ğŸ†• URL ìºì‹œ ì €ì¥ (4ë²ˆ ë°©ì‹ ì ìš©)\n",
    "    save_collected_urls(city_name, urls_to_crawl)\n",
    "    print(f\"ğŸ’¾ {city_name} URL ìºì‹œ ì €ì¥ ì™„ë£Œ: {len(urls_to_crawl)}ê°œ\")\n",
    "    print(f\"ğŸ¯ ë‹¤ìŒ ë‹¨ê³„: ê·¸ë£¹ 9ì—ì„œ {total_products_to_crawl}ê°œ ìƒí’ˆ í¬ë¡¤ë§ ì‹œì‘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe82a02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ ê·¸ë£¹ 9-A: í˜ì´ì§€ë„¤ì´ì…˜ í•µì‹¬ ì‹œìŠ¤í…œ ë¡œë”©...\n",
      "âœ… ê·¸ë£¹ 9-A: í˜ì´ì§€ë„¤ì´ì…˜ í•µì‹¬ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ!\n",
      "   ğŸ“Š save_pagination_state() - í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ì €ì¥\n",
      "   ğŸ“Š load_pagination_state() - í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ë¡œë“œ\n",
      "   ğŸ”— save_list_page_url() - ëª©ë¡í˜ì´ì§€ URL ì €ì¥\n",
      "   ğŸ”™ return_to_list_page() - ëª©ë¡í˜ì´ì§€ ì•ˆì „ ë³µê·€\n",
      "   ğŸ”„ click_next_page_enhanced() - ê°•í™”ëœ ë‹¤ìŒí˜ì´ì§€ ì´ë™\n",
      "   ğŸ”§ attempt_page_recovery() - í˜ì´ì§€ ì˜¤ë¥˜ ë³µêµ¬\n",
      "   ğŸ§° validate_pagination_environment() - í™˜ê²½ ê²€ì¦\n",
      "\n",
      "ğŸš€ ë‹¤ìŒ: ê·¸ë£¹ 9-Bë¥¼ ì‹¤í–‰í•˜ì—¬ ì™„ì „í•œ í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ ì‹œì‘!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ğŸš€ ê·¸ë£¹ 9-A: í˜ì´ì§€ë„¤ì´ì…˜ í•µì‹¬ ì‹œìŠ¤í…œ\n",
    "# - í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ê´€ë¦¬, URL ì €ì¥/ë³µê·€, í˜ì´ì§€ ì´ë™ í•¨ìˆ˜ë“¤\n",
    "# - ê¸°ì¡´ ê·¸ë£¹ 1-8ì˜ ëª¨ë“  ì—°ì†ì„± ë³´ì¥ ì‹œìŠ¤í…œ í™œìš©\n",
    "# =============================================================================\n",
    "\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"ğŸ”§ ê·¸ë£¹ 9-A: í˜ì´ì§€ë„¤ì´ì…˜ í•µì‹¬ ì‹œìŠ¤í…œ ë¡œë”©...\")\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ“Š í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ\n",
    "# =============================================================================\n",
    "\n",
    "def save_pagination_state(city_name, current_page, current_list_url, total_crawled, target_products):\n",
    "    \"\"\"\n",
    "    í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœë¥¼ ì €ì¥í•˜ì—¬ ì„¸ì…˜ ê°„ ì—°ì†ì„± ë³´ì¥\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(\"pagination_state\", exist_ok=True)\n",
    "        state_file = os.path.join(\"pagination_state\", f\"{city_name}_pagination.json\")\n",
    "        \n",
    "        pagination_state = {\n",
    "            \"city\": city_name,\n",
    "            \"current_page\": current_page,\n",
    "            \"current_list_url\": current_list_url,\n",
    "            \"total_crawled\": total_crawled,\n",
    "            \"target_products\": target_products,\n",
    "            \"last_updated\": datetime.now().isoformat(),\n",
    "            \"session_id\": datetime.now().strftime('%Y%m%d_%H%M%S'),\n",
    "            \"status\": \"active\"\n",
    "        }\n",
    "        \n",
    "        with open(state_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(pagination_state, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"      âœ… í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ì €ì¥: {current_page}í˜ì´ì§€, {total_crawled}ê°œ ì™„ë£Œ\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"      âŒ í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "def load_pagination_state(city_name):\n",
    "    \"\"\"\n",
    "    ì´ì „ ì„¸ì…˜ì˜ í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ë¡œë“œ\n",
    "    \"\"\"\n",
    "    try:\n",
    "        state_file = os.path.join(\"pagination_state\", f\"{city_name}_pagination.json\")\n",
    "        \n",
    "        if not os.path.exists(state_file):\n",
    "            print(f\"      â„¹ï¸ í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ íŒŒì¼ ì—†ìŒ - ìƒˆ ì„¸ì…˜ ì‹œì‘\")\n",
    "            return None\n",
    "        \n",
    "        with open(state_file, 'r', encoding='utf-8') as f:\n",
    "            state = json.load(f)\n",
    "        \n",
    "        print(f\"      âœ… í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ë¡œë“œ: {state.get('current_page', 1)}í˜ì´ì§€ë¶€í„° ì¬ê°œ\")\n",
    "        print(f\"      ğŸ“Š ì´ì „ ì§„í–‰: {state.get('total_crawled', 0)}ê°œ ì™„ë£Œ\")\n",
    "        \n",
    "        return state\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"      âš ï¸ í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "def clear_pagination_state(city_name):\n",
    "    \"\"\"\n",
    "    í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ì´ˆê¸°í™” (í¬ë¡¤ë§ ì™„ë£Œ ì‹œ)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        state_file = os.path.join(\"pagination_state\", f\"{city_name}_pagination.json\")\n",
    "        \n",
    "        if os.path.exists(state_file):\n",
    "            # ì™„ë£Œ ìƒíƒœë¡œ ë§ˆí‚¹\n",
    "            with open(state_file, 'r', encoding='utf-8') as f:\n",
    "                state = json.load(f)\n",
    "            \n",
    "            state[\"status\"] = \"completed\"\n",
    "            state[\"completed_time\"] = datetime.now().isoformat()\n",
    "            \n",
    "            with open(state_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(state, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            print(f\"      âœ… í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ì™„ë£Œ ì²˜ë¦¬\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"      âš ï¸ í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ì •ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ”— ëª©ë¡í˜ì´ì§€ URL ì €ì¥ ë° ë³µê·€ ì‹œìŠ¤í…œ\n",
    "# =============================================================================\n",
    "\n",
    "def save_list_page_url(driver, city_name, page_number):\n",
    "    \"\"\"\n",
    "    í˜„ì¬ ëª©ë¡í˜ì´ì§€ URLì„ ì €ì¥\n",
    "    \"\"\"\n",
    "    try:\n",
    "        current_url = driver.current_url\n",
    "        \n",
    "        # URL ê²€ì¦\n",
    "        if not is_valid_list_page_url(current_url, city_name):\n",
    "            print(f\"      âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ ëª©ë¡í˜ì´ì§€ URL: {current_url}\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"      ğŸ“ {page_number}í˜ì´ì§€ URL ì €ì¥: ...{current_url[-50:]}\")\n",
    "        return current_url\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"      âŒ ëª©ë¡í˜ì´ì§€ URL ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "def return_to_list_page(driver, saved_url, city_name, max_attempts=3):\n",
    "    \"\"\"\n",
    "    ì €ì¥ëœ ëª©ë¡í˜ì´ì§€ URLë¡œ ì•ˆì „í•˜ê²Œ ë³µê·€\n",
    "    \"\"\"\n",
    "    print(f\"      ğŸ”™ ëª©ë¡í˜ì´ì§€ë¡œ ë³µê·€ ì¤‘...\")\n",
    "    \n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            current_url = driver.current_url\n",
    "            \n",
    "            # ì´ë¯¸ ëª©ë¡í˜ì´ì§€ì— ìˆëŠ”ì§€ í™•ì¸\n",
    "            if is_valid_list_page_url(current_url, city_name):\n",
    "                # ìƒí’ˆ ë§í¬ ê°œìˆ˜ë¡œ í™•ì¸\n",
    "                product_links = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/products/'], a[href*='/offers/']\")\n",
    "                if len(product_links) >= 10:\n",
    "                    print(f\"      âœ… ì´ë¯¸ ì˜¬ë°”ë¥¸ ëª©ë¡í˜ì´ì§€ì— ìˆìŒ ({len(product_links)}ê°œ ìƒí’ˆ)\")\n",
    "                    return True, current_url\n",
    "            \n",
    "            print(f\"      ğŸ”„ ëª©ë¡í˜ì´ì§€ ë³µê·€ ì‹œë„ {attempt + 1}/{max_attempts}\")\n",
    "            \n",
    "            if saved_url:\n",
    "                # ì €ì¥ëœ URLë¡œ ì§ì ‘ ì´ë™\n",
    "                driver.get(saved_url)\n",
    "                print(f\"      ğŸ“ ì €ì¥ëœ URLë¡œ ì´ë™: ...{saved_url[-50:]}\")\n",
    "            else:\n",
    "                # ë’¤ë¡œê°€ê¸° ì‹œë„\n",
    "                driver.back()\n",
    "                print(f\"      â¬…ï¸ ë’¤ë¡œê°€ê¸° ì‹œë„\")\n",
    "            \n",
    "            time.sleep(random.uniform(3, 5))\n",
    "            \n",
    "            # ë³µê·€ í™•ì¸\n",
    "            new_url = driver.current_url\n",
    "            product_links = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/products/'], a[href*='/offers/']\")\n",
    "            \n",
    "            if len(product_links) >= 10:\n",
    "                print(f\"      âœ… ëª©ë¡í˜ì´ì§€ ë³µê·€ ì„±ê³µ! ({len(product_links)}ê°œ ìƒí’ˆ í™•ì¸)\")\n",
    "                return True, new_url\n",
    "            else:\n",
    "                print(f\"      âš ï¸ ë³µê·€í–ˆì§€ë§Œ ìƒí’ˆ ìˆ˜ ë¶€ì¡±: {len(product_links)}ê°œ\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"      âŒ ë³µê·€ ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}\")\n",
    "            \n",
    "        if attempt < max_attempts - 1:\n",
    "            print(f\"      â° 2ì´ˆ í›„ ì¬ì‹œë„...\")\n",
    "            time.sleep(2)\n",
    "    \n",
    "    print(f\"      ğŸš¨ ëª©ë¡í˜ì´ì§€ ë³µê·€ ìµœì¢… ì‹¤íŒ¨\")\n",
    "    return False, None\n",
    "\n",
    "def is_valid_list_page_url(url, city_name):\n",
    "    \"\"\"\n",
    "    ìœ íš¨í•œ ëª©ë¡í˜ì´ì§€ URLì¸ì§€ í™•ì¸\n",
    "    \"\"\"\n",
    "    if not url:\n",
    "        return False\n",
    "    \n",
    "    # ìƒí’ˆ ìƒì„¸í˜ì´ì§€ê°€ ì•„ë‹Œì§€ í™•ì¸\n",
    "    if \"/products/\" in url and url.count(\"/\") > 5:\n",
    "        return False\n",
    "    if \"/offers/\" in url and url.count(\"/\") > 5:\n",
    "        return False\n",
    "    \n",
    "    # ê¸°ë³¸ ëª©ë¡í˜ì´ì§€ íŒ¨í„´ í™•ì¸\n",
    "    valid_patterns = [\n",
    "        \"/experiences\",\n",
    "        \"/offers\",\n",
    "        \"/search\"\n",
    "    ]\n",
    "    \n",
    "    return any(pattern in url for pattern in valid_patterns)\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ”„ í˜ì´ì§€ ì´ë™ ë° ë³µêµ¬ ì‹œìŠ¤í…œ\n",
    "# =============================================================================\n",
    "\n",
    "def click_next_page_enhanced(driver, current_page=None):\n",
    "    \"\"\"\n",
    "    ë‹¤ìŒ í˜ì´ì§€ë¡œ ì•ˆì „í•˜ê²Œ ì´ë™ (ê°•í™”ëœ ë²„ì „)\n",
    "    \"\"\"\n",
    "    print(f\"    ğŸ” ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ì°¾ëŠ” ì¤‘...\")\n",
    "    \n",
    "    try:\n",
    "        # í˜„ì¬ ìƒíƒœ ì €ì¥\n",
    "        current_url = driver.current_url\n",
    "        current_products = len(collect_all_24_urls(driver))\n",
    "        \n",
    "        # ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ì…€ë ‰í„°ë“¤ (ë§ˆë‹ë¼ ìµœì í™” + ë²”ìš©)\n",
    "        next_button_selectors = [\n",
    "            # ë§ˆë‹ë¼ íŠ¹í™” ì…€ë ‰í„°\n",
    "            (By.XPATH, \"/html/body/div[4]/div[2]/div/div/div[2]/main/div/div[4]/div/li[7]/button\"),\n",
    "            (By.CSS_SELECTOR, \"button.css-13fjuep\"),\n",
    "            (By.XPATH, \"//img[@src='https://dffoxz5he03rp.cloudfront.net/icons/ic_arrowright_sm_blue_500.svg']/ancestor::button\"),\n",
    "            \n",
    "            # ë²”ìš© ì…€ë ‰í„°ë“¤\n",
    "            (By.XPATH, \"//button[.//img[contains(@src, 'arrow') and contains(@src, 'right')]]\"),\n",
    "            (By.XPATH, \"//button[contains(@aria-label, 'ë‹¤ìŒ') and not(@disabled)]\"),\n",
    "            (By.XPATH, \"//button[contains(text(), 'ë‹¤ìŒ') and not(@disabled)]\"),\n",
    "            (By.CSS_SELECTOR, \"button[aria-label*='next']:not([disabled])\"),\n",
    "            (By.XPATH, \"//button[contains(@class, 'pagination')]//img[contains(@src, 'arrow')]\"),\n",
    "            (By.XPATH, \"//li[last()]//button[not(@disabled)]\"),  # ë§ˆì§€ë§‰ liì˜ ë²„íŠ¼\n",
    "        ]\n",
    "        \n",
    "        next_button = None\n",
    "        used_selector = None\n",
    "        \n",
    "        # ë²„íŠ¼ ì°¾ê¸°\n",
    "        for selector_type, selector in next_button_selectors:\n",
    "            try:\n",
    "                buttons = driver.find_elements(selector_type, selector)\n",
    "                for button in buttons:\n",
    "                    if button.is_displayed() and button.is_enabled():\n",
    "                        # disabled ì†ì„± ì¶”ê°€ ì²´í¬\n",
    "                        disabled = button.get_attribute(\"disabled\")\n",
    "                        aria_disabled = button.get_attribute(\"aria-disabled\")\n",
    "                        \n",
    "                        if not disabled and aria_disabled != \"true\":\n",
    "                            next_button = button\n",
    "                            used_selector = selector\n",
    "                            break\n",
    "                \n",
    "                if next_button:\n",
    "                    break\n",
    "                    \n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        if not next_button:\n",
    "            print(f\"    âŒ ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "            return False, \"ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ì—†ìŒ\", current_url\n",
    "        \n",
    "        print(f\"    âœ… ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ë°œê²¬!\")\n",
    "        \n",
    "        # ì•ˆì „í•œ í´ë¦­ ì‹¤í–‰\n",
    "        for click_attempt in range(3):\n",
    "            try:\n",
    "                print(f\"    ğŸ–±ï¸ ë‹¤ìŒ í˜ì´ì§€ í´ë¦­ ì‹œë„ {click_attempt + 1}/3...\")\n",
    "                \n",
    "                # ìŠ¤í¬ë¡¤ í›„ í´ë¦­\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", next_button)\n",
    "                time.sleep(1)\n",
    "                \n",
    "                # JavaScript í´ë¦­\n",
    "                driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                \n",
    "                # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°\n",
    "                print(f\"    â° í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° ì¤‘...\")\n",
    "                time.sleep(random.uniform(4, 7))\n",
    "                \n",
    "                # ë³€í™” ê²€ì¦\n",
    "                new_url = driver.current_url\n",
    "                new_products = len(collect_all_24_urls(driver))\n",
    "                \n",
    "                # ì„±ê³µ ì¡°ê±´ í™•ì¸\n",
    "                if new_url != current_url:\n",
    "                    print(f\"    âœ… URL ë³€í™” ê°ì§€: í˜ì´ì§€ ì´ë™ ì„±ê³µ!\")\n",
    "                    print(f\"    ğŸ“ ìƒˆ URL: ...{new_url[-60:]}\")\n",
    "                    return True, \"í˜ì´ì§€ ì´ë™ ì„±ê³µ\", new_url\n",
    "                    \n",
    "                elif new_products != current_products and new_products > 0:\n",
    "                    print(f\"    âœ… ìƒí’ˆ ìˆ˜ ë³€í™” ê°ì§€: {current_products} â†’ {new_products}\")\n",
    "                    return True, \"ìƒí’ˆ ë³€í™”ë¡œ ì´ë™ í™•ì¸\", new_url\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"    âš ï¸ í´ë¦­ {click_attempt+1}: í˜ì´ì§€ ë³€í™” ë¯¸ê°ì§€\")\n",
    "                    if click_attempt < 2:\n",
    "                        time.sleep(2)\n",
    "                        continue\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    âŒ í´ë¦­ ì‹œë„ {click_attempt+1} ì‹¤íŒ¨: {e}\")\n",
    "                if click_attempt < 2:\n",
    "                    time.sleep(2)\n",
    "                    continue\n",
    "        \n",
    "        # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨\n",
    "        print(f\"    ğŸ ë§ˆì§€ë§‰ í˜ì´ì§€ì´ê±°ë‚˜ í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨\")\n",
    "        return False, \"í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨ (3íšŒ ì‹œë„ í›„)\", current_url\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    âŒ ë‹¤ìŒ í˜ì´ì§€ ì´ë™ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        return False, f\"ì˜¤ë¥˜: {type(e).__name__}\", driver.current_url\n",
    "\n",
    "def attempt_page_recovery(driver, city_name, target_page):\n",
    "    \"\"\"\n",
    "    í˜ì´ì§€ ì˜¤ë¥˜ ë³µêµ¬ ì‹œë„ (ë„ì‹œë³„ URL ì§€ì›)\n",
    "    \"\"\"\n",
    "    print(f\"    ğŸ”§ í˜ì´ì§€ ë³µêµ¬ ì‹œë„: {target_page}í˜ì´ì§€\")\n",
    "    \n",
    "    try:\n",
    "        # ë„ì‹œë³„ ê¸°ë³¸ ëª©ë¡í˜ì´ì§€ URL ë§¤í•‘\n",
    "        city_base_urls = {\n",
    "            \"ë§ˆë‹ë¼\": \"https://www.myrealtrip.com/offers?t=llp&qct=Manila&qcr=Philippines\",\n",
    "            \"ë°”ë¥´ì…€ë¡œë‚˜\": \"https://www.myrealtrip.com/experiences/?destination=%EB%B0%94%EB%A5%B4%EC%85%80%EB%A1%9C%EB%82%98\",\n",
    "            \"ë°©ì½•\": \"https://www.myrealtrip.com/experiences/?destination=%EB%B0%A9%EC%BD%95\",\n",
    "            \"íŒŒë¦¬\": \"https://www.myrealtrip.com/experiences/?destination=%ED%8C%8C%EB%A6%AC\",\n",
    "            # í•„ìš”ì‹œ ì¶”ê°€...\n",
    "        }\n",
    "        \n",
    "        base_url = city_base_urls.get(city_name, \"https://www.myrealtrip.com/experiences/\")\n",
    "        \n",
    "        # í˜ì´ì§€ ë²ˆí˜¸ ì¶”ê°€\n",
    "        if target_page > 1:\n",
    "            separator = \"&\" if \"?\" in base_url else \"?\"\n",
    "            recovery_url = f\"{base_url}{separator}page={target_page}\"\n",
    "        else:\n",
    "            recovery_url = base_url\n",
    "        \n",
    "        print(f\"    ğŸ“ ë³µêµ¬ URLë¡œ ì´ë™: ...{recovery_url[-60:]}\")\n",
    "        driver.get(recovery_url)\n",
    "        time.sleep(random.uniform(5, 8))\n",
    "        \n",
    "        # ë³µêµ¬ í™•ì¸\n",
    "        product_links = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/products/'], a[href*='/offers/']\")\n",
    "        \n",
    "        if len(product_links) >= 10:\n",
    "            print(f\"    âœ… í˜ì´ì§€ ë³µêµ¬ ì„±ê³µ! ({len(product_links)}ê°œ ìƒí’ˆ í™•ì¸)\")\n",
    "            return True, recovery_url\n",
    "        else:\n",
    "            print(f\"    âŒ í˜ì´ì§€ ë³µêµ¬ ì‹¤íŒ¨: ìƒí’ˆ {len(product_links)}ê°œë§Œ ë°œê²¬\")\n",
    "            return False, None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"    âŒ í˜ì´ì§€ ë³µêµ¬ ì˜¤ë¥˜: {e}\")\n",
    "        return False, None\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ§° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤\n",
    "# =============================================================================\n",
    "\n",
    "def validate_pagination_environment():\n",
    "    \"\"\"\n",
    "    í˜ì´ì§€ë„¤ì´ì…˜ ì‹¤í–‰ í™˜ê²½ ê²€ì¦\n",
    "    \"\"\"\n",
    "    print(\"ğŸ” í˜ì´ì§€ë„¤ì´ì…˜ í™˜ê²½ ê²€ì¦ ì¤‘...\")\n",
    "    \n",
    "    # í•„ìˆ˜ ë³€ìˆ˜ë“¤ í™•ì¸\n",
    "    required_vars = ['driver', 'city_name', 'start_number', 'completed_urls', 'continent', 'country']\n",
    "    missing_vars = []\n",
    "    \n",
    "    for var_name in required_vars:\n",
    "        if var_name not in globals():\n",
    "            missing_vars.append(var_name)\n",
    "    \n",
    "    if missing_vars:\n",
    "        print(f\"âŒ í•„ìˆ˜ ë³€ìˆ˜ ëˆ„ë½: {', '.join(missing_vars)}\")\n",
    "        print(\"ğŸ’¡ ê·¸ë£¹ 6-8ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”!\")\n",
    "        return False, missing_vars\n",
    "    \n",
    "    # ë“œë¼ì´ë²„ ìƒíƒœ í™•ì¸\n",
    "    try:\n",
    "        current_url = driver.current_url\n",
    "        print(f\"âœ… ë“œë¼ì´ë²„ ìƒíƒœ: ì •ìƒ ({current_url[:50]}...)\")\n",
    "    except:\n",
    "        print(f\"âŒ ë“œë¼ì´ë²„ ìƒíƒœ: ë¹„ì •ìƒ\")\n",
    "        return False, [\"driver_inactive\"]\n",
    "    \n",
    "    # í˜„ì¬ í˜ì´ì§€ê°€ ëª©ë¡í˜ì´ì§€ì¸ì§€ í™•ì¸\n",
    "    try:\n",
    "        product_links = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/products/'], a[href*='/offers/']\")\n",
    "        if len(product_links) >= 5:\n",
    "            print(f\"âœ… ëª©ë¡í˜ì´ì§€ í™•ì¸: {len(product_links)}ê°œ ìƒí’ˆ ë§í¬\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ ëª©ë¡í˜ì´ì§€ ì˜ì‹¬: {len(product_links)}ê°œ ìƒí’ˆ ë§í¬ë§Œ ë°œê²¬\")\n",
    "    except:\n",
    "        print(f\"âš ï¸ í˜ì´ì§€ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨\")\n",
    "    \n",
    "    print(f\"âœ… í˜ì´ì§€ë„¤ì´ì…˜ í™˜ê²½ ê²€ì¦ ì™„ë£Œ!\")\n",
    "    return True, []\n",
    "\n",
    "def get_pagination_progress_info(total_crawled, target_products, current_page):\n",
    "    \"\"\"\n",
    "    í˜ì´ì§€ë„¤ì´ì…˜ ì§„í–‰ ìƒí™© ì •ë³´ ìƒì„±\n",
    "    \"\"\"\n",
    "    progress_percentage = (total_crawled / target_products * 100) if target_products > 0 else 0\n",
    "    remaining = max(0, target_products - total_crawled)\n",
    "    \n",
    "    return {\n",
    "        'total_crawled': total_crawled,\n",
    "        'target_products': target_products,\n",
    "        'remaining': remaining,\n",
    "        'progress_percentage': progress_percentage,\n",
    "        'current_page': current_page,\n",
    "        'estimated_pages': (target_products // 24) + (1 if target_products % 24 > 0 else 0)\n",
    "    }\n",
    "\n",
    "def print_pagination_progress(progress_info):\n",
    "    \"\"\"\n",
    "    í˜ì´ì§€ë„¤ì´ì…˜ ì§„í–‰ë¥  ì‹œê°ì  í‘œì‹œ\n",
    "    \"\"\"\n",
    "    percentage = progress_info['progress_percentage']\n",
    "    bar_length = 30\n",
    "    filled_length = int(bar_length * progress_info['total_crawled'] // progress_info['target_products'])\n",
    "    bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š í˜ì´ì§€ë„¤ì´ì…˜ ì§„í–‰ë¥ : [{bar}] {percentage:.1f}%\")\n",
    "    print(f\"   ğŸ¯ ì§„í–‰: {progress_info['total_crawled']}/{progress_info['target_products']}ê°œ\")\n",
    "    print(f\"   ğŸ“„ í˜ì´ì§€: {progress_info['current_page']}í˜ì´ì§€\")\n",
    "    print(f\"   â±ï¸ ë‚¨ì€ ìƒí’ˆ: {progress_info['remaining']}ê°œ\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ¯ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ\n",
    "# =============================================================================\n",
    "\n",
    "print(\"âœ… ê·¸ë£¹ 9-A: í˜ì´ì§€ë„¤ì´ì…˜ í•µì‹¬ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ!\")\n",
    "print(\"   ğŸ“Š save_pagination_state() - í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ì €ì¥\")\n",
    "print(\"   ğŸ“Š load_pagination_state() - í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ë¡œë“œ\")\n",
    "print(\"   ğŸ”— save_list_page_url() - ëª©ë¡í˜ì´ì§€ URL ì €ì¥\")\n",
    "print(\"   ğŸ”™ return_to_list_page() - ëª©ë¡í˜ì´ì§€ ì•ˆì „ ë³µê·€\")\n",
    "print(\"   ğŸ”„ click_next_page_enhanced() - ê°•í™”ëœ ë‹¤ìŒí˜ì´ì§€ ì´ë™\")\n",
    "print(\"   ğŸ”§ attempt_page_recovery() - í˜ì´ì§€ ì˜¤ë¥˜ ë³µêµ¬\")\n",
    "print(\"   ğŸ§° validate_pagination_environment() - í™˜ê²½ ê²€ì¦\")\n",
    "print()\n",
    "print(\"ğŸš€ ë‹¤ìŒ: ê·¸ë£¹ 9-Bë¥¼ ì‹¤í–‰í•˜ì—¬ ì™„ì „í•œ í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ ì‹œì‘!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f836a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ ê·¸ë£¹ 9-B: ì™„ì „í•œ í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ ì‹¤í–‰ ë¡œë”©...\n",
      "âœ… ê·¸ë£¹ 9-B: í¬ë¡¤ë§ ì—”ì§„ ë¡œë“œ ì™„ë£Œ!\n",
      "   âš™ï¸ ì´ ì…€ì€ ì‹¤ì œ í¬ë¡¤ë§ì„ ìˆ˜í–‰í•˜ëŠ” í•µì‹¬ ì—”ì§„ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
      "\n",
      "ğŸš€ ë‹¤ìŒ: ê·¸ë£¹ 10ì„ ì‹¤í–‰í•˜ì—¬ ì œì–´íŒì„ ì‚¬ìš©í•˜ì„¸ìš”.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ğŸš€ ê·¸ë£¹ 9-B: ì™„ì „í•œ í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ ì‹¤í–‰\n",
    "# - ë©”ì¸ í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ ë£¨í”„, ë‹¨ì¼ ìƒí’ˆ í¬ë¡¤ë§, í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤\n",
    "# - ê·¸ë£¹ 9-Aì˜ í•µì‹¬ ì‹œìŠ¤í…œ + ê¸°ì¡´ ê·¸ë£¹ 1-8ì˜ ëª¨ë“  í•¨ìˆ˜ë“¤ í™œìš©\n",
    "# =============================================================================\n",
    "\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"ğŸ”§ ê·¸ë£¹ 9-B: ì™„ì „í•œ í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ ì‹¤í–‰ ë¡œë”©...\")\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ¯ ë©”ì¸ í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ ì‹œìŠ¤í…œ\n",
    "# =============================================================================\n",
    "\n",
    "def crawl_with_full_pagination(city_name, target_products=100, resume_session=True):\n",
    "    \"\"\"\n",
    "    ğŸ¯ ì™„ì „í•œ í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ ë©”ì¸ í•¨ìˆ˜\n",
    "    \n",
    "    Args:\n",
    "        city_name: í¬ë¡¤ë§í•  ë„ì‹œëª…\n",
    "        target_products: ëª©í‘œ ìƒí’ˆ ìˆ˜\n",
    "        resume_session: ì´ì „ ì„¸ì…˜ ì´ì–´ì„œ ì‹¤í–‰ ì—¬ë¶€\n",
    "    \"\"\"\n",
    "    print(f\"ğŸš€ ì™„ì „í•œ í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ ì‹œì‘!\")\n",
    "    print(f\"ğŸ¯ ëª©í‘œ: {city_name} {target_products}ê°œ ìƒí’ˆ\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. í™˜ê²½ ê²€ì¦\n",
    "    env_valid, missing = validate_pagination_environment()\n",
    "    if not env_valid:\n",
    "        print(f\"âŒ í™˜ê²½ ê²€ì¦ ì‹¤íŒ¨: {missing}\")\n",
    "        return False\n",
    "    \n",
    "    # 2. ì „ì—­ ë³€ìˆ˜ í™œìš© (ê·¸ë£¹ 6-8ì—ì„œ ì„¤ì •ë¨)\n",
    "    global start_number, completed_urls, continent, country, driver\n",
    "    \n",
    "   \n",
    "    # 3. ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ (1ë¶€í„° ì‹œì‘ ë³´ì¥)\n",
    "    current_page = 1\n",
    "    total_crawled = 0\n",
    "    current_product_number = max(1, start_number)  # ìµœì†Œ 1 ë³´ì¥\n",
    "    all_results = []\n",
    "\n",
    "    # ì´ì „ ì„¸ì…˜ ë³µì› ì‹œë„\n",
    "    if resume_session:\n",
    "        prev_state = load_pagination_state(city_name)\n",
    "        if prev_state and prev_state.get(\"status\") != \"completed\":\n",
    "            current_page = prev_state.get(\"current_page\", 1)\n",
    "            print(f\"ğŸ”„ ì´ì „ ì„¸ì…˜ ë³µì›: {current_page}í˜ì´ì§€ë¶€í„° ì¬ê°œ\")\n",
    "            \n",
    "            # í•´ë‹¹ í˜ì´ì§€ë¡œ ë³µêµ¬ ì‹œë„\n",
    "            if current_page > 1:\n",
    "                recovery_success, recovery_url = attempt_page_recovery(driver, city_name, current_page)\n",
    "                if not recovery_success:\n",
    "                    print(f\"âš ï¸ í˜ì´ì§€ ë³µêµ¬ ì‹¤íŒ¨ - 1í˜ì´ì§€ë¶€í„° ì¬ì‹œì‘\")\n",
    "                    current_page = 1\n",
    "    \n",
    "    print(f\"ğŸ“Š í¬ë¡¤ë§ ì„¤ì •:\")\n",
    "    print(f\"   ğŸ™ï¸ ë„ì‹œ: {city_name}\")\n",
    "    print(f\"   ğŸ¯ ëª©í‘œ: {target_products}ê°œ\")\n",
    "    print(f\"   ğŸ”¢ ì‹œì‘ ë²ˆí˜¸: {current_product_number}\")\n",
    "    print(f\"   ğŸ“„ ì‹œì‘ í˜ì´ì§€: {current_page}\")\n",
    "    print(f\"   ğŸ“ ìœ„ì¹˜: {continent}/{country}\")\n",
    "    \n",
    "    # 4. ë©”ì¸ í˜ì´ì§€ë„¤ì´ì…˜ ë£¨í”„\n",
    "    while total_crawled < target_products:\n",
    "        \n",
    "        # [ì¶”ê°€] 5í˜ì´ì§€ë§ˆë‹¤ í•œ ë²ˆì”© ê¸¸ê²Œ íœ´ì‹\n",
    "        if current_page > 1 and current_page % 5 == 0:\n",
    "            long_sleep = random.uniform(CONFIG[\"LONG_MIN_DELAY\"], CONFIG[\"LONG_MAX_DELAY\"])\n",
    "            print(f\"  â˜•ï¸ ë´‡ íƒì§€ íšŒí”¼ë¥¼ ìœ„í•´ ì ì‹œ íœ´ì‹í•©ë‹ˆë‹¤... ({long_sleep:.1f}ì´ˆ)\")\n",
    "            time.sleep(long_sleep)\n",
    "        print(f\"\\nğŸ“„ === {current_page}í˜ì´ì§€ ì²˜ë¦¬ ì‹œì‘ ===\")\n",
    "        \n",
    "        try:\n",
    "            # í˜„ì¬ ëª©ë¡í˜ì´ì§€ URL ì €ì¥\n",
    "            current_list_url = save_list_page_url(driver, city_name, current_page)\n",
    "            if not current_list_url:\n",
    "                print(f\"âŒ ëª©ë¡í˜ì´ì§€ URL ì €ì¥ ì‹¤íŒ¨\")\n",
    "                break\n",
    "            \n",
    "            # í˜„ì¬ í˜ì´ì§€ì˜ URL ìˆ˜ì§‘\n",
    "            print(f\"ğŸ“Š {current_page}í˜ì´ì§€ URL ìˆ˜ì§‘ ì¤‘...\")\n",
    "            page_urls = collect_all_24_urls(driver)\n",
    "            \n",
    "            if random.random() < 0.4:  # 40% í™•ë¥ \n",
    "                human_like_scroll_patterns(driver)\n",
    "\n",
    "            if not page_urls:\n",
    "                print(f\"âš ï¸ {current_page}í˜ì´ì§€: URL ì—†ìŒ\")\n",
    "                break\n",
    "            \n",
    "            print(f\"âœ… {current_page}í˜ì´ì§€ì—ì„œ {len(page_urls)}ê°œ URL ë°œê²¬\")\n",
    "\n",
    "            # DEPRECATED: í…ŒìŠ¤íŠ¸ìš© í˜ì´ì§€ë‹¹ 2ê°œ ì œí•œ (v1.0ì—ì„œ ì‚¬ìš© ì¤‘ë‹¨) #\n",
    "            #remaining_target = min(1, target_products - total_crawled)  \n",
    "\n",
    "            # í˜„ì¬ ê¶Œì¥ ì½”ë“œ\n",
    "            remaining_target = target_products - total_crawled  # ì œí•œ ì—†ìŒ (24ê°œê¹Œì§€)\n",
    "            urls_to_process = page_urls[:remaining_target]\n",
    "            \n",
    "            print(f\"ğŸ¯ {current_page}í˜ì´ì§€ì—ì„œ {len(urls_to_process)}ê°œ ìƒí’ˆ í¬ë¡¤ë§ ì‹œì‘...\")\n",
    "            \n",
    "            \n",
    "            # 5. í˜ì´ì§€ ë‚´ ìƒí’ˆë“¤ ìˆœì°¨ í¬ë¡¤ë§\n",
    "            page_results = []\n",
    "            \n",
    "            for url_index, product_url in enumerate(urls_to_process):\n",
    "                print(f\"    ğŸ“¦ ìƒí’ˆ {current_product_number} ì²˜ë¦¬ ì¤‘... ({url_index+1}/{len(urls_to_process)})\")\n",
    "                \n",
    "                # ğŸ†• í¬ë¡¤ë§ ë°©ë²• ì„ íƒ ë¡œì§ (ê¸°ì¡´ ì½”ë“œ ëŒ€ì²´)\n",
    "                use_new_tab_method = CONFIG.get(\"NEW_TAB_ENABLED\", False)\n",
    "                \n",
    "                if use_new_tab_method:\n",
    "                    print(f\"    âš¡ ìƒˆ íƒ­ ìµœì í™” ë°©ì‹ ì‚¬ìš©\")\n",
    "                    result = crawl_single_product_new_tab_method(  # ê·¸ë£¹ 5ì˜ ìƒˆ í•¨ìˆ˜\n",
    "                        driver, product_url, current_product_number, \n",
    "                        city_name, continent, country, current_page\n",
    "                    )\n",
    "                else:\n",
    "                    print(f\"    ğŸ”„ ê¸°ì¡´ ì•ˆì •ì  ë°©ì‹ ì‚¬ìš©\")\n",
    "                    result = crawl_single_product_optimized(  # ê¸°ì¡´ í•¨ìˆ˜\n",
    "                        driver, product_url, current_product_number, \n",
    "                        city_name, continent, country, current_page\n",
    "                    )\n",
    "                \n",
    "                if result:\n",
    "                    page_results.append(result)\n",
    "                    total_crawled += 1\n",
    "                    current_product_number += 1\n",
    "                    \n",
    "                    print(f\"    âœ… ìƒí’ˆ {current_product_number-1} ì™„ë£Œ: {result.get('ìƒí’ˆëª…', '')[:30]}...\")\n",
    "                    \n",
    "                    # ìƒíƒœ ì €ì¥ (ê° ìƒí’ˆ ì™„ë£Œ ì‹œ)\n",
    "                    save_crawler_state(crawler_state, product_url)\n",
    "                    \n",
    "                    # ëª©í‘œ ë‹¬ì„± í™•ì¸\n",
    "                    if total_crawled >= target_products:\n",
    "                        print(f\"    ğŸ‰ ëª©í‘œ {target_products}ê°œ ë‹¬ì„±! í¬ë¡¤ë§ ì™„ë£Œ\")\n",
    "                        break\n",
    "                else:\n",
    "                    print(f\"    âŒ ìƒí’ˆ {current_product_number} ì²˜ë¦¬ ì‹¤íŒ¨\")\n",
    "                    current_product_number += 1\n",
    "                    continue\n",
    "\n",
    "                        \n",
    "            # 6. í˜ì´ì§€ë³„ ë°°ì¹˜ ì €ì¥\n",
    "            if page_results:\n",
    "                batch_result = save_batch_data(page_results, city_name)\n",
    "                if batch_result:\n",
    "                    print(f\"âœ… {current_page}í˜ì´ì§€ ë°°ì¹˜ ì €ì¥ ì™„ë£Œ: {len(page_results)}ê°œ\")\n",
    "                all_results.extend(page_results)\n",
    "            \n",
    "            # 7. í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ì €ì¥\n",
    "            save_pagination_state(city_name, current_page, current_list_url, total_crawled, target_products)\n",
    "            \n",
    "            # 8. ì§„í–‰ë¥  í‘œì‹œ\n",
    "            progress_info = get_pagination_progress_info(total_crawled, target_products, current_page)\n",
    "            print_pagination_progress(progress_info)\n",
    "            \n",
    "            print(f\"ğŸ“„ {current_page}í˜ì´ì§€ ì™„ë£Œ: {len(page_results)}ê°œ ìˆ˜ì§‘ (ì „ì²´: {total_crawled}/{target_products})\")\n",
    "            \n",
    "            # 9. ëª©í‘œ ë‹¬ì„± í™•ì¸\n",
    "            if total_crawled >= target_products:\n",
    "                print(f\"ğŸ‰ ëª©í‘œ {target_products}ê°œ ë‹¬ì„±! í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ ì™„ë£Œ\")\n",
    "                break\n",
    "            \n",
    "            # 10. ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™\n",
    "            print(f\"ğŸ”„ ë‹¤ìŒ í˜ì´ì§€ ì´ë™ ì¤€ë¹„...\")\n",
    "            \n",
    "            # ëª©ë¡í˜ì´ì§€ë¡œ ë³µê·€\n",
    "            return_success, new_list_url = return_to_list_page(driver, current_list_url, city_name)\n",
    "            \n",
    "            if not return_success:\n",
    "                print(f\"âŒ ëª©ë¡í˜ì´ì§€ ë³µê·€ ì‹¤íŒ¨ - ë³µêµ¬ ì‹œë„\")\n",
    "                recovery_success, recovery_url = attempt_page_recovery(driver, city_name, current_page)\n",
    "                if not recovery_success:\n",
    "                    print(f\"ğŸš¨ ë³µêµ¬ ì‹¤íŒ¨: í¬ë¡¤ë§ ì¤‘ë‹¨\")\n",
    "                    break\n",
    "                new_list_url = recovery_url\n",
    "            \n",
    "            # ë‹¤ìŒ í˜ì´ì§€ ì´ë™\n",
    "            next_success, next_message, next_url = click_next_page_enhanced(driver, current_page)\n",
    "            \n",
    "            if next_success:\n",
    "                current_page += 1\n",
    "                print(f\"âœ… {current_page}í˜ì´ì§€ë¡œ ì´ë™ ì™„ë£Œ\")\n",
    "                time.sleep(random.uniform(2, 4))\n",
    "            else:\n",
    "                if \"ë§ˆì§€ë§‰ í˜ì´ì§€\" in next_message or \"ë²„íŠ¼ ì—†ìŒ\" in next_message:\n",
    "                    print(f\"ğŸ ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬: {next_message}\")\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"âŒ í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨: {next_message}\")\n",
    "                    # ë³µêµ¬ ì‹œë„\n",
    "                    recovery_success, recovery_url = attempt_page_recovery(driver, city_name, current_page + 1)\n",
    "                    if recovery_success:\n",
    "                        current_page += 1\n",
    "                        print(f\"âœ… ë³µêµ¬ë¡œ {current_page}í˜ì´ì§€ ì´ë™\")\n",
    "                    else:\n",
    "                        print(f\"ğŸš¨ ë³µêµ¬ ì‹¤íŒ¨: í¬ë¡¤ë§ ì¤‘ë‹¨\")\n",
    "                        break\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ {current_page}í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "            \n",
    "            # í˜ì´ì§€ ì˜¤ë¥˜ ë³µêµ¬ ì‹œë„\n",
    "            recovery_success, recovery_url = attempt_page_recovery(driver, city_name, current_page)\n",
    "            if recovery_success:\n",
    "                print(f\"âœ… í˜ì´ì§€ ì˜¤ë¥˜ ë³µêµ¬ ì„±ê³µ\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"ğŸš¨ í˜ì´ì§€ ì˜¤ë¥˜ ë³µêµ¬ ì‹¤íŒ¨: í¬ë¡¤ë§ ì¤‘ë‹¨\")\n",
    "                break\n",
    "    \n",
    "    # 11. ìµœì¢… ì™„ë£Œ ì²˜ë¦¬\n",
    "    clear_pagination_state(city_name)\n",
    "    \n",
    "    print(f\"ğŸ”„ í¬ë¡¤ë§ ì™„ë£Œ - ì‚¼ì¤‘ ë™ê¸°í™” ì‹¤í–‰ ì¤‘...\")\n",
    "    triple_sync_url_system(city_name)\n",
    "    print(f\"\\nğŸ‰ ì™„ì „í•œ í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ ì™„ë£Œ!\")\n",
    "    print(f\"ğŸ“Š ìµœì¢… ê²°ê³¼:\")\n",
    "    print(f\"   ğŸ¯ ëª©í‘œ/ì‹¤ì œ: {target_products}/{total_crawled}ê°œ\")\n",
    "    print(f\"   ğŸ“„ ì²˜ë¦¬ í˜ì´ì§€: {current_page}í˜ì´ì§€\")\n",
    "    print(f\"   ğŸ”¢ ë²ˆí˜¸ ë²”ìœ„: {start_number} ~ {current_product_number - 1}\")\n",
    "    print(f\"   ğŸ“ ì €ì¥ ìœ„ì¹˜: data/{continent}/{country}/{city_name}/\")\n",
    "    print(f\"   ğŸ“· ì´ë¯¸ì§€ ìœ„ì¹˜: myrealtripthumb_img/{continent}/{country}/{city_name}/\")\n",
    "    \n",
    "    return {\n",
    "        'success': True,\n",
    "        'total_crawled': total_crawled,\n",
    "        'pages_processed': current_page,\n",
    "        'final_product_number': current_product_number - 1,\n",
    "        'results': all_results\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ”§ ë‹¨ì¼ ìƒí’ˆ í¬ë¡¤ë§ í•¨ìˆ˜ (ê¸°ì¡´ ê·¸ë£¹ 1-2 í•¨ìˆ˜ë“¤ í™œìš©)\n",
    "# =============================================================================\n",
    "\n",
    "def crawl_single_product_optimized(driver, product_url, product_number, city_name, continent, country, page_num):\n",
    "    \"\"\"\n",
    "    ë‹¨ì¼ ìƒí’ˆ í¬ë¡¤ë§ ìµœì í™” ë²„ì „ (ë„ì‹œID ì¶”ê°€)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ìƒí’ˆ í˜ì´ì§€ ì´ë™\n",
    "        driver.get(product_url)\n",
    "        time.sleep(random.uniform(CONFIG[\"MEDIUM_MIN_DELAY\"], CONFIG[\"MEDIUM_MAX_DELAY\"]))\n",
    "        \n",
    "        # URL íƒ€ì… íŒë³„\n",
    "        url_type = \"Product\" if \"/products/\" in product_url else \"Offer\"\n",
    "        \n",
    "        # ì •ë³´ ìˆ˜ì§‘ (ê¸°ì¡´ ê·¸ë£¹ 1-2 í•¨ìˆ˜ë“¤ í™œìš©)\n",
    "        product_name = get_product_name(driver, url_type)\n",
    "        price_raw = get_price(driver)\n",
    "        price_clean = clean_price(price_raw)\n",
    "        rating_raw = get_rating(driver)\n",
    "        rating_clean = clean_rating(rating_raw)\n",
    "        review_count = get_review_count(driver)\n",
    "        language = get_language(driver)\n",
    "        \n",
    "        # ğŸ†• ë„ì‹œID ìƒì„± (1ë¶€í„° ì‹œì‘)\n",
    "        city_code = get_city_code(city_name)\n",
    "        city_id = f\"{city_code}_{product_number}\"\n",
    "        \n",
    "        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ê¸°ì¡´ í•¨ìˆ˜ í™œìš©)\n",
    "        if CONFIG[\"SAVE_IMAGES\"]:\n",
    "            img_info = download_image(driver, product_name, city_name, product_number)\n",
    "        else:\n",
    "            img_info = {\n",
    "                'filename': '', 'relative_path': '', 'path': '', \n",
    "                'status': 'skipped', 'size': 0\n",
    "            }\n",
    "        \n",
    "        # ê²°ê³¼ ë°˜í™˜ (ë„ì‹œID í•„ë“œ ì¶”ê°€)\n",
    "        return {\n",
    "            'ë²ˆí˜¸': product_number,\n",
    "            'ë„ì‹œID': city_id,  # ğŸ†• ì¶”ê°€\n",
    "            'í˜ì´ì§€': page_num,\n",
    "            'ëŒ€ë¥™': continent,\n",
    "            'êµ­ê°€': country,\n",
    "            'ë„ì‹œ': city_name,\n",
    "            'ê³µí•­ì½”ë“œ': city_code,\n",
    "            'ìƒí’ˆíƒ€ì…': url_type,\n",
    "            'ìƒí’ˆëª…': product_name,\n",
    "            'ê°€ê²©_ì›ë³¸': price_raw,\n",
    "            'ê°€ê²©_ì •ì œ': price_clean,\n",
    "            'í‰ì _ì›ë³¸': rating_raw,\n",
    "            'í‰ì _ì •ì œ': rating_clean,\n",
    "            'ë¦¬ë·°ìˆ˜': review_count,\n",
    "            'ì–¸ì–´': language,\n",
    "            'ì´ë¯¸ì§€_íŒŒì¼ëª…': img_info.get('filename', ''),\n",
    "            'ì´ë¯¸ì§€_ìƒëŒ€ê²½ë¡œ': img_info.get('relative_path', ''),\n",
    "            'ì´ë¯¸ì§€_ì „ì²´ê²½ë¡œ': img_info.get('path', ''),\n",
    "            'ì´ë¯¸ì§€_ìƒíƒœ': img_info.get('status', ''),\n",
    "            'ì´ë¯¸ì§€_í¬ê¸°': img_info.get('size', 0),\n",
    "            'URL': product_url,\n",
    "            'ìˆ˜ì§‘_ì‹œê°„': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'ìƒíƒœ': 'ì™„ì „ìˆ˜ì§‘'\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"      âŒ ìƒí’ˆ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ¯ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ\n",
    "# =============================================================================\n",
    "\n",
    "print(\"âœ… ê·¸ë£¹ 9-B: í¬ë¡¤ë§ ì—”ì§„ ë¡œë“œ ì™„ë£Œ!\")\n",
    "print(\"   âš™ï¸ ì´ ì…€ì€ ì‹¤ì œ í¬ë¡¤ë§ì„ ìˆ˜í–‰í•˜ëŠ” í•µì‹¬ ì—”ì§„ì„ ì •ì˜í•©ë‹ˆë‹¤.\")\n",
    "print(\"\\nğŸš€ ë‹¤ìŒ: ê·¸ë£¹ 10ì„ ì‹¤í–‰í•˜ì—¬ ì œì–´íŒì„ ì‚¬ìš©í•˜ì„¸ìš”.\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab853b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ ê·¸ë£¹ 10: ê°œì„ ëœ ì™„ì „ ë²”ìš© ì ì‘í˜• í¬ë¡¤ë§ ì‹œìŠ¤í…œ ë¡œë”©...\n",
      "âœ… ê°œì„ ëœ ê·¸ë£¹ 10 ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ!\n",
      "\n",
      "ğŸ”§ ì£¼ìš” ê°œì„ ì‚¬í•­:\n",
      "   ğŸ¯ ë‹¤ì¤‘ ì„ íƒì íŒ¨í„´ ì§€ì›\n",
      "   ğŸ“Š ì ìˆ˜ ê¸°ë°˜ ë²„íŠ¼ ì„ íƒ\n",
      "   ğŸ”„ ë‹¤ë‹¨ê³„ fallback ì‹œìŠ¤í…œ\n",
      "   ğŸ” ê°•í™”ëœ ë””ë²„ê¹… ê¸°ëŠ¥\n",
      "\n",
      "ğŸš€ ë””ë²„ê¹… í•¨ìˆ˜:\n",
      "   debug_page_state(driver)      # í˜ì´ì§€ ìƒíƒœ í™•ì¸\n",
      "   test_group11_with_debug()     # ë””ë²„ê¹… í¬í•¨ í…ŒìŠ¤íŠ¸\n",
      "   find_tour_ticket_buttons(driver)  # ë²„íŠ¼ ì°¾ê¸°ë§Œ í…ŒìŠ¤íŠ¸\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ğŸš€ ê·¸ë£¹ 10: ê°œì„ ëœ ì™„ì „ ë²”ìš© ì ì‘í˜• í¬ë¡¤ë§ ì‹œìŠ¤í…œ\n",
    "# - ë” ê°•ë ¥í•œ ë²„íŠ¼ ì°¾ê¸° ë¡œì§\n",
    "# - ë‹¤ì¤‘ ì„ íƒì íŒ¨í„´ ì§€ì›\n",
    "# - ë””ë²„ê¹… ì •ë³´ ê°•í™”\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ”§ ê·¸ë£¹ 10: ê°œì„ ëœ ì™„ì „ ë²”ìš© ì ì‘í˜• í¬ë¡¤ë§ ì‹œìŠ¤í…œ ë¡œë”©...\")\n",
    "\n",
    "def detect_search_system_type(driver):\n",
    "    \"\"\"í˜„ì¬ í˜ì´ì§€ê°€ ì–´ë–¤ íƒ€ì…ì˜ ê²€ìƒ‰ ê²°ê³¼ì¸ì§€ íƒì§€ (ê°•í™”ëœ ë²„ì „)\"\"\"\n",
    "    print(\"  ğŸ” ê²€ìƒ‰ ì‹œìŠ¤í…œ íƒ€ì… íƒì§€ ì¤‘...\")\n",
    "\n",
    "    try:\n",
    "        current_url = driver.current_url\n",
    "        print(f\"    ğŸ“ í˜„ì¬ URL: {current_url}\")\n",
    "\n",
    "        # URL íŒ¨í„´ìœ¼ë¡œ 1ì°¨ íŒë³„\n",
    "        if \"offers\" in current_url and (\"qct=\" in current_url or \"qcr=\" in current_url):\n",
    "            print(\"  âœ… ê°ì§€: ê¸°ì¡´ í˜ì´ì§€ë„¤ì´ì…˜ ê¸°ë°˜ ê²€ìƒ‰ (offers)\")\n",
    "            return \"pagination_based\"\n",
    "\n",
    "        if \"search\" in current_url and \"q=\" in current_url:\n",
    "            print(\"  âœ… ê°ì§€: ìƒˆë¡œìš´ í†µí•© ê²€ìƒ‰ ì‹œìŠ¤í…œ\")\n",
    "            return \"integrated_search\"\n",
    "\n",
    "        # í˜ì´ì§€ ì½˜í…ì¸ ë¡œ 2ì°¨ íŒë³„ (ëŒ€ê¸° ì‹œê°„ ì¦ê°€)\n",
    "        time.sleep(3)\n",
    "\n",
    "        # ğŸŒ ë‹¤ì–‘í•œ ì„ íƒìë¡œ íˆ¬ì–´Â·í‹°ì¼“ ë²„íŠ¼ íƒì§€\n",
    "        tour_selectors = [\n",
    "            \"a[href*='tab=tour']\",\n",
    "            \"a[href*='tours']\", \n",
    "            \"button[href*='tour']\",\n",
    "            \"div[data-testid*='tour'] a\",\n",
    "            \"section[data-category='tour'] a\"\n",
    "        ]\n",
    "        \n",
    "        tour_ticket_buttons = []\n",
    "        for selector in tour_selectors:\n",
    "            elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "            tour_ticket_buttons.extend(elements)\n",
    "            if elements:\n",
    "                print(f\"    ğŸ¯ ì„ íƒì '{selector}'ë¡œ {len(elements)}ê°œ ìš”ì†Œ ë°œê²¬\")\n",
    "\n",
    "        # ì¹´í…Œê³ ë¦¬ í—¤ë” íƒì§€ (ë‹¤ì–‘í•œ ì„ íƒì)\n",
    "        header_selectors = [\n",
    "            \"header.css-1tahspn\",\n",
    "            \"h2[class*='category']\",\n",
    "            \"div[class*='category-header']\",\n",
    "            \".category-title\",\n",
    "            \"[data-testid*='category']\"\n",
    "        ]\n",
    "        \n",
    "        category_headers = []\n",
    "        for selector in header_selectors:\n",
    "            elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "            category_headers.extend(elements)\n",
    "\n",
    "        if len(tour_ticket_buttons) > 0 and len(category_headers) > 0:\n",
    "            print(f\"  âœ… ê°ì§€: ìƒˆë¡œìš´ ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ê²€ìƒ‰ ({len(category_headers)}ê°œ ì¹´í…Œê³ ë¦¬)\")\n",
    "            return \"category_based\"\n",
    "\n",
    "        # ì¼ë°˜ ìƒí’ˆ ë§í¬ ê°œìˆ˜ë¡œ 3ì°¨ íŒë³„\n",
    "        product_selectors = [\n",
    "            \"a[href*='/products/']\",\n",
    "            \"a[href*='/offers/']\", \n",
    "            \"a[href*='/activities/']\",\n",
    "            \"[data-testid*='product'] a\"\n",
    "        ]\n",
    "        \n",
    "        product_links = []\n",
    "        for selector in product_selectors:\n",
    "            elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "            product_links.extend(elements)\n",
    "\n",
    "        unique_products = len(set(link.get_attribute('href') for link in product_links if link.get_attribute('href')))\n",
    "\n",
    "        if unique_products >= 20:\n",
    "            print(f\"  âœ… ê°ì§€: í‘œì¤€ ëª©ë¡ í˜ì´ì§€ ({unique_products}ê°œ ê³ ìœ  ìƒí’ˆ)\")\n",
    "            return \"standard_list\"\n",
    "\n",
    "        print(f\"  âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” í˜ì´ì§€ íƒ€ì… (ê³ ìœ  ìƒí’ˆ ë§í¬: {unique_products}ê°œ)\")\n",
    "        return \"unknown\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ ì‹œìŠ¤í…œ íƒ€ì… íƒì§€ ì‹¤íŒ¨: {e}\")\n",
    "        return \"error\"\n",
    "\n",
    "def find_tour_ticket_buttons(driver):\n",
    "    \"\"\"\n",
    "    ğŸ” ê°•í™”ëœ íˆ¬ì–´Â·í‹°ì¼“ ë²„íŠ¼ ì°¾ê¸° ë¡œì§\n",
    "    - ë‹¤ì¤‘ ì„ íƒì íŒ¨í„´ ì§€ì›\n",
    "    - í…ìŠ¤íŠ¸ íŒ¨í„´ ë¶„ì„ ê°•í™”\n",
    "    - ê°€ì‹œì„± ë° í™œì„±í™” ìƒíƒœ ì²´í¬\n",
    "    \"\"\"\n",
    "    print(\"  ğŸ” íˆ¬ì–´Â·í‹°ì¼“ ë²„íŠ¼ ì°¾ê¸° ì‹œì‘...\")\n",
    "    \n",
    "    # ğŸ¯ ë‹¤ì–‘í•œ ì„ íƒì íŒ¨í„´ìœ¼ë¡œ ë§í¬ ìˆ˜ì§‘\n",
    "    selectors = [\n",
    "        \"a[href*='tab=tour']\",\n",
    "        \"a[href*='tours']\",\n",
    "        \"a[href*='tour']\",\n",
    "        \"a[class*='tour']\",\n",
    "        \"[data-testid*='tour'] a\",\n",
    "        \"button[onclick*='tour']\"\n",
    "    ]\n",
    "    \n",
    "    all_links = []\n",
    "    \n",
    "    for selector in selectors:\n",
    "        try:\n",
    "            elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "            for element in elements:\n",
    "                if element not in all_links:\n",
    "                    all_links.append(element)\n",
    "            if elements:\n",
    "                print(f\"    ğŸ“Š ì„ íƒì '{selector}': {len(elements)}ê°œ ìš”ì†Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"    âš ï¸ ì„ íƒì '{selector}' ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    print(f\"    ğŸ“ˆ ì´ {len(all_links)}ê°œ í›„ë³´ ë§í¬ ë°œê²¬\")\n",
    "    \n",
    "    if not all_links:\n",
    "        return []\n",
    "    \n",
    "    # ğŸ¯ í›„ë³´ ë§í¬ë“¤ ë¶„ì„\n",
    "    analyzed_buttons = []\n",
    "    \n",
    "    for i, link in enumerate(all_links):\n",
    "        try:\n",
    "            analysis = analyze_button(link, i)\n",
    "            if analysis:\n",
    "                analyzed_buttons.append(analysis)\n",
    "        except Exception as e:\n",
    "            print(f\"    âš ï¸ ë§í¬ {i} ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    return analyzed_buttons\n",
    "\n",
    "def analyze_button(element, index):\n",
    "    \"\"\"\n",
    "    ğŸ”¬ ê°œë³„ ë²„íŠ¼ ìƒì„¸ ë¶„ì„\n",
    "    - í…ìŠ¤íŠ¸ íŒ¨í„´ ë¶„ì„\n",
    "    - URL íŒ¨í„´ ë¶„ì„  \n",
    "    - ê°€ì‹œì„± ë° ìƒí˜¸ì‘ìš© ê°€ëŠ¥ì„± ì²´í¬\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = element.text.strip()\n",
    "        href = element.get_attribute('href') or \"\"\n",
    "        \n",
    "        # ê¸°ë³¸ ì •ë³´ ì¶œë ¥\n",
    "        print(f\"    ğŸ” ë²„íŠ¼ {index}: '{text}' -> {href}\")\n",
    "        \n",
    "        # ì¡°ê±´ë³„ ì ìˆ˜ ê³„ì‚°\n",
    "        score = 0\n",
    "        reasons = []\n",
    "        \n",
    "        # 1. í…ìŠ¤íŠ¸ íŒ¨í„´ ë¶„ì„ (ê°€ì¤‘ì¹˜ ë†’ìŒ)\n",
    "        text_lower = text.lower()\n",
    "        if 'ë”ë³´ê¸°' in text:\n",
    "            score += 30\n",
    "            reasons.append(\"í…ìŠ¤íŠ¸ì— 'ë”ë³´ê¸°' í¬í•¨\")\n",
    "        if 'íˆ¬ì–´' in text or 'tour' in text_lower:\n",
    "            score += 20\n",
    "            reasons.append(\"íˆ¬ì–´ ê´€ë ¨ í…ìŠ¤íŠ¸\")\n",
    "        if 'í‹°ì¼“' in text or 'ticket' in text_lower:\n",
    "            score += 15\n",
    "            reasons.append(\"í‹°ì¼“ ê´€ë ¨ í…ìŠ¤íŠ¸\")\n",
    "        if any(char.isdigit() for char in text):\n",
    "            score += 25\n",
    "            reasons.append(\"ìˆ«ì í¬í•¨\")\n",
    "        \n",
    "        # 2. URL íŒ¨í„´ ë¶„ì„\n",
    "        if 'tab=tour' in href:\n",
    "            score += 40\n",
    "            reasons.append(\"URLì— tab=tour\")\n",
    "        if 'extra=' in href:\n",
    "            score += 20\n",
    "            reasons.append(\"URLì— extra= íŒŒë¼ë¯¸í„°\")\n",
    "        if 'www.myrealtrip.com' in href:\n",
    "            score += 15\n",
    "            reasons.append(\"ì˜¬ë°”ë¥¸ ë„ë©”ì¸\")\n",
    "        if 'accommodation.myrealtrip.com' in href:\n",
    "            score -= 50  # ìˆ™ì†Œ ì‚¬ì´íŠ¸ëŠ” ì œì™¸\n",
    "            reasons.append(\"âŒ ìˆ™ì†Œ ì‚¬ì´íŠ¸ (ì œì™¸)\")\n",
    "        \n",
    "        # 3. ìš”ì†Œ ìƒíƒœ ë¶„ì„\n",
    "        if element.is_displayed():\n",
    "            score += 10\n",
    "            reasons.append(\"í™”ë©´ì— í‘œì‹œë¨\")\n",
    "        if element.is_enabled():\n",
    "            score += 10\n",
    "            reasons.append(\"í´ë¦­ ê°€ëŠ¥í•¨\")\n",
    "        \n",
    "        # 4. ì¶”ê°€ í•„í„°ë§\n",
    "        if not text:  # í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ì ìˆ˜ ì°¨ê°\n",
    "            score -= 20\n",
    "            reasons.append(\"âŒ í…ìŠ¤íŠ¸ ì—†ìŒ\")\n",
    "        \n",
    "        if len(text) > 100:  # ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ëŠ” ì˜ì‹¬\n",
    "            score -= 15\n",
    "            reasons.append(\"âŒ í…ìŠ¤íŠ¸ ë„ˆë¬´ ê¹€\")\n",
    "        \n",
    "        print(f\"        ğŸ“Š ì ìˆ˜: {score}ì \")\n",
    "        print(f\"        ğŸ“ ì´ìœ : {', '.join(reasons)}\")\n",
    "        \n",
    "        return {\n",
    "            'element': element,\n",
    "            'text': text,\n",
    "            'href': href,\n",
    "            'score': score,\n",
    "            'reasons': reasons,\n",
    "            'index': index\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"        âŒ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "def navigate_to_scroll_list(driver, city_name):\n",
    "    \"\"\"\n",
    "    ğŸŒ ê°œì„ ëœ íˆ¬ì–´Â·í‹°ì¼“ ì¹´í…Œê³ ë¦¬ ì´ë™ ì‹œìŠ¤í…œ\n",
    "    - ì ìˆ˜ ê¸°ë°˜ ìµœì  ë²„íŠ¼ ì„ íƒ\n",
    "    - ë‹¤ë‹¨ê³„ fallback ì§€ì›\n",
    "    \"\"\"\n",
    "    print(f\"  ğŸ¯ '{city_name}' íˆ¬ì–´Â·í‹°ì¼“ ì¹´í…Œê³ ë¦¬ ì´ë™ ì‹œì‘...\")\n",
    "\n",
    "    try:\n",
    "        # í˜ì´ì§€ ë¡œë”© ì™„ë£Œ ëŒ€ê¸°\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        time.sleep(3)\n",
    "\n",
    "        # ğŸ” ê°•í™”ëœ ë²„íŠ¼ ì°¾ê¸°\n",
    "        analyzed_buttons = find_tour_ticket_buttons(driver)\n",
    "        \n",
    "        if not analyzed_buttons:\n",
    "            print(\"    âŒ íˆ¬ì–´Â·í‹°ì¼“ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "            return False, \"ë²„íŠ¼ ì—†ìŒ\"\n",
    "\n",
    "        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬\n",
    "        analyzed_buttons.sort(key=lambda x: x['score'], reverse=True)\n",
    "        \n",
    "        print(f\"    ğŸ“Š ë¶„ì„ ê²°ê³¼ (ì ìˆ˜ ìˆœ):\")\n",
    "        for i, btn in enumerate(analyzed_buttons[:3]):  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ\n",
    "            print(f\"      {i+1}. {btn['score']}ì : '{btn['text']}' ({btn['index']}ë²ˆ)\")\n",
    "\n",
    "        # ğŸ¯ ìµœê³  ì ìˆ˜ ë²„íŠ¼ë¶€í„° ì‹œë„\n",
    "        for attempt, button_info in enumerate(analyzed_buttons):\n",
    "            if button_info['score'] < 20:  # ìµœì†Œ ì ìˆ˜ ê¸°ì¤€\n",
    "                print(f\"    âš ï¸ ë‚¨ì€ ë²„íŠ¼ë“¤ì˜ ì ìˆ˜ê°€ ë„ˆë¬´ ë‚®ìŒ ({button_info['score']}ì )\")\n",
    "                break\n",
    "                \n",
    "            print(f\"    ğŸ¯ ì‹œë„ {attempt + 1}: {button_info['score']}ì  ë²„íŠ¼ í´ë¦­\")\n",
    "            \n",
    "            success, result = attempt_button_click(driver, button_info)\n",
    "            \n",
    "            if success:\n",
    "                print(f\"    âœ… ë²„íŠ¼ í´ë¦­ ì„±ê³µ!\")\n",
    "                return True, result\n",
    "            else:\n",
    "                print(f\"    âŒ ë²„íŠ¼ í´ë¦­ ì‹¤íŒ¨: {result}\")\n",
    "                if attempt < len(analyzed_buttons) - 1:\n",
    "                    print(f\"    ğŸ”„ ë‹¤ìŒ ë²„íŠ¼ ì‹œë„...\")\n",
    "                    time.sleep(2)\n",
    "\n",
    "        print(\"    âŒ ëª¨ë“  ë²„íŠ¼ ì‹œë„ ì‹¤íŒ¨\")\n",
    "        return False, \"ëª¨ë“  ë²„íŠ¼ ì‹¤íŒ¨\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ íˆ¬ì–´Â·í‹°ì¼“ ì¹´í…Œê³ ë¦¬ ì´ë™ ì‹¤íŒ¨: {e}\")\n",
    "        return False, f\"ì˜¤ë¥˜: {e}\"\n",
    "\n",
    "def attempt_button_click(driver, button_info):\n",
    "    \"\"\"\n",
    "    ğŸ¯ ì•ˆì „í•œ ë²„íŠ¼ í´ë¦­ ì‹œë„\n",
    "    - ì—¬ëŸ¬ í´ë¦­ ë°©ë²• ì‹œë„\n",
    "    - ê²°ê³¼ ê²€ì¦\n",
    "    \"\"\"\n",
    "    element = button_info['element']\n",
    "    text = button_info['text']\n",
    "    \n",
    "    try:\n",
    "        # 1. ìŠ¤í¬ë¡¤í•˜ì—¬ ìš”ì†Œë¥¼ í™”ë©´ ì¤‘ì•™ìœ¼ë¡œ\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", element)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # 2. ìš”ì†Œê°€ í´ë¦­ ê°€ëŠ¥í•  ë•Œê¹Œì§€ ëŒ€ê¸°\n",
    "        wait = WebDriverWait(driver, 5)\n",
    "        wait.until(EC.element_to_be_clickable(element))\n",
    "        \n",
    "        # 3. JavaScript í´ë¦­ ì‹œë„ (ìš°ì„ )\n",
    "        try:\n",
    "            driver.execute_script(\"arguments[0].click();\", element)\n",
    "            print(f\"        âœ… JavaScript í´ë¦­ ì„±ê³µ: '{text}'\")\n",
    "        except Exception:\n",
    "            # 4. ì¼ë°˜ í´ë¦­ fallback\n",
    "            element.click()\n",
    "            print(f\"        âœ… ì¼ë°˜ í´ë¦­ ì„±ê³µ: '{text}'\")\n",
    "        \n",
    "        # 5. í˜ì´ì§€ ì´ë™ ëŒ€ê¸° ë° í™•ì¸\n",
    "        print(f\"        â° í˜ì´ì§€ ì´ë™ í™•ì¸ ì¤‘...\")\n",
    "        time.sleep(random.uniform(5, 8))\n",
    "        \n",
    "        # 6. ê²°ê³¼ ê²€ì¦\n",
    "        new_url = driver.current_url\n",
    "        \n",
    "        # ìƒí’ˆ ë§í¬ í™•ì¸ (ë‹¤ì–‘í•œ ì„ íƒì)\n",
    "        product_selectors = [\n",
    "            \"a[href*='/products/']\",\n",
    "            \"a[href*='/offers/']\",\n",
    "            \"a[href*='/activities/']\",\n",
    "            \"[data-testid*='product'] a\"\n",
    "        ]\n",
    "        \n",
    "        total_products = 0\n",
    "        for selector in product_selectors:\n",
    "            products = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "            total_products += len(products)\n",
    "        \n",
    "        print(f\"        ğŸ“Š ì´ë™ í›„ ìƒí’ˆ ìˆ˜: {total_products}ê°œ\")\n",
    "        \n",
    "        if total_products >= 5:  # ê¸°ì¤€ì„ ë‚®ì¶¤\n",
    "            print(f\"        âœ… ëª©ë¡ í˜ì´ì§€ ì´ë™ í™•ì¸!\")\n",
    "            return True, new_url\n",
    "        else:\n",
    "            print(f\"        âŒ ìƒí’ˆ ìˆ˜ ë¶€ì¡± (ìµœì†Œ 5ê°œ í•„ìš”)\")\n",
    "            return False, \"ìƒí’ˆ ìˆ˜ ë¶€ì¡±\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"        âŒ í´ë¦­ ì‹œë„ ì‹¤íŒ¨: {e}\")\n",
    "        return False, f\"í´ë¦­ ì˜¤ë¥˜: {e}\"\n",
    "\n",
    "def debug_page_state(driver):\n",
    "    \"\"\"\n",
    "    ğŸ”§ í˜ì´ì§€ ìƒíƒœ ë””ë²„ê¹… í•¨ìˆ˜\n",
    "    - í˜„ì¬ í˜ì´ì§€ì˜ ëª¨ë“  ê´€ë ¨ ìš”ì†Œ ì¶œë ¥\n",
    "    \"\"\"\n",
    "    print(\"ğŸ”§ í˜ì´ì§€ ìƒíƒœ ë””ë²„ê¹…...\")\n",
    "    \n",
    "    try:\n",
    "        print(f\"ğŸ“ í˜„ì¬ URL: {driver.current_url}\")\n",
    "        print(f\"ğŸ·ï¸ í˜ì´ì§€ ì œëª©: {driver.title}\")\n",
    "        \n",
    "        # ëª¨ë“  ë§í¬ ë¶„ì„\n",
    "        all_links = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "        tour_related = [link for link in all_links if \n",
    "                       'tour' in (link.get_attribute('href') or '').lower() or\n",
    "                       'tour' in link.text.lower() or\n",
    "                       'íˆ¬ì–´' in link.text or\n",
    "                       'ë”ë³´ê¸°' in link.text]\n",
    "        \n",
    "        print(f\"ğŸ“Š ì „ì²´ ë§í¬: {len(all_links)}ê°œ\")\n",
    "        print(f\"ğŸ¯ íˆ¬ì–´ ê´€ë ¨ ë§í¬: {len(tour_related)}ê°œ\")\n",
    "        \n",
    "        for i, link in enumerate(tour_related[:5]):  # ì²˜ìŒ 5ê°œë§Œ\n",
    "            print(f\"  {i+1}. '{link.text.strip()}' -> {link.get_attribute('href')}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë””ë²„ê¹… ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ì— ë””ë²„ê¹… ì¶”ê°€\n",
    "def test_group11_with_debug():\n",
    "    \"\"\"ğŸ§ª ë””ë²„ê¹…ì´ í¬í•¨ëœ ê·¸ë£¹ 11 í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ§ª ë””ë²„ê¹… í¬í•¨ ê·¸ë£¹ 11 í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    try:\n",
    "        if 'driver' not in globals():\n",
    "            print(\"âŒ ë“œë¼ì´ë²„ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤\")\n",
    "            return False\n",
    "\n",
    "        test_city = \"ì¹˜ì•™ë§ˆì´\"\n",
    "        print(f\"ğŸ” {test_city} ê²€ìƒ‰ ì‹œì‘...\")\n",
    "\n",
    "        # ê²€ìƒ‰ ì‹¤í–‰ (ì´ í•¨ìˆ˜ëŠ” ê¸°ì¡´ ì½”ë“œì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)\n",
    "        # perform_new_search(driver, test_city)\n",
    "        \n",
    "        # í˜ì´ì§€ ìƒíƒœ ë””ë²„ê¹…\n",
    "        debug_page_state(driver)\n",
    "        \n",
    "        # ì‹œìŠ¤í…œ íƒ€ì… íƒì§€\n",
    "        system_type = detect_search_system_type(driver)\n",
    "        print(f\"ğŸ“Š ì‹œìŠ¤í…œ íƒ€ì…: {system_type}\")\n",
    "        \n",
    "        if system_type == \"category_based\":\n",
    "            # ë²„íŠ¼ ì°¾ê¸° í…ŒìŠ¤íŠ¸\n",
    "            buttons = find_tour_ticket_buttons(driver)\n",
    "            print(f\"ğŸ” ë°œê²¬ëœ ë²„íŠ¼ ìˆ˜: {len(buttons)}\")\n",
    "            \n",
    "            # ë„¤ë¹„ê²Œì´ì…˜ ì‹œë„\n",
    "            success, result = navigate_to_scroll_list(driver, test_city)\n",
    "            \n",
    "            if success:\n",
    "                print(f\"âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ!\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {result}\")\n",
    "                return False\n",
    "        \n",
    "        elif system_type == \"integrated_search\":  # ğŸ†• ì¶”ê°€ í•„ìš”\n",
    "            print(\"ğŸ¯ í†µí•© ê²€ìƒ‰ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘...\")\n",
    "            buttons = find_tour_ticket_buttons(driver)\n",
    "            success, result = navigate_to_scroll_list(driver, test_city)\n",
    "\n",
    "        else:\n",
    "            print(f\"âš ï¸ ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ì´ ì•„ë‹Œ ì‹œìŠ¤í…œ: {system_type}\")\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"âœ… ê°œì„ ëœ ê·¸ë£¹ 10 ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ!\")\n",
    "print()\n",
    "print(\"ğŸ”§ ì£¼ìš” ê°œì„ ì‚¬í•­:\")\n",
    "print(\"   ğŸ¯ ë‹¤ì¤‘ ì„ íƒì íŒ¨í„´ ì§€ì›\")\n",
    "print(\"   ğŸ“Š ì ìˆ˜ ê¸°ë°˜ ë²„íŠ¼ ì„ íƒ\")\n",
    "print(\"   ğŸ”„ ë‹¤ë‹¨ê³„ fallback ì‹œìŠ¤í…œ\")\n",
    "print(\"   ğŸ” ê°•í™”ëœ ë””ë²„ê¹… ê¸°ëŠ¥\")\n",
    "print()\n",
    "print(\"ğŸš€ ë””ë²„ê¹… í•¨ìˆ˜:\")\n",
    "print(\"   debug_page_state(driver)      # í˜ì´ì§€ ìƒíƒœ í™•ì¸\")\n",
    "print(\"   test_group11_with_debug()     # ë””ë²„ê¹… í¬í•¨ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"   find_tour_ticket_buttons(driver)  # ë²„íŠ¼ ì°¾ê¸°ë§Œ í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e24fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd571a6d89dd457486bf4545d3f5a82e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='í¬ë¡¤ëŸ¬ ì œì–´íŒ'), Label(value=''), Text(value='', description='ë„ì‹œ:', layout=Layout(width=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b70230327a4466883b55862fa54aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "SyntaxError",
     "evalue": "name 'urls_to_crawl' is assigned to before global declaration (2772047160.py, line 292)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[138], line 292\u001b[1;36m\u001b[0m\n\u001b[1;33m    global urls_to_crawl\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m name 'urls_to_crawl' is assigned to before global declaration\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ğŸ¯ ê·¸ë£¹ 11: completion_state ì´ˆê¸°í™” ê¸°ëŠ¥ (ìµœì¢… ì •ë¦¬ë³¸)\n",
    "# - ì¬ì‹¤í–‰ ì‹œ ì´ì „ ì™„ë£Œ ìƒíƒœë¥¼ ìë™ìœ¼ë¡œ ì •ë¦¬í•˜ëŠ” ê°„ë‹¨í•œ ê¸°ëŠ¥\n",
    "# - CSV ë°ì´í„°ëŠ” í•­ìƒ ë³´ì¡´í•˜ì—¬ ì—°ì†ì„± í™•ë³´\n",
    "# =============================================================================\n",
    "\n",
    "def reset_crawler_state(city_name):\n",
    "    \"\"\"í¬ë¡¤ëŸ¬ ìƒíƒœ ì´ˆê¸°í™” (CSVëŠ” í•­ìƒ ë³´ì¡´)\"\"\"\n",
    "    print(f\"ğŸ”„ '{city_name}' í¬ë¡¤ëŸ¬ ìƒíƒœ ì´ˆê¸°í™”...\")\n",
    "    \n",
    "    try:\n",
    "        config_dir = ensure_config_directory()\n",
    "        cleared = []\n",
    "        \n",
    "        # 1. completed_urls.log ì‚­ì œ\n",
    "        urls_log = os.path.join(config_dir, \"completed_urls.log\")\n",
    "        if os.path.exists(urls_log):\n",
    "            os.remove(urls_log)\n",
    "            cleared.append('completed_urls.log')\n",
    "        \n",
    "        # 2. crawler_meta.json ì´ˆê¸°í™”\n",
    "        meta_file = os.path.join(config_dir, \"crawler_meta.json\")\n",
    "        default_state = {\n",
    "            \"total_collected_count\": 0,\n",
    "            \"last_crawled_page\": 1,\n",
    "            \"current_session_start\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            \"last_updated\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            \"reset_city\": city_name,\n",
    "            \"reset_timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        with open(meta_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(default_state, f, ensure_ascii=False, indent=2)\n",
    "        cleared.append('crawler_meta.json')\n",
    "        \n",
    "        # 3. url_history ì‚­ì œ\n",
    "        os.makedirs(\"url_history\", exist_ok=True)\n",
    "        history_file = os.path.join(\"url_history\", f\"{city_name}.json\")\n",
    "        if os.path.exists(history_file):\n",
    "            os.remove(history_file)\n",
    "            cleared.append(f'url_history/{city_name}.json')\n",
    "        \n",
    "        # 4. url_cache ì •ë¦¬\n",
    "        os.makedirs(\"url_cache\", exist_ok=True)\n",
    "        cache_file = os.path.join(\"url_cache\", f\"{city_name}_collected.json\")\n",
    "        if os.path.exists(cache_file):\n",
    "            os.remove(cache_file)\n",
    "            cleared.append(f'url_cache/{city_name}_collected.json')\n",
    "        \n",
    "        print(f\"âœ… ì´ˆê¸°í™” ì™„ë£Œ: {len(cleared)}ê°œ íŒŒì¼ ì²˜ë¦¬\")\n",
    "        for item in cleared:\n",
    "            print(f\"   - {item}\")\n",
    "        \n",
    "        # CSV ë³´ì¡´ í™•ì¸\n",
    "        try:\n",
    "            csv_count = len(get_crawled_urls_from_csv(city_name))\n",
    "            if csv_count > 0:\n",
    "                print(f\"ğŸ›¡ï¸ CSV ë°ì´í„° ë³´ì¡´ë¨: {csv_count}ê°œ ì™„ë£Œ ìƒí’ˆ\")\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "def check_crawler_sync(city_name):\n",
    "    \"\"\"í¬ë¡¤ëŸ¬ ë™ê¸°í™” ìƒíƒœ ê°„ë‹¨ ì²´í¬\"\"\"\n",
    "    try:\n",
    "        csv_urls = get_crawled_urls_from_csv(city_name)\n",
    "        config_dir = ensure_config_directory()\n",
    "        log_urls = validate_completed_urls(config_dir)\n",
    "        \n",
    "        print(f\"ğŸ“Š '{city_name}' ë™ê¸°í™” ìƒíƒœ:\")\n",
    "        print(f\"   CSV: {len(csv_urls)}ê°œ\")\n",
    "        print(f\"   Log: {len(log_urls)}ê°œ\")\n",
    "        \n",
    "        if len(csv_urls) == 0 and len(log_urls) == 0:\n",
    "            print(\"â„¹ï¸ ì‹ ê·œ ë„ì‹œ (ë°ì´í„° ì—†ìŒ)\")\n",
    "            return True\n",
    "        elif csv_urls == log_urls:\n",
    "            print(\"âœ… ì™„ë²½ ë™ê¸°í™”\")\n",
    "            return True\n",
    "        else:\n",
    "            missing_count = len(csv_urls - log_urls)\n",
    "            extra_count = len(log_urls - csv_urls)\n",
    "            print(\"âš ï¸ ë™ê¸°í™” í•„ìš”\")\n",
    "            if missing_count > 0:\n",
    "                print(f\"   Log ëˆ„ë½: {missing_count}ê°œ\")\n",
    "            if extra_count > 0:\n",
    "                print(f\"   Log ì´ˆê³¼: {extra_count}ê°œ\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì²´í¬ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "def quick_reset(city_name):\n",
    "    \"\"\"ì›í´ë¦­ í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” (CSV ë³´ì¡´) - ê°€ì¥ ë§ì´ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    print(f\"âš¡ '{city_name}' ì›í´ë¦­ ì´ˆê¸°í™”\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # 1ë‹¨ê³„: í˜„ì¬ ìƒíƒœ ì²´í¬\n",
    "    print(\"1ï¸âƒ£ í˜„ì¬ ìƒíƒœ ì²´í¬...\")\n",
    "    is_synced = check_crawler_sync(city_name)\n",
    "    \n",
    "    # 2ë‹¨ê³„: ì´ˆê¸°í™” ì‹¤í–‰\n",
    "    print(\"\\n2ï¸âƒ£ ìƒíƒœ ì´ˆê¸°í™” ì‹¤í–‰...\")\n",
    "    success = reset_crawler_state(city_name)\n",
    "    \n",
    "    # 3ë‹¨ê³„: ê²°ê³¼ ë° ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´\n",
    "    if success:\n",
    "        print(\"\\nğŸ‰ ì´ˆê¸°í™” ì™„ë£Œ! ìƒˆë¡œìš´ í¬ë¡¤ë§ ì¤€ë¹„ë¨\")\n",
    "        print(f\"ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "        print(f\"   1. CITIES_TO_SEARCH = ['{city_name}'] ì„¤ì •\")\n",
    "        print(f\"   2. ê·¸ë£¹ 6-8 ì‹¤í–‰í•˜ì—¬ í¬ë¡¤ë§ ì‹œì‘\")\n",
    "    else:\n",
    "        print(\"\\nâŒ ì´ˆê¸°í™” ì‹¤íŒ¨ - ìˆ˜ë™ í™•ì¸ í•„ìš”\")\n",
    "    \n",
    "    return success\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸš€ ê·¸ë£¹ 10: ì¸í„°ë ‰í‹°ë¸Œ ì»¨íŠ¸ë¡¤ íŒ¨ë„ (ìµœì¢… ì™„ì„±ë³¸)\n",
    "# =============================================================================\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# --- 1. ìœ„ì ¯ ìƒì„± ---\n",
    "city_input = widgets.Text(value='', description='ë„ì‹œ:', layout={'width': '200px'})\n",
    "product_count_input = widgets.IntText(value=None, description='ìƒí’ˆ ìˆ˜:', layout={'width': '200px'})\n",
    "\n",
    "run_button = widgets.Button(description=\"ğŸš€ í¬ë¡¤ë§ ì‹œì‘\", button_style='danger')\n",
    "diag_button = widgets.Button(description=\"ğŸ©º ì‹œìŠ¤í…œ ì§„ë‹¨\")\n",
    "reset_button = widgets.Button(description=\"ğŸ”„ ì‹œìŠ¤í…œ ì´ˆê¸°í™”\", button_style='warning')\n",
    "\n",
    "\n",
    "# ğŸ†• ìŠ¤ìœ„ì¹˜ ì½”ë“œ ì¶”ê°€ (ìˆ˜ì •ë¨)\n",
    "group10_switch = widgets.Checkbox(  # ğŸ†• ë³€ìˆ˜ëª… ë³€ê²½\n",
    "    value=False,\n",
    "    description='ğŸš€ ìŠ¤í¬ë¡¤ ëª¨ë“œ',  # ğŸ†• í…ìŠ¤íŠ¸ ë³€ê²½\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "# ğŸ†• ê³ ì • ë„ˆë¹„ ë¼ë²¨ë¡œ ìœ„ì¹˜ ì•ˆì •í™”\n",
    "mode_label = widgets.Label(\n",
    "    value=\"ğŸ”„ ê¸°ë³¸ëª¨ë“œ (ì•ˆì •ì )\",  # ğŸ†• ì´ˆê¸°ê°’ì€ ë™ì¼\n",
    "    layout=widgets.Layout(width='250px')  # ê³ ì • ë„ˆë¹„\n",
    ")\n",
    "\n",
    "def on_switch_change(change):\n",
    "    if change['new']:\n",
    "        mode_label.value = \"ğŸš€ ìŠ¤í¬ë¡¤ ëª¨ë“œ (ìƒˆë¡œìš´ í˜ì´ì§€ ëŒ€ì‘)\"  # ğŸ†• ë³€ê²½\n",
    "    else:\n",
    "        mode_label.value = \"ğŸ”„ ê¸°ë³¸ëª¨ë“œ (ì•ˆì •ì )\"  # ğŸ†• ë™ì¼\n",
    "\n",
    "group10_switch.observe(on_switch_change, names='value')  # ğŸ†• ë³€ìˆ˜ëª… ë³€ê²½\n",
    "\n",
    "output_area = widgets.Output()\n",
    "LAST_SEARCHED_CITY = \"\" # ë§ˆì§€ë§‰ ê²€ìƒ‰ ë„ì‹œ ê¸°ì–µìš©\n",
    "\n",
    "# --- 2. ë²„íŠ¼ í´ë¦­ ì‹œ ë™ì‘í•  í•¨ìˆ˜ ì •ì˜ ---\n",
    "def on_diag_button_clicked(b):\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        print(\"ğŸ©º ì‹œìŠ¤í…œ ì§„ë‹¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "        quick_pagination_status_check()\n",
    "        print(\"âœ… ì§„ë‹¨ ì™„ë£Œ.\")\n",
    "\n",
    "def on_run_button_clicked(b):\n",
    "      with output_area:\n",
    "          output_area.clear_output()\n",
    "          city = city_input.value.strip()\n",
    "          count = product_count_input.value\n",
    "          use_group10 = group10_switch.value\n",
    "          # âœ… ê°„ë‹¨í•œ ê²€ì¦ë§Œ (run_crawlerì—ì„œ ëª¨ë“  ë™ê¸°í™” ì²˜ë¦¬)\n",
    "          if not city:\n",
    "              # ìœ„ì ¯ì´ ë¹„ì–´ìˆìœ¼ë©´ ê·¸ë£¹1 ì„¤ì • ì‚¬ìš©\n",
    "              if 'CITIES_TO_SEARCH' in globals() and CITIES_TO_SEARCH:\n",
    "                  city = CITIES_TO_SEARCH[0]\n",
    "                  city_input.value = city  # ìœ„ì ¯ì—ë„ ë°˜ì˜\n",
    "                  print(f\"ğŸ”„ ê·¸ë£¹1 ì„¤ì • ì‚¬ìš©: '{city}'\")\n",
    "              else:\n",
    "                  print(\"âš ï¸ ë„ì‹œ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!\")\n",
    "                  return\n",
    "          if count is None or count <= 0:\n",
    "              print(\"âš ï¸ ìˆ˜ì§‘í•  ìƒí’ˆ ê°œìˆ˜ë¥¼ 1 ì´ìƒìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”!\")\n",
    "              return\n",
    "          mode_text = \"ìŠ¤í¬ë¡¤ ëª¨ë“œ\" if use_group10 else \"ê¸°ë³¸ëª¨ë“œ\"\n",
    "          print(f\"ğŸš€ '{city}' ë„ì‹œ ìƒí’ˆ {count}ê°œ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤... ({mode_text})\")\n",
    "          # run_crawlerì—ì„œ ëª¨ë“  ë™ê¸°í™” ì²˜ë¦¬ (ì¤‘ë³µ ì œê±°)\n",
    "          run_crawler(city=city, num_products_to_crawl=count, use_group10=use_group10)\n",
    "        \n",
    "def on_reset_button_clicked(b):\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        city = city_input.value.strip()\n",
    "        if city:\n",
    "            quick_reset(city)\n",
    "        else:\n",
    "            print(\"âš ï¸ ë„ì‹œ ì´ë¦„ì„ ë¨¼ì € ì…ë ¥í•˜ì„¸ìš”!\")\n",
    "\n",
    "# --- 3. ë²„íŠ¼ê³¼ í•¨ìˆ˜ ì—°ê²° ---\n",
    "diag_button.on_click(on_diag_button_clicked)\n",
    "run_button.on_click(on_run_button_clicked)\n",
    "reset_button.on_click(on_reset_button_clicked)\n",
    "\n",
    "# --- 4. í™”ë©´ì— ì»¨íŠ¸ë¡¤ íŒ¨ë„ í‘œì‹œ ---\n",
    "controls = widgets.VBox([\n",
    "    widgets.Label(value=\"í¬ë¡¤ëŸ¬ ì œì–´íŒ\"),\n",
    "    widgets.Label(value=\"\"),  # ğŸ†• ìœ„ìª½ ì—¬ë°±\n",
    "    city_input,\n",
    "    product_count_input,\n",
    "    widgets.Label(value=\"\"),  # ğŸ†• ì¤‘ê°„ ì—¬ë°±\n",
    "    widgets.HBox([\n",
    "        mode_label,\n",
    "        widgets.HTML(value=\"&nbsp;&nbsp;&nbsp;\"),  # ğŸ†• 3ì¹¸ ê³µë°± ì¶”ê°€\n",
    "        group10_switch\n",
    "    ], layout=widgets.Layout(align_items='center')),  # ğŸ†• ìˆ˜ì§ ê°€ìš´ë° ì •ë ¬\n",
    "    widgets.Label(value=\"\"),  # ğŸ†• ì•„ë˜ìª½ ì—¬ë°±\n",
    "    widgets.HBox([run_button, diag_button, reset_button])\n",
    "])\n",
    "display(controls, output_area)\n",
    "\n",
    "# =============================================================================\n",
    "# ë˜í¼ ë° í…ŒìŠ¤íŠ¸/ì§„ë‹¨ í•¨ìˆ˜ ì •ì˜ (ì»¨íŠ¸ë¡¤ íŒ¨ë„ì´ í˜¸ì¶œ)\n",
    "# =============================================================================\n",
    "\n",
    "def run_crawler(city, num_products_to_crawl, use_group10=False, resume_session=True):\n",
    "    # ğŸ†• íŒŒë¼ë¯¸í„° ì¶”ê°€\n",
    "    \"\"\"\n",
    "    [ìµœì¢… ìˆ˜ì •ë³¸] CSV ê²€ì¦ ê²°í•© ì•ˆì „ì„± ê°œì„  í¬ë¡¤ë§ í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    # í•„ìˆ˜ í•¨ìˆ˜ë“¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "    required_functions = [\n",
    "        'get_last_product_number', 'load_collected_urls', 'filter_new_urls_from_csv',\n",
    "        'perform_new_search_with_switch', 'crawl_with_full_pagination'  # ğŸ†• í•¨ìˆ˜ëª… ë³€ê²½\n",
    "    ]\n",
    "    missing_functions = []\n",
    "    for func_name in required_functions:\n",
    "        if func_name not in globals():\n",
    "            missing_functions.append(func_name)\n",
    "    if missing_functions:\n",
    "        print(f\"âŒ í•„ìˆ˜ í•¨ìˆ˜ë“¤ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing_functions)}\")\n",
    "        print(\"ğŸ’¡ ê·¸ë£¹ 1-10ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”!\")\n",
    "        return\n",
    "    \n",
    "    global LAST_SEARCHED_CITY, driver, CITIES_TO_SEARCH, city_name, start_number\n",
    "    global continent, country, urls_to_crawl  # ğŸ†• ì¶”ê°€\n",
    "    CITIES_TO_SEARCH = [city]\n",
    "    city_name = city\n",
    "    \n",
    "    # ğŸ†• ë„ì‹œ ì •ë³´ ì—…ë°ì´íŠ¸\n",
    "    continent, country = get_city_info(city_name)\n",
    "    print(f\"ğŸ”„ ë„ì‹œ ì •ë³´ ì—…ë°ì´íŠ¸: {city_name} â†’ {continent}, {country}\")\n",
    "    print(f\"ğŸ”¢ '{city}' ë²ˆí˜¸ ì—°ì†ì„± í™•ì¸ ì¤‘...\")\n",
    "    \n",
    "    try:\n",
    "        last_product_number = get_last_product_number(city_name)\n",
    "        start_number = last_product_number + 1\n",
    "        print(f\"   ì‹œì‘ ë²ˆí˜¸: {start_number}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ë²ˆí˜¸ í™•ì¸ ì‹¤íŒ¨: {e}, ê¸°ë³¸ê°’ 0 ì‚¬ìš©\")\n",
    "        start_number = 0\n",
    "    \n",
    "    # ğŸ†• ê°œì„ ëœ URL ìºì‹œ ì‹œìŠ¤í…œ (ì‚¼ì¤‘ ë™ê¸°í™” ì ìš©)\n",
    "    try:\n",
    "        # 1. ì‚¼ì¤‘ ë™ê¸°í™” ì‹¤í–‰\n",
    "        triple_sync_url_system(city)\n",
    "        \n",
    "        # 2. ìºì‹œëœ URL í™•ì¸\n",
    "        cached_urls = load_collected_urls(city)\n",
    "        if cached_urls and len(cached_urls) > 0:\n",
    "            print(f\"âœ… URL ìºì‹œ ë°œê²¬: {len(cached_urls)}ê°œ URL ë°œê²¬\")\n",
    "            # CSV ê²€ì¦ ê²°í•©ìœ¼ë¡œ ì‹¤ì œ ë¯¸ì™„ë£Œë§Œ í•„í„°ë§\n",
    "            remaining_urls = filter_new_urls_from_csv(cached_urls, city)\n",
    "            if remaining_urls:\n",
    "                print(f\"âœ… ë¯¸ì™„ë£Œ URL {len(remaining_urls)}ê°œ ì•ˆì „ ì¬ì‚¬ìš©\")\n",
    "                print(f\"âœ… ë„ì‹œ ìºì‹œ: '{city}' ê²€ì¦ëœ URLë¡œ ì‘ì—… ê³„ì†\")\n",
    "                global urls_to_crawl\n",
    "                urls_to_crawl = remaining_urls\n",
    "\n",
    "            else:\n",
    "                print(f\"âš ï¸ ìºì‹œëœ URL ëª¨ë‘ ì™„ë£Œë¨ - ìƒˆë¡œ ê²€ìƒ‰ ì‹œì‘\")\n",
    "                perform_new_search_with_switch(driver, city, use_group10)\n",
    "\n",
    "                # â­ URL ìˆ˜ì§‘ ë° ì €ì¥\n",
    "                collected_urls = collect_urls_with_csv_safety(driver, city)\n",
    "                if collected_urls:\n",
    "                    save_collected_urls(city, collected_urls)\n",
    "                    urls_to_crawl = collected_urls[:num_products_to_crawl]\n",
    "                    print(f\"âœ… {len(collected_urls)}ê°œ ìƒˆë¡œìš´ URL ìˆ˜ì§‘ ì™„ë£Œ\")\n",
    "                else:\n",
    "                    print(f\"âŒ ìƒˆë¡œìš´ URL ìˆ˜ì§‘ ì‹¤íŒ¨\")\n",
    "                    return\n",
    "        \n",
    "        else:\n",
    "            # 3. ìƒˆë¡œìš´ URL ìˆ˜ì§‘ ì‹œì‘ (ìºì‹œëŠ” ë¹„ìš°ê³  ìƒˆë¡œ ì‹œì‘)\n",
    "            print(f\"ğŸ”„ '{city}' ìƒˆë¡œìš´ URL ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "            perform_new_search_with_switch(driver, city, use_group10)\n",
    "\n",
    "            # â­ URL ìˆ˜ì§‘ ë° ì €ì¥\n",
    "            collected_urls = collect_urls_with_csv_safety(driver, city)\n",
    "            if collected_urls:\n",
    "                save_collected_urls(city, collected_urls)\n",
    "                urls_to_crawl = collected_urls[:num_products_to_crawl]\n",
    "                print(f\"âœ… {len(collected_urls)}ê°œ ìƒˆë¡œìš´ URL ìˆ˜ì§‘ ì™„ë£Œ\")\n",
    "            else:\n",
    "                print(f\"âŒ ìƒˆë¡œìš´ URL ìˆ˜ì§‘ ì‹¤íŒ¨\")\n",
    "                return\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ URL ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "        return\n",
    "    \n",
    "    LAST_SEARCHED_CITY = city\n",
    "    \n",
    "    # ê¸°ì¡´ í¬ë¡¤ë§ ì—”ì§„ í˜¸ì¶œ\n",
    "    try:\n",
    "        crawl_with_full_pagination(\n",
    "            city_name=city,\n",
    "            target_products=num_products_to_crawl,\n",
    "            resume_session=resume_session\n",
    "        )\n",
    "        print(f\"\\nğŸ‰ '{city}' ë„ì‹œ í¬ë¡¤ë§ ì‘ì—…ì´ ëª¨ë‘ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í¬ë¡¤ë§ ì‹¤í–‰ ì‹¤íŒ¨: {e}\")\n",
    "        print(\"ğŸ’¡ ê·¸ë£¹ 9-Bê°€ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”!\")\n",
    "\n",
    "def quick_pagination_status_check():\n",
    "    \"\"\"í˜„ì¬ í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ë¹ ë¥¸ í™•ì¸\"\"\"\n",
    "    print(\"ğŸ” í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ë¹ ë¥¸ í™•ì¸\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # validate_pagination_environment í•¨ìˆ˜ê°€ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬\n",
    "    try:\n",
    "        env_valid, missing = validate_pagination_environment()\n",
    "        if env_valid:\n",
    "            print(\"âœ… í™˜ê²½: ì •ìƒ\")\n",
    "        else:\n",
    "            print(f\"âŒ í™˜ê²½: ë¬¸ì œ ({missing})\")\n",
    "            return\n",
    "    except NameError:\n",
    "        print(\"âš ï¸ validate_pagination_environment í•¨ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "        print(\"ğŸ’¡ ê·¸ë£¹ 9-Aê°€ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # driver ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "        if 'driver' not in globals():\n",
    "            print(\"âŒ ë“œë¼ì´ë²„ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤\")\n",
    "            print(\"ğŸ’¡ ê·¸ë£¹ 6ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”\")\n",
    "            return\n",
    "            \n",
    "        current_url = driver.current_url\n",
    "        product_links = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/products/'], a[href*='/offers/']\")\n",
    "        print(f\"ğŸ“ í˜„ì¬ URL: ...{current_url[-50:]}\")\n",
    "        print(f\"ğŸ“Š ìƒí’ˆ ë§í¬: {len(product_links)}ê°œ\")\n",
    "        next_buttons = driver.find_elements(By.XPATH, \"//button[contains(@aria-label, 'ë‹¤ìŒ') or .//img[contains(@src, 'arrow')]]\")\n",
    "        print(f\"ğŸ”„ ë‹¤ìŒí˜ì´ì§€ ë²„íŠ¼: {len(next_buttons)}ê°œ\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "        return\n",
    "    \n",
    "    # city_name ë° load_pagination_state í•¨ìˆ˜ ì•ˆì „ í™•ì¸\n",
    "    try:\n",
    "        if 'city_name' in globals():\n",
    "            saved_state = load_pagination_state(city_name)\n",
    "            if saved_state:\n",
    "                print(f\"ğŸ’¾ ì €ì¥ëœ ìƒíƒœ: {saved_state.get('current_page', 'N/A')}í˜ì´ì§€, {saved_state.get('total_crawled', 0)}ê°œ ì™„ë£Œ\")\n",
    "            else:\n",
    "                print(f\"ğŸ’¾ ì €ì¥ëœ ìƒíƒœ: ì—†ìŒ\")\n",
    "        else:\n",
    "            print(\"ğŸ’¾ ì €ì¥ëœ ìƒíƒœ: city_name ì„¤ì • í•„ìš”\")\n",
    "    except NameError:\n",
    "        print(\"ğŸ’¾ ì €ì¥ëœ ìƒíƒœ: load_pagination_state í•¨ìˆ˜ ì—†ìŒ\")\n",
    "    \n",
    "print(\"âœ… ê·¸ë£¹ 11 ì™„ë£Œ: ê°„ì†Œí™”ëœ ìŠ¤ìœ„ì¹˜ ì‹œìŠ¤í…œ ì»¨íŠ¸ë¡¤ íŒ¨ë„!\")\n",
    "print(\"   ğŸ”„ ê¸°ë³¸ëª¨ë“œ: ê¸°ì¡´ click_view_all() ë°©ì‹\")\n",
    "print(\"   ğŸš€ ê·¸ë£¹10ëª¨ë“œ: ìƒˆë¡œìš´ navigate_to_scroll_list() ë°©ì‹\")\n",
    "print(\"   ğŸ›ï¸ ì‹¤ì‹œê°„ ëª¨ë“œ ì „í™˜ + ìë™ fallback ì§€ì›\")\n",
    "print(\"   ğŸ“‹ ì‚¬ìš©ë²•: ë„ì‹œ ì…ë ¥ â†’ ëª¨ë“œ ì„ íƒ â†’ í¬ë¡¤ë§ ì‹œì‘\")\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ“ í•µì‹¬ í•¨ìˆ˜: perform_new_search_with_switch (ëˆ„ë½ëœ í•„ìˆ˜ í•¨ìˆ˜)\n",
    "# =============================================================================\n",
    "\n",
    "def perform_new_search_with_switch(driver, city, use_group10=False):\n",
    "    \"\"\"ê°„ì†Œí™”ëœ ìŠ¤ìœ„ì¹˜ ê¸°ë°˜ ê²€ìƒ‰ í•¨ìˆ˜\"\"\"\n",
    "    # í•„ìˆ˜ í•¨ìˆ˜ë“¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "    required_functions = [\n",
    "        'go_to_main_page', 'find_and_fill_search', 'click_search_button',\n",
    "        'handle_popup', 'click_view_all'\n",
    "    ]\n",
    "    \n",
    "    missing_functions = []\n",
    "    for func_name in required_functions:\n",
    "        if func_name not in globals():\n",
    "            missing_functions.append(func_name)\n",
    "    \n",
    "    if missing_functions:\n",
    "        print(f\"âŒ í•„ìˆ˜ í•¨ìˆ˜ë“¤ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing_functions)}\")\n",
    "        print(\"ğŸ’¡ ê·¸ë£¹ 5 (ë¸Œë¼ìš°ì € ì œì–´ í•¨ìˆ˜ë“¤)ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”!\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        go_to_main_page(driver)\n",
    "        find_and_fill_search(driver, city)\n",
    "        click_search_button(driver)\n",
    "        print(\"  âœ… í˜ì´ì§€ ìµœì í™” ì¤‘ (íŒì—… ì²˜ë¦¬)...\")\n",
    "        handle_popup(driver)\n",
    "        \n",
    "        if use_group10:\n",
    "            # ğŸš€ ê·¸ë£¹10ëª¨ë“œ (ê°„ì†Œí™”ë¨)\n",
    "            print(\"  ğŸš€ ìŠ¤í¬ë¡¤ ëª¨ë“œ: ìƒˆë¡œìš´ í˜ì´ì§€ êµ¬ì¡° ëŒ€ì‘\")\n",
    "            success, result = navigate_to_scroll_list(driver, city)\n",
    "            \n",
    "            if success:\n",
    "                print(\"  âœ… ìŠ¤í¬ë¡¤ ëª¨ë“œ ì„±ê³µ!\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"  âŒ ìŠ¤í¬ë¡¤ ëª¨ë“œ ì‹¤íŒ¨: {result} - ê¸°ë³¸ëª¨ë“œë¡œ ì „í™˜\")\n",
    "                # fallback ê³„ì† ì§„í–‰\n",
    "        \n",
    "        # ğŸ”„ ê¸°ë³¸ëª¨ë“œ (ê·¸ë£¹10 ì‹¤íŒ¨ ì‹œì—ë„ ì‹¤í–‰)\n",
    "        print(\"  ğŸ”„ ê¸°ë³¸ëª¨ë“œ: ì•ˆì •ì ì¸ ë°©ì‹\")\n",
    "        click_view_all(driver)\n",
    "        print(\"  â³ ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ê°€ ì™„ì „íˆ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°í•©ë‹ˆë‹¤...\")\n",
    "        \n",
    "        # WebDriverWait ë° ê´€ë ¨ ëª¨ë“ˆë“¤ import í™•ì¸\n",
    "        try:\n",
    "            WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"a[href*='/products/'], a[href*='/offers/']\"))\n",
    "            )\n",
    "            print(\"  âœ… ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ ë¡œë“œ í™•ì¸ ì™„ë£Œ.\")\n",
    "        except TimeoutException:\n",
    "            print(\"  âš ï¸ ì‹œê°„ ì´ˆê³¼: ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ ë¡œë“œì— ì‹¤íŒ¨í–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "        except NameError:\n",
    "            print(\"  âš ï¸ WebDriverWait ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - ê¸°ë³¸ ëŒ€ê¸° ì‚¬ìš©\")\n",
    "            import time\n",
    "            time.sleep(5)\n",
    "            print(\"  âœ… ê¸°ë³¸ ëŒ€ê¸° ì™„ë£Œ\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"ğŸ”§ í•µì‹¬ í•¨ìˆ˜ perform_new_search_with_switch ì¶”ê°€ ì™„ë£Œ!\")\n",
    "print(\"âœ… ì´ì œ ìŠ¤í¬ë¡¤ ëª¨ë“œì™€ ê¸°ë³¸ëª¨ë“œ ì „í™˜ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mikael_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
