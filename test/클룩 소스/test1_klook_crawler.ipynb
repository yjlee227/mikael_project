{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a801c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====Klook í¬ë¡¤ë§ ì‹œìŠ¤í…œ=========================================================\n",
    "# ğŸš€ ê·¸ë£¹ 1: í†µì¼ëœ í•¨ìˆ˜ëª… - (hashlib ë¦¬íŒ©í† ë§ ì™„ë£Œ)\n",
    "# - ë„ì‹œ ì •ë³´ë¥¼ UNIFIED_CITY_INFOë¡œ í†µí•©í•˜ì—¬ ë‹¨ì¼ ì†ŒìŠ¤ë¡œ ê´€ë¦¬\n",
    "# - hashlib ê¸°ë°˜ ì´ˆê³ ì† ì¤‘ë³µ ë°©ì§€ ì‹œìŠ¤í…œ ì¶”ê°€\n",
    "#cd \"/mnt/c/Users/redsk/OneDrive/ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—/mikael_project/test_folder\"\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import warnings, os, time, shutil, urllib, random\n",
    "import threading \n",
    "_csv_loading_lock = threading.Lock() ## ğŸ”’ ìë¬¼ì‡  ê±¸ê¸°\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import platform\n",
    "import re                        # ê°€ê²©/í‰ì  ì •ì œìš© ì •ê·œì‹\n",
    "import json                      # ë©”íƒ€ë°ì´í„° JSON ì €ì¥ìš©\n",
    "import hashlib                   # ğŸ†• ì´ˆê³ ì† URL ì¤‘ë³µ ë°©ì§€ ì‹œìŠ¤í…œìš©\n",
    "from datetime import datetime    # íƒ€ì„ìŠ¤íƒ¬í”„ìš©\n",
    "from PIL import Image\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException\n",
    "\n",
    "import chromedriver_autoinstaller\n",
    "import undetected_chromedriver as uc\n",
    "from user_agents import parse\n",
    "import selenium\n",
    "\n",
    "print(f\"ğŸ”§ Selenium ë²„ì „: {selenium.__version__}\")\n",
    "\n",
    "# â­â­â­ ì¤‘ìš” ì„¤ì •: ì—¬ê¸°ì„œ ìˆ˜ì •í•˜ì„¸ìš”! â­â­â­\n",
    "CONFIG = {\n",
    "    \"WAIT_TIMEOUT\": 10,\n",
    "    \"RETRY_COUNT\": 3,\n",
    "    \"POPUP_WAIT\": 5,\n",
    "    \"SAVE_IMAGES\": True,\n",
    "    \n",
    "\n",
    "    # ğŸ†• hashlib ì‹œìŠ¤í…œ ì„¤ì •\n",
    "    \"USE_HASH_SYSTEM\": True,       # hashlib ì‹œìŠ¤í…œ ì‚¬ìš© ì—¬ë¶€\n",
    "    \"HASH_LENGTH\": 12,             # í•´ì‹œ ê¸¸ì´ (ê¸°ë³¸ 12ìë¦¬)\n",
    "    \"KEEP_CSV_SYSTEM\": True,       # ê¸°ì¡´ CSV ì‹œìŠ¤í…œ ë³‘í–‰ ìœ ì§€\n",
    "\n",
    "    # ğŸ†• V2 3-tier URL ì‹œìŠ¤í…œ ì„¤ì •\n",
    "    \"USE_V2_URL_SYSTEM\": True,     # V2 3-tier URL ì‹œìŠ¤í…œ ì‚¬ìš©\n",
    "    \"V2_URL_COLLECTED\": \"url_collected\",    # ìˆ˜ì§‘ ëŒ€ê¸° URL í´ë”\n",
    "    \"V2_URL_DONE\": \"url_done\",             # ì™„ë£Œëœ URL í´ë”\n",
    "    \"V2_URL_PROGRESS\": \"url_progress\",     # ì§„í–‰ ìƒí™© í´ë”\n",
    "\n",
    "    # ğŸ†• í˜ì´ì§€ ìµœì í™” ì„¤ì • ì¶”ê°€\n",
    "    \"SMART_WAIT_MAX\": 8,          # smart_wait_for_page_load ìµœëŒ€ ëŒ€ê¸°\n",
    "    \"NEW_TAB_ENABLED\": False,      # ìƒˆ íƒ­ í¬ë¡¤ë§ í™œì„±í™”\n",
    "    \"PAGE_LOAD_TIMEOUT\": 6,       # í˜ì´ì§€ ë¡œë“œ íƒ€ì„ì•„ì›ƒ\n",
    "\n",
    "    \"SHORT_MIN_DELAY\": 0.2,    # íƒ€ì´í•‘ ê°„ê²© (0.2ì´ˆ ~ 0.5ì´ˆ)\n",
    "    \"SHORT_MAX_DELAY\": 0.5,\n",
    "\n",
    "    \"MEDIUM_MIN_DELAY\": 7,     # í˜ì´ì§€ ë¡œë“œ ë“± ì¼ë°˜ ëŒ€ê¸° (7ì´ˆ ~ 15ì´ˆ)\n",
    "    \"MEDIUM_MAX_DELAY\": 15,\n",
    "\n",
    "    \"LONG_MIN_DELAY\": 20,      # ê°€ë”ì”© ì‰¬ëŠ” ì‹œê°„ (20ì´ˆ ~ 40ì´ˆ)\n",
    "    \"LONG_MAX_DELAY\": 40,\n",
    "    \n",
    "    \"MAX_PRODUCTS_PER_CITY\": 1,     #â­â­â­â­â­â­â­â­â­#\n",
    "    \n",
    "    # ğŸ†• Gemini ì§€ì ì‚¬í•­ í•´ê²°: USER_AGENT ì¶”ê°€\n",
    "    \"USER_AGENT\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\",\n",
    "}\n",
    "\n",
    "# ğŸ™ï¸ ê²€ìƒ‰í•  ë„ì‹œë“¤ (ì—¬ê¸°ì„œ ë³€ê²½!)\n",
    "CITIES_TO_SEARCH = [\"ì„œìš¸\"]\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ“ [ìµœì¢… ìˆ˜ì •ë³¸] ë‹¨ì¼ ì •ë³´ ì†ŒìŠ¤ ë° ë¦¬íŒ©í† ë§ëœ í•¨ìˆ˜\n",
    "# =============================================================================\n",
    "\n",
    "UNIFIED_CITY_INFO = {\n",
    "    # -------------------------------\n",
    "    # í•œêµ­\n",
    "    # -------------------------------\n",
    "    \"ì„œìš¸\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"SEL\", \"ì˜ë¬¸ëª…\": \"seoul\"},\n",
    "    \"ë¶€ì‚°\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"PUS\", \"ì˜ë¬¸ëª…\": \"busan\"},\n",
    "    \"ì œì£¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"CJU\", \"ì˜ë¬¸ëª…\": \"jeju\"},\n",
    "    \"ëŒ€êµ¬\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"TAE\", \"ì˜ë¬¸ëª…\": \"daegu\"},\n",
    "    \"ê´‘ì£¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"KWJ\", \"ì˜ë¬¸ëª…\": \"gwangju\"},\n",
    "    \"ì—¬ìˆ˜\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"RSU\", \"ì˜ë¬¸ëª…\": \"yeosu\"},\n",
    "    \"ì¸ì²œ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"ICN\", \"ì˜ë¬¸ëª…\": \"incheon\"},\n",
    "    \"ì†ì´ˆ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"SOK\", \"ì˜ë¬¸ëª…\": \"sokcho\"},\n",
    "    \"ê°•ë¦‰\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"GAN\", \"ì˜ë¬¸ëª…\": \"gangneung\"},\n",
    "    \"ê¹€í¬\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"GMP\", \"ì˜ë¬¸ëª…\": \"gimpo\"},\n",
    "\n",
    "    # -------------------------------\n",
    "    # ë™ë‚¨ì•„ì‹œì•„\n",
    "    # -------------------------------\n",
    "    # íƒœêµ­\n",
    "    \"ë°©ì½•\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"BKK\", \"ì˜ë¬¸ëª…\": \"bangkok\"},\n",
    "    \"íŒŒíƒ€ì•¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"BKK\", \"ì˜ë¬¸ëª…\": \"pattaya\"},\n",
    "    \"ì•„ìœ íƒ€ì•¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"BKK\", \"ì˜ë¬¸ëª…\": \"ayutthaya\"},\n",
    "    \"ì¹˜ì•™ë§ˆì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"CNX\", \"ì˜ë¬¸ëª…\": \"chiang mai\"},\n",
    "    \"ë¹ ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"CNX\", \"ì˜ë¬¸ëª…\": \"pai\"},\n",
    "    \"ì¹˜ì•™ë¼ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"CEI\", \"ì˜ë¬¸ëª…\": \"chiang rai\"},\n",
    "    \"í‘¸ì¼“\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"HKT\", \"ì˜ë¬¸ëª…\": \"phuket\"},\n",
    "    \"í”¼í”¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"KBV\", \"ì˜ë¬¸ëª…\": \"phi phi\"},\n",
    "    \"í¬ë¼ë¹„\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"KBV\", \"ì˜ë¬¸ëª…\": \"krabi\"},\n",
    "    \"í›„ì•„íŒ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"HHQ\", \"ì˜ë¬¸ëª…\": \"hua hin\"},\n",
    "    \"ì½”ì‚¬ë¬´ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"USM\", \"ì˜ë¬¸ëª…\": \"koh samui\"},\n",
    "    \"ì½”íŒ¡ì•ˆ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"USM\", \"ì˜ë¬¸ëª…\": \"koh phangan\"},  # ì½”ì‚¬ë¬´ì´ ê²½ìœ \n",
    "\n",
    "    # ì‹±ê°€í¬ë¥´\n",
    "    \"ì‹±ê°€í¬ë¥´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì‹±ê°€í¬ë¥´\", \"ì½”ë“œ\": \"SIN\", \"ì˜ë¬¸ëª…\": \"singapore\"},\n",
    "\n",
    "    # ë§ë ˆì´ì‹œì•„\n",
    "    \"ì¿ ì•Œë¼ë£¸í‘¸ë¥´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë§ë ˆì´ì‹œì•„\", \"ì½”ë“œ\": \"KUL\", \"ì˜ë¬¸ëª…\": \"kuala lumpur\"},\n",
    "    \"ì½”íƒ€í‚¤ë‚˜ë°œë£¨\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë§ë ˆì´ì‹œì•„\", \"ì½”ë“œ\": \"BKI\", \"ì˜ë¬¸ëª…\": \"kota kinabalu\"},\n",
    "    \"í˜ë‚­\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë§ë ˆì´ì‹œì•„\", \"ì½”ë“œ\": \"PEN\", \"ì˜ë¬¸ëª…\": \"penang\"},\n",
    "    \"ë‘ì¹´ìœ„\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë§ë ˆì´ì‹œì•„\", \"ì½”ë“œ\": \"LGK\", \"ì˜ë¬¸ëª…\": \"langkawi\"},\n",
    "    \"ì¡°í˜¸ë¥´ë°”ë£¨\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë§ë ˆì´ì‹œì•„\", \"ì½”ë“œ\": \"JHB\", \"ì˜ë¬¸ëª…\": \"johor bahru\"},\n",
    "\n",
    "    # í•„ë¦¬í•€\n",
    "    \"ì„¸ë¶€\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"í•„ë¦¬í•€\", \"ì½”ë“œ\": \"CEB\", \"ì˜ë¬¸ëª…\": \"cebu\"},\n",
    "    \"ë³´í™€\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"í•„ë¦¬í•€\", \"ì½”ë“œ\": \"TAG\", \"ì˜ë¬¸ëª…\": \"bohol\"},\n",
    "    \"ë§ˆë‹ë¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"í•„ë¦¬í•€\", \"ì½”ë“œ\": \"MNL\", \"ì˜ë¬¸ëª…\": \"manila\"},\n",
    "    \"ë³´ë¼ì¹´ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"í•„ë¦¬í•€\", \"ì½”ë“œ\": \"MPH\", \"ì˜ë¬¸ëª…\": \"boracay\"},\n",
    "    \"íŒ”ë¼ì™„\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"í•„ë¦¬í•€\", \"ì½”ë“œ\": \"PPS\", \"ì˜ë¬¸ëª…\": \"palawan\"},\n",
    "    \"ë‹¤ë°”ì˜¤\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"í•„ë¦¬í•€\", \"ì½”ë“œ\": \"DVO\", \"ì˜ë¬¸ëª…\": \"davao\"},\n",
    "\n",
    "    # ë² íŠ¸ë‚¨\n",
    "    \"ë‹¤ë‚­\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"DAD\", \"ì˜ë¬¸ëª…\": \"da nang\"},\n",
    "    \"í˜¸ì´ì•ˆ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"DAD\", \"ì˜ë¬¸ëª…\": \"hoi an\"},\n",
    "    \"í›„ì—\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"HUI\", \"ì˜ë¬¸ëª…\": \"hue\"},\n",
    "    \"í˜¸ì¹˜ë¯¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"SGN\", \"ì˜ë¬¸ëª…\": \"ho chi minh city\"},\n",
    "    \"ë¬´ì´ë„¤\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"SGN\", \"ì˜ë¬¸ëª…\": \"mui ne\"},\n",
    "    \"í‘¸ê¾¸ì˜¥\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"PQC\", \"ì˜ë¬¸ëª…\": \"phu quoc\"},\n",
    "    \"ë‚˜íŠ¸ë‘\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"CXR\", \"ì˜ë¬¸ëª…\": \"nha trang\"},\n",
    "    \"í•˜ë…¸ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"HAN\", \"ì˜ë¬¸ëª…\": \"hanoi\"},\n",
    "    \"ë‹¬ë\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"DLI\", \"ì˜ë¬¸ëª…\": \"da lat\"},\n",
    "    \"ì‚¬íŒŒ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"HAN\", \"ì˜ë¬¸ëª…\": \"sapa\"},  # í•˜ë…¸ì´ ê²½ìœ \n",
    "    \"ê»€í„°\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"VCA\", \"ì˜ë¬¸ëª…\": \"can tho\"},\n",
    "\n",
    "    # ìº„ë³´ë””ì•„\n",
    "    \"í”„ë†ˆíœ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ìº„ë³´ë””ì•„\", \"ì½”ë“œ\": \"PNH\", \"ì˜ë¬¸ëª…\": \"phnom penh\"},\n",
    "    \"ì‹œì— ë¦½\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ìº„ë³´ë””ì•„\", \"ì½”ë“œ\": \"REP\", \"ì˜ë¬¸ëª…\": \"siem reap\"},\n",
    "    \"ì”¨ì— ë¦½\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ìº„ë³´ë””ì•„\", \"ì½”ë“œ\": \"REP\", \"ì˜ë¬¸ëª…\": \"siem reap\"},\n",
    "\n",
    "    # ë¼ì˜¤ìŠ¤\n",
    "    \"ë¹„ì—”í‹°ì•ˆ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë¼ì˜¤ìŠ¤\", \"ì½”ë“œ\": \"VTE\", \"ì˜ë¬¸ëª…\": \"vientiane\"},\n",
    "    \"ë°©ë¹„ì—¥\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë¼ì˜¤ìŠ¤\", \"ì½”ë“œ\": \"VTE\", \"ì˜ë¬¸ëª…\": \"vang vieng\"},\n",
    "    \"ë£¨ì•™í”„ë¼ë°©\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë¼ì˜¤ìŠ¤\", \"ì½”ë“œ\": \"LPQ\", \"ì˜ë¬¸ëª…\": \"luang prabang\"},\n",
    "\n",
    "    # ì¸ë„ë„¤ì‹œì•„\n",
    "    \"ë°œë¦¬\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¸ë„ë„¤ì‹œì•„\", \"ì½”ë“œ\": \"DPS\", \"ì˜ë¬¸ëª…\": \"bali\"},\n",
    "\n",
    "    # ëª°ë””ë¸Œ\n",
    "    \"ë§ë ˆ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëª°ë””ë¸Œ\", \"ì½”ë“œ\": \"MLE\", \"ì˜ë¬¸ëª…\": \"male\"},\n",
    "\n",
    "    # ìŠ¤ë¦¬ë‘ì¹´\n",
    "    \"ì½œë¡¬ë³´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ìŠ¤ë¦¬ë‘ì¹´\", \"ì½”ë“œ\": \"CMB\", \"ì˜ë¬¸ëª…\": \"colombo\"},\n",
    "\n",
    "    # ìš°ì¦ˆë² í‚¤ìŠ¤íƒ„\n",
    "    \"íƒ€ìŠˆì¼„íŠ¸\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ìš°ì¦ˆë² í‚¤ìŠ¤íƒ„\", \"ì½”ë“œ\": \"TAS\", \"ì˜ë¬¸ëª…\": \"tashkent\"},\n",
    "    \"ì‚¬ë§ˆë¥´ì¹¸íŠ¸\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ìš°ì¦ˆë² í‚¤ìŠ¤íƒ„\", \"ì½”ë“œ\": \"SKD\", \"ì˜ë¬¸ëª…\": \"samarkand\"},\n",
    "    \"ë¶€í•˜ë¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ìš°ì¦ˆë² í‚¤ìŠ¤íƒ„\", \"ì½”ë“œ\": \"BHK\", \"ì˜ë¬¸ëª…\": \"bukhara\"},\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# ì¼ë³¸ + ì¤‘êµ­/ëŒ€ë§Œ\n",
    "# -------------------------------\n",
    "UNIFIED_CITY_INFO.update({\n",
    "    # ì¼ë³¸ (ê¸°ì¡´ + ì¶”ê°€)\n",
    "    \"ë„ì¿„\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"NRT\", \"ì˜ë¬¸ëª…\": \"tokyo\"},\n",
    "    \"ì˜¤ì‚¬ì¹´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"KIX\", \"ì˜ë¬¸ëª…\": \"osaka\"},\n",
    "    \"êµí† \": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"KIX\", \"ì˜ë¬¸ëª…\": \"kyoto\"},  # KIX ì´ìš©\n",
    "    \"ë‚˜ê³ ì•¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"NGO\", \"ì˜ë¬¸ëª…\": \"nagoya\"},\n",
    "    \"í›„ì¿ ì˜¤ì¹´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"FUK\", \"ì˜ë¬¸ëª…\": \"fukuoka\"},\n",
    "    \"ë²³í‘¸\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"OIT\", \"ì˜ë¬¸ëª…\": \"beppu\"},  # OIT ì´ìš©\n",
    "    \"ì˜¤ì´íƒ€\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"OIT\", \"ì˜ë¬¸ëª…\": \"oita\"},\n",
    "    \"êµ¬ë§ˆëª¨í† \": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"KMJ\", \"ì˜ë¬¸ëª…\": \"kumamoto\"},\n",
    "    \"ì˜¤í‚¤ë‚˜ì™€\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"OKA\", \"ì˜ë¬¸ëª…\": \"okinawa\"},\n",
    "    \"ë¯¸ì•¼ì½”ì§€ë§ˆ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"MMY\", \"ì˜ë¬¸ëª…\": \"miyakojima\"},\n",
    "    \"ì‚¿í¬ë¡œ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"CTS\", \"ì˜ë¬¸ëª…\": \"sapporo\"},\n",
    "    # ì¼ë³¸ ì¶”ê°€\n",
    "    \"ë‚˜ê°€ì‚¬í‚¤\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"NGS\", \"ì˜ë¬¸ëª…\": \"nagasaki\"},\n",
    "    \"ì‚¬ê°€\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"HSG\", \"ì˜ë¬¸ëª…\": \"saga\"},\n",
    "    \"ë¯¸ì•¼ìí‚¤\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"KMI\", \"ì˜ë¬¸ëª…\": \"miyazaki\"},\n",
    "    \"ê°€ê³ ì‹œë§ˆ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"KOJ\", \"ì˜ë¬¸ëª…\": \"kagoshima\"},\n",
    "    \"ìš”ì½”í•˜ë§ˆ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"HND\", \"ì˜ë¬¸ëª…\": \"yokohama\"},  # ë„ì¿„ í•˜ë„¤ë‹¤ ì´ìš©\n",
    "    \"ë‚˜ë¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"KIX\", \"ì˜ë¬¸ëª…\": \"nara\"},      # ê°„ì‚¬ì´ ì´ìš©\n",
    "    \"íˆë¡œì‹œë§ˆ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"HIJ\", \"ì˜ë¬¸ëª…\": \"hiroshima\"},\n",
    "    \"í•˜ì½”ë‹¤í…Œ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"HKD\", \"ì˜ë¬¸ëª…\": \"hakodate\"},\n",
    "\n",
    "    # ì¤‘êµ­/ëŒ€ë§Œ\n",
    "    \"íƒ€ì´ë² ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€ë§Œ\", \"ì½”ë“œ\": \"TPE\", \"ì˜ë¬¸ëª…\": \"taipei\"},\n",
    "    \"ê°€ì˜¤ìŠ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€ë§Œ\", \"ì½”ë“œ\": \"KHH\", \"ì˜ë¬¸ëª…\": \"kaohsiung\"},\n",
    "    \"íƒ€ì´ì¤‘\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€ë§Œ\", \"ì½”ë“œ\": \"RMQ\", \"ì˜ë¬¸ëª…\": \"taichung\"},\n",
    "    \"ìƒí•˜ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¤‘êµ­\", \"ì½”ë“œ\": \"PVG\", \"ì˜ë¬¸ëª…\": \"shanghai\"},\n",
    "    \"ë² ì´ì§•\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¤‘êµ­\", \"ì½”ë“œ\": \"PEK\", \"ì˜ë¬¸ëª…\": \"beijing\"},\n",
    "    \"ì‹¼ì•¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¤‘êµ­\", \"ì½”ë“œ\": \"SYX\", \"ì˜ë¬¸ëª…\": \"sanya\"},\n",
    "    \"í™ì½©\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"í™ì½©\", \"ì½”ë“œ\": \"HKG\", \"ì˜ë¬¸ëª…\": \"hong kong\"},\n",
    "    \"ë§ˆì¹´ì˜¤\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë§ˆì¹´ì˜¤\", \"ì½”ë“œ\": \"MFM\", \"ì˜ë¬¸ëª…\": \"macau\"},\n",
    "})\n",
    "\n",
    "# -------------------------------\n",
    "# ìœ ëŸ½ (ì´íƒˆë¦¬ì•„ í™•ì¥ + ì¶”ì²œì§€ í¬í•¨)\n",
    "# -------------------------------\n",
    "UNIFIED_CITY_INFO.update({\n",
    "    # í”„ë‘ìŠ¤\n",
    "    \"íŒŒë¦¬\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í”„ë‘ìŠ¤\", \"ì½”ë“œ\": \"CDG\", \"ì˜ë¬¸ëª…\": \"paris\"},\n",
    "    \"ë‹ˆìŠ¤\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í”„ë‘ìŠ¤\", \"ì½”ë“œ\": \"NCE\", \"ì˜ë¬¸ëª…\": \"nice\"},\n",
    "    \"ë¦¬ì˜¹\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í”„ë‘ìŠ¤\", \"ì½”ë“œ\": \"LYS\", \"ì˜ë¬¸ëª…\": \"lyon\"},\n",
    "\n",
    "    # ì˜êµ­Â·ì•„ì¼ëœë“œ\n",
    "    \"ëŸ°ë˜\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì˜êµ­\", \"ì½”ë“œ\": \"LHR\", \"ì˜ë¬¸ëª…\": \"london\"},\n",
    "    \"ë”ë¸”ë¦°\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì•„ì¼ëœë“œ\", \"ì½”ë“œ\": \"DUB\", \"ì˜ë¬¸ëª…\": \"dublin\"},\n",
    "\n",
    "    # ì´íƒˆë¦¬ì•„ (ê¸°ì¡´ + ì•„ë§í”¼ í•´ì•ˆ)\n",
    "    \"ë¡œë§ˆ\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"FCO\", \"ì˜ë¬¸ëª…\": \"rome\"},\n",
    "    \"í”¼ë Œì²´\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"FLR\", \"ì˜ë¬¸ëª…\": \"florence\"},\n",
    "    \"ë² ë„¤ì¹˜ì•„\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"VCE\", \"ì˜ë¬¸ëª…\": \"venice\"},\n",
    "    \"ë°€ë¼ë…¸\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"MXP\", \"ì˜ë¬¸ëª…\": \"milan\"},\n",
    "    \"ë‚˜í´ë¦¬\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"NAP\", \"ì˜ë¬¸ëª…\": \"naples\"},\n",
    "    \"ì•„ë§í”¼\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"NAP\", \"ì˜ë¬¸ëª…\": \"amalfi\"},\n",
    "    \"í¬ì‹œíƒ€ë…¸\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"NAP\", \"ì˜ë¬¸ëª…\": \"positano\"},\n",
    "    \"ë¼ë²¨ë¡œ\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"NAP\", \"ì˜ë¬¸ëª…\": \"ravello\"},\n",
    "    \"ì†Œë Œí† \": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"NAP\", \"ì˜ë¬¸ëª…\": \"sorrento\"},\n",
    "    \"ì¹´í”„ë¦¬\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"NAP\", \"ì˜ë¬¸ëª…\": \"capri\"},\n",
    "    \"íŒ”ë ˆë¥´ëª¨\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"PMO\", \"ì˜ë¬¸ëª…\": \"palermo\"},\n",
    "    \"ì¹´íƒ€ë‹ˆì•„\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"CTA\", \"ì˜ë¬¸ëª…\": \"catania\"},\n",
    "    \"í† ë¦¬ë…¸\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"TRN\", \"ì˜ë¬¸ëª…\": \"turin\"},\n",
    "    \"ì œë…¸ë°”\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"GOA\", \"ì˜ë¬¸ëª…\": \"genoa\"},\n",
    "    \"ë² ë¡œë‚˜\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"VRN\", \"ì˜ë¬¸ëª…\": \"verona\"},\n",
    "    \"í”¼ì‚¬\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"PSA\", \"ì˜ë¬¸ëª…\": \"pisa\"},\n",
    "    \"ì‹œì—ë‚˜\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"FLR\", \"ì˜ë¬¸ëª…\": \"siena\"},  # FLR ì´ìš©\n",
    "\n",
    "    # ìŠ¤í˜ì¸\n",
    "    \"ë°”ë¥´ì…€ë¡œë‚˜\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤í˜ì¸\", \"ì½”ë“œ\": \"BCN\", \"ì˜ë¬¸ëª…\": \"barcelona\"},\n",
    "    \"ë§ˆë“œë¦¬ë“œ\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤í˜ì¸\", \"ì½”ë“œ\": \"MAD\", \"ì˜ë¬¸ëª…\": \"madrid\"},\n",
    "    \"ì„¸ë¹„ì•¼\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤í˜ì¸\", \"ì½”ë“œ\": \"SVQ\", \"ì˜ë¬¸ëª…\": \"seville\"},\n",
    "    \"ê·¸ë¼ë‚˜ë‹¤\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤í˜ì¸\", \"ì½”ë“œ\": \"GRX\", \"ì˜ë¬¸ëª…\": \"granada\"},\n",
    "    \"ì´ë¹„ì\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤í˜ì¸\", \"ì½”ë“œ\": \"IBZ\", \"ì˜ë¬¸ëª…\": \"ibiza\"},\n",
    "    \"ë°œë Œì‹œì•„\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤í˜ì¸\", \"ì½”ë“œ\": \"VLC\", \"ì˜ë¬¸ëª…\": \"valencia\"},\n",
    "    \"ë§ë¼ê°€\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤í˜ì¸\", \"ì½”ë“œ\": \"AGP\", \"ì˜ë¬¸ëª…\": \"malaga\"},\n",
    "\n",
    "    # í¬ë¥´íˆ¬ê°ˆ\n",
    "    \"ë¦¬ìŠ¤ë³¸\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í¬ë¥´íˆ¬ê°ˆ\", \"ì½”ë“œ\": \"LIS\", \"ì˜ë¬¸ëª…\": \"lisbon\"},\n",
    "    \"í¬ë¥´íˆ¬\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í¬ë¥´íˆ¬ê°ˆ\", \"ì½”ë“œ\": \"OPO\", \"ì˜ë¬¸ëª…\": \"porto\"},\n",
    "\n",
    "    # ì¤‘ë¶€Â·ë™ìœ ëŸ½\n",
    "    \"í”„ë¼í•˜\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì²´ì½”\", \"ì½”ë“œ\": \"PRG\", \"ì˜ë¬¸ëª…\": \"prague\"},\n",
    "    \"ë¹„ì—”ë‚˜\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì˜¤ìŠ¤íŠ¸ë¦¬ì•„\", \"ì½”ë“œ\": \"VIE\", \"ì˜ë¬¸ëª…\": \"vienna\"},\n",
    "    \"ë¶€ë‹¤í˜ìŠ¤íŠ¸\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í—ê°€ë¦¬\", \"ì½”ë“œ\": \"BUD\", \"ì˜ë¬¸ëª…\": \"budapest\"},\n",
    "    \"ë°”ë¥´ìƒ¤ë°”\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í´ë€ë“œ\", \"ì½”ë“œ\": \"WAW\", \"ì˜ë¬¸ëª…\": \"warsaw\"},\n",
    "    \"í¬ë¼ì¿ í”„\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í´ë€ë“œ\", \"ì½”ë“œ\": \"KRK\", \"ì˜ë¬¸ëª…\": \"krakow\"},\n",
    "\n",
    "    # ìŠ¤ìœ„ìŠ¤\n",
    "    \"ì·¨ë¦¬íˆ\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤ìœ„ìŠ¤\", \"ì½”ë“œ\": \"ZRH\", \"ì˜ë¬¸ëª…\": \"zurich\"},\n",
    "    \"ì¸í„°ë¼ì¼„\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤ìœ„ìŠ¤\", \"ì½”ë“œ\": \"ZRH\", \"ì˜ë¬¸ëª…\": \"interlaken\"},  # ZRH ì´ìš©\n",
    "    \"ì œë„¤ë°”\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤ìœ„ìŠ¤\", \"ì½”ë“œ\": \"GVA\", \"ì˜ë¬¸ëª…\": \"geneva\"},\n",
    "\n",
    "    # ë² ë„¤ë£©ìŠ¤Â·ë¶ìœ ëŸ½Â·ë°œì¹¸\n",
    "    \"ì•”ìŠ¤í…Œë¥´ë‹´\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ë„¤ëœë€ë“œ\", \"ì½”ë“œ\": \"AMS\", \"ì˜ë¬¸ëª…\": \"amsterdam\"},\n",
    "    \"ë¸Œë¤¼ì…€\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ë²¨ê¸°ì—\", \"ì½”ë“œ\": \"BRU\", \"ì˜ë¬¸ëª…\": \"brussels\"},\n",
    "    \"ë¸Œë¤¼í—¤\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ë²¨ê¸°ì—\", \"ì½”ë“œ\": \"BRU\", \"ì˜ë¬¸ëª…\": \"bruges\"},  # ë¸Œë¤¼ì…€ ê²½ìœ \n",
    "    \"ì½”íœí•˜ê²\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ë´ë§ˆí¬\", \"ì½”ë“œ\": \"CPH\", \"ì˜ë¬¸ëª…\": \"copenhagen\"},\n",
    "    \"ìŠ¤í†¡í™€ë¦„\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤ì›¨ë´\", \"ì½”ë“œ\": \"ARN\", \"ì˜ë¬¸ëª…\": \"stockholm\"},\n",
    "    \"ì˜¤ìŠ¬ë¡œ\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ë…¸ë¥´ì›¨ì´\", \"ì½”ë“œ\": \"OSL\", \"ì˜ë¬¸ëª…\": \"oslo\"},\n",
    "    \"í—¬ì‹±í‚¤\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í•€ë€ë“œ\", \"ì½”ë“œ\": \"HEL\", \"ì˜ë¬¸ëª…\": \"helsinki\"},\n",
    "    \"ìê·¸ë ˆë¸Œ\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í¬ë¡œì•„í‹°ì•„\", \"ì½”ë“œ\": \"ZAG\", \"ì˜ë¬¸ëª…\": \"zagreb\"},\n",
    "    \"ë‘ë¸Œë¡œë¸Œë‹ˆí¬\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í¬ë¡œì•„í‹°ì•„\", \"ì½”ë“œ\": \"DBV\", \"ì˜ë¬¸ëª…\": \"dubrovnik\"},\n",
    "    \"ìŠ¤í”Œë¦¬íŠ¸\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í¬ë¡œì•„í‹°ì•„\", \"ì½”ë“œ\": \"SPU\", \"ì˜ë¬¸ëª…\": \"split\"},\n",
    "\n",
    "    # ë…ì¼\n",
    "    \"ë®Œí—¨\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ë…ì¼\", \"ì½”ë“œ\": \"MUC\", \"ì˜ë¬¸ëª…\": \"munich\"},\n",
    "    \"ë² ë¥¼ë¦°\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ë…ì¼\", \"ì½”ë“œ\": \"BER\", \"ì˜ë¬¸ëª…\": \"berlin\"},\n",
    "    \"í”„ë‘í¬í‘¸ë¥´íŠ¸\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ë…ì¼\", \"ì½”ë“œ\": \"FRA\", \"ì˜ë¬¸ëª…\": \"frankfurt\"},\n",
    "\n",
    "    # ê·¸ë¦¬ìŠ¤Â·í„°í‚¤\n",
    "    \"ì•„í…Œë„¤\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ê·¸ë¦¬ìŠ¤\", \"ì½”ë“œ\": \"ATH\", \"ì˜ë¬¸ëª…\": \"athens\"},\n",
    "    \"ì‚°í† ë¦¬ë‹ˆ\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ê·¸ë¦¬ìŠ¤\", \"ì½”ë“œ\": \"JTR\", \"ì˜ë¬¸ëª…\": \"santorini\"},\n",
    "    \"ì´ìŠ¤íƒ„ë¶ˆ\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í„°í‚¤\", \"ì½”ë“œ\": \"IST\", \"ì˜ë¬¸ëª…\": \"istanbul\"},\n",
    "})\n",
    "\n",
    "# -------------------------------\n",
    "# ë¶ë¯¸, ì˜¤ì„¸ì•„ë‹ˆì•„\n",
    "# -------------------------------\n",
    "UNIFIED_CITY_INFO.update({\n",
    "    \"ë‰´ìš•\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"JFK\", \"ì˜ë¬¸ëª…\": \"new york city\"},\n",
    "    \"ë¡œìŠ¤ì•¤ì ¤ë ˆìŠ¤\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"LAX\", \"ì˜ë¬¸ëª…\": \"los angeles\"},\n",
    "    \"ì‹œì¹´ê³ \": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"ORD\", \"ì˜ë¬¸ëª…\": \"chicago\"},\n",
    "    \"í•˜ì™€ì´\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"HNL\", \"ì˜ë¬¸ëª…\": \"hawaii\"},\n",
    "    \"ìƒŒí”„ë€ì‹œìŠ¤ì½”\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"SFO\", \"ì˜ë¬¸ëª…\": \"san francisco\"},\n",
    "    \"ë¼ìŠ¤ë² ì´ê±°ìŠ¤\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"LAS\", \"ì˜ë¬¸ëª…\": \"las vegas\"},\n",
    "    \"ì›Œì‹±í„´ D.C.\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"IAD\", \"ì˜ë¬¸ëª…\": \"washington, d.c.\"},\n",
    "    \"ë³´ìŠ¤í„´\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"BOS\", \"ì˜ë¬¸ëª…\": \"boston\"},\n",
    "    \"ì‹œì• í‹€\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"SEA\", \"ì˜ë¬¸ëª…\": \"seattle\"},\n",
    "\n",
    "    # ë¯¸êµ­ ì¶”ê°€\n",
    "    \"ë§ˆì´ì• ë¯¸\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"MIA\", \"ì˜ë¬¸ëª…\": \"miami\"},\n",
    "    \"ì˜¬ëœë„\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"MCO\", \"ì˜ë¬¸ëª…\": \"orlando\"},\n",
    "    \"ë‰´ì˜¬ë¦¬ì–¸ìŠ¤\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"MSY\", \"ì˜ë¬¸ëª…\": \"new orleans\"},\n",
    "\n",
    "    # ìºë‚˜ë‹¤\n",
    "    \"ë°´ì¿ ë²„\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ìºë‚˜ë‹¤\", \"ì½”ë“œ\": \"YVR\", \"ì˜ë¬¸ëª…\": \"vancouver\"},\n",
    "    \"í† ë¡ í† \": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ìºë‚˜ë‹¤\", \"ì½”ë“œ\": \"YYZ\", \"ì˜ë¬¸ëª…\": \"toronto\"},\n",
    "    \"ëª¬íŠ¸ë¦¬ì˜¬\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ìºë‚˜ë‹¤\", \"ì½”ë“œ\": \"YUL\", \"ì˜ë¬¸ëª…\": \"montreal\"},\n",
    "    \"ìº˜ê±°ë¦¬\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ìºë‚˜ë‹¤\", \"ì½”ë“œ\": \"YYC\", \"ì˜ë¬¸ëª…\": \"calgary\"},\n",
    "\n",
    "    # ë©•ì‹œì½”\n",
    "    \"ì¹¸ì¿¤\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë©•ì‹œì½”\", \"ì½”ë“œ\": \"CUN\", \"ì˜ë¬¸ëª…\": \"cancun\"},\n",
    "    \"ë©•ì‹œì½”ì‹œí‹°\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë©•ì‹œì½”\", \"ì½”ë“œ\": \"MEX\", \"ì˜ë¬¸ëª…\": \"mexico city\"},\n",
    "    \"ì‹œë“œë‹ˆ\": {\"ëŒ€ë¥™\": \"ì˜¤ì„¸ì•„ë‹ˆì•„\", \"êµ­ê°€\": \"í˜¸ì£¼\", \"ì½”ë“œ\": \"SYD\", \"ì˜ë¬¸ëª…\": \"sydney\"},\n",
    "\n",
    "    # ì˜¤ì„¸ì•„ë‹ˆì•„\n",
    "    \"ë©œë²„ë¥¸\": {\"ëŒ€ë¥™\": \"ì˜¤ì„¸ì•„ë‹ˆì•„\", \"êµ­ê°€\": \"í˜¸ì£¼\", \"ì½”ë“œ\": \"MEL\", \"ì˜ë¬¸ëª…\": \"melbourne\"},\n",
    "    \"ë¸Œë¦¬ì¦ˆë²ˆ\": {\"ëŒ€ë¥™\": \"ì˜¤ì„¸ì•„ë‹ˆì•„\", \"êµ­ê°€\": \"í˜¸ì£¼\", \"ì½”ë“œ\": \"BNE\", \"ì˜ë¬¸ëª…\": \"brisbane\"},\n",
    "    \"í¼ìŠ¤\": {\"ëŒ€ë¥™\": \"ì˜¤ì„¸ì•„ë‹ˆì•„\", \"êµ­ê°€\": \"í˜¸ì£¼\", \"ì½”ë“œ\": \"PER\", \"ì˜ë¬¸ëª…\": \"perth\"},\n",
    "    \"ì¼€ì–¸ì¦ˆ\": {\"ëŒ€ë¥™\": \"ì˜¤ì„¸ì•„ë‹ˆì•„\", \"êµ­ê°€\": \"í˜¸ì£¼\", \"ì½”ë“œ\": \"CNS\", \"ì˜ë¬¸ëª…\": \"cairns\"},\n",
    "\n",
    "    \"ì˜¤í´ëœë“œ\": {\"ëŒ€ë¥™\": \"ì˜¤ì„¸ì•„ë‹ˆì•„\", \"êµ­ê°€\": \"ë‰´ì§ˆëœë“œ\", \"ì½”ë“œ\": \"AKL\", \"ì˜ë¬¸ëª…\": \"auckland\"},\n",
    "    \"í€¸ìŠ¤íƒ€ìš´\": {\"ëŒ€ë¥™\": \"ì˜¤ì„¸ì•„ë‹ˆì•„\", \"êµ­ê°€\": \"ë‰´ì§ˆëœë“œ\", \"ì½”ë“œ\": \"ZQN\", \"ì˜ë¬¸ëª…\": \"queenstown\"},\n",
    "\n",
    "    # ë¯¸í¬ë¡œë„¤ì‹œì•„ (í•œêµ­ ì¸ê¸° íœ´ì–‘ì§€)\n",
    "    \"ê´Œ\": {\"ëŒ€ë¥™\": \"ì˜¤ì„¸ì•„ë‹ˆì•„\", \"êµ­ê°€\": \"ê´Œ\", \"ì½”ë“œ\": \"GUM\", \"ì˜ë¬¸ëª…\": \"guam\"},\n",
    "    \"ì‚¬ì´íŒ\": {\"ëŒ€ë¥™\": \"ì˜¤ì„¸ì•„ë‹ˆì•„\", \"êµ­ê°€\": \"ë¶ë§ˆë¦¬ì•„ë‚˜ ì œë„\", \"ì½”ë“œ\": \"SPN\", \"ì˜ë¬¸ëª…\": \"saipan\"},\n",
    "})\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# ì¤‘ë™, ì•„í”„ë¦¬ì¹´\n",
    "# -------------------------------\n",
    "UNIFIED_CITY_INFO.update({\n",
    "    \"ë‘ë°”ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì•„ëì—ë¯¸ë¦¬íŠ¸\", \"ì½”ë“œ\": \"DXB\", \"ì˜ë¬¸ëª…\": \"dubai\"},\n",
    "    \"ì•„ë¶€ë‹¤ë¹„\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì•„ëì—ë¯¸ë¦¬íŠ¸\", \"ì½”ë“œ\": \"AUH\", \"ì˜ë¬¸ëª…\": \"abu dhabi\"},\n",
    "    \"ë„í•˜\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¹´íƒ€ë¥´\", \"ì½”ë“œ\": \"DOH\", \"ì˜ë¬¸ëª…\": \"doha\"},\n",
    "    \"í…”ì•„ë¹„ë¸Œ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì´ìŠ¤ë¼ì—˜\", \"ì½”ë“œ\": \"TLV\", \"ì˜ë¬¸ëª…\": \"tel aviv\"},\n",
    "    \"ì˜ˆë£¨ì‚´ë ˜\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì´ìŠ¤ë¼ì—˜\", \"ì½”ë“œ\": \"TLV\", \"ì˜ë¬¸ëª…\": \"jerusalem\"},  # TLV ì´ìš©\n",
    "    \"ì¹´ì´ë¡œ\": {\"ëŒ€ë¥™\": \"ì•„í”„ë¦¬ì¹´\", \"êµ­ê°€\": \"ì´ì§‘íŠ¸\", \"ì½”ë“œ\": \"CAI\", \"ì˜ë¬¸ëª…\": \"cairo\"},\n",
    "    \"ë§ˆë¼ì¼€ì‹œ\": {\"ëŒ€ë¥™\": \"ì•„í”„ë¦¬ì¹´\", \"êµ­ê°€\": \"ëª¨ë¡œì½”\", \"ì½”ë“œ\": \"RAK\", \"ì˜ë¬¸ëª…\": \"marrakech\"},\n",
    "    \"ì¹´ì‚¬ë¸”ë‘ì¹´\": {\"ëŒ€ë¥™\": \"ì•„í”„ë¦¬ì¹´\", \"êµ­ê°€\": \"ëª¨ë¡œì½”\", \"ì½”ë“œ\": \"CMN\", \"ì˜ë¬¸ëª…\": \"casablanca\"},\n",
    "    \"ì¼€ì´í”„íƒ€ìš´\": {\"ëŒ€ë¥™\": \"ì•„í”„ë¦¬ì¹´\", \"êµ­ê°€\": \"ë‚¨ì•„í”„ë¦¬ì¹´ê³µí™”êµ­\", \"ì½”ë“œ\": \"CPT\", \"ì˜ë¬¸ëª…\": \"cape town\"},\n",
    "    \"ìš”í•˜ë„¤ìŠ¤ë²„ê·¸\": {\"ëŒ€ë¥™\": \"ì•„í”„ë¦¬ì¹´\", \"êµ­ê°€\": \"ë‚¨ì•„í”„ë¦¬ì¹´ê³µí™”êµ­\", \"ì½”ë“œ\": \"JNB\", \"ì˜ë¬¸ëª…\": \"johannesburg\"},\n",
    "    \"ë‚˜ì´ë¡œë¹„\": {\"ëŒ€ë¥™\": \"ì•„í”„ë¦¬ì¹´\", \"êµ­ê°€\": \"ì¼€ëƒ\", \"ì½”ë“œ\": \"NBO\", \"ì˜ë¬¸ëª…\": \"nairobi\"},\n",
    "})\n",
    "\n",
    "\n",
    "print(f\"âœ… UNIFIED_CITY_INFO ìµœì¢… ì—…ë°ì´íŠ¸ ì™„ë£Œ! ì´ {len(UNIFIED_CITY_INFO)}ê°œ ë„ì‹œ\")\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ†• hashlib ê¸°ë°˜ ì´ˆê³ ì† ì¤‘ë³µ ë°©ì§€ ì‹œìŠ¤í…œ\n",
    "# =============================================================================\n",
    "\n",
    "def get_url_hash(url):\n",
    "    \"\"\"URLì„ ê³ ìœ í•œ ì§§ì€ í•´ì‹œë¡œ ë³€í™˜ (0.0001ì´ˆ)\"\"\"\n",
    "    hash_length = CONFIG.get(\"HASH_LENGTH\", 12)\n",
    "    return hashlib.md5(url.encode('utf-8')).hexdigest()[:hash_length]\n",
    "\n",
    "def is_url_processed_fast(url, city_name):\n",
    "    \"\"\"í•´ì‹œ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ë¡œ ì´ˆê³ ì† ì¤‘ë³µ ì²´í¬ (0.001ì´ˆ)\"\"\"\n",
    "    if not CONFIG.get(\"USE_HASH_SYSTEM\", True):\n",
    "        return False\n",
    "        \n",
    "    url_hash = get_url_hash(url)\n",
    "    hash_file = os.path.join(\"hash_index\", city_name, f\"{url_hash}.done\")\n",
    "    return os.path.exists(hash_file)\n",
    "\n",
    "def mark_url_processed_fast(url, city_name, product_number=None):\n",
    "    \"\"\"í•´ì‹œ íŒŒì¼ ìƒì„±ìœ¼ë¡œ ì™„ë£Œ í‘œì‹œ (0.002ì´ˆ)\"\"\"\n",
    "    if not CONFIG.get(\"USE_HASH_SYSTEM\", True):\n",
    "        return False\n",
    "        \n",
    "    url_hash = get_url_hash(url)\n",
    "    hash_dir = os.path.join(\"hash_index\", city_name)\n",
    "    os.makedirs(hash_dir, exist_ok=True)\n",
    "    \n",
    "    hash_file = os.path.join(hash_dir, f\"{url_hash}.done\")\n",
    "    with open(hash_file, 'w', encoding='utf-8') as f:\n",
    "        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        f.write(f\"URL: {url}\\n\")\n",
    "        f.write(f\"Product: {product_number}\\n\")\n",
    "        f.write(f\"Completed: {timestamp}\\n\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def get_hash_stats(city_name):\n",
    "    \"\"\"í•´ì‹œ ì‹œìŠ¤í…œ í†µê³„ (0.01ì´ˆ)\"\"\"\n",
    "    hash_dir = os.path.join(\"hash_index\", city_name)\n",
    "    if not os.path.exists(hash_dir):\n",
    "        return {'total': 0, 'files': [], 'latest': None}\n",
    "    \n",
    "    done_files = [f for f in os.listdir(hash_dir) if f.endswith('.done')]\n",
    "    latest_file = None\n",
    "    \n",
    "    if done_files:\n",
    "        latest_file = max(done_files, \n",
    "                         key=lambda x: os.path.getctime(os.path.join(hash_dir, x)))\n",
    "    \n",
    "    return {\n",
    "        'total': len(done_files),\n",
    "        'files': done_files,\n",
    "        'latest': latest_file\n",
    "    }\n",
    "\n",
    "def migrate_csv_to_hash(city_name):\n",
    "    \"\"\"ê¸°ì¡´ CSV ë°ì´í„°ë¥¼ í•´ì‹œ ì‹œìŠ¤í…œìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜\"\"\"\n",
    "    print(f\"ğŸ”„ {city_name} CSV â†’ í•´ì‹œ ì‹œìŠ¤í…œ ë§ˆì´ê·¸ë ˆì´ì…˜...\")\n",
    "    \n",
    "    try:\n",
    "        # ê¸°ì¡´ CSVì—ì„œ URL ì½ê¸°\n",
    "        csv_urls = get_completed_urls_from_csv(city_name)\n",
    "        \n",
    "        if not csv_urls:\n",
    "            print(f\"   â„¹ï¸ ë§ˆì´ê·¸ë ˆì´ì…˜í•  CSV ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤\")\n",
    "            return True\n",
    "        \n",
    "        # í•´ì‹œ í´ë” ìƒì„±\n",
    "        hash_dir = os.path.join(\"hash_index\", city_name)\n",
    "        os.makedirs(hash_dir, exist_ok=True)\n",
    "        \n",
    "        # ê° URLì„ í•´ì‹œ íŒŒì¼ë¡œ ë³€í™˜\n",
    "        migrated_count = 0\n",
    "        for url in csv_urls:\n",
    "            if not is_url_processed_fast(url, city_name):\n",
    "                mark_url_processed_fast(url, city_name, \"migrated\")\n",
    "                migrated_count += 1\n",
    "        \n",
    "        print(f\"   âœ… {migrated_count}ê°œ URL ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ\")\n",
    "        print(f\"   ğŸ“Š í•´ì‹œ ì‹œìŠ¤í…œ í†µê³„: {get_hash_stats(city_name)}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "def hybrid_is_processed(url, city_name):\n",
    "    \"\"\"í•˜ì´ë¸Œë¦¬ë“œ ì¤‘ë³µ ì²´í¬: í•´ì‹œ(ë¹ ë¦„) + CSV(í˜¸í™˜ì„±)\"\"\"\n",
    "    # 1. ì´ˆê³ ì† í•´ì‹œ ì²´í¬ ë¨¼ì € (0.001ì´ˆ)\n",
    "    if is_url_processed_fast(url, city_name):\n",
    "        return True\n",
    "    \n",
    "    # 2. ê¸°ì¡´ CSV í˜¸í™˜ì„± ì²´í¬ (0.1ì´ˆ, í•„ìš”ì‹œì—ë§Œ)\n",
    "    if CONFIG.get(\"KEEP_CSV_SYSTEM\", True):\n",
    "        csv_urls = get_completed_urls_from_csv(city_name)\n",
    "        if url in csv_urls:\n",
    "            # CSVì—ëŠ” ìˆì§€ë§Œ í•´ì‹œì— ì—†ìœ¼ë©´ í•´ì‹œì—ë„ ì¶”ê°€\n",
    "            mark_url_processed_fast(url, city_name, \"csv_sync\")\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def ensure_url_directories_v2():\n",
    "    \"\"\"V2 3-tier URL ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±\"\"\"\n",
    "    if not CONFIG.get(\"USE_V2_URL_SYSTEM\", True):\n",
    "        return True\n",
    "    \n",
    "    try:\n",
    "        directories = [\n",
    "            CONFIG[\"V2_URL_COLLECTED\"],  # url_collected/\n",
    "            CONFIG[\"V2_URL_DONE\"],       # url_done/\n",
    "            CONFIG[\"V2_URL_PROGRESS\"]    # url_progress/\n",
    "        ]\n",
    "        for directory in directories:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ V2 URL ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "    \n",
    "# =============================================================================\n",
    "# ğŸ”§ í•µì‹¬ í•¨ìˆ˜ë“¤ - ë‹¨ì¼ ì •ë³´ ì†ŒìŠ¤(UNIFIED_CITY_INFO) ì‚¬ìš© + hashlib í†µí•©\n",
    "# =============================================================================\n",
    "\n",
    "# ë„ì‹œë³„ë¡œ ì‘ì—… ë‚´ì—­ì„ ê¸°ë¡í•  ë¡œê·¸ íŒŒì¼ ê²½ë¡œ í…œí”Œë¦¿\n",
    "URL_LOG_FILE_TEMPLATE = 'url_done/{city_code}_done.log'\n",
    "\n",
    "def get_completed_urls_from_csv(city_name):\n",
    "    \"\"\"[V2 3-tier + CSV í†µí•© ë²„ì „] ì™„ë£Œëœ URLì„ 3-tier ì‹œìŠ¤í…œì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤.\"\"\"\n",
    "    # 1. V2 ì‹œìŠ¤í…œì—ì„œ ì™„ë£Œëœ URL ë¡œë“œ\n",
    "    v2_urls = set()\n",
    "    if CONFIG.get(\"USE_V2_URL_SYSTEM\", True):\n",
    "        try:\n",
    "            city_code = get_city_code(city_name)\n",
    "            done_file = os.path.join(CONFIG[\"V2_URL_DONE\"], f\"{city_code}_done.log\")\n",
    "            if os.path.exists(done_file):\n",
    "                with open(done_file, 'r', encoding='utf-8') as f:\n",
    "                    v2_urls = set(line.strip() for line in f if line.strip())\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ V2 URL ë¡œë“œ ì˜¤ë¥˜: {e}\")\n",
    "    \n",
    "    # 2. ê¸°ì¡´ CSVì—ì„œ URL ë¡œë“œ (í˜¸í™˜ì„±)\n",
    "    csv_urls = set()\n",
    "    try:\n",
    "        continent, country = get_city_info(city_name)\n",
    "        # ë„ì‹œêµ­ê°€ íŠ¹ë³„ ì²˜ë¦¬\n",
    "        if city_name in [\"ë§ˆì¹´ì˜¤\", \"í™ì½©\", \"ì‹±ê°€í¬ë¥´\"]:\n",
    "            csv_path = os.path.join(\"data\", continent, f\"klook_{city_name}_products.csv\")\n",
    "        else:\n",
    "            csv_path = os.path.join(\"data\", continent, country, city_name, f\"klook_{city_name}_products.csv\")\n",
    "        \n",
    "        if os.path.exists(csv_path):\n",
    "            import pandas as pd\n",
    "            df = pd.read_csv(csv_path, encoding='utf-8-sig', usecols=['URL'])\n",
    "            csv_urls = set(df['URL'].dropna())\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ CSVì—ì„œ URLì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë¬´ì‹œ ê°€ëŠ¥): {e}\")\n",
    "    \n",
    "    # 3. V2 + CSV í†µí•© ê²°ê³¼ ë°˜í™˜\n",
    "    combined_urls = v2_urls.union(csv_urls)\n",
    "    \n",
    "    # ì¶œë ¥ í™ìˆ˜ ë°©ì§€ - ì¶œë ¥ ë©”ì‹œì§€ ì œê±°\n",
    "    # if CONFIG.get(\"USE_V2_URL_SYSTEM\", True) and len(v2_urls) > 0:\n",
    "    #     print(f\"âœ… V2+CSV í†µí•© ë¡œë“œ: V2({len(v2_urls)}) + CSV({len(csv_urls)}) = {len(combined_urls)}ê°œ\")\n",
    "    \n",
    "    return combined_urls\n",
    " \n",
    "def load_session_state(city_name):\n",
    "    \"\"\"\n",
    "    [hashlib í†µí•© ë²„ì „] ì´ì „ ì„¸ì…˜ì˜ ìƒíƒœë¥¼ CSVì™€ í•´ì‹œ ì‹œìŠ¤í…œì„ êµì°¨ ê²€ì¦í•˜ì—¬ ì™„ë²½í•˜ê²Œ ë³µì›í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ”„ '{city_name}' ë„ì‹œì˜ ì´ì „ ì‘ì—… ì„¸ì…˜ ìƒíƒœë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...\")\n",
    "\n",
    "    # 1. V2+CSV í†µí•©ì—ì„œ ì™„ë£Œëœ URL ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ê°€ì¥ í™•ì‹¤í•œ ì¦ê±°)\n",
    "    completed_urls_from_csv = get_completed_urls_from_csv(city_name)\n",
    "    print(f\"   - ìµœì¢… ê²°ê³¼ë¬¼(CSV)ì—ì„œ {len(completed_urls_from_csv)}ê°œì˜ ì™„ë£Œëœ URLì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # 2. í•´ì‹œ ì‹œìŠ¤í…œ í†µê³„ í™•ì¸\n",
    "    hash_stats = get_hash_stats(city_name)\n",
    "    print(f\"   - í•´ì‹œ ì‹œìŠ¤í…œì—ì„œ {hash_stats['total']}ê°œì˜ ì™„ë£Œëœ URLì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # 3. í•„ìš”ì‹œ ë§ˆì´ê·¸ë ˆì´ì…˜ ìˆ˜í–‰\n",
    "    if len(completed_urls_from_csv) > hash_stats['total']:\n",
    "        print(f\"   - CSV â†’ í•´ì‹œ ì‹œìŠ¤í…œ ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜ ìˆ˜í–‰ ì¤‘...\")\n",
    "        migrate_csv_to_hash(city_name)\n",
    "\n",
    "    # 4. ë„ì‹œë³„ ë¡œê·¸ íŒŒì¼ì—ì„œ ì™„ë£Œëœ URL ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (í˜¸í™˜ì„±)\n",
    "    city_code = get_city_code(city_name)\n",
    "    log_file = URL_LOG_FILE_TEMPLATE.format(city_code=city_code)\n",
    "    completed_urls_from_log = set()\n",
    "    try:\n",
    "        with open(log_file, 'r', encoding='utf-8') as f:\n",
    "            completed_urls_from_log = set(line.strip() for line in f)\n",
    "        print(f\"   - ì‘ì—… ë…¸íŠ¸(Log)ì—ì„œ {len(completed_urls_from_log)}ê°œì˜ ì™„ë£Œëœ URLì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"   - ì´ ë„ì‹œì˜ ì‘ì—… ë…¸íŠ¸(Log)ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "    # 5. í†µí•© ë§ˆìŠ¤í„° ëª©ë¡ ìƒì„± (í•´ì‹œ ì‹œìŠ¤í…œì´ ë©”ì¸, CSV/LogëŠ” ë°±ì—…)\n",
    "    master_completed_urls = completed_urls_from_csv.union(completed_urls_from_log)\n",
    "    print(f\"   - ì´ {len(master_completed_urls)}ê°œì˜ ê³ ìœ í•œ URLì„ ì™„ë£Œí•œ ê²ƒìœ¼ë¡œ ìµœì¢… í™•ì¸ë©ë‹ˆë‹¤.\")\n",
    "\n",
    "    # 6. ë§ˆì§€ë§‰ ìƒí’ˆ ë²ˆí˜¸ ë¶ˆëŸ¬ì˜¤ê¸° (ê¸°ì¡´ í•¨ìˆ˜ ì‚¬ìš©)\n",
    "    last_number = get_last_product_number(city_name)\n",
    "    start_number = last_number + 1\n",
    "    print(f\"   - ë§ˆì§€ë§‰ ìƒí’ˆ ë²ˆí˜¸ëŠ” {last_number}ë²ˆ ì…ë‹ˆë‹¤.\")\n",
    "    print(f\"âœ… ìƒíƒœ ë³µì› ì™„ë£Œ. í¬ë¡¤ë§ì€ {start_number}ë²ˆë¶€í„° ì‹œì‘ë©ë‹ˆë‹¤.\")\n",
    "    print(f\"ğŸš€ í•´ì‹œ ì‹œìŠ¤í…œ í™œì„±í™”: {CONFIG.get('USE_HASH_SYSTEM', True)}\")\n",
    "\n",
    "    return start_number, master_completed_urls\n",
    "\n",
    "def save_url_to_log(city_name, url):\n",
    "    \"\"\"[V2 3-tier + hashlib í†µí•© ë²„ì „] ìˆ˜ì§‘ ì™„ë£Œí•œ URLì„ 3-tier ì‹œìŠ¤í…œì— ê¸°ë¡í•©ë‹ˆë‹¤.\"\"\"\n",
    "    # 1. V2 3-tier ì‹œìŠ¤í…œì— ê¸°ë¡ (ìƒˆë¡œìš´ ë°©ì‹)\n",
    "    if CONFIG.get(\"USE_V2_URL_SYSTEM\", True):\n",
    "        ensure_url_directories_v2()\n",
    "        city_code = get_city_code(city_name)\n",
    "        done_file = os.path.join(CONFIG[\"V2_URL_DONE\"], f\"{city_code}_done.log\")\n",
    "        with open(done_file, 'a', encoding='utf-8') as f:\n",
    "            f.write(url + '\\n')\n",
    "    \n",
    "    # 2. í•´ì‹œ ì‹œìŠ¤í…œì— ê¸°ë¡ (ì´ˆê³ ì†)\n",
    "    if CONFIG.get(\"USE_HASH_SYSTEM\", True):\n",
    "        mark_url_processed_fast(url, city_name)\n",
    "    \n",
    "    # 3. ê¸°ì¡´ ë¡œê·¸ ì‹œìŠ¤í…œë„ ìœ ì§€ (í˜¸í™˜ì„±)\n",
    "    if CONFIG.get(\"KEEP_CSV_SYSTEM\", True):\n",
    "        os.makedirs(\"url_cache/completed\", exist_ok=True)\n",
    "        log_file = os.path.join(\"url_cache\", \"completed\", f\"{city_name}_done.log\")\n",
    "        with open(log_file, 'a', encoding='utf-8') as f:\n",
    "            f.write(url + '\\n')\n",
    "\n",
    "def get_city_code(city_name):\n",
    "    \"\"\"ë„ì‹œëª…ìœ¼ë¡œ ê³µí•­ ì½”ë“œ ë°˜í™˜ (UNIFIED_CITY_INFO ì‚¬ìš©)\"\"\"\n",
    "    info = UNIFIED_CITY_INFO.get(city_name)\n",
    "    if info:\n",
    "        code = info.get(\"ì½”ë“œ\", city_name[:3].upper())\n",
    "        return code\n",
    "    return city_name[:3].upper()\n",
    "\n",
    "def get_city_info(city_name):\n",
    "    \"\"\"í†µí•©ëœ ë„ì‹œ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì‚¬ì „ ì •ì˜ëœ ê°’ë§Œ ì‚¬ìš©)\"\"\"\n",
    "    info = UNIFIED_CITY_INFO.get(city_name)\n",
    "    if info:\n",
    "        return info[\"ëŒ€ë¥™\"], info[\"êµ­ê°€\"]\n",
    "    else:\n",
    "        # ì •ì˜ë˜ì§€ ì•Šì€ ë„ì‹œì— ëŒ€í•œ ê¸°ë³¸ê°’\n",
    "        return \"ê¸°íƒ€\", \"ê¸°íƒ€\"\n",
    "\n",
    "def get_last_product_number(city_name):\n",
    "    \"\"\"ê¸°ì¡´ CSVì—ì„œ ë§ˆì§€ë§‰ ë²ˆí˜¸ í™•ì¸ (ë²ˆí˜¸ ì—°ì†ì„± í™•ë³´)\"\"\"\n",
    "    try:\n",
    "        continent, country = get_city_info(city_name)\n",
    "        \n",
    "        # ğŸ¯ ========== ë„ì‹œêµ­ê°€ íŠ¹ë³„ ì²˜ë¦¬ ì¶”ê°€ ==========\n",
    "        if city_name in [\"ë§ˆì¹´ì˜¤\", \"í™ì½©\", \"ì‹±ê°€í¬ë¥´\"]:\n",
    "            # ë„ì‹œêµ­ê°€: ëŒ€ë¥™ í´ë” ë°”ë¡œ ì•„ë˜ì—ì„œ ì°¾ê¸°\n",
    "            csv_path = os.path.join(\"data\", continent, f\"klook_{city_name}_products.csv\")\n",
    "        else:\n",
    "            # ì¼ë°˜ ë„ì‹œ: ê¸°ì¡´ êµ¬ì¡°\n",
    "            csv_path = os.path.join(\"data\", continent, country, city_name, f\"klook_{city_name}_products.csv\")\n",
    "        # ================================================\n",
    "        \n",
    "        if os.path.exists(csv_path):\n",
    "            df = pd.read_csv(csv_path, encoding='utf-8-sig')\n",
    "            if not df.empty and 'ë²ˆí˜¸' in df.columns:\n",
    "                last_number = df['ë²ˆí˜¸'].max()\n",
    "                print(f\"ğŸ“Š ê¸°ì¡´ CSV ë§ˆì§€ë§‰ ë²ˆí˜¸: {last_number}\")\n",
    "                return last_number\n",
    "        \n",
    "        print(f\"ğŸ“„ ê¸°ì¡´ CSV íŒŒì¼ ì—†ìŒ - 0ë¶€í„° ì‹œì‘\")\n",
    "        return 0   # íŒŒì¼ì´ ì—†ìœ¼ë©´ 0 ë°˜í™˜ (ë‹¤ìŒì€ 1ë¶€í„° ì‹œì‘)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ë§ˆì§€ë§‰ ë²ˆí˜¸ í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "        return 0   # 0 ë°˜í™˜í•˜ì—¬ ë‹¤ìŒì´ 1ë¶€í„° ì‹œì‘\n",
    "\n",
    "def get_product_name(driver, url_type=\"Product\"):\n",
    "    \"\"\"âœ… ìƒí’ˆëª… ìˆ˜ì§‘ (KLOOK ìµœì í™”)\"\"\"\n",
    "    print(f\"  ğŸ“Š {url_type} ìƒí’ˆëª… ìˆ˜ì§‘ ì¤‘...\")\n",
    "\n",
    "    title_selectors = [\n",
    "        (By.CSS_SELECTOR, \"#activity_title > h1 > span\"),    # KLOOK ìµœìš°ì„  (100% í™•ì¸ë¨)\n",
    "        (By.CSS_SELECTOR, \"#activity_title .vam\"),           # KLOOK ë°±ì—…\n",
    "        (By.CSS_SELECTOR, \"#activity_title h1\"),             # KLOOK ë°±ì—…2\n",
    "        (By.CSS_SELECTOR, \"h1\"),                             # ë²”ìš© ë°±ì—…\n",
    "    ]\n",
    "\n",
    "    for selector_type, selector_value in title_selectors:\n",
    "        try:\n",
    "            title_element = WebDriverWait(driver, CONFIG[\"WAIT_TIMEOUT\"]).until(\n",
    "                EC.presence_of_element_located((selector_type, selector_value))\n",
    "            )\n",
    "            found_name = title_element.text\n",
    "            return found_name\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "    \n",
    "    raise NoSuchElementException(\"ìƒí’ˆëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "\n",
    "def get_price(driver, logger=None):\n",
    "    \"\"\"âœ… ê°€ê²© ìˆ˜ì§‘ - KLOOK ìµœì í™” ë²„ì „ (ë¡œê¹… ê°•í™”)\"\"\"\n",
    "    log = logger if logger else print\n",
    "    log(\"  ğŸ’° ê°€ê²© ì •ë³´ ìˆ˜ì§‘ ì¤‘...\")\n",
    "\n",
    "    price_selectors = [\n",
    "        (By.CSS_SELECTOR, \"#banner_atlas .salling-price span\"),     # íŒë§¤ê°€ (ìµœìš°ì„ )\n",
    "        (By.CSS_SELECTOR, \"#banner_atlas .market-price b\"),         # ì •ê°€\n",
    "        (By.CSS_SELECTOR, \"#banner_atlas .price-box span\"),         # ë²”ìš© ë°±ì—…\n",
    "        (By.CSS_SELECTOR, \"span[data-v-7d296880]\"),                 # data-v ì†ì„±\n",
    "        (By.CSS_SELECTOR, \".price\"),\n",
    "        (By.CSS_SELECTOR, \"[class*='price']\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'â‚©') and string-length(text()) < 30]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'ì›') and contains(text(), ',') and string-length(text()) < 30]\"),\n",
    "    ]\n",
    "\n",
    "    invalid_keywords = [\n",
    "        'ì¿ í°', 'ë°›ê¸°', 'ë‹¤ìš´', 'í• ì¸', 'ì ë¦½', 'í¬ì¸íŠ¸',\n",
    "        'ìµœì†Œ', 'ì¸ì›', 'ëª…', 'ìµœëŒ€', 'ì„ íƒ', 'ì˜µì…˜',\n",
    "        'ì˜ˆì•½', 'ì‹ ì²­', 'ë¬¸ì˜', 'ìƒë‹´', 'í™•ì¸', 'ëª…ë¶€í„°',\n",
    "        'ì‹œê°„', 'ì¼ì •', 'ì½”ìŠ¤', 'íˆ¬ì–´', 'ì—¬í–‰',\n",
    "        'ì–¸ì–´', 'ê°€ì´ë“œ', 'í¬í•¨', 'ë¶ˆí¬í•¨', 'ì´ìƒ',\n",
    "        'ì·¨ì†Œ', 'í™˜ë¶ˆ', 'ë³€ê²½', 'ì•ˆë‚´', 'ëª¨ì§‘'\n",
    "    ]\n",
    "\n",
    "    price_patterns = [\n",
    "        r'â‚©\\s*\\d{1,3}(?:,\\d{3})+',        # â‚© 35,400\n",
    "        r'\\d{1,3}(?:,\\d{3})+ì›[~-]?',     # 10,000ì›~\n",
    "        r'\\d+,\\d+ì›[~-]?',                # ê°„ë‹¨í•œ ì²œë‹¨ìœ„\n",
    "        r'\\d{4,}ì›[~-]?',                 # 10000ì›~\n",
    "    ]\n",
    "\n",
    "    for selector_type, selector_value in price_selectors:\n",
    "        try:\n",
    "            log(f\"  ğŸ” ì…€ë ‰í„° ì‹œë„: {selector_type} | {selector_value}\")\n",
    "            price_elements = driver.find_elements(selector_type, selector_value)\n",
    "            if not price_elements:\n",
    "                log(\"    â†ª ìš”ì†Œ ì—†ìŒ\")\n",
    "                continue\n",
    "\n",
    "            for idx, price_element in enumerate(price_elements, start=1):\n",
    "                try:\n",
    "                    found_price = price_element.text.strip()\n",
    "                except StaleElementReferenceException as e:\n",
    "                    log(f\"    âš ï¸ ìš”ì†Œ#{idx} StaleElementReference: {e}\")\n",
    "                    continue\n",
    "                except WebDriverException as e:\n",
    "                    log(f\"    âš ï¸ ìš”ì†Œ#{idx} WebDriverException: {e}\")\n",
    "                    continue\n",
    "\n",
    "                if not found_price:\n",
    "                    log(f\"    â†ª ìš”ì†Œ#{idx} ë¹ˆ í…ìŠ¤íŠ¸ -> ìŠ¤í‚µ\")\n",
    "                    continue\n",
    "\n",
    "                if any(keyword in found_price for keyword in invalid_keywords):\n",
    "                    log(f\"    â†ª ìš”ì†Œ#{idx} ê¸ˆì§€ í‚¤ì›Œë“œ í¬í•¨('{found_price}') -> ìŠ¤í‚µ\")\n",
    "                    continue\n",
    "\n",
    "                if len(found_price) > 30:\n",
    "                    log(f\"    â†ª ìš”ì†Œ#{idx} ê¸¸ì´ ì´ˆê³¼('{found_price}') -> ìŠ¤í‚µ\")\n",
    "                    continue\n",
    "\n",
    "                is_valid_price = any(re.search(pattern, found_price) for pattern in price_patterns)\n",
    "                if is_valid_price and ('ì›' in found_price or 'â‚©' in found_price):\n",
    "                    log(f\"    âœ… ìœ íš¨í•œ ê°€ê²© ë°œê²¬: '{found_price}'\")\n",
    "                    return found_price\n",
    "                else:\n",
    "                    log(f\"    â†ª ìš”ì†Œ#{idx} íŒ¨í„´ ë¶ˆì¼ì¹˜('{found_price}') -> ìŠ¤í‚µ\")\n",
    "\n",
    "        except (NoSuchElementException, TimeoutException) as e:\n",
    "            log(f\"  âŒ ì…€ë ‰í„° ì‹¤íŒ¨: {type(e).__name__} | {selector_value} | {e}\")\n",
    "            continue\n",
    "        except WebDriverException as e:\n",
    "            log(f\"  âŒ ë“œë¼ì´ë²„ ì˜ˆì™¸: {type(e).__name__} | {e}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            log(f\"  âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì˜ˆì™¸: {type(e).__name__} | {e}\")\n",
    "            continue\n",
    "\n",
    "    log(\"    âŒ ê°€ê²© ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "    return \"ì •ë³´ ì—†ìŒ\"\n",
    "\n",
    "def clean_price(price_text):\n",
    "    \"\"\"âœ… ê°€ê²© ì •ì œ (ëª¨ë“  ì‚¬ì´íŠ¸ í†µì¼: 77,900ì› í˜•íƒœ)\"\"\"\n",
    "    if not price_text or price_text == \"ì •ë³´ ì—†ìŒ\":\n",
    "        return \"ì •ë³´ ì—†ìŒ\"\n",
    "    \n",
    "    # ëª¨ë“  ê°€ê²© íŒ¨í„´ (â‚©, ì›, $ ë“± ëª¨ë‘ ì§€ì›)\n",
    "    price_patterns = [\n",
    "        r'â‚©\\s*(\\d{1,3}(?:,\\d{3})*)',           # â‚© 77,900\n",
    "        r'\\$\\s*(\\d{1,3}(?:,\\d{3})*)',          # $ 100\n",
    "        r'(\\d{1,3}(?:,\\d{3})*)\\s*ì›[~-]?',     # 77,900ì›\n",
    "        r'(\\d{1,3}(?:,\\d{3})*)'                # 77900 (ìˆ«ìë§Œ)\n",
    "    ]\n",
    "    \n",
    "    for pattern in price_patterns:\n",
    "        match = re.search(pattern, price_text)\n",
    "        if match:\n",
    "            # ëª¨ë“  ê²½ìš°ì— \"77,900ì›\" í˜•íƒœë¡œ í†µì¼\n",
    "            return f\"{match.group(1)}ì›\"\n",
    "    \n",
    "    return price_text\n",
    "\n",
    "def clean_rating(rating_text):\n",
    "    \"\"\"âœ… í‰ì  ì •ì œ (ê¸°ì¡´: extract_clean_rating â†’ ìƒˆë¡œìš´: clean_rating) (ê³µìš© í•¨ìˆ˜)\"\"\"\n",
    "    if not rating_text or rating_text == \"ì •ë³´ ì—†ìŒ\":\n",
    "        return \"ì •ë³´ ì—†ìŒ\"\n",
    "    \n",
    "    rating_pattern = r'(\\d+\\.?\\d*)'\n",
    "    match = re.search(rating_pattern, rating_text)\n",
    "    \n",
    "    if match:\n",
    "        try:\n",
    "            return float(match.group(1))\n",
    "        except ValueError:\n",
    "            return rating_text\n",
    "    else:\n",
    "        return rating_text\n",
    "    \n",
    "  # =============================================================================\n",
    "  # ğŸš€ V2 3-tier URL ì‹œìŠ¤í…œ ìë™ ì´ˆê¸°í™”\n",
    "  # =============================================================================\n",
    "\n",
    "# V2 ì‹œìŠ¤í…œì´ í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ë””ë ‰í† ë¦¬ ìë™ ìƒì„±\n",
    "if CONFIG.get(\"USE_V2_URL_SYSTEM\", True):\n",
    "    ensure_url_directories_v2()\n",
    "    print(f\"ğŸš€ V2 3-tier URL ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
    "    print(f\"   ğŸ“‚ ìˆ˜ì§‘ ëŒ€ê¸°: {CONFIG['V2_URL_COLLECTED']}/\")\n",
    "    print(f\"   ğŸ“‚ ì™„ë£Œë¨: {CONFIG['V2_URL_DONE']}/\")\n",
    "    print(f\"   ğŸ“‚ ì§„í–‰ìƒí™©: {CONFIG['V2_URL_PROGRESS']}/\")\n",
    "\n",
    "print(\"âœ… ê·¸ë£¹ 1 ì™„ë£Œ: ê¸°ë³¸ ì„¤ì • ë° hashlib í†µí•© ì‹œìŠ¤í…œ ì •ì˜ ì™„ë£Œ!\")\n",
    "print(f\"ğŸš€ hashlib ì‹œìŠ¤í…œ ìƒíƒœ: {'í™œì„±í™”' if CONFIG.get('USE_HASH_SYSTEM', True) else 'ë¹„í™œì„±í™”'}\")\n",
    "print(f\"ğŸ”„ CSV í˜¸í™˜ì„±: {'ìœ ì§€' if CONFIG.get('KEEP_CSV_SYSTEM', True) else 'ë¹„í™œì„±í™”'}\")\n",
    "print(f\"ğŸ“Š í•´ì‹œ ê¸¸ì´: {CONFIG.get('HASH_LENGTH', 12)}ìë¦¬\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f698bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ğŸš€ ê·¸ë£¹ 2: ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ë°ì´í„° ì €ì¥ í•¨ìˆ˜ë“¤\n",
    "# - ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ, ë°ì´í„° ì €ì¥, ê²°ê³¼ ì²˜ë¦¬ ê´€ë ¨ í•¨ìˆ˜ë“¤\n",
    "# =============================================================================\n",
    "\n",
    "def download_image(driver, product_name, city_name, product_number):\n",
    "    \"\"\"âœ… ë©”ì¸+ì¸ë„¤ì¼ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ - KLOOK 2ê°œ ì´ë¯¸ì§€ ì‹œìŠ¤í…œ (ê³„ì¸µ êµ¬ì¡° ì €ì¥)\"\"\"\n",
    "    if not CONFIG[\"SAVE_IMAGES\"]:\n",
    "        return {\n",
    "            'main_image': {\n",
    "                'status': 'ì´ë¯¸ì§€ ì €ì¥ ë¹„í™œì„±í™”',\n",
    "                'filename': '',\n",
    "                'path': '',\n",
    "                'relative_path': '',\n",
    "                'size': 0\n",
    "            },\n",
    "            'thumbnail_image': {\n",
    "                'status': 'ì´ë¯¸ì§€ ì €ì¥ ë¹„í™œì„±í™”',\n",
    "                'filename': '',\n",
    "                'path': '',\n",
    "                'relative_path': '',\n",
    "                'size': 0\n",
    "            }\n",
    "        }\n",
    "\n",
    "    print(f\"  ğŸ–¼ï¸ KLOOK ë©”ì¸+ì¸ë„¤ì¼ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
    "\n",
    "    # KLOOK ì „ìš© ì´ë¯¸ì§€ ì…€ë ‰í„°ë“¤\n",
    "    main_image_selectors = [\n",
    "        (By.CSS_SELECTOR, \"#banner_atlas .activity-banner-image-container_left img\"),  # KLOOK ë©”ì¸ ì´ë¯¸ì§€\n",
    "        (By.CSS_SELECTOR, \".activity-banner-image-container_left img\"),                 # ë°±ì—… 1\n",
    "        (By.CSS_SELECTOR, \".main-image img\"),                                           # ì¼ë°˜ ë°±ì—…\n",
    "        (By.CSS_SELECTOR, \".hero-image img\"),                                           # ì¼ë°˜ ë°±ì—…\n",
    "        (By.CSS_SELECTOR, \".product-image img\"),                                        # ì¼ë°˜ ë°±ì—…\n",
    "    ]\n",
    "\n",
    "    thumbnail_image_selectors = [\n",
    "        (By.CSS_SELECTOR, \"#banner_atlas .activity-banner-image-container_right img\"),  # KLOOK ì¸ë„¤ì¼ ì´ë¯¸ì§€\n",
    "        (By.CSS_SELECTOR, \".activity-banner-image-container_right img\"),                # ë°±ì—… 1\n",
    "        (By.CSS_SELECTOR, \".product-gallery img:nth-child(2)\"),                        # ì¼ë°˜ ë°±ì—…\n",
    "        (By.CSS_SELECTOR, \".gallery img:nth-child(2)\"),                                # ì¼ë°˜ ë°±ì—…\n",
    "        (By.CSS_SELECTOR, \".slider img:nth-child(2)\"),                                 # ì¼ë°˜ ë°±ì—…\n",
    "    ]\n",
    "\n",
    "    # íŒŒì¼ëª… ì¤€ë¹„\n",
    "    city_code = get_city_code(city_name)\n",
    "    safe_number = max(1, product_number)\n",
    "    main_filename = f\"{city_code}_{safe_number:04d}.jpg\"\n",
    "    thumb_filename = f\"{city_code}_{safe_number:04d}_thumb.jpg\"\n",
    "\n",
    "    # ê³„ì¸µ êµ¬ì¡° í´ë” ê²½ë¡œ ì„¤ì •\n",
    "    continent, country = get_city_info(city_name)\n",
    "    base_folder = \"klook_thumb_img\"\n",
    "\n",
    "    if city_name in [\"ë§ˆì¹´ì˜¤\", \"í™ì½©\", \"ì‹±ê°€í¬ë¥´\"]:\n",
    "        hierarchical_folder = os.path.join(base_folder, continent, city_name)\n",
    "        main_relative_path = os.path.join(continent, city_name, main_filename)\n",
    "        thumb_relative_path = os.path.join(continent, city_name, thumb_filename)\n",
    "    else:\n",
    "        hierarchical_folder = os.path.join(base_folder, continent, country, city_name)\n",
    "        main_relative_path = os.path.join(continent, country, city_name, main_filename)\n",
    "        thumb_relative_path = os.path.join(continent, country, city_name, thumb_filename)\n",
    "\n",
    "    # í´ë” ìƒì„±\n",
    "    os.makedirs(hierarchical_folder, exist_ok=True)\n",
    "    print(f\"    ğŸ“ ê³„ì¸µ í´ë” í™•ì¸: {hierarchical_folder}\")\n",
    "\n",
    "    # ë©”ì¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ\n",
    "    main_result = download_single_image(\n",
    "        driver, main_image_selectors, hierarchical_folder,\n",
    "        main_filename, main_relative_path, \"ë©”ì¸\"\n",
    "    )\n",
    "\n",
    "    # ì¸ë„¤ì¼ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ\n",
    "    thumb_result = download_single_image(\n",
    "        driver, thumbnail_image_selectors, hierarchical_folder,\n",
    "        thumb_filename, thumb_relative_path, \"ì¸ë„¤ì¼\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'main_image': main_result,\n",
    "        'thumbnail_image': thumb_result\n",
    "    }\n",
    "\n",
    "\n",
    "def download_single_image(driver, selectors, folder_path, filename, relative_path, image_type):\n",
    "    \"\"\"ë‹¨ì¼ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í—¬í¼ í•¨ìˆ˜\"\"\"\n",
    "    print(f\"    ğŸ” {image_type} ì´ë¯¸ì§€ URL ì°¾ëŠ” ì¤‘...\")\n",
    "\n",
    "    img_url = None\n",
    "    for selector_type, selector_value in selectors:\n",
    "        try:\n",
    "            img_elements = driver.find_elements(selector_type, selector_value)\n",
    "            for img_element in img_elements:\n",
    "                try:\n",
    "                    img_url = img_element.get_attribute('src')\n",
    "                    if not img_url or not img_url.startswith('http'):\n",
    "                        continue\n",
    "\n",
    "                    # ì œì™¸í•  íŒ¨í„´ë“¤\n",
    "                    exclude_patterns = ['logo', 'icon', 'banner', 'ad', 'avatar', 'profile', 'button', 'arrow', 'star', 'small', 'mini']\n",
    "                    if any(pattern in img_url.lower() for pattern in exclude_patterns):\n",
    "                        continue\n",
    "\n",
    "                    # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸\n",
    "                    try:\n",
    "                        size = img_element.size\n",
    "                        if size and (size.get('width', 0) < 100 or size.get('height', 0) < 100):\n",
    "                            continue\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "                    print(f\"      âœ… {image_type} URL ë°œê²¬: {img_url[:50]}...\")\n",
    "                    break\n",
    "                except Exception:\n",
    "                    continue\n",
    "            if img_url:\n",
    "                break\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if not img_url:\n",
    "        print(f\"      âŒ {image_type} ì´ë¯¸ì§€ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "        return {\n",
    "            'status': f'{image_type} URL ì—†ìŒ',\n",
    "            'filename': filename,\n",
    "            'path': '',\n",
    "            'relative_path': '',\n",
    "            'size': 0\n",
    "        }\n",
    "\n",
    "    # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œë„\n",
    "    try:\n",
    "        full_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # User-Agent ì¶”ê°€ë¡œ ë‹¤ìš´ë¡œë“œ ì„±ê³µë¥  ë†’ì´ê¸°\n",
    "        req = urllib.request.Request(\n",
    "            img_url,\n",
    "            headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "        )\n",
    "\n",
    "        with urllib.request.urlopen(req, timeout=10) as response:\n",
    "            with open(full_path, 'wb') as f:\n",
    "                f.write(response.read())\n",
    "\n",
    "        file_size = os.path.getsize(full_path)\n",
    "\n",
    "        if file_size < 1024:\n",
    "            os.remove(full_path)\n",
    "            print(f\"      âŒ {image_type} íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤ ({file_size} bytes)\")\n",
    "            return {\n",
    "                'status': f'{image_type} íŒŒì¼ ë„ˆë¬´ ì‘ìŒ',\n",
    "                'filename': filename,\n",
    "                'path': '',\n",
    "                'relative_path': '',\n",
    "                'size': 0\n",
    "            }\n",
    "\n",
    "        print(f\"      âœ… {image_type} ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ! ({file_size:,} bytes)\")\n",
    "        print(f\"      ğŸ“ ì €ì¥ ìœ„ì¹˜: {relative_path}\")\n",
    "\n",
    "        return {\n",
    "            'status': f'{image_type} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ',\n",
    "            'filename': filename,\n",
    "            'path': full_path,\n",
    "            'relative_path': relative_path,\n",
    "            'size': file_size\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"      âš ï¸ {image_type} ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {type(e).__name__}: {e}\")\n",
    "        return {\n",
    "            'status': f'{image_type} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {type(e).__name__}',\n",
    "            'filename': filename,\n",
    "            'path': '',\n",
    "            'relative_path': '',\n",
    "            'size': 0\n",
    "        }\n",
    "\n",
    "\n",
    "def save_results(products_data):\n",
    "    \"\"\"âœ… ë°ì´í„° ì €ì¥ (ë„ì‹œIDëŠ” ì´ë¯¸ í¬í•¨ë¨)\"\"\"\n",
    "    print(\"ğŸ’¾ í•˜ì´ë¸Œë¦¬ë“œ êµ¬ì¡°ë¡œ ë°ì´í„° ì €ì¥ ì¤‘...\")\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    city_name = products_data[0]['ë„ì‹œ'] if products_data else 'unknown'\n",
    "    \n",
    "    # DataFrame ìƒì„± (ë„ì‹œIDëŠ” ì´ë¯¸ crawl_single_product_optimizedì—ì„œ ìƒì„±ë¨)\n",
    "    df = pd.DataFrame(products_data)\n",
    "    \n",
    "    csv_path = f\"klook_{city_name}_products_{len(products_data)}ê°œ_{timestamp}.csv\"\n",
    "    df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"ğŸ“ ê°œë³„ CSV ì €ì¥ ì™„ë£Œ: {csv_path}\")\n",
    "    \n",
    "    # ë„ì‹œID ì¡´ì¬ í™•ì¸ ë° ì¶œë ¥\n",
    "    if 'ë„ì‹œID' in df.columns and not df['ë„ì‹œID'].empty:\n",
    "        first_id = df['ë„ì‹œID'].iloc[0]\n",
    "        last_id = df['ë„ì‹œID'].iloc[-1]\n",
    "        print(f\"ğŸ†” ë„ì‹œID í™•ì¸: {first_id} ~ {last_id}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ ë„ì‹œID ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤ - crawl_single_product_optimized í™•ì¸ í•„ìš”\")\n",
    "    \n",
    "    city_code = get_city_code(city_name)\n",
    "    metadata = {\n",
    "        \"klook\": {\n",
    "            \"last_update\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            \"product_count\": len(products_data),\n",
    "            \"status\": \"success\",\n",
    "            \"csv_path\": csv_path,\n",
    "            \"city\": city_name,\n",
    "            \"city_id_pattern\": f\"{city_code}_X\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        os.makedirs('config', exist_ok=True)\n",
    "        with open('config/data_metadata.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"ğŸ“ ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: config/data_metadata.json\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    return csv_path\n",
    "\n",
    "def safe_csv_write(file_path, df, mode='w', header=True):\n",
    "    \"\"\"CSV íŒŒì¼ì„ ì•ˆì „í•˜ê²Œ ì‘ì„± (Permission denied ì˜¤ë¥˜ í•´ê²°)\"\"\"\n",
    "    max_retries = 5\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # ê¸°ì¡´ íŒŒì¼ì´ ìˆê³  ì“°ê¸° ëª¨ë“œì¸ ê²½ìš° ë°±ì—… ìƒì„±\n",
    "            if mode == 'a' and os.path.exists(file_path):\n",
    "                # íŒŒì¼ì´ ì ê²¨ìˆëŠ”ì§€ í™•ì¸\n",
    "                try:\n",
    "                    with open(file_path, 'a', encoding='utf-8-sig') as test_file:\n",
    "                        test_file.write('')  # ë¹ˆ ë¬¸ìì—´ ì“°ê¸° í…ŒìŠ¤íŠ¸\n",
    "                except PermissionError:\n",
    "                    print(f\"    âš ï¸ íŒŒì¼ì´ ì ê²¨ìˆìŒ, {attempt+1}ë²ˆì§¸ ì¬ì‹œë„...\")\n",
    "                    time.sleep(2)  # 2ì´ˆ ëŒ€ê¸°\n",
    "                    continue\n",
    "            \n",
    "            # CSV íŒŒì¼ ì‘ì„±\n",
    "            df.to_csv(file_path, mode=mode, header=header, index=False, encoding='utf-8-sig')\n",
    "            return True\n",
    "            \n",
    "        except PermissionError as e:\n",
    "            print(f\"    âš ï¸ ê¶Œí•œ ì˜¤ë¥˜ ({attempt+1}/{max_retries}): {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                # ì ê¹ ëŒ€ê¸° í›„ ì¬ì‹œë„\n",
    "                wait_time = (attempt + 1) * 2  # 2, 4, 6, 8ì´ˆ\n",
    "                print(f\"    â° {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                # ìµœì¢… ì‹œë„ - ë°±ì—… íŒŒì¼ë¡œ ì €ì¥\n",
    "                backup_path = file_path.replace('.csv', f'_backup_{datetime.now().strftime(\"%H%M%S\")}.csv')\n",
    "                try:\n",
    "                    df.to_csv(backup_path, mode='w', header=True, index=False, encoding='utf-8-sig')\n",
    "                    print(f\"    ğŸ’¾ ë°±ì—… íŒŒì¼ë¡œ ì €ì¥: {backup_path}\")\n",
    "                    return True\n",
    "                except Exception as backup_error:\n",
    "                    print(f\"    âŒ ë°±ì—… ì €ì¥ë„ ì‹¤íŒ¨: {backup_error}\")\n",
    "                    return False\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"    âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}\")\n",
    "            return False\n",
    "    \n",
    "    return False\n",
    "\n",
    "def save_batch_data(batch_results, city_name):\n",
    "    \"\"\"ë°°ì¹˜ ë°ì´í„° ì €ì¥ (ë„ì‹œID + êµ­ê°€ë³„ ì—°ì†ë²ˆí˜¸ ê°œì„  ë²„ì „)\"\"\"\n",
    "    if not batch_results:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # =================================================================\n",
    "        # ğŸ‘‘ (í•µì‹¬ ì˜¤ë¥˜ ìˆ˜ì •) city_code ë³€ìˆ˜ë¥¼ í•¨ìˆ˜ ì‹œì‘ ì‹œ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "        # =================================================================\n",
    "        city_code = get_city_code(city_name)\n",
    "        # =================================================================\n",
    "\n",
    "        continent, country = get_city_info(city_name)\n",
    "        \n",
    "        df = pd.DataFrame(batch_results)\n",
    "        \n",
    "        if 'ë„ì‹œID' not in df.columns or df['ë„ì‹œID'].empty:\n",
    "            df['ë„ì‹œID'] = [f\"{city_code}_{i}\" for i in range(1, len(df) + 1)]\n",
    "            print(f\"âœ… ë„ì‹œID ì»¬ëŸ¼ ì¶”ê°€: {city_code}_1 ~ {city_code}_{len(df)}\")\n",
    "        else:\n",
    "            first_id = df['ë„ì‹œID'].iloc[0]\n",
    "            last_id = df['ë„ì‹œID'].iloc[-1] \n",
    "            print(f\"âœ… ë„ì‹œID í™•ì¸: {first_id} ~ {last_id}\")\n",
    "        \n",
    "        if 'ë²ˆí˜¸' not in df.columns:\n",
    "            df['ë²ˆí˜¸'] = range(1, len(df) + 1)\n",
    "            print(f\"âœ… ë²ˆí˜¸ ì»¬ëŸ¼ ì¶”ê°€: 1 ~ {len(df)}\")\n",
    "        \n",
    "        if city_name in [\"ë§ˆì¹´ì˜¤\", \"í™ì½©\", \"ì‹±ê°€í¬ë¥´\"]:\n",
    "            data_dir = os.path.join(\"data\", continent)\n",
    "            os.makedirs(data_dir, exist_ok=True)\n",
    "            city_csv = os.path.join(data_dir, f\"klook_{city_name}_products.csv\")\n",
    "            \n",
    "            if os.path.exists(city_csv):\n",
    "                city_success = safe_csv_write(city_csv, df, mode='a', header=False)\n",
    "            else:\n",
    "                city_success = safe_csv_write(city_csv, df, mode='w', header=True)\n",
    "            \n",
    "            if city_success:\n",
    "                print(f\"âœ… ë„ì‹œêµ­ê°€ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {city_csv}\")\n",
    "                return {\n",
    "                    \"city_csv\": city_csv,\n",
    "                    \"country_csv\": \"ë„ì‹œêµ­ê°€ë¼ì„œ ë¶ˆí•„ìš”\",\n",
    "                    \"data_count\": len(batch_results)\n",
    "                }\n",
    "            else:\n",
    "                print(f\"âŒ ë„ì‹œêµ­ê°€ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨\")\n",
    "                return None\n",
    "\n",
    "        data_dir = os.path.join(\"data\", continent, country, city_name)\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "        city_csv = os.path.join(data_dir, f\"klook_{city_name}_products.csv\")\n",
    "        if os.path.exists(city_csv):\n",
    "            city_success = safe_csv_write(city_csv, df, mode='a', header=False)\n",
    "        else:\n",
    "            city_success = safe_csv_write(city_csv, df, mode='w', header=True)\n",
    "\n",
    "        country_dir = os.path.join(\"data\", continent, country)\n",
    "        os.makedirs(country_dir, exist_ok=True)\n",
    "        country_csv = os.path.join(country_dir, f\"{country}_klook_products_all.csv\")\n",
    "        \n",
    "        country_df = df.copy()\n",
    "        \n",
    "        if os.path.exists(country_csv):\n",
    "            existing_df = pd.read_csv(country_csv, encoding='utf-8-sig')\n",
    "            if not existing_df.empty and 'ë²ˆí˜¸' in existing_df.columns:\n",
    "                last_number = existing_df['ë²ˆí˜¸'].max()\n",
    "                country_df['ë²ˆí˜¸'] = list(range(int(last_number) + 1, int(last_number) + 1 + len(country_df)))\n",
    "                print(f\"ğŸ”— êµ­ê°€ë³„ ì—°ì†ë²ˆí˜¸: {last_number + 1} ~ {last_number + len(country_df)}\")\n",
    "            country_success = safe_csv_write(country_csv, country_df, mode='a', header=False)\n",
    "        else:\n",
    "            country_df['ë²ˆí˜¸'] = range(1, len(country_df) + 1)\n",
    "            print(f\"ğŸ†• êµ­ê°€ë³„ ì‹ ê·œíŒŒì¼: 1 ~ {len(country_df)}\")\n",
    "            country_success = safe_csv_write(country_csv, country_df, mode='w', header=True)\n",
    "\n",
    "        if city_success and country_success:\n",
    "            print(f\"âœ… ë°°ì¹˜ ë°ì´í„° ì €ì¥ ì™„ë£Œ:\")\n",
    "            print(f\"   ğŸ“ ë„ì‹œë³„: {city_csv}\")\n",
    "            print(f\"   ğŸ“ êµ­ê°€ë³„: {country_csv}\")\n",
    "            print(f\"   ğŸ†” ë„ì‹œID íŒ¨í„´: {city_code}_X\")\n",
    "            print(f\"   ğŸ”¢ êµ­ê°€ë³„ ë²ˆí˜¸: ì—°ì† ì²˜ë¦¬ë¨\")\n",
    "            \n",
    "            return {\n",
    "                \"city_csv\": city_csv,\n",
    "                \"country_csv\": country_csv,\n",
    "                \"data_count\": len(batch_results),\n",
    "                \"city_id_pattern\": f\"{city_code}_X\",\n",
    "                \"country_numbering\": \"ì—°ì†\"\n",
    "            }\n",
    "        else:\n",
    "            print(f\"âš ï¸ ì¼ë¶€ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨ (ë„ì‹œ:{city_success}, êµ­ê°€:{country_success})\")\n",
    "            return {\n",
    "                \"city_csv\": city_csv if city_success else \"ì €ì¥ì‹¤íŒ¨\",\n",
    "                \"country_csv\": country_csv if country_success else \"ì €ì¥ì‹¤íŒ¨\",\n",
    "                \"data_count\": len(batch_results)\n",
    "            }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë°°ì¹˜ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_categories(driver, logger=None):\n",
    "    \"\"\"âœ… ì¹´í…Œê³ ë¦¬ ì •ë³´ ìˆ˜ì§‘ - KLOOK ë¸Œë ˆë“œí¬ëŸ¼ ìµœì í™” ë²„ì „\"\"\"\n",
    "    log = logger if logger else print\n",
    "    log(\"  ğŸ·ï¸ ì¹´í…Œê³ ë¦¬ ì •ë³´ ìˆ˜ì§‘ ì¤‘...\")\n",
    "\n",
    "    category_selectors = [\n",
    "        (By.CSS_SELECTOR, \"#breadCrumb .klk-breadcrumb-item-inner\"),        # KLOOK ìµœìš°ì„ \n",
    "        (By.CSS_SELECTOR, \"#breadCrumb a\"),                                 # ë²”ìš© ë°±ì—…\n",
    "        (By.CSS_SELECTOR, \".klk-breadcrumb-item-inner\"),                    # í´ë˜ìŠ¤ ê¸°ë°˜ ë°±ì—…\n",
    "        (By.XPATH, \"//nav//a[contains(@class, 'breadcrumb')]\"),             # ë²”ìš© ë°±ì—…\n",
    "    ]\n",
    "\n",
    "    for selector_type, selector_value in category_selectors:\n",
    "        try:\n",
    "            log(f\"  ğŸ” ì¹´í…Œê³ ë¦¬ ì…€ë ‰í„° ì‹œë„: {selector_value}\")\n",
    "            category_elements = driver.find_elements(selector_type, selector_value)\n",
    "\n",
    "            if category_elements:\n",
    "                categories = []\n",
    "                for element in category_elements:\n",
    "                    category_text = element.text.strip()\n",
    "                    # \"Klook Travel\" ì œì™¸ ë° ë¹ˆ í…ìŠ¤íŠ¸ í•„í„°ë§\n",
    "                    if category_text and category_text != \"Klook Travel\" and len(category_text) > 0:\n",
    "                        categories.append(category_text)\n",
    "\n",
    "                if categories:\n",
    "                    # \" > \"ë¡œ êµ¬ë¶„ëœ ì¹´í…Œê³ ë¦¬ ê²½ë¡œ ìƒì„±\n",
    "                    category_path = \" > \".join(categories)\n",
    "                    log(f\"    âœ… ì¹´í…Œê³ ë¦¬ ê²½ë¡œ: {category_path}\")\n",
    "                    return category_path\n",
    "\n",
    "        except Exception as e:\n",
    "            log(f\"  âŒ ì¹´í…Œê³ ë¦¬ ì…€ë ‰í„° ì‹¤íŒ¨: {selector_value} | {e}\")\n",
    "            continue\n",
    "\n",
    "    log(\"    âŒ ì¹´í…Œê³ ë¦¬ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "    return \"ì •ë³´ ì—†ìŒ\"\n",
    "\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "def get_highlights(driver, logger=None):\n",
    "    \"\"\"âœ… ìƒí’ˆ í•˜ì´ë¼ì´íŠ¸/ìš”ì•½ ì •ë³´ ìˆ˜ì§‘ - KLOOK í† ê¸€ ëª¨ë‹¬ ìµœì í™” ë²„ì „\"\"\"\n",
    "    log = logger if logger else print\n",
    "    log(\"  âœ¨ ìƒí’ˆ í•˜ì´ë¼ì´íŠ¸ ì •ë³´ ìˆ˜ì§‘ ì¤‘...\")\n",
    "\n",
    "    try:\n",
    "        # 1ë‹¨ê³„: í¼ì¹˜ê¸° ë²„íŠ¼ ì°¾ê¸°\n",
    "        expand_selectors = [\n",
    "            (By.CSS_SELECTOR, \"#highlight .experience-view-more_text\"),\n",
    "            (By.CSS_SELECTOR, \"#highlight .experience-view-more\"),\n",
    "            (By.CSS_SELECTOR, \".experience-view-more_text\"),\n",
    "        ]\n",
    "\n",
    "        expand_button = None\n",
    "        for selector_type, selector_value in expand_selectors:\n",
    "            try:\n",
    "                expand_button = driver.find_element(selector_type, selector_value)\n",
    "                if expand_button and expand_button.is_displayed():\n",
    "                    log(f\"  ğŸ” í¼ì¹˜ê¸° ë²„íŠ¼ ë°œê²¬: {selector_value}\")\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        if not expand_button:\n",
    "            log(\"  â„¹ï¸ í¼ì¹˜ê¸° ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "            return \"ì •ë³´ ì—†ìŒ\"\n",
    "\n",
    "        # 2ë‹¨ê³„: í¼ì¹˜ê¸° ë²„íŠ¼ í´ë¦­\n",
    "        driver.execute_script(\"arguments[0].click();\", expand_button)\n",
    "        time.sleep(1)  # ëª¨ë‹¬ ë¡œë”© ëŒ€ê¸°\n",
    "\n",
    "        # 3ë‹¨ê³„: ëª¨ë‹¬ì—ì„œ ìƒì„¸ ë‚´ìš© ìˆ˜ì§‘\n",
    "        content_selectors = [\n",
    "            (By.CSS_SELECTOR, \".klk-modal-body .klk-markdown\"),\n",
    "            (By.CSS_SELECTOR, \".klk-modal-body ul\"),\n",
    "            (By.CSS_SELECTOR, \".klk-modal-body\"),\n",
    "        ]\n",
    "\n",
    "        for selector_type, selector_value in content_selectors:\n",
    "            try:\n",
    "                content_element = driver.find_element(selector_type, selector_value)\n",
    "                highlight_text = content_element.text.strip()\n",
    "\n",
    "                if highlight_text and len(highlight_text) > 10:\n",
    "                    log(f\"    âœ… í•˜ì´ë¼ì´íŠ¸ ë‚´ìš© ìˆ˜ì§‘: {len(highlight_text)}ì\")\n",
    "\n",
    "                    # 4ë‹¨ê³„: ëª¨ë‹¬ ë‹«ê¸°\n",
    "                    close_button = driver.find_element(By.CSS_SELECTOR, \".klk-modal-wrapper i\")\n",
    "                    driver.execute_script(\"arguments[0].click();\", close_button)\n",
    "                    time.sleep(0.5)\n",
    "\n",
    "                    return highlight_text[:500] + \"...\" if len(highlight_text) > 500 else highlight_text\n",
    "\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        log(\"    âŒ ìƒì„¸ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "        return \"ì •ë³´ ì—†ìŒ\"\n",
    "\n",
    "    except Exception as e:\n",
    "        log(f\"    âŒ í•˜ì´ë¼ì´íŠ¸ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}\")\n",
    "        return \"ì •ë³´ ì—†ìŒ\"\n",
    "\n",
    "\n",
    "def get_rating(driver, logger=None):\n",
    "    \"\"\"âœ… í‰ì  ìˆ˜ì§‘ - KLOOK ìµœì í™” ë²„ì „\"\"\"\n",
    "    log = logger if logger else print\n",
    "    log(\"  â­ í‰ì  ì •ë³´ ìˆ˜ì§‘ ì¤‘...\")\n",
    "\n",
    "    rating_selectors = [\n",
    "        (By.CSS_SELECTOR, \"#score_participants .review-rating__avg\"),    # ìµœìš°ì„  (í…ìŠ¤íŠ¸ í‰ì )\n",
    "        (By.CSS_SELECTOR, \"#score_participants .score-slot-box\"),        # ë³„+ì ìˆ˜ í˜•íƒœ\n",
    "        (By.CSS_SELECTOR, \"#score_participants .review-rating\"),         # ì „ì²´ ì˜ì—­ ë°±ì—…\n",
    "        (By.CSS_SELECTOR, \".review-rating__avg\"),                        # ë²”ìš© ë°±ì—…\n",
    "        (By.CSS_SELECTOR, \".score-slot-box\"),                            # ë²”ìš© ë°±ì—…\n",
    "    ]\n",
    "\n",
    "    for selector_type, selector_value in rating_selectors:\n",
    "        try:\n",
    "            log(f\"  ğŸ” í‰ì  ì…€ë ‰í„° ì‹œë„: {selector_value}\")\n",
    "            rating_element = driver.find_element(selector_type, selector_value)\n",
    "            found_rating = rating_element.text.strip()\n",
    "\n",
    "            if found_rating and any(char.isdigit() for char in found_rating):\n",
    "                # í‰ì  ìˆ«ìë§Œ ì¶”ì¶œ (ì˜ˆ: \"4.8/5\" â†’ \"4.8\")\n",
    "                rating_match = re.search(r'(\\d+\\.?\\d*)', found_rating)\n",
    "                if rating_match:\n",
    "                    rating_value = rating_match.group(1)\n",
    "                    log(f\"    âœ… ìœ íš¨í•œ í‰ì  ë°œê²¬: '{rating_value}'\")\n",
    "                    return rating_value\n",
    "\n",
    "        except Exception as e:\n",
    "            log(f\"  âŒ í‰ì  ì…€ë ‰í„° ì‹¤íŒ¨: {selector_value} | {e}\")\n",
    "            continue\n",
    "\n",
    "    log(\"    âŒ í‰ì  ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "    return \"ì •ë³´ ì—†ìŒ\"\n",
    "\n",
    "def get_review_count(driver, logger=None):\n",
    "    \"\"\"âœ… ë¦¬ë·°ìˆ˜ ìˆ˜ì§‘ - KLOOK ìµœì í™” ë²„ì „\"\"\"\n",
    "    log = logger if logger else print\n",
    "    log(\"  ğŸ“ ë¦¬ë·°ìˆ˜ ì •ë³´ ìˆ˜ì§‘ ì¤‘...\")\n",
    "\n",
    "    review_count_selectors = [\n",
    "        (By.CSS_SELECTOR, \"#score_participants .review-count span\"),      # ìµœìš°ì„  (ì¼ë°˜ í˜•íƒœ)\n",
    "        (By.CSS_SELECTOR, \"#score_participants .text-underline\"),         # ì–¸ë”ë¼ì¸ í˜•íƒœ\n",
    "        (By.CSS_SELECTOR, \"#score_participants .review-box span\"),        # ë°±ì—…\n",
    "        (By.XPATH, \"//span[contains(text(), 'ì´ìš©í›„ê¸°') and contains(text(), 'ê±´')]\"),  # í…ìŠ¤íŠ¸ ê¸°ë°˜\n",
    "    ]\n",
    "\n",
    "    for selector_type, selector_value in review_count_selectors:\n",
    "        try:\n",
    "            log(f\"  ğŸ” ë¦¬ë·°ìˆ˜ ì…€ë ‰í„° ì‹œë„: {selector_value}\")\n",
    "            review_element = driver.find_element(selector_type, selector_value)\n",
    "            review_text = review_element.text.strip()\n",
    "\n",
    "            if review_text and 'ì´ìš©í›„ê¸°' in review_text and 'ê±´' in review_text:\n",
    "                # í‰ì  ì •ë³´ê°€ ì¤‘ë³µ í¬í•¨ëœ ê²½ìš° ì œê±° (8ë²ˆì§¸ ì¼€ì´ìŠ¤ ëŒ€ì‘)\n",
    "                if '<div' in review_text or '/5' in review_text:\n",
    "                    # \"ì´ìš©í›„ê¸° 14.3Kê±´\" ë¶€ë¶„ë§Œ ì¶”ì¶œ\n",
    "                    clean_review = re.search(r'ì´ìš©í›„ê¸°\\s*[\\d.K+]+ê±´', review_text)\n",
    "                    if clean_review:\n",
    "                        review_text = clean_review.group(0)\n",
    "\n",
    "                log(f\"    âœ… ìœ íš¨í•œ ë¦¬ë·°ìˆ˜ ë°œê²¬: '{review_text}'\")\n",
    "                return review_text\n",
    "\n",
    "        except Exception as e:\n",
    "            log(f\"  âŒ ë¦¬ë·°ìˆ˜ ì…€ë ‰í„° ì‹¤íŒ¨: {selector_value} | {e}\")\n",
    "            continue\n",
    "\n",
    "    log(\"    âŒ ë¦¬ë·°ìˆ˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "    return \"ì •ë³´ ì—†ìŒ\"\n",
    "\n",
    "\n",
    "def get_language(driver, logger=None):\n",
    "    \"\"\"âœ… ì–¸ì–´ ì •ë³´ ìˆ˜ì§‘ - KLOOK ìµœì í™” ë²„ì „\"\"\"\n",
    "    log = logger if logger else print\n",
    "    log(\"  ğŸŒ ì–¸ì–´ ì •ë³´ ìˆ˜ì§‘ ì¤‘...\")\n",
    "\n",
    "    language_selectors = [\n",
    "        (By.CSS_SELECTOR, \"#activity_attribute_tags .js-tag-content-node\"),        # KLOOK ìµœìš°ì„ \n",
    "        (By.CSS_SELECTOR, \"#activity_attribute_tags span.js-tag-content-node\"),    # êµ¬ì²´ì  ë²„ì „\n",
    "        (By.CSS_SELECTOR, \"#activity_attribute_tags [data-v-4b7be482]\"),           # data ì†ì„± ê¸°ë°˜\n",
    "        (By.CSS_SELECTOR, \"#activity_attribute_tags span span\"),                   # ë²”ìš© ë°±ì—…\n",
    "        # ê¸°ì¡´ ë°±ì—… ì…€ë ‰í„°ë“¤ë„ ìœ ì§€\n",
    "        (By.XPATH, \"//dt[contains(text(), 'ì–¸ì–´')]/following-sibling::dd\"),\n",
    "        (By.XPATH, \"//span[contains(@class, 'language')]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'í•œêµ­ì–´') and string-length(text()) < 50]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'ì˜ì–´') and string-length(text()) < 50]\"),\n",
    "    ]\n",
    "\n",
    "    for selector_type, selector_value in language_selectors:\n",
    "        try:\n",
    "            log(f\"  ğŸ” ì–¸ì–´ ì…€ë ‰í„° ì‹œë„: {selector_value}\")\n",
    "            language_element = driver.find_element(selector_type, selector_value)\n",
    "            language_text = language_element.text.strip()\n",
    "\n",
    "            if language_text and len(language_text) > 0:\n",
    "                # ì–¸ì–´ ì •ë³´ ê²€ì¦\n",
    "                language_keywords = ['ì–´', 'è¯­', 'English', 'Chinese', 'Korean', 'Japanese', 'Thai']\n",
    "                if any(keyword in language_text for keyword in language_keywords):\n",
    "                    log(f\"    âœ… ì–¸ì–´ ì •ë³´ ë°œê²¬: '{language_text}'\")\n",
    "                    return language_text\n",
    "\n",
    "        except Exception as e:\n",
    "            log(f\"  âŒ ì–¸ì–´ ì…€ë ‰í„° ì‹¤íŒ¨: {selector_value} | {e}\")\n",
    "            continue\n",
    "\n",
    "    log(\"    âŒ ì–¸ì–´ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "    return \"ì •ë³´ ì—†ìŒ\"\n",
    "\n",
    "\n",
    "print(\"âœ… ê·¸ë£¹ 2 ì™„ë£Œ: ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ë°ì´í„° ì €ì¥ í•¨ìˆ˜ë“¤ ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de59945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ğŸ”„ ê·¸ë£¹ 3: ê°„ì†Œí™”ëœ ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ (hashlib í†µí•©)\n",
    "# - hashlib ì‹œìŠ¤í…œê³¼ í†µí•©ëœ ë‹¨ìˆœí•œ ìƒíƒœ ê´€ë¦¬\n",
    "# - ë³µì¡í•œ ê¸°ì¡´ ì‹œìŠ¤í…œì„ hashlibë¡œ ëŒ€ì²´\n",
    "# =============================================================================\n",
    "\n",
    "def ensure_config_directory():\n",
    "    \"\"\"config ë””ë ‰í† ë¦¬ ì•ˆì •ì„± í™•ë³´ (ë‹¨ìˆœí™”ëœ ë²„ì „)\"\"\"\n",
    "    config_dir = os.path.join(os.getcwd(), \"config\")\n",
    "    os.makedirs(config_dir, exist_ok=True)\n",
    "    return config_dir\n",
    "\n",
    "def load_crawler_state():\n",
    "    \"\"\"í¬ë¡¤ë§ ìƒíƒœ ë¡œë“œ (hashlib í†µí•© ë²„ì „)\"\"\"\n",
    "    config_dir = ensure_config_directory()\n",
    "    state_file = os.path.join(config_dir, \"crawler_meta.json\")\n",
    "\n",
    "    # ê¸°ë³¸ ìƒíƒœ\n",
    "    default_state = {\n",
    "        \"total_collected_count\": 0,\n",
    "        \"last_crawled_page\": 1,\n",
    "        \"current_session_start\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"last_updated\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"hash_system_enabled\": CONFIG.get(\"USE_HASH_SYSTEM\", True)\n",
    "    }\n",
    "\n",
    "    # ìƒíƒœ íŒŒì¼ ë¡œë“œ\n",
    "    if os.path.exists(state_file):\n",
    "        try:\n",
    "            with open(state_file, 'r', encoding='utf-8') as f:\n",
    "                state = json.load(f)\n",
    "            print(f\"âœ… ìƒíƒœ íŒŒì¼ ë¡œë“œ: {state['total_collected_count']}ê°œ ìˆ˜ì§‘ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ìƒíƒœ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}, ê¸°ë³¸ê°’ ì‚¬ìš©\")\n",
    "            state = default_state\n",
    "    else:\n",
    "        state = default_state\n",
    "        print(\"ğŸ†• ìƒˆë¡œìš´ í¬ë¡¤ë§ ì„¸ì…˜ ì‹œì‘\")\n",
    "\n",
    "    # ğŸ†• hashlib ì‹œìŠ¤í…œì´ í™œì„±í™”ëœ ê²½ìš° ë³µì¡í•œ URL ë¡œë“œ ê³¼ì • ìƒëµ\n",
    "    if CONFIG.get(\"USE_HASH_SYSTEM\", True):\n",
    "        print(\"ğŸš€ hashlib ì‹œìŠ¤í…œ í™œì„±í™” - ë¹ ë¥¸ ìƒíƒœ ë¡œë“œ\")\n",
    "        completed_urls = set()  # hashlib ì‹œìŠ¤í…œì—ì„œ ìë™ ì²˜ë¦¬\n",
    "    else:\n",
    "        # ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ URL ëª©ë¡ ë¡œë“œ\n",
    "        completed_urls = get_completed_urls_from_csv(CITIES_TO_SEARCH[0]) if CITIES_TO_SEARCH else set()\n",
    "        print(f\"âœ… ì™„ë£Œëœ URL {len(completed_urls)}ê°œ ë¡œë“œ\")\n",
    "\n",
    "    return state, completed_urls\n",
    "\n",
    "def save_crawler_state(state, new_url=None):\n",
    "    \"\"\"í¬ë¡¤ë§ ìƒíƒœ ì €ì¥ (hashlib í†µí•© ë²„ì „)\"\"\"\n",
    "    config_dir = ensure_config_directory()\n",
    "    state_file = os.path.join(config_dir, \"crawler_meta.json\")\n",
    "\n",
    "    # ìƒíƒœ ì—…ë°ì´íŠ¸\n",
    "    state[\"last_updated\"] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    state[\"hash_system_enabled\"] = CONFIG.get(\"USE_HASH_SYSTEM\", True)\n",
    "\n",
    "    try:\n",
    "        # ìƒíƒœ íŒŒì¼ ì €ì¥\n",
    "        with open(state_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(state, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        # ğŸ†• hashlib ì‹œìŠ¤í…œ í™œì„±í™” ì‹œ URL ê¸°ë¡ì€ save_url_to_logì—ì„œ ì²˜ë¦¬\n",
    "        # ë³„ë„ ì²˜ë¦¬ ë¶ˆí•„ìš”\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ìƒíƒœ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "def collect_product_urls_from_page(driver, use_infinite_scroll=False):\n",
    "    \"\"\"\n",
    "    ğŸ¯ [ìŠ¤ìœ„ì¹˜ ê¸°ë°˜ ì ì‘í˜•] URL ìˆ˜ì§‘ - ê¸°ë³¸ëª¨ë“œ/ìŠ¤í¬ë¡¤ëª¨ë“œ ì„ íƒ ê°€ëŠ¥\n",
    "    \"\"\"\n",
    "    if use_infinite_scroll:\n",
    "        print(\"ğŸ“Š [ìŠ¤í¬ë¡¤ëª¨ë“œ] ë¬´í•œìŠ¤í¬ë¡¤ + ìì—°ìŠ¤ëŸ¬ìš´ ìŠ¤í¬ë¡¤ë¡œ URL ìˆ˜ì§‘...\")\n",
    "        return collect_with_infinite_scroll(driver)\n",
    "    else:\n",
    "        print(\"ğŸ“Š [ê¸°ë³¸ëª¨ë“œ] í˜„ì¬ í™”ë©´ ë‹¨ì¼ ìŠ¤ìº”ìœ¼ë¡œ URL ìˆ˜ì§‘...\")\n",
    "        return collect_with_single_scan(driver)\n",
    "\n",
    "def collect_with_single_scan(driver):\n",
    "    \"\"\"ê¸°ë³¸ëª¨ë“œ: í˜„ì¬ í™”ë©´ë§Œ 1íšŒ ìŠ¤ìº” (ê¸°ì¡´ ë°©ì‹)\"\"\"\n",
    "    print(\"   ğŸ” ë‹¨ì¼ ìŠ¤ìº” ëª¨ë“œë¡œ URL ìˆ˜ì§‘ ì¤‘...\")\n",
    "\n",
    "    # ëœë¤ ìŠ¤í¬ë¡¤ íšŸìˆ˜ (3~5íšŒ)\n",
    "    scroll_count = random.randint(3, 5)\n",
    "    print(f\"      ğŸ¯ ìì—°ìŠ¤ëŸ¬ìš´ ìŠ¤í¬ë¡¤ íŒ¨í„´ìœ¼ë¡œ í˜ì´ì§€ íƒìƒ‰ ì¤‘... ({scroll_count}íšŒ)\")\n",
    "\n",
    "    time.sleep(random.uniform(1, 2))  # í˜ì´ì§€ ë¡œë“œ í›„ ì ì‹œ ë¨¸ë¬¼ê¸°\n",
    "\n",
    "    for i in range(scroll_count):\n",
    "        smart_scroll_selector(driver)  # ì¡°ìš©íˆ ì‹¤í–‰\n",
    "        time.sleep(random.uniform(0.8, 2.0))  # ìŠ¤í¬ë¡¤ ê°„ ëŒ€ê¸°\n",
    "\n",
    "    thinking_time = random.uniform(2, 4)\n",
    "    print(f\"      ğŸ¤” {thinking_time:.1f}ì´ˆ ì„ íƒ ê³ ë¯¼ ì¤‘...\")\n",
    "    time.sleep(thinking_time)\n",
    "\n",
    "    # ğŸ”§ KLOOK ì „ìš© ì…€ë ‰í„°ë¡œ ìˆ˜ì •\n",
    "    all_selectors = [\n",
    "        \"a[href*='/activity/']\",  # KLOOK ìƒí’ˆ í˜ì´ì§€ íŒ¨í„´\n",
    "        \".product-item a\",\n",
    "        \".experience-card a\",\n",
    "        \".product-gallery a\",\n",
    "        \".search-result-list a\",  # KLOOK ê²€ìƒ‰ ê²°ê³¼\n",
    "        \".product-card a\"  # KLOOK ìƒí’ˆ ì¹´ë“œ\n",
    "    ]\n",
    "\n",
    "    collected_urls = []\n",
    "\n",
    "    # URL ìˆ˜ì§‘ (ê¸°ì¡´ ì½”ë“œ)\n",
    "    for selector in all_selectors:\n",
    "        try:\n",
    "            from selenium.webdriver.common.by import By\n",
    "            elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "            for element in elements:\n",
    "                try:\n",
    "                    url = element.get_attribute('href')\n",
    "                    if url:\n",
    "                        collected_urls.append(url)\n",
    "                except Exception:\n",
    "                    continue\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    # ì¤‘ë³µ ì œê±° ë° ìœ íš¨ì„± ê²€ì¦ (KLOOK íŒ¨í„´ìœ¼ë¡œ ìˆ˜ì •)\n",
    "    seen = set()\n",
    "    unique_and_valid_urls = []\n",
    "    for url in collected_urls:\n",
    "        if url not in seen:\n",
    "            seen.add(url)\n",
    "            import re\n",
    "            # KLOOK activity URL íŒ¨í„´ ê²€ì¦\n",
    "            if re.search(r'/activity/\\d+', url):\n",
    "                unique_and_valid_urls.append(url)\n",
    "\n",
    "    print(f\"   âœ… ë‹¨ì¼ ìŠ¤ìº” ì™„ë£Œ: {len(unique_and_valid_urls)}ê°œ URL ìˆ˜ì§‘\")\n",
    "\n",
    "    # URL íƒ€ì…ë³„ í†µê³„ (KLOOK íŒ¨í„´)\n",
    "    activity_count = sum(1 for url in unique_and_valid_urls if '/activity/' in url)\n",
    "\n",
    "    print(f\"      ğŸ¯ KLOOK Activities: {activity_count}ê°œ\")\n",
    "\n",
    "    return unique_and_valid_urls\n",
    "\n",
    "def collect_with_infinite_scroll(driver):\n",
    "    \"\"\"ìŠ¤í¬ë¡¤ëª¨ë“œ: ë¬´í•œìŠ¤í¬ë¡¤ + ìì—°ìŠ¤ëŸ¬ìš´ ìŠ¤í¬ë¡¤ íŒ¨í„´\"\"\"\n",
    "    print(\"   ğŸŒŠ ë¬´í•œìŠ¤í¬ë¡¤ ì‹œì‘...\")\n",
    "\n",
    "    all_urls = []\n",
    "    scroll_attempts = 0\n",
    "    max_scrolls = 5\n",
    "\n",
    "    while scroll_attempts < max_scrolls:\n",
    "        # 1. í˜„ì¬ í™”ë©´ì˜ URL ìˆ˜ì§‘\n",
    "        current_urls = collect_basic_urls_from_current_view(driver)\n",
    "        new_urls = [url for url in current_urls if url not in all_urls]\n",
    "        all_urls.extend(new_urls)\n",
    "\n",
    "        if new_urls:\n",
    "            print(f\"      ğŸ“Š ìŠ¤í¬ë¡¤ {scroll_attempts+1}: {len(new_urls)}ê°œ ì‹ ê·œ URL ë°œê²¬\")\n",
    "\n",
    "        # 2. ğŸ¯ ìì—°ìŠ¤ëŸ¬ìš´ ìŠ¤í¬ë¡¤ íŒ¨í„´ ì ìš© (ë´‡ íšŒí”¼ í•µì‹¬!)\n",
    "        smart_scroll_selector(driver)\n",
    "\n",
    "        # 3. ìŠ¤í¬ë¡¤ í›„ ë¡œë”© ëŒ€ê¸°\n",
    "        time.sleep(random.uniform(3, 5))\n",
    "\n",
    "        # 4. ë” ì´ìƒ ìƒˆë¡œìš´ URLì´ ì—†ìœ¼ë©´ ì¢…ë£Œ\n",
    "        if not new_urls and scroll_attempts > 1:\n",
    "            print(f\"      ğŸ ìƒˆë¡œìš´ ìƒí’ˆ ì—†ìŒ - ìŠ¤í¬ë¡¤ ì¢…ë£Œ\")\n",
    "            break\n",
    "\n",
    "        scroll_attempts += 1\n",
    "\n",
    "    # ì¤‘ë³µ ì œê±° ë° ìœ íš¨ì„± ê²€ì¦ (KLOOK íŒ¨í„´ìœ¼ë¡œ ìˆ˜ì •)\n",
    "    seen = set()\n",
    "    unique_and_valid_urls = []\n",
    "    for url in all_urls:\n",
    "        if url not in seen:\n",
    "            seen.add(url)\n",
    "            # KLOOK activity URL íŒ¨í„´ ê²€ì¦\n",
    "            import re\n",
    "            if re.search(r'/activity/\\d+', url):\n",
    "                unique_and_valid_urls.append(url)\n",
    "\n",
    "    print(f\"   âœ… ë¬´í•œìŠ¤í¬ë¡¤ ì™„ë£Œ: {len(unique_and_valid_urls)}ê°œ ê³ ìœ  URL ìˆ˜ì§‘\")\n",
    "\n",
    "    # URL íƒ€ì…ë³„ í†µê³„ (KLOOK íŒ¨í„´)\n",
    "    activity_count = sum(1 for url in unique_and_valid_urls if '/activity/' in url)\n",
    "\n",
    "    print(f\"      ğŸ¯ KLOOK Activities: {activity_count}ê°œ\")\n",
    "\n",
    "    return unique_and_valid_urls\n",
    "\n",
    "def collect_basic_urls_from_current_view(driver):\n",
    "    \"\"\"í˜„ì¬ í™”ë©´ì—ì„œë§Œ URL ìˆ˜ì§‘ (ìŠ¤í¬ë¡¤ ì—†ìŒ) - í—¬í¼ í•¨ìˆ˜\"\"\"\n",
    "    # ğŸ”§ KLOOK ì „ìš© ì…€ë ‰í„°ë¡œ ìˆ˜ì •\n",
    "    all_selectors = [\n",
    "        \"a[href*='/activity/']\",  # KLOOK ìƒí’ˆ í˜ì´ì§€ íŒ¨í„´\n",
    "        \".product-item a\",\n",
    "        \".experience-card a\",\n",
    "        \".product-gallery a\",\n",
    "        \".search-result-list a\",  # KLOOK ê²€ìƒ‰ ê²°ê³¼\n",
    "        \".product-card a\"  # KLOOK ìƒí’ˆ ì¹´ë“œ\n",
    "    ]\n",
    "\n",
    "    collected_urls = []\n",
    "    for selector in all_selectors:\n",
    "        try:\n",
    "            from selenium.webdriver.common.by import By\n",
    "            elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "            for element in elements:\n",
    "                try:\n",
    "                    url = element.get_attribute('href')\n",
    "                    if url:\n",
    "                        collected_urls.append(url)\n",
    "                except Exception:\n",
    "                    continue\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    return collected_urls\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ”— ê°„ì†Œí™”ëœ URL ê´€ë¦¬ ì‹œìŠ¤í…œ (hashlib í†µí•©)\n",
    "# =============================================================================\n",
    "\n",
    "def collect_urls_with_csv_safety(driver, city_name, use_infinite_scroll=False):\n",
    "    \"\"\"KLOOK sitemap ê¸°ë°˜ URL ìˆ˜ì§‘ ì‹œìŠ¤í…œ\"\"\"\n",
    "    print(f\"ğŸ—ºï¸ KLOOK sitemap ê¸°ë°˜ URL ìˆ˜ì§‘ ì‹œì‘... (ë„ì‹œ: {city_name})\")\n",
    "\n",
    "    try:\n",
    "        # KLOOK sitemapì—ì„œ URL ìˆ˜ì§‘\n",
    "        collected_urls = fetch_klook_urls_from_sitemap(city_name)\n",
    "\n",
    "        if not collected_urls:\n",
    "            print(f\"âŒ {city_name}ì— ëŒ€í•œ KLOOK ìƒí’ˆ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "            return []\n",
    "\n",
    "        # ğŸš€ hashlib ì‹œìŠ¤í…œìœ¼ë¡œ ì¤‘ë³µ í•„í„°ë§ (ì´ˆê³ ì†)\n",
    "        if CONFIG.get(\"USE_HASH_SYSTEM\", True):\n",
    "            new_urls = []\n",
    "            for url in collected_urls:\n",
    "                if not hybrid_is_processed(url, city_name):  # í•˜ì´ë¸Œë¦¬ë“œ ì²´í¬ ì‚¬ìš©\n",
    "                    new_urls.append(url)\n",
    "\n",
    "            print(f\"ğŸš€ sitemap ê¸°ë°˜ ì¤‘ë³µ í•„í„°ë§:\")\n",
    "            print(f\"   ğŸ“Š sitemap URL: {len(collected_urls)}ê°œ\")\n",
    "            print(f\"   ğŸ†• ìƒˆë¡œìš´ URL: {len(new_urls)}ê°œ\")\n",
    "\n",
    "            return new_urls\n",
    "        else:\n",
    "            # ê¸°ì¡´ CSV ê¸°ë°˜ ë°©ì‹ (í˜¸í™˜ì„±)\n",
    "            return filter_new_urls_from_csv(collected_urls, city_name)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ KLOOK sitemap URL ìˆ˜ì§‘ ì‹¤íŒ¨: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def fetch_klook_urls_from_sitemap(city_name):\n",
    "    \"\"\"KLOOK sitemapì—ì„œ íŠ¹ì • ë„ì‹œì˜ URL ì¶”ì¶œ\"\"\"\n",
    "    import requests\n",
    "    import xml.etree.ElementTree as ET\n",
    "\n",
    "    print(f\"ğŸ—ºï¸ KLOOK sitemapì—ì„œ '{city_name}' ìƒí’ˆ ê²€ìƒ‰ ì¤‘...\")\n",
    "\n",
    "    try:\n",
    "        # 1. KLOOK ë§ˆìŠ¤í„° sitemap ì ‘ê·¼\n",
    "        master_url = \"https://www.klook.com/ko/sitemap-master-index.xml\"\n",
    "        response = requests.get(master_url, timeout=15)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"âŒ sitemap ì ‘ê·¼ ì‹¤íŒ¨: HTTP {response.status_code}\")\n",
    "            return []\n",
    "\n",
    "        root = ET.fromstring(response.content)\n",
    "        print(f\"âœ… ë§ˆìŠ¤í„° sitemap ì ‘ê·¼ ì„±ê³µ\")\n",
    "\n",
    "        # 2. experiences-activity sitemap ì°¾ê¸° (KLOOK ì£¼ìš” ìƒí’ˆ)\n",
    "        target_sitemaps = []\n",
    "        for sitemap in root.findall('.//{http://www.sitemaps.org/schemas/sitemap/0.9}sitemap'):\n",
    "            loc_elem = sitemap.find('{http://www.sitemaps.org/schemas/sitemap/0.9}loc')\n",
    "            if loc_elem is not None:\n",
    "                sitemap_url = loc_elem.text\n",
    "                if 'experiences-activity' in sitemap_url:\n",
    "                    target_sitemaps.append(sitemap_url)\n",
    "\n",
    "        print(f\"ğŸ¯ ëŒ€ìƒ sitemap {len(target_sitemaps)}ê°œ ë°œê²¬\")\n",
    "\n",
    "        # 3. ë„ì‹œ í‚¤ì›Œë“œ ë§¤í•‘ (ê·¸ë£¹ 1 í•¨ìˆ˜ í™œìš©)\n",
    "        city_code = get_city_code(city_name)\n",
    "        continent, country = get_city_info(city_name)\n",
    "        keywords = [\n",
    "            city_name.lower(),    # \"ì„œìš¸\"\n",
    "            'seoul',              # ì •í™•í•œ ì˜ë¬¸ëª… ì¶”ê°€\n",
    "            country.lower(),      # \"ëŒ€í•œë¯¼êµ­\"\n",
    "            'korea'               # ì •í™•í•œ ì˜ë¬¸ êµ­ê°€ëª… ì¶”ê°€\n",
    "            # city_code ì œê±° - ë„ˆë¬´ ëª¨í˜¸í•¨\n",
    "        ]\n",
    "        print(f\"ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ: {keywords} (from {continent}/{country}/{city_code})\")\n",
    "\n",
    "        # 4. sitemapì—ì„œ ë„ì‹œë³„ URL ì¶”ì¶œ\n",
    "        city_urls = []\n",
    "        for sitemap_url in target_sitemaps[:2]:  # ì²˜ìŒ 2ê°œ sitemapë§Œ ì²˜ë¦¬ (ì†ë„ ìµœì í™”)\n",
    "            try:\n",
    "                print(f\"   ğŸ“„ sitemap ë¶„ì„ ì¤‘: {sitemap_url.split('/')[-1]}\")\n",
    "                sub_response = requests.get(sitemap_url, timeout=15)\n",
    "                sub_root = ET.fromstring(sub_response.content)\n",
    "\n",
    "                previous_count = len(city_urls)  # ì´ì „ ê°œìˆ˜ ì €ì¥\n",
    "                \n",
    "                for url in sub_root.findall('.//{http://www.sitemaps.org/schemas/sitemap/0.9}url'):\n",
    "                    loc = url.find('{http://www.sitemaps.org/schemas/sitemap/0.9}loc')\n",
    "                    if loc is not None:\n",
    "                        url_text = loc.text.lower()\n",
    "                        # í‚¤ì›Œë“œ ë§¤ì¹­ ë° activity URL í•„í„°ë§\n",
    "                        if any(keyword in url_text for keyword in keywords) and '/activity/' in url_text:\n",
    "                            city_urls.append(loc.text)\n",
    "\n",
    "                new_count = len(city_urls) - previous_count\n",
    "                print(f\"   ğŸ“Š {new_count}ê°œ URL ì¶”ì¶œë¨\")\n",
    "\n",
    "            except Exception as sub_e:\n",
    "                print(f\"   âš ï¸ sitemap ì²˜ë¦¬ ì‹¤íŒ¨: {sub_e}\")\n",
    "                continue\n",
    "\n",
    "        # 5. ì¤‘ë³µ ì œê±° ë° ê²°ê³¼ ë°˜í™˜\n",
    "        unique_urls = list(set(city_urls))\n",
    "        print(f\"ğŸ‰ ì´ {len(unique_urls)}ê°œì˜ ê³ ìœ í•œ {city_name} ìƒí’ˆ URL ë°œê²¬!\")\n",
    "\n",
    "        # ìƒ˜í”Œ URL ì¶œë ¥\n",
    "        if unique_urls:\n",
    "            print(f\"ğŸ“‹ ìƒ˜í”Œ URL:\")\n",
    "            for i, url in enumerate(unique_urls[:3], 1):\n",
    "                print(f\"   {i}. {url}\")\n",
    "\n",
    "        return unique_urls\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ sitemap ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        return []\n",
    "\n",
    "def save_collected_urls(city_name, urls_list):\n",
    "    \"\"\"\n",
    "    [V2 3-tier í†µí•© ë²„ì „] URL ì €ì¥ ì‹œìŠ¤í…œ\n",
    "    ìˆ˜ì§‘ëœ URL ëª©ë¡ì„ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # V2 ì‹œìŠ¤í…œ ìš°ì„  ì‚¬ìš©\n",
    "    if CONFIG.get(\"USE_V2_URL_SYSTEM\", True):\n",
    "        try:\n",
    "            # V2 ì‹œìŠ¤í…œì„ ìœ„í•œ ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¥¼ í™•ì¸í•˜ê³  ìƒì„±í•©ë‹ˆë‹¤.\n",
    "            ensure_url_directories_v2()\n",
    "            # ë„ì‹œ ì´ë¦„ìœ¼ë¡œ ë„ì‹œ ì½”ë“œë¥¼ ì–»ìŠµë‹ˆë‹¤.\n",
    "            city_code = get_city_code(city_name)\n",
    "            # ì €ì¥í•  íŒŒì¼ ê²½ë¡œë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "            collect_file = os.path.join(CONFIG[\"V2_URL_COLLECTED\"], f\"{city_code}_collect.json\")\n",
    "\n",
    "            # ì €ì¥í•  ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "            cache_data = {\n",
    "                \"city\": city_name,\n",
    "                \"city_code\": city_code,\n",
    "                \"urls\": urls_list,\n",
    "                \"collected_time\": datetime.now().isoformat(),\n",
    "                \"total_count\": len(urls_list),\n",
    "                \"v2_system\": True\n",
    "            }\n",
    "\n",
    "            # íŒŒì¼ì— ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "            with open(collect_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(cache_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "            print(f\"âœ… V2 URL ìºì‹œ ì €ì¥: {len(urls_list)}ê°œ ({collect_file})\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            # V2 ì‹œìŠ¤í…œì— ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ì˜¤ë¥˜ë¥¼ ì¶œë ¥í•˜ê³  Falseë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "            print(f\"âŒ V2 URL ì €ì¥ ì‹¤íŒ¨, ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©: {e}\")\n",
    "\n",
    "    # ê¸°ì¡´ ì‹œìŠ¤í…œ (fallback)\n",
    "    try:\n",
    "        # ê¸°ì¡´ ì‹œìŠ¤í…œì„ ìœ„í•œ ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "        os.makedirs(\"url_cache/collected\", exist_ok=True)\n",
    "        # ì €ì¥í•  íŒŒì¼ ê²½ë¡œë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "        cache_file = os.path.join(\"url_cache\", \"collected\", f\"{city_name}_urls.json\")\n",
    "\n",
    "        # ì €ì¥í•  ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "        cache_data = {\n",
    "            \"city\": city_name,\n",
    "            \"urls\": urls_list,\n",
    "            \"collected_time\": datetime.now().isoformat(),\n",
    "            \"total_count\": len(urls_list),\n",
    "            \"hashlib_enabled\": CONFIG.get(\"USE_HASH_SYSTEM\", True)\n",
    "        }\n",
    "\n",
    "        # íŒŒì¼ì— ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "        with open(cache_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(cache_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        print(f\"âœ… ê¸°ì¡´ URL ìºì‹œ ì €ì¥: {len(urls_list)}ê°œ ({cache_file})\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        # ê¸°ì¡´ ì‹œìŠ¤í…œì— ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ì˜¤ë¥˜ë¥¼ ì¶œë ¥í•˜ê³  Falseë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "        print(f\"âŒ URL ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "def load_collected_urls(city_name):\n",
    "    \"\"\"\n",
    "    [V2 3-tier í†µí•© ë²„ì „] URL ë¡œë“œ ì‹œìŠ¤í…œ\n",
    "    JSON íŒŒì¼ì— ì €ì¥ëœ URL ëª©ë¡ì„ ë¡œë“œí•˜ê³ , ë¯¸ì™„ë£Œëœ URLë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # V2 ì‹œìŠ¤í…œ ìš°ì„  ì‚¬ìš©\n",
    "    if CONFIG.get(\"USE_V2_URL_SYSTEM\", True):\n",
    "        try:\n",
    "            city_code = get_city_code(city_name)\n",
    "            collect_file = os.path.join(CONFIG[\"V2_URL_COLLECTED\"], f\"{city_code}_collect.json\")\n",
    "\n",
    "            if os.path.exists(collect_file):\n",
    "                with open(collect_file, 'r', encoding='utf-8') as f:\n",
    "                    cache_data = json.load(f)\n",
    "\n",
    "                cached_urls = cache_data.get('urls', [])\n",
    "                collected_time = cache_data.get('collected_time', '')\n",
    "\n",
    "                print(f\"âœ… V2 URL ìºì‹œ ë¡œë“œ: {len(cached_urls)}ê°œ ({collected_time})\")\n",
    "\n",
    "                # ì™„ë£Œëœ URL í•„í„°ë§ (V2 + hashlib í•˜ì´ë¸Œë¦¬ë“œ)\n",
    "                pending_urls = []\n",
    "                for url in cached_urls:\n",
    "                    if not hybrid_is_processed(url, city_name):\n",
    "                        pending_urls.append(url)\n",
    "\n",
    "                if pending_urls:\n",
    "                    print(f\"ğŸ¯ V2 ë¯¸ì™„ë£Œ URL: {len(pending_urls)}ê°œ\")\n",
    "                    return pending_urls\n",
    "                else:\n",
    "                    print(f\"âœ… V2 ëª¨ë“  URL ì™„ë£Œë¨\")\n",
    "                    return None\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ V2 URL ë¡œë“œ ì‹¤íŒ¨, ê¸°ì¡´ ë°©ì‹ ì‹œë„: {e}\")\n",
    "\n",
    "    # ê¸°ì¡´ ì‹œìŠ¤í…œ (fallback)\n",
    "    try:\n",
    "        cache_file = os.path.join(\"url_cache\", \"collected\", f\"{city_name}_urls.json\")\n",
    "\n",
    "        if not os.path.exists(cache_file):\n",
    "            print(f\"â„¹ï¸ URL ìºì‹œ ì—†ìŒ: ì‹ ê·œ ê²€ìƒ‰ í•„ìš”\")\n",
    "            return None\n",
    "\n",
    "        with open(cache_file, 'r', encoding='utf-8') as f:\n",
    "            cache_data = json.load(f)\n",
    "\n",
    "        cached_urls = cache_data.get('urls', [])\n",
    "        collected_time = cache_data.get('collected_time', '')\n",
    "\n",
    "        print(f\"âœ… ê¸°ì¡´ URL ìºì‹œ ë¡œë“œ: {len(cached_urls)}ê°œ ({collected_time})\")\n",
    "\n",
    "        # ì™„ë£Œëœ URL í•„í„°ë§\n",
    "        pending_urls = []\n",
    "        for url in cached_urls:\n",
    "            if not hybrid_is_processed(url, city_name):\n",
    "                pending_urls.append(url)\n",
    "\n",
    "        return pending_urls if pending_urls else None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ URL ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ§¹ ë‹¨ìˆœí™”ëœ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (ì„ íƒì  ì‚¬ìš©)\n",
    "# =============================================================================\n",
    "\n",
    "def filter_new_urls_from_csv(all_urls, city_name):\n",
    "    \"\"\"CSV ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ URLë§Œ í•„í„°ë§ (hashlib ë¹„í™œì„±í™” ì‹œì—ë§Œ ì‚¬ìš©)\"\"\"\n",
    "    if CONFIG.get(\"USE_HASH_SYSTEM\", True):\n",
    "        print(\"ğŸš€ hashlib ì‹œìŠ¤í…œ í™œì„±í™” - CSV í•„í„°ë§ ëŒ€ì‹  í•´ì‹œ ì²´í¬ ì‚¬ìš©\")\n",
    "        return [url for url in all_urls if not hybrid_is_processed(url, city_name)]\n",
    "\n",
    "    # ê¸°ì¡´ CSV ë°©ì‹\n",
    "    crawled_urls = get_completed_urls_from_csv(city_name)\n",
    "    new_urls = [url for url in all_urls if url not in crawled_urls]\n",
    "\n",
    "    print(f\"ğŸ” CSV ê¸°ë°˜ URL í•„í„°ë§:\")\n",
    "    print(f\"   ğŸ“Š ì „ì²´ URL: {len(all_urls)}ê°œ\")\n",
    "    print(f\"   âœ… ì´ë¯¸ ì™„ë£Œ: {len(crawled_urls)}ê°œ\")\n",
    "    print(f\"   ğŸ†• ìƒˆë¡œìš´ URL: {len(new_urls)}ê°œ\")\n",
    "\n",
    "    return new_urls\n",
    "\n",
    "# ğŸš€ hashlib ì‹œìŠ¤í…œì„ ìœ„í•œ ë³„ì¹­ í•¨ìˆ˜ë“¤\n",
    "collect_all_24_urls = collect_product_urls_from_page  # ë³„ì¹­\n",
    "filter_new_urls = filter_new_urls_from_csv  # ë³„ì¹­\n",
    "\n",
    "print(\"âœ… ê·¸ë£¹ 3 ì™„ë£Œ: KLOOK ì „ìš© URL íŒ¨í„´ + hashlib í†µí•© ê°„ì†Œí™”ëœ ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ!\")\n",
    "print(f\"ğŸš€ hashlib ìµœì í™”: {'í™œì„±í™”' if CONFIG.get('USE_HASH_SYSTEM', True) else 'ë¹„í™œì„±í™”'}\")\n",
    "print(\"ğŸ§¹ KLOOK /activity/ íŒ¨í„´ìœ¼ë¡œ ì™„ì „ ë³€ê²½ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb292a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ğŸš€ ê·¸ë£¹ 4: í™•ì¥ì„± ê°œì„  ì‹œìŠ¤í…œ 1\n",
    "# - ë„ì‹œ ê´€ë¦¬, í˜ì´ì§€ë„¤ì´ì…˜ ë¶„ì„, ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "# =============================================================================\n",
    "\n",
    "def create_city_codes_file():\n",
    "    \"\"\"ë„ì‹œ ì½”ë“œë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥ (UNIFIED_CITY_INFO ê¸°ë°˜)\"\"\"\n",
    "    enhanced_city_data = {\n",
    "        \"version\": \"3.0\",\n",
    "        \"last_updated\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"cities\": {},\n",
    "        \"total_cities\": len(UNIFIED_CITY_INFO)\n",
    "    }\n",
    "\n",
    "    for city_name, info in UNIFIED_CITY_INFO.items():\n",
    "        enhanced_city_data[\"cities\"][city_name] = {\n",
    "            \"code\": info.get(\"ì½”ë“œ\", \"N/A\"),\n",
    "            \"continent\": info.get(\"ëŒ€ë¥™\", \"ê¸°íƒ€\"),\n",
    "            \"country\": info.get(\"êµ­ê°€\", \"ê¸°íƒ€\")\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        # ğŸ†• ê·¸ë£¹ 1 í•¨ìˆ˜ í™œìš©í•˜ì—¬ config í´ë” ìƒì„±\n",
    "        config_dir = ensure_config_directory()\n",
    "        config_file = os.path.join(config_dir, \"city_codes.json\")\n",
    "\n",
    "        with open(config_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(enhanced_city_data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"âœ… {config_file} íŒŒì¼ ìƒì„± ì™„ë£Œ! ({len(UNIFIED_CITY_INFO)}ê°œ ë„ì‹œ)\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "def load_city_codes_from_file():\n",
    "    \"\"\"JSON íŒŒì¼ì—ì„œ ë„ì‹œ ì½”ë“œ ë¡œë“œ (UNIFIED_CITY_INFOì™€ ë™ê¸°í™”)\"\"\"\n",
    "    if not os.path.exists('config/city_codes.json'):\n",
    "        print(\"ğŸ“ config/city_codes.json íŒŒì¼ì´ ì—†ì–´ì„œ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...\")\n",
    "        create_city_codes_file()\n",
    "    \n",
    "    try:\n",
    "        with open('config/city_codes.json', 'r', encoding='utf-8') as f:\n",
    "            city_data = json.load(f)\n",
    "        \n",
    "        loaded_cities = city_data.get(\"cities\", {})\n",
    "        \n",
    "        for city, info in loaded_cities.items():\n",
    "            if city not in UNIFIED_CITY_INFO:\n",
    "                 UNIFIED_CITY_INFO[city] = {\n",
    "                     \"ëŒ€ë¥™\": info.get(\"continent\"),\n",
    "                     \"êµ­ê°€\": info.get(\"country\"),\n",
    "                     \"ì½”ë“œ\": info.get(\"code\")\n",
    "                 }\n",
    "        \n",
    "        print(f\"âœ… config/city_codes.json ë¡œë“œ ë° ë™ê¸°í™” ì™„ë£Œ! ({len(UNIFIED_CITY_INFO)}ê°œ ë„ì‹œ)\")\n",
    "        print(f\"ğŸ“… ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {city_data.get('last_updated', 'ì•Œ ìˆ˜ ì—†ìŒ')}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        print(\"ğŸ’¡ ì½”ë“œì˜ UNIFIED_CITY_INFOë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "def show_supported_cities():\n",
    "    \"\"\"ì§€ì›í•˜ëŠ” ë„ì‹œ ëª©ë¡ í‘œì‹œ (UNIFIED_CITY_INFO ê¸°ë°˜)\"\"\"\n",
    "    print(\"\\nğŸŒ ì§€ì›í•˜ëŠ” ë„ì‹œ ëª©ë¡:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    cities_by_continent = {}\n",
    "    for city, info in UNIFIED_CITY_INFO.items():\n",
    "        continent = info.get(\"ëŒ€ë¥™\", \"ê¸°íƒ€\")\n",
    "        if continent not in cities_by_continent:\n",
    "            cities_by_continent[continent] = []\n",
    "        cities_by_continent[continent].append(city)\n",
    "\n",
    "    for continent, cities in sorted(cities_by_continent.items()):\n",
    "        print(f\"\\nğŸ“ {continent}:\")\n",
    "        for city in sorted(cities):\n",
    "            code = UNIFIED_CITY_INFO[city].get(\"ì½”ë“œ\", \"N/A\")\n",
    "            print(f\"   {city} â†’ {code}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ì´ {len(UNIFIED_CITY_INFO)}ê°œ ë„ì‹œ ì§€ì›\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "def validate_city(city_name):\n",
    "    \"\"\"ë„ì‹œëª… ìœ íš¨ì„± ê²€ì‚¬ (UNIFIED_CITY_INFO ê¸°ë°˜)\"\"\"\n",
    "    if not city_name or len(city_name.strip()) == 0:\n",
    "        return False, \"ë„ì‹œëª…ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    if city_name in UNIFIED_CITY_INFO:\n",
    "        code = UNIFIED_CITY_INFO[city_name].get(\"ì½”ë“œ\", \"N/A\")\n",
    "        return True, f\"ì§€ì›í•˜ëŠ” ë„ì‹œì…ë‹ˆë‹¤. ({code})\"\n",
    "    \n",
    "    similar_cities = [c for c in UNIFIED_CITY_INFO if city_name.lower() in c.lower() or c.lower() in city_name.lower()]\n",
    "    \n",
    "    if similar_cities:\n",
    "        return False, f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë„ì‹œì…ë‹ˆë‹¤. ë¹„ìŠ·í•œ ë„ì‹œ: {', '.join(similar_cities)}\"\n",
    "    else:\n",
    "        return False, f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë„ì‹œì…ë‹ˆë‹¤. show_supported_cities()ë¡œ ì§€ì› ë„ì‹œ ëª©ë¡ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\"\n",
    "        \n",
    "\n",
    "def update_config_for_scalability():\n",
    "    \"\"\"í™•ì¥ì„±ì„ ìœ„í•œ CONFIG ì—…ë°ì´íŠ¸\"\"\"\n",
    "    global CONFIG\n",
    "    \n",
    "    scalability_config = {\n",
    "        \"AUTO_LOAD_CITIES\": True,\n",
    "        \"AUTO_SAVE_NEW_CITIES\": True,\n",
    "        \"ENABLE_MULTI_CITY\": False,\n",
    "        \"CITY_PROCESSING_ORDER\": \"sequential\",\n",
    "        \"BACKUP_OLD_DATA\": True,\n",
    "        \"DATA_RETENTION_DAYS\": 30,\n",
    "        \"ENABLE_CITY_VALIDATION\": True,\n",
    "        \"ENABLE_DUPLICATE_CHECK\": True,\n",
    "    }\n",
    "    \n",
    "    CONFIG.update(scalability_config)\n",
    "    print(\"âš™ï¸ CONFIG í™•ì¥ì„± ì„¤ì • ì—…ë°ì´íŠ¸ ì™„ë£Œ!\")\n",
    "\n",
    "def analyze_pagination(driver):\n",
    "    \"\"\"í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„ - ì´ í˜ì´ì§€ ìˆ˜, ìƒí’ˆ ìˆ˜ íŒŒì•…\"\"\"\n",
    "    print(f\"  ğŸ” í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„ ì¤‘...\")\n",
    "    \n",
    "    try:\n",
    "        # í˜ì´ì§€ ë¡œë”© ì™„ë£Œ ëŒ€ê¸°\n",
    "        time.sleep(3)\n",
    "        \n",
    "        # ì´ ìƒí’ˆ ìˆ˜ ì°¾ê¸°\n",
    "        total_products = 0\n",
    "        total_selectors = [\n",
    "            \"//span[contains(text(), 'ì´') and contains(text(), 'ê°œ')]\",\n",
    "            \"//span[contains(text(), 'ì „ì²´') and contains(text(), 'ê°œ')]\", \n",
    "            \"//div[contains(@class, 'total') or contains(@class, 'count')]//span\",\n",
    "            \"//span[contains(text(), 'ê²°ê³¼')]\",\n",
    "        ]\n",
    "        \n",
    "        for selector in total_selectors:\n",
    "            try:\n",
    "                elements = driver.find_elements(By.XPATH, selector)\n",
    "                for element in elements:\n",
    "                    text = element.text.strip()\n",
    "                    if 'ê°œ' in text and any(char.isdigit() for char in text):\n",
    "                        # ìˆ«ì ì¶”ì¶œ\n",
    "                        import re\n",
    "                        numbers = re.findall(r'\\d+', text)\n",
    "                        if numbers:\n",
    "                            total_products = int(numbers[0])\n",
    "                            print(f\"    âœ… ì´ ìƒí’ˆ ìˆ˜ ë°œê²¬: {total_products}ê°œ\")\n",
    "                            break\n",
    "                if total_products > 0:\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ì°¾ê¸°\n",
    "        total_pages = 1\n",
    "        has_next_button = False\n",
    "        \n",
    "        # ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ì°¾ê¸°\n",
    "        next_button_selectors = [\n",
    "            \"//button[contains(@aria-label, 'ë‹¤ìŒ')]\",\n",
    "            \"//button[contains(text(), 'ë‹¤ìŒ')]\",\n",
    "            \"//a[contains(@aria-label, 'ë‹¤ìŒ')]\", \n",
    "            \"//a[contains(text(), 'ë‹¤ìŒ')]\",\n",
    "            \"//button[contains(@class, 'next')]\",\n",
    "            \"//a[contains(@class, 'next')]\",\n",
    "            \".pagination .next\",\n",
    "            \".pager .next\"\n",
    "        ]\n",
    "        \n",
    "        for selector in next_button_selectors:\n",
    "            try:\n",
    "                if selector.startswith('//'):\n",
    "                    elements = driver.find_elements(By.XPATH, selector)\n",
    "                else:\n",
    "                    elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                    \n",
    "                for element in elements:\n",
    "                    if element.is_enabled() and element.is_displayed():\n",
    "                        has_next_button = True\n",
    "                        print(f\"    âœ… 'ë‹¤ìŒ í˜ì´ì§€' ë²„íŠ¼ ë°œê²¬!\")\n",
    "                        break\n",
    "                if has_next_button:\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # í˜ì´ì§€ ë²ˆí˜¸ ì°¾ê¸° (ì´ í˜ì´ì§€ ìˆ˜ ì¶”ì •)\n",
    "        page_number_selectors = [\n",
    "            \"//button[contains(@class, 'page') or contains(@class, 'pagination')]//span\",\n",
    "            \"//a[contains(@class, 'page') or contains(@class, 'pagination')]//span\",\n",
    "            \".pagination button span\",\n",
    "            \".pager a span\"\n",
    "        ]\n",
    "        \n",
    "        max_page = 1\n",
    "        for selector in page_number_selectors:\n",
    "            try:\n",
    "                if selector.startswith('//'):\n",
    "                    elements = driver.find_elements(By.XPATH, selector)\n",
    "                else:\n",
    "                    elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                    \n",
    "                for element in elements:\n",
    "                    text = element.text.strip()\n",
    "                    if text.isdigit():\n",
    "                        page_num = int(text)\n",
    "                        max_page = max(max_page, page_num)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        total_pages = max_page\n",
    "\n",
    "        # 495ê°œ ìƒí’ˆì´ 1í˜ì´ì§€ ë¬¸ì œ í•´ê²° ë¡œì§\n",
    "        if total_products > 100 and total_pages == 1:\n",
    "            estimated_pages = (total_products + 23) // 24  # ë…¼ë¦¬ì  ê³„ì‚° (24ê°œì”©)\n",
    "            if has_next_button:\n",
    "                total_pages = estimated_pages  # ì¶”ì •ê°’ ì ìš©\n",
    "                print(f\"    ğŸ”§ í˜ì´ì§€ ìˆ˜ ë³´ì •: {total_products}ê°œ ìƒí’ˆ â†’ {total_pages}í˜ì´ì§€ë¡œ ìˆ˜ì •\")\n",
    "                print(f\"    ğŸ“Š ì˜ˆìƒ í˜ì´ì§€ë‹¹ ìƒí’ˆ ìˆ˜: ~{total_products // total_pages}ê°œ\")\n",
    "            else:\n",
    "                print(f\"    âš ï¸ ë‹¤ìŒ ë²„íŠ¼ ì—†ìŒ: ì‹¤ì œë¡œ 1í˜ì´ì§€ì¼ ìˆ˜ ìˆìŒ (ìƒí’ˆ {total_products}ê°œ)\")\n",
    "                # ì‹¤ì œë¡œ 1í˜ì´ì§€ì¸ì§€ í™•ì¸í•˜ê¸° ìœ„í•œ ì¶”ê°€ ë¡œì§ í•„ìš”í•  ìˆ˜ ìˆìŒ\n",
    "                \n",
    "                # í˜ì´ì§€ë‹¹ ìƒí’ˆ ìˆ˜ ì¶”ì • (í˜„ì¬ í˜ì´ì§€ ê¸°ì¤€)\n",
    "                products_per_page = 24  # ê¸°ë³¸ê°’\n",
    "                if total_products > 0 and total_pages > 0:\n",
    "                    products_per_page = min(24, total_products // total_pages + (1 if total_products % total_pages > 0 else 0))\n",
    "                \n",
    "                return {\n",
    "                    'total_products': total_products,\n",
    "                    'total_pages': total_pages, \n",
    "                    'products_per_page': products_per_page,\n",
    "                    'has_next_button': has_next_button,\n",
    "                    'is_pagination_available': has_next_button or total_pages > 1\n",
    "                }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    âŒ í˜ì´ì§€ë„¤ì´ì…˜ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "        return {\n",
    "            'total_products': 0,\n",
    "            'total_pages': 1,\n",
    "            'products_per_page': 24,\n",
    "            'has_next_button': False,\n",
    "            'is_pagination_available': False\n",
    "        }\n",
    "\n",
    "def check_next_button(driver):\n",
    "    \"\"\"KLOOK ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ì‘ë™ í™•ì¸\"\"\"\n",
    "    print(f\"  ğŸ” KLOOK ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ í™•ì¸ ì¤‘...\")\n",
    "\n",
    "    try:\n",
    "        # KLOOKì—ì„œ disabled ë²„íŠ¼ì´ ìˆìœ¼ë©´ ë§ˆì§€ë§‰ í˜ì´ì§€\n",
    "        driver.find_element(By.CSS_SELECTOR, \".klk-pagination-next-btn-disabled\")\n",
    "        print(f\"    ğŸ ë§ˆì§€ë§‰ í˜ì´ì§€ì…ë‹ˆë‹¤ (disabled ë²„íŠ¼ ë°œê²¬)\")\n",
    "        return False\n",
    "    except NoSuchElementException:\n",
    "        # disabled ë²„íŠ¼ì´ ì—†ìœ¼ë©´ ë‹¤ìŒ í˜ì´ì§€ ìˆìŒ\n",
    "        try:\n",
    "            # í™œì„±í™”ëœ ë‹¤ìŒí˜ì´ì§€ ë²„íŠ¼ í™•ì¸\n",
    "            next_button = driver.find_element(By.CSS_SELECTOR, \".klk-pagination-next-btn:not(.klk-pagination-next-btn-disabled)\")\n",
    "            if next_button.is_displayed():\n",
    "                print(f\"    âœ… ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì´ ì‘ë™ ê°€ëŠ¥í•©ë‹ˆë‹¤!\")\n",
    "                return True\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    print(f\"    âŒ ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    return False\n",
    "\n",
    "\n",
    "def generate_crawling_plan(pagination_info, city_name):\n",
    "    \"\"\"í¬ë¡¤ë§ ê³„íš ìƒì„± ë° ë³´ê³ \"\"\"\n",
    "    print(f\"\\nğŸ“‹ í¬ë¡¤ë§ ê³„íš ìˆ˜ë¦½ ì¤‘...\")\n",
    "    \n",
    "    plan = {\n",
    "        'city': city_name,\n",
    "        'total_products': pagination_info['total_products'],\n",
    "        'total_pages': pagination_info['total_pages'],\n",
    "        'products_per_page': pagination_info['products_per_page'],\n",
    "        'pagination_available': pagination_info['is_pagination_available'],\n",
    "        'estimated_time_minutes': 0,\n",
    "        'recommended_batch_size': CONFIG['MAX_PRODUCTS_PER_CITY'],\n",
    "        'strategy': 'ë‹¨ì¼ í˜ì´ì§€'\n",
    "    }\n",
    "    \n",
    "    # ì˜ˆìƒ ì†Œìš” ì‹œê°„ ê³„ì‚° (ìƒí’ˆë‹¹ ì•½ 30ì´ˆ ì¶”ì •)\n",
    "    products_to_crawl = min(pagination_info['total_products'], CONFIG['MAX_PRODUCTS_PER_CITY'])\n",
    "    plan['estimated_time_minutes'] = products_to_crawl * 0.5  # ìƒí’ˆë‹¹ 30ì´ˆ\n",
    "    \n",
    "    # ì „ëµ ê²°ì •\n",
    "    if pagination_info['is_pagination_available'] and pagination_info['total_pages'] > 1:\n",
    "        plan['strategy'] = 'ë‹¤ì¤‘ í˜ì´ì§€ ìˆœíšŒ'\n",
    "        if pagination_info['total_products'] > CONFIG['MAX_PRODUCTS_PER_CITY']:\n",
    "            plan['strategy'] += f\" (ìµœëŒ€ {CONFIG['MAX_PRODUCTS_PER_CITY']}ê°œ ì œí•œ)\"\n",
    "    \n",
    "    return plan\n",
    "\n",
    "def report_reconnaissance_results(plan):\n",
    "    \"\"\"ì •ì°° ê²°ê³¼ ë³´ê³ \"\"\"\n",
    "    print(f\"\\nğŸ” === ì •ì°° ì™„ë£Œ ë³´ê³ ì„œ ===\")\n",
    "    print(f\"ğŸ“ ë„ì‹œ: {plan['city']}\")\n",
    "    print(f\"ğŸ“Š ë°œê²¬ëœ ì´ ìƒí’ˆ ìˆ˜: {plan['total_products']}ê°œ\")\n",
    "    print(f\"ğŸ“„ ì´ í˜ì´ì§€ ìˆ˜: {plan['total_pages']}í˜ì´ì§€\")\n",
    "    print(f\"ğŸ“‹ í˜ì´ì§€ë‹¹ ìƒí’ˆ ìˆ˜: {plan['products_per_page']}ê°œ\")\n",
    "    print(f\"ğŸ”„ í˜ì´ì§€ë„¤ì´ì…˜ ê°€ëŠ¥: {'âœ… ì˜ˆ' if plan['pagination_available'] else 'âŒ ì•„ë‹ˆì˜¤'}\")\n",
    "    print(f\"â±ï¸ ì˜ˆìƒ ì†Œìš” ì‹œê°„: {plan['estimated_time_minutes']:.1f}ë¶„\")\n",
    "    print(f\"ğŸ¯ í¬ë¡¤ë§ ì „ëµ: {plan['strategy']}\")\n",
    "    print(f\"ğŸ“¦ ì‹¤ì œ ìˆ˜ì§‘ ì˜ˆì •: {min(plan['total_products'], plan['recommended_batch_size'])}ê°œ\")\n",
    "    print(f\"=\" * 50)\n",
    "    \n",
    "    if plan['pagination_available']:\n",
    "        print(f\"ğŸš€ í˜ì´ì§€ë„¤ì´ì…˜ì„ í™œìš©í•œ ì „ì²´ í¬ë¡¤ë§ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"âš ï¸ í˜ì´ì§€ë„¤ì´ì…˜ì´ ì œí•œì ì…ë‹ˆë‹¤. í˜„ì¬ í˜ì´ì§€ë§Œ í¬ë¡¤ë§ ê°€ëŠ¥í•©ë‹ˆë‹¤.\")\n",
    "        return False\n",
    "\n",
    "def initialize_file_system():\n",
    "    \"\"\"íŒŒì¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ì„¤ì • (ë¦¬íŒ©í† ë§ëœ ë²„ì „)\"\"\"\n",
    "    print(\"ğŸ”§ ê·¸ë£¹ 4: í™•ì¥ì„± ê°œì„  ì‹œìŠ¤í…œ ì´ˆê¸°í™”...\")\n",
    "    \n",
    "    update_config_for_scalability()\n",
    "    \n",
    "    if CONFIG.get(\"AUTO_LOAD_CITIES\", True):\n",
    "        load_city_codes_from_file()\n",
    "    \n",
    "    print(\"âœ… ê·¸ë£¹ 4 ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
    "    return True\n",
    "\n",
    "# ìë™ ì´ˆê¸°í™” ì‹¤í–‰\n",
    "try:\n",
    "    initialize_file_system()\n",
    "    print(\"   - create_city_codes_file(): ë„ì‹œ ì½”ë“œ JSON íŒŒì¼ ìƒì„±\")\n",
    "    print(\"   - show_supported_cities(): ì§€ì› ë„ì‹œ ëª©ë¡ í‘œì‹œ\")\n",
    "    print(\"   - validate_city(): ë„ì‹œëª… ìœ íš¨ì„± ê²€ì‚¬\")\n",
    "    print(\"   - analyze_pagination(): í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„\")\n",
    "    print(\"   - check_next_button(): ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ í™•ì¸\")\n",
    "    print(\"   - generate_crawling_plan(): í¬ë¡¤ë§ ê³„íš ìˆ˜ë¦½\")\n",
    "    print(\"   - report_reconnaissance_results(): ì •ì°° ê²°ê³¼ ë³´ê³ \")\n",
    "    print(\"ğŸ¯ í˜ì´ì§€ë„¤ì´ì…˜ ìë™í™”ë¥¼ ìœ„í•œ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ê·¸ë£¹ 4 ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ’¡ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ê³„ì† ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fe0af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ğŸ› ï¸ ê·¸ë£¹ 5: ë¸Œë¼ìš°ì € ì œì–´ ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤\n",
    "# - ë“œë¼ì´ë²„ ì„¤ì •, í˜ì´ì§€ ë„¤ë¹„ê²Œì´ì…˜, ìœ í‹¸ë¦¬í‹° ê¸°ëŠ¥ë“¤\n",
    "# =============================================================================\n",
    "\n",
    "def make_user_agent(ua, is_mobile):\n",
    "    \"\"\"User Agent ìƒì„± í•¨ìˆ˜\"\"\"\n",
    "    user_agent = parse(ua)\n",
    "    model = user_agent.device.model\n",
    "    platform = user_agent.os.family\n",
    "    platform_version = user_agent.os.version_string + \".0.0\"\n",
    "    version = user_agent.browser.version[0]\n",
    "    ua_full_version = user_agent.browser.version_string\n",
    "    architecture = \"x86\"\n",
    "    print(platform)\n",
    "    if is_mobile:\n",
    "        platform_info = \"Linux armv8l\"\n",
    "        architecture= \"\"\n",
    "    else:\n",
    "        platform_info = \"Win32\"\n",
    "        model = \"\"\n",
    "    RET_USER_AGENT = {\n",
    "        \"appVersion\" : ua.replace(\"Mozilla/\", \"\"),\n",
    "        \"userAgent\": ua,\n",
    "        \"platform\" : f\"{platform_info}\",\n",
    "        \"acceptLanguage\" : \"ko-KR, kr, en-US, en\",\n",
    "        \"userAgentMetadata\":{\n",
    "            \"brands\" : [\n",
    "                {\"brand\":\"Google Chrome\", \"version\":f\"{version}\"},\n",
    "                {\"brand\":\"Chromium\", \"version\":f\"{version}\"},\n",
    "                {\"brand\":\" Not A;Brand\", \"version\":\"99\"}\n",
    "            ],\n",
    "            \"fullVersionList\" : [\n",
    "                {\"brand\":\"Google Chrome\", \"version\":f\"{version}\"},\n",
    "                {\"brand\":\"Chromium\", \"version\":f\"{version}\"},\n",
    "                {\"brand\":\" Not A;Brand\", \"version\":\"99\"}\n",
    "            ],\n",
    "            \"fullVersion\":f\"{ua_full_version}\",\n",
    "            \"platform\" :platform,\n",
    "            \"platformVersion\":platform_version,\n",
    "            \"architecture\":architecture,\n",
    "            \"model\" : model,\n",
    "            \"mobile\":is_mobile\n",
    "        }\n",
    "    }\n",
    "    return RET_USER_AGENT\n",
    "\n",
    "def generate_random_geolocation():\n",
    "    \"\"\"ëœë¤ ì§€ë¦¬ì  ìœ„ì¹˜ ìƒì„±\"\"\"\n",
    "    ltop_lat = 37.75415601640249\n",
    "    ltop_long = 126.86767642302573\n",
    "    rbottom_lat = 37.593829172663945\n",
    "    rbottom_long = 127.15276051439332\n",
    "\n",
    "    targetLat = random.uniform(rbottom_lat, ltop_lat)\n",
    "    targetLong = random.uniform(ltop_long,rbottom_long)\n",
    "    return {\"latitude\":targetLat, \"longitude\" : targetLong, \"accuracy\":100}\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì • ë° ì‹¤í–‰\"\"\"\n",
    "    chromedriver_autoinstaller.install()\n",
    "    \n",
    "    options = uc.ChromeOptions()\n",
    "    \n",
    "    UA = CONFIG[\"USER_AGENT\"]\n",
    "    options.add_argument(f\"--user-agent={UA}\")\n",
    "    \n",
    "    rand_user_folder = random.randrange(1,100)\n",
    "    raw_path = os.path.abspath(\"cookies\")\n",
    "    try:\n",
    "        # shutil.rmtree(raw_path) # í´ë” ì‚­ì œ ë°©ì§€ë¥¼ ìœ„í•´ ì´ ì¤„ì„ ì£¼ì„ ì²˜ë¦¬\n",
    "        pass\n",
    "    except:\n",
    "        pass\n",
    "    os.makedirs(raw_path, exist_ok=True)\n",
    "    user_cookie_name = f\"{raw_path}/{rand_user_folder}\"\n",
    "    if os.path.exists(user_cookie_name) == False:\n",
    "        os.makedirs(user_cookie_name, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        driver = uc.Chrome(user_data_dir=user_cookie_name, options=options)\n",
    "        print(\"âœ… í¬ë¡¬ ë“œë¼ì´ë²„ ì‹¤í–‰ ì„±ê³µ!\")\n",
    "        print(platform.system())\n",
    "    except Exception as e:\n",
    "        print('\\n',\"-\"*50,'\\n',\"-\"*50,'\\n')\n",
    "        print(\"# í‚¤í™ˆ ë©”ì„¸ì§€ : í˜¹ì‹œ ì—¬ê¸°ì„œ ì—ëŸ¬ ë°œìƒì‹œ [ì•„ë˜ ë¸”ë¡œê·¸ ì°¸ê³  -> ì¬ë¶€íŒ… -> ë‹¤ì‹œ ì½”ë“œì‹¤í–‰] í•´ë³´ì‹œê¸¸ ë°”ëë‹ˆë‹¤! \\n (êµ¬ê¸€í¬ë¡¬ ë²„ì ¼ ì—…ê·¸ë ˆì´ë“œ ë¬¸ì œ)\")\n",
    "        raise RuntimeError\n",
    "        \n",
    "    UA_Data = make_user_agent(UA,False)\n",
    "    driver.execute_cdp_cmd(\"Network.setUserAgentOverride\",UA_Data)\n",
    "    \n",
    "    GEO_DATA = generate_random_geolocation()\n",
    "    driver.execute_cdp_cmd(\"Emulation.setGeolocationOverride\", GEO_DATA)\n",
    "    driver.execute_cdp_cmd(\"Emulation.setUserAgentOverride\", UA_Data)\n",
    "    driver.execute_cdp_cmd(\"Emulation.setNavigatorOverrides\",{\"platform\":\"Linux armv8l\"})\n",
    "    \n",
    "    return driver\n",
    "\n",
    "def go_to_main_page(driver):\n",
    "    \"\"\"KLOOK ë©”ì¸ í˜ì´ì§€ë¡œ ì´ë™\"\"\"\n",
    "    driver.get(\"https://www.klook.com/ko/search/result/?query=%EC%84%9C%EC%9A%B8\")\n",
    "    time.sleep(random.uniform(CONFIG[\"MEDIUM_MIN_DELAY\"], CONFIG[\"MEDIUM_MAX_DELAY\"]))\n",
    "    # ğŸ†• ë©”ì¸ í˜ì´ì§€ ìì—°ìŠ¤ëŸ¬ìš´ íƒìƒ‰\n",
    "    smart_scroll_selector(driver)\n",
    "    return True\n",
    "\n",
    "def find_and_fill_search(driver, city_name):\n",
    "    \"\"\"ê²€ìƒ‰ì°½ ì°¾ê¸° ë° ì¸ê°„ì ì¸ íƒ€ì´í•‘ ì ìš©\"\"\"\n",
    "    print(f\"  ğŸ” '{city_name}' ê²€ìƒ‰ì°½ ì°¾ëŠ” ì¤‘...\")\n",
    "    search_selectors = [\n",
    "        (By.CSS_SELECTOR, \"#js-header-search-box input\"),          # KLOOK ìµœìš°ì„ \n",
    "        (By.CSS_SELECTOR, \"input[name='klkHeadSearch']\"),          # KLOOK name ì†ì„± ê¸°ë°˜\n",
    "        (By.CSS_SELECTOR, \".search-box_input\"),                   # KLOOK í´ë˜ìŠ¤ ê¸°ë°˜\n",
    "        (By.XPATH, \"//input[@placeholder='ì–´ë””ë¡œ ë†€ëŸ¬ ê°€ì„¸ìš”?']\"),    # KLOOK placeholder ê¸°ë°˜\n",
    "    ]\n",
    "\n",
    "    search_input = None\n",
    "    for selector_type, selector_value in search_selectors:\n",
    "        try:\n",
    "            search_input = WebDriverWait(driver, CONFIG[\"WAIT_TIMEOUT\"]).until(\n",
    "                EC.presence_of_element_located((selector_type, selector_value))\n",
    "            )\n",
    "            print(f\"  âœ… ê²€ìƒ‰ì°½ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!\")\n",
    "            break\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "\n",
    "    if not search_input:\n",
    "        raise NoSuchElementException(\"ê²€ìƒ‰ì°½ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "\n",
    "    # [ìˆ˜ì •] ì‚¬ëŒì²˜ëŸ¼ í•œ ê¸€ìì”© íƒ€ì´í•‘í•˜ëŠ” ë¡œì§\n",
    "    search_input.clear()\n",
    "    for char in city_name:\n",
    "        search_input.send_keys(char)\n",
    "        # ê° ê¸€ì ì‚¬ì´ì— ì•„ì£¼ ì§§ì€ ë¬´ì‘ìœ„ ë”œë ˆì´ ì¶”ê°€\n",
    "        time.sleep(random.uniform(CONFIG[\"SHORT_MIN_DELAY\"], CONFIG[\"SHORT_MAX_DELAY\"]))\n",
    "    \n",
    "    # ë‹¨ì–´ ì…ë ¥ í›„ ì ì‹œ ìƒê°í•˜ëŠ” ê²ƒì²˜ëŸ¼ ëŒ€ê¸°\n",
    "    time.sleep(random.uniform(1, 2))\n",
    "    print(f\"  ğŸ“ '{city_name}' í‚¤ì›Œë“œ ì…ë ¥ ì™„ë£Œ\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def click_search_button(driver):\n",
    "    \"\"\"ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­\"\"\"\n",
    "    print(f\"  ğŸ” ê²€ìƒ‰ ë²„íŠ¼ ì°¾ëŠ” ì¤‘...\")\n",
    "    search_button_selectors = [\n",
    "        (By.CSS_SELECTOR, \"#js-header-search-box button\"),        # KLOOK ìµœìš°ì„ \n",
    "        (By.CSS_SELECTOR, \"#js-header-search-box > button\"),     # KLOOK êµ¬ì²´ì  ë²„ì „\n",
    "        (By.XPATH, \"//div[@id='js-header-search-box']//button\"),  # KLOOK xpath ë°±ì—…\n",
    "    ]\n",
    "    search_clicked = False\n",
    "    for selector_type, selector_value in search_button_selectors:\n",
    "        try:\n",
    "            search_button = WebDriverWait(driver, CONFIG[\"WAIT_TIMEOUT\"]).until(\n",
    "                EC.element_to_be_clickable((selector_type, selector_value))\n",
    "            )\n",
    "            search_button.click()\n",
    "            print(f\"  âœ… ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­ ì„±ê³µ!\")\n",
    "            search_clicked = True\n",
    "            time.sleep(random.uniform(CONFIG[\"MEDIUM_MIN_DELAY\"], CONFIG[\"MEDIUM_MAX_DELAY\"]))\n",
    "            break\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "\n",
    "    if not search_clicked:\n",
    "        raise NoSuchElementException(\"ê²€ìƒ‰ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "    return True\n",
    "\n",
    "def handle_popup(driver):\n",
    "    \"\"\"íŒì—… ì²˜ë¦¬\"\"\"\n",
    "    popup_selectors = [\n",
    "        (By.CSS_SELECTOR, \".popup-close\"),\n",
    "        (By.CSS_SELECTOR, \".modal-close\"),\n",
    "        (By.XPATH, \"//button[contains(@aria-label, 'ë‹«ê¸°')]\"),\n",
    "        (By.XPATH, \"//button[contains(text(), 'ë‹«ê¸°')]\"),\n",
    "        (By.XPATH, \"/html/body/div[15]/div[2]/button\")\n",
    "    ]\n",
    "\n",
    "    popup_closed = False\n",
    "    for selector_type, selector_value in popup_selectors:\n",
    "        try:\n",
    "            popup_button = WebDriverWait(driver, CONFIG[\"POPUP_WAIT\"]).until(\n",
    "                EC.element_to_be_clickable((selector_type, selector_value))\n",
    "            )\n",
    "            popup_button.click()\n",
    "            print(f\"  âœ… íŒì—…ì°½ì„ ë‹«ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "            popup_closed = True\n",
    "            time.sleep(random.uniform(1, 4))\n",
    "            break\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "\n",
    "    if not popup_closed:\n",
    "        print(f\"  â„¹ï¸ íŒì—…ì°½ì´ ì—†ê±°ë‚˜ ì´ë¯¸ ë‹«í˜€ìˆìŠµë‹ˆë‹¤.\")\n",
    "    return True\n",
    "\n",
    "def click_view_all(driver):\n",
    "    \"\"\"ì „ì²´ ìƒí’ˆ ë³´ê¸° ë²„íŠ¼ í´ë¦­ (ì•ˆì •ì„± ê°•í™”)\"\"\"\n",
    "    print(f\"  ğŸ“‹ ì „ì²´ ìƒí’ˆ ë³´ê¸° ë²„íŠ¼ ì°¾ëŠ” ì¤‘...\")\n",
    "    \n",
    "    view_all_selectors = [\n",
    "        (By.XPATH, \"//button[contains(text(), 'ì „ì²´')]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'ì „ì²´')]//parent::button\"),\n",
    "        (By.CSS_SELECTOR, \"button[aria-label*='ì „ì²´']\"),\n",
    "        (By.XPATH, \"/html/body/div[4]/div[2]/div/div/div/span[21]/button\")\n",
    "    ]\n",
    "\n",
    "    view_all_clicked = False\n",
    "    for selector_type, selector_value in view_all_selectors:\n",
    "        try:\n",
    "            view_all_button = WebDriverWait(driver, CONFIG[\"WAIT_TIMEOUT\"]).until(\n",
    "                EC.element_to_be_clickable((selector_type, selector_value))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_all_button)\n",
    "            \n",
    "            print(f\"  âœ… ì „ì²´ ìƒí’ˆ ë³´ê¸° í´ë¦­ ì„±ê³µ!\")\n",
    "            view_all_clicked = True\n",
    "            time.sleep(random.uniform(CONFIG[\"MEDIUM_MIN_DELAY\"], CONFIG[\"MEDIUM_MAX_DELAY\"]))\n",
    "            break\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "\n",
    "    if not view_all_clicked:\n",
    "        print(f\"  âš ï¸ ì „ì²´ ìƒí’ˆ ë³´ê¸° ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ìƒí’ˆìœ¼ë¡œ ì§„í–‰...\")\n",
    "        \n",
    "    return True\n",
    "\n",
    "def safe_browser_restart():\n",
    "    \"\"\"ì•ˆì „í•œ ë¸Œë¼ìš°ì € ì¬ì‹œì‘ with 3ë²ˆ ì¬ì‹œë„\"\"\"\n",
    "    global driver\n",
    "    \n",
    "    for attempt in range(3):  # 3ë²ˆ ì‹œë„\n",
    "        try:\n",
    "            print(f\"ğŸ”„ ë¸Œë¼ìš°ì € ì¬ì‹œì‘ ì‹œë„ {attempt+1}/3...\")\n",
    "            \n",
    "            # 1ë‹¨ê³„: ì•ˆì „í•œ ì¢…ë£Œ\n",
    "            if 'driver' in globals() and driver:\n",
    "                driver.quit()\n",
    "                driver = None\n",
    "            \n",
    "            # 2ë‹¨ê³„: ëŒ€ê¸° ë° ì •ë¦¬\n",
    "            wait_time = random.uniform(5, 10)\n",
    "            print(f\"â° {wait_time:.1f}ì´ˆ ëŒ€ê¸° ì¤‘...\")\n",
    "            time.sleep(wait_time)\n",
    "            \n",
    "            # 3ë‹¨ê³„: ìƒˆ ë¸Œë¼ìš°ì € ì‹œì‘\n",
    "            print(\"ğŸš€ ìƒˆ ë¸Œë¼ìš°ì € ì‹œì‘ ì¤‘...\")\n",
    "            driver = setup_driver()\n",
    "            \n",
    "            # 4ë‹¨ê³„: ë™ì‘ ê²€ì¦\n",
    "            print(\"ğŸ” ë¸Œë¼ìš°ì € ë™ì‘ ê²€ì¦ ì¤‘...\")\n",
    "            driver.get(\"https://www.klook.com/\")\n",
    "            time.sleep(2)\n",
    "            \n",
    "            print(\"âœ… ë¸Œë¼ìš°ì € ì¬ì‹œì‘ ì„±ê³µ!\")\n",
    "            return True, \"ì¬ì‹œì‘ ì„±ê³µ\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì¬ì‹œì‘ ì‹œë„ {attempt+1} ì‹¤íŒ¨: {type(e).__name__}: {e}\")\n",
    "            if attempt == 2:  # ë§ˆì§€ë§‰ ì‹œë„\n",
    "                print(\"ğŸš¨ ë¸Œë¼ìš°ì € ì¬ì‹œì‘ ìµœì¢… ì‹¤íŒ¨!\")\n",
    "                return False, f\"ì¬ì‹œì‘ ë¶ˆê°€: {e}\"\n",
    "            print(f\"ğŸ”„ {3-attempt-1}ì´ˆ í›„ ì¬ì‹œë„...\")\n",
    "            time.sleep(3)  # ë‹¤ìŒ ì‹œë„ ì „ ëŒ€ê¸°\n",
    "    \n",
    "    return False, \"ìµœì¢… ì‹¤íŒ¨\"\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ› ï¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (ì§„í–‰ë¥  í‘œì‹œ, ì¬ì‹œë„ ë¡œì§ ë“±)\n",
    "# =============================================================================\n",
    "\n",
    "def print_progress(current, total, city_name, status=\"ì§„í–‰ì¤‘\"):\n",
    "    \"\"\"ì§„í–‰ë¥ ì„ ì‹œê°ì ìœ¼ë¡œ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    percentage = (current / total) * 100\n",
    "    bar_length = 30\n",
    "    filled_length = int(bar_length * current // total)\n",
    "    bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)\n",
    "    \n",
    "    emoji = \"ğŸ”\" if status == \"ì§„í–‰ì¤‘\" else \"âœ…\" if status == \"ì™„ë£Œ\" else \"âŒ\"\n",
    "    \n",
    "    print(f\"\\n{emoji} ì§„í–‰ë¥ : [{bar}] {percentage:.1f}% ({current}/{total})\")\n",
    "    print(f\"ğŸ“ í˜„ì¬ ì‘ì—…: {city_name} - {status}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "def print_product_progress(current, total, product_name):\n",
    "    \"\"\"ìƒí’ˆë³„ ì§„í–‰ë¥  í‘œì‹œ í•¨ìˆ˜\"\"\"\n",
    "    percentage = (current / total) * 100\n",
    "    bar_length = 20\n",
    "    filled_length = int(bar_length * current // total)\n",
    "    bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)\n",
    "    \n",
    "    safe_name = str(product_name)[:30] + \"...\" if len(str(product_name)) > 30 else str(product_name)\n",
    "    print(f\"    ğŸ¯ ìƒí’ˆ ì§„í–‰ë¥ : [{bar}] {percentage:.1f}% ({current}/{total})\")\n",
    "    print(f\"    ğŸ“¦ í˜„ì¬ ìƒí’ˆ: {safe_name}\")\n",
    "\n",
    "def save_intermediate_results(results, city_name):\n",
    "    \"\"\"ì¤‘ê°„ ê²°ê³¼ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    if results and CONFIG.get(\"SAVE_INTERMEDIATE\", False):\n",
    "        try:\n",
    "            timestamp = time.strftime('%Y%m%d_%H%M%S')\n",
    "            temp_filename = f\"temp_ì¤‘ê°„ì €ì¥_{city_name}_{timestamp}.csv\"\n",
    "            pd.DataFrame(results).to_csv(temp_filename, index=False, encoding='utf-8-sig')\n",
    "            print(f\"  ğŸ’¾ ì¤‘ê°„ ê²°ê³¼ ì €ì¥: {temp_filename}\")\n",
    "            return temp_filename\n",
    "        except Exception as e:\n",
    "            print(f\"  âš ï¸ ì¤‘ê°„ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def retry_operation(func, operation_name, max_retries=None):\n",
    "    \"\"\"ì‹¤íŒ¨í•œ ì‘ì—…ì„ ì¬ì‹œë„í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    if max_retries is None:\n",
    "        max_retries = CONFIG[\"RETRY_COUNT\"]\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return func()\n",
    "        except (TimeoutException, NoSuchElementException, WebDriverException) as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                print(f\"  âŒ {operation_name} ìµœì¢… ì‹¤íŒ¨: {type(e).__name__}\")\n",
    "                raise e\n",
    "            print(f\"  ğŸ”„ {operation_name} ì¬ì‹œë„ {attempt + 1}/{max_retries} (ì˜¤ë¥˜: {type(e).__name__})\")\n",
    "            time.sleep(2)\n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ {operation_name} ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {type(e).__name__}: {e}\")\n",
    "            raise e\n",
    "\n",
    "def make_safe_filename(filename):\n",
    "    \"\"\"íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°\"\"\"\n",
    "    if not filename:\n",
    "        return \"ê¸°ë³¸íŒŒì¼ëª…\"\n",
    "    \n",
    "    safe_filename = str(filename)\n",
    "    unsafe_chars = ['/', '\\\\', ':', '*', '?', '\"', '<', '>', '|', '\\n', '\\r', '\\t']\n",
    "    for char in unsafe_chars:\n",
    "        safe_filename = safe_filename.replace(char, '_')\n",
    "    \n",
    "    if len(safe_filename) > 200:\n",
    "        safe_filename = safe_filename[:200]\n",
    "    \n",
    "    if safe_filename.startswith('.'):\n",
    "        safe_filename = '_' + safe_filename[1:]\n",
    "    \n",
    "    return safe_filename\n",
    "\n",
    "# =============================================================================\n",
    "# âš¡ í˜ì´ì§€ ë¡œë”© ìµœì í™” ì‹œìŠ¤í…œ (ê·¸ë£¹ 5 í™•ì¥)\n",
    "# =============================================================================\n",
    "\n",
    "def smart_wait_for_page_load(driver, max_wait=None):\n",
    "    \"\"\"ë™ì  ëŒ€ê¸°ì‹œê°„ - í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ ê°ì§€\"\"\"\n",
    "    if max_wait is None:\n",
    "        max_wait = CONFIG.get(\"SMART_WAIT_MAX\", 8)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < max_wait:\n",
    "        try:\n",
    "            if driver.execute_script(\"return document.readyState\") == \"complete\":\n",
    "                # í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ í›„ ìµœì†Œ ëŒ€ê¸°\n",
    "                time.sleep(random.uniform(0.5, 1.5))\n",
    "                return True\n",
    "        except (WebDriverException, Exception):\n",
    "            pass\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    # ìµœëŒ€ ëŒ€ê¸°ì‹œê°„ ì´ˆê³¼ ì‹œì—ë„ ìµœì†Œ ëŒ€ê¸°\n",
    "    time.sleep(random.uniform(1, 2))\n",
    "    return False\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ”§ í˜ì´ì§€ ë¡œë”© ìµœì í™” ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤\n",
    "# =============================================================================\n",
    "\n",
    "def wait_for_page_ready(driver, timeout=10):\n",
    "    \"\"\"í˜ì´ì§€ê°€ ì™„ì „íˆ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°\"\"\"\n",
    "    try:\n",
    "        WebDriverWait(driver, timeout).until(\n",
    "            lambda d: d.execute_script(\"return document.readyState\") == \"complete\"\n",
    "        )\n",
    "        return True\n",
    "    except TimeoutException:\n",
    "        print(f\"      âš ï¸ í˜ì´ì§€ ì¤€ë¹„ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼ ({timeout}ì´ˆ)\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"      âŒ í˜ì´ì§€ ì¤€ë¹„ í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def adaptive_wait(base_time=2):\n",
    "    \"\"\"ì ì‘í˜• ëŒ€ê¸° ì‹œê°„ (ì‹œìŠ¤í…œ ë¶€í•˜ì— ë”°ë¼ ì¡°ì •)\"\"\"\n",
    "    # CONFIGì—ì„œ ì„¤ì •ëœ ë²”ìœ„ ë‚´ì—ì„œ ëœë¤ ëŒ€ê¸°\n",
    "    min_delay = CONFIG.get(\"SHORT_MIN_DELAY\", 0.2)\n",
    "    max_delay = CONFIG.get(\"SHORT_MAX_DELAY\", 0.5)\n",
    "    \n",
    "    # ê¸°ë³¸ ì‹œê°„ì— ëœë¤ ìš”ì†Œ ì¶”ê°€\n",
    "    wait_time = base_time + random.uniform(min_delay, max_delay)\n",
    "    time.sleep(wait_time)\n",
    "    return wait_time\n",
    "\n",
    "\n",
    "def safe_tab_operation(driver, operation_func, *args, **kwargs):\n",
    "    \"\"\"ì•ˆì „í•œ íƒ­ ì‘ì—… ìˆ˜í–‰ (ì—ëŸ¬ ë³µêµ¬ í¬í•¨)\"\"\"\n",
    "    main_tab = driver.current_window_handle\n",
    "    \n",
    "    try:\n",
    "        result = operation_func(*args, **kwargs)\n",
    "        return True, result\n",
    "    except Exception as e:\n",
    "        print(f\"      âŒ íƒ­ ì‘ì—… ì‹¤íŒ¨: {e}\")\n",
    "        try:\n",
    "            # ë©”ì¸ íƒ­ìœ¼ë¡œ ë³µê·€ ì‹œë„\n",
    "            driver.switch_to.window(main_tab)\n",
    "            return False, f\"íƒ­ ì‘ì—… ì‹¤íŒ¨: {e}\"\n",
    "        except Exception as recovery_error:\n",
    "            print(f\"      ğŸš¨ íƒ­ ë³µêµ¬ë„ ì‹¤íŒ¨: {recovery_error}\")\n",
    "            return False, f\"íƒ­ ë³µêµ¬ ì‹¤íŒ¨: {recovery_error}\"\n",
    "        \n",
    "def human_like_scroll_patterns(driver):\n",
    "    \"\"\"ğŸ­ ìˆœìˆ˜ ìŠ¤í¬ë¡¤ íŒ¨í„´ë§Œ (ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ì¤‘ë³µ ì—†ìŒ)\"\"\"\n",
    "    patterns = [\"smooth_reading\", \"comparison_scroll\", \"quick_scan\"]\n",
    "    selected = random.choice(patterns)\n",
    "    \n",
    "    try:\n",
    "        if selected == \"smooth_reading\":\n",
    "            for i in range(3, 6):\n",
    "                scroll_amount = random.randint(250, 500)\n",
    "                driver.execute_script(f\"\"\"\n",
    "                    function smoothScroll(distance) {{\n",
    "                        const startY = window.pageYOffset;\n",
    "                        const targetY = startY + distance;\n",
    "                        const duration = 800 + Math.random() * 400;\n",
    "                        let start = null;\n",
    "                        function step(timestamp) {{\n",
    "                            if (!start) start = timestamp;\n",
    "                            const progress = Math.min((timestamp - start) / duration, 1);\n",
    "                            const easing = progress < 0.5 ? 2 * progress * progress : -1 + (4 - 2 * progress) * progress;\n",
    "                            const currentY = startY + (targetY - startY) * easing;\n",
    "                            window.scrollTo(0, currentY);\n",
    "                            if (progress < 1) requestAnimationFrame(step);\n",
    "                        }}\n",
    "                        requestAnimationFrame(step);\n",
    "                    }}\n",
    "                    smoothScroll({scroll_amount});\n",
    "                \"\"\")\n",
    "                time.sleep(random.uniform(0.5, 2.0))\n",
    "\n",
    "        elif selected == \"comparison_scroll\":\n",
    "            for i in range(2, 4):\n",
    "                down_amount = random.randint(400, 700)\n",
    "                driver.execute_script(f\"\"\"\n",
    "                    function smoothScroll(distance) {{\n",
    "                        const startY = window.pageYOffset;\n",
    "                        const targetY = startY + distance;\n",
    "                        const duration = 1000 + Math.random() * 500;\n",
    "                        let start = null;\n",
    "                        function step(timestamp) {{\n",
    "                            if (!start) start = timestamp;\n",
    "                            const progress = Math.min((timestamp - start) / duration, 1);\n",
    "                            const easing = progress < 0.5 ? 2 * progress * progress : -1 + (4 - 2 * progress) * progress;\n",
    "                            const currentY = startY + (targetY - startY) * easing;\n",
    "                            window.scrollTo(0, currentY);\n",
    "                            if (progress < 1) requestAnimationFrame(step);\n",
    "                        }}\n",
    "                        requestAnimationFrame(step);\n",
    "                    }}\n",
    "                    smoothScroll({down_amount});\n",
    "                \"\"\")\n",
    "                time.sleep(random.uniform(0.5, 2.0))\n",
    "\n",
    "                up_amount = random.randint(100, 300)\n",
    "                driver.execute_script(f\"\"\"\n",
    "                    function smoothScroll(distance) {{\n",
    "                        const startY = window.pageYOffset;\n",
    "                        const targetY = startY - distance;\n",
    "                        const duration = 600 + Math.random() * 300;\n",
    "                        let start = null;\n",
    "                        function step(timestamp) {{\n",
    "                            if (!start) start = timestamp;\n",
    "                            const progress = Math.min((timestamp - start) / duration, 1);\n",
    "                            const easing = progress < 0.5 ? 2 * progress * progress : -1 + (4 - 2 * progress) * progress;\n",
    "                            const currentY = startY + (targetY - startY) * easing;\n",
    "                            window.scrollTo(0, currentY);\n",
    "                            if (progress < 1) requestAnimationFrame(step);\n",
    "                        }}\n",
    "                        requestAnimationFrame(step);\n",
    "                    }}\n",
    "                    smoothScroll({up_amount});\n",
    "                \"\"\")\n",
    "                time.sleep(random.uniform(0.5, 2.0))\n",
    "\n",
    "        elif selected == \"quick_scan\":\n",
    "            for i in range(4, 8):\n",
    "                scroll_amount = random.randint(300, 600)\n",
    "                driver.execute_script(f\"\"\"\n",
    "                    function smoothScroll(distance) {{\n",
    "                        const startY = window.pageYOffset;\n",
    "                        const targetY = startY + distance;\n",
    "                        const duration = 800 + Math.random() * 400;\n",
    "                        let start = null;\n",
    "                        function step(timestamp) {{\n",
    "                            if (!start) start = timestamp;\n",
    "                            const progress = Math.min((timestamp - start) / duration, 1);\n",
    "                            const easing = progress < 0.5 ? 2 * progress * progress : -1 + (4 - 2 * progress) * progress;\n",
    "                            const currentY = startY + (targetY - startY) * easing;\n",
    "                            window.scrollTo(0, currentY);\n",
    "                            if (progress < 1) requestAnimationFrame(step);\n",
    "                        }}\n",
    "                        requestAnimationFrame(step);\n",
    "                    }}\n",
    "                    smoothScroll({scroll_amount});\n",
    "                \"\"\")\n",
    "                time.sleep(random.uniform(0.25, 1.0))\n",
    "\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸ ìŠ¤í¬ë¡¤ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "\n",
    "def enhanced_scroll_patterns(driver):\n",
    "    \"\"\"ğŸ­ í–¥ìƒëœ 5ê°€ì§€ ìŠ¤í¬ë¡¤ íŒ¨í„´ (í˜¸í™˜ì„± ê°œì„  ë²„ì „)\"\"\"\n",
    "    patterns = [\n",
    "        \"natural_reading\",      # ìì—°ìŠ¤ëŸ¬ìš´ ì½ê¸°\n",
    "        \"search_and_compare\",   # ê²€ìƒ‰í•˜ê³  ë¹„êµí•˜ê¸°\n",
    "        \"rapid_overview\",       # ë¹ ë¥¸ ê°œìš” íŒŒì•…\n",
    "        \"detailed_inspection\",  # ìì„¸í•œ ê²€ì‚¬\n",
    "        \"hesitant_browsing\"     # ë§ì„¤ì´ë©° íƒìƒ‰\n",
    "    ]\n",
    "\n",
    "    selected = random.choice(patterns)\n",
    "    \n",
    "    try:\n",
    "        if selected == \"natural_reading\":\n",
    "            # ìì—°ìŠ¤ëŸ¬ìš´ ì½ê¸° íŒ¨í„´ - ì¼ì •í•œ ì†ë„ë¡œ ì•„ë˜ë¡œ\n",
    "            for i in range(4, 7):\n",
    "                scroll_amount = random.randint(200, 400)\n",
    "                driver.execute_script(f\"\"\"\n",
    "                    function smoothScroll(distance) {{\n",
    "                        const startY = window.pageYOffset;\n",
    "                        const targetY = startY + distance;\n",
    "                        const duration = 800 + Math.random() * 400;\n",
    "                        let start = null;\n",
    "                        function step(timestamp) {{\n",
    "                            if (!start) start = timestamp;\n",
    "                            const progress = Math.min((timestamp - start) / duration, 1);\n",
    "                            const easing = progress < 0.5 ? 2 * progress * progress : -1 + (4 - 2 * progress) * progress;\n",
    "                            const currentY = startY + (targetY - startY) * easing;\n",
    "                            window.scrollTo(0, currentY);\n",
    "                            if (progress < 1) requestAnimationFrame(step);\n",
    "                        }}\n",
    "                        requestAnimationFrame(step);\n",
    "                    }}\n",
    "                    smoothScroll({scroll_amount});\n",
    "                \"\"\")\n",
    "\n",
    "                # ì½ê¸° ì‹œê°„ - ë‚´ìš©ì— ë”°ë¼ ë‹¤ë¦„\n",
    "                reading_time = random.uniform(1.5, 3.5)\n",
    "                time.sleep(reading_time)\n",
    "\n",
    "                # ê°€ë” ì¡°ê¸ˆ ìœ„ë¡œ ë˜ëŒì•„ê°€ê¸° (ì¬í™•ì¸)\n",
    "                if random.random() < 0.3:\n",
    "                    back_scroll = random.randint(50, 150)\n",
    "                    driver.execute_script(f\"\"\"\n",
    "                        function smoothScroll(distance) {{\n",
    "                            const startY = window.pageYOffset;\n",
    "                            const targetY = startY - distance;\n",
    "                            const duration = 400 + Math.random() * 200;\n",
    "                            let start = null;\n",
    "                            function step(timestamp) {{\n",
    "                                if (!start) start = timestamp;\n",
    "                                const progress = Math.min((timestamp - start) / duration, 1);\n",
    "                                const easing = progress < 0.5 ? 2 * progress * progress : -1 + (4 - 2 * progress) * progress;\n",
    "                                const currentY = startY + (targetY - startY) * easing;\n",
    "                                window.scrollTo(0, currentY);\n",
    "                                if (progress < 1) requestAnimationFrame(step);\n",
    "                            }}\n",
    "                            requestAnimationFrame(step);\n",
    "                        }}\n",
    "                        smoothScroll({back_scroll});\n",
    "                    \"\"\")\n",
    "                    time.sleep(random.uniform(0.5, 1.0))\n",
    "\n",
    "        elif selected == \"search_and_compare\":\n",
    "            # íŠ¹ì • í•­ëª©ì„ ì°¾ê³  ë¹„êµí•˜ëŠ” íŒ¨í„´\n",
    "            for i in range(3, 6):\n",
    "                # ë¹ ë¥´ê²Œ ìŠ¤í¬ë¡¤í•´ì„œ í›‘ì–´ë³´ê¸°\n",
    "                fast_scroll = random.randint(500, 800)\n",
    "                driver.execute_script(f\"\"\"\n",
    "                    function smoothScroll(distance) {{\n",
    "                        const startY = window.pageYOffset;\n",
    "                        const targetY = startY + distance;\n",
    "                        const duration = 800 + Math.random() * 400;\n",
    "                        let start = null;\n",
    "                        function step(timestamp) {{\n",
    "                            if (!start) start = timestamp;\n",
    "                            const progress = Math.min((timestamp - start) / duration, 1);\n",
    "                            const easing = 1 - Math.pow(1 - progress, 4);\n",
    "                            const currentY = startY + (targetY - startY) * easing;\n",
    "                            window.scrollTo(0, currentY);\n",
    "                            if (progress < 1) requestAnimationFrame(step);\n",
    "                        }}\n",
    "                        requestAnimationFrame(step);\n",
    "                    }}\n",
    "                    smoothScroll({fast_scroll});\n",
    "                \"\"\")\n",
    "                time.sleep(random.uniform(0.8, 1.5))\n",
    "\n",
    "                # ê´€ì‹¬ ìˆëŠ” ë¶€ë¶„ì—ì„œ ë©ˆì¶°ì„œ ìì„¸íˆ ë³´ê¸°\n",
    "                if random.random() < 0.6:\n",
    "                    # ìœ„ë¡œ ì¡°ê¸ˆ ë˜ëŒì•„ê°€ì„œ ë‹¤ì‹œ ë³´ê¸°\n",
    "                    back_amount = random.randint(200, 400)\n",
    "                    driver.execute_script(f\"\"\"\n",
    "                        function smoothScroll(distance) {{\n",
    "                            const startY = window.pageYOffset;\n",
    "                            const targetY = startY - distance;\n",
    "                            const duration = 600 + Math.random() * 300;\n",
    "                            let start = null;\n",
    "                            function step(timestamp) {{\n",
    "                                if (!start) start = timestamp;\n",
    "                                const progress = Math.min((timestamp - start) / duration, 1);\n",
    "                                const easing = progress < 0.5 ? 2 * progress * progress : -1 + (4 - 2 * progress) * progress;\n",
    "                                const currentY = startY + (targetY - startY) * easing;\n",
    "                                window.scrollTo(0, currentY);\n",
    "                                if (progress < 1) requestAnimationFrame(step);\n",
    "                            }}\n",
    "                            requestAnimationFrame(step);\n",
    "                        }}\n",
    "                        smoothScroll({back_amount});\n",
    "                    \"\"\")\n",
    "                    time.sleep(random.uniform(2.0, 4.0))  # ë¹„êµ ê²€í†  ì‹œê°„\n",
    "\n",
    "                    # ë‹¤ì‹œ ì•„ë˜ë¡œ ì¡°ê¸ˆ\n",
    "                    forward_amount = random.randint(100, 300)\n",
    "                    driver.execute_script(f\"\"\"\n",
    "                        function smoothScroll(distance) {{\n",
    "                            const startY = window.pageYOffset;\n",
    "                            const targetY = startY + distance;\n",
    "                            const duration = 500 + Math.random() * 200;\n",
    "                            let start = null;\n",
    "                            function step(timestamp) {{\n",
    "                                if (!start) start = timestamp;\n",
    "                                const progress = Math.min((timestamp - start) / duration, 1);\n",
    "                                const easing = progress < 0.5 ? 2 * progress * progress : -1 + (4 - 2 * progress) * progress;\n",
    "                                const currentY = startY + (targetY - startY) * easing;\n",
    "                                window.scrollTo(0, currentY);\n",
    "                                if (progress < 1) requestAnimationFrame(step);\n",
    "                            }}\n",
    "                            requestAnimationFrame(step);\n",
    "                        }}\n",
    "                        smoothScroll({forward_amount});\n",
    "                    \"\"\")\n",
    "                    time.sleep(random.uniform(1.0, 2.0))\n",
    "\n",
    "        elif selected == \"rapid_overview\":\n",
    "            # ë¹ ë¥¸ ê°œìš” íŒŒì•… - ì „ì²´ì ìœ¼ë¡œ í›‘ì–´ë³´ê¸°\n",
    "            for i in range(6, 10):\n",
    "                scroll_amount = random.randint(400, 700)\n",
    "                driver.execute_script(f\"\"\"\n",
    "                    function smoothScroll(distance) {{\n",
    "                        const startY = window.pageYOffset;\n",
    "                        const targetY = startY + distance;\n",
    "                        const duration = 800 + Math.random() * 400;\n",
    "                        let start = null;\n",
    "                        function step(timestamp) {{\n",
    "                            if (!start) start = timestamp;\n",
    "                            const progress = Math.min((timestamp - start) / duration, 1);\n",
    "                            const easing = progress < 0.5 ? 2 * progress * progress : -1 + (4 - 2 * progress) * progress;\n",
    "                            const currentY = startY + (targetY - startY) * easing;\n",
    "                            window.scrollTo(0, currentY);\n",
    "                            if (progress < 1) requestAnimationFrame(step);\n",
    "                        }}\n",
    "                        requestAnimationFrame(step);\n",
    "                    }}\n",
    "                    smoothScroll({scroll_amount});\n",
    "                \"\"\")\n",
    "                time.sleep(random.uniform(0.3, 0.8))  # ì§§ì€ ì •ì§€\n",
    "\n",
    "        elif selected == \"detailed_inspection\":\n",
    "            # ìì„¸í•œ ê²€ì‚¬ - ì²œì²œíˆ ê¼¼ê¼¼íˆ\n",
    "            for i in range(3, 5):\n",
    "                small_scroll = random.randint(150, 300)\n",
    "                driver.execute_script(f\"\"\"\n",
    "                    function smoothScroll(distance) {{\n",
    "                        const startY = window.pageYOffset;\n",
    "                        const targetY = startY + distance;\n",
    "                        const duration = 1500 + Math.random() * 800;\n",
    "                        let start = null;\n",
    "                        function step(timestamp) {{\n",
    "                            if (!start) start = timestamp;\n",
    "                            const progress = Math.min((timestamp - start) / duration, 1);\n",
    "                            const easing = -(Math.cos(Math.PI * progress) - 1) / 2;\n",
    "                            const currentY = startY + (targetY - startY) * easing;\n",
    "                            window.scrollTo(0, currentY);\n",
    "                            if (progress < 1) requestAnimationFrame(step);\n",
    "                        }}\n",
    "                        requestAnimationFrame(step);\n",
    "                    }}\n",
    "                    smoothScroll({small_scroll});\n",
    "                \"\"\")\n",
    "\n",
    "                # ê¸´ ê²€í†  ì‹œê°„\n",
    "                inspection_time = random.uniform(3.0, 6.0)\n",
    "                time.sleep(inspection_time)\n",
    "\n",
    "                # ğŸ”§ í˜¸í™˜ì„± ê°œì„ : ë³µì¡í•œ ë§ˆìš°ìŠ¤ ì´ë²¤íŠ¸ ì œê±°\n",
    "                # ê°„ë‹¨í•œ ë§ˆìš°ìŠ¤ ì›€ì§ì„ë§Œ ì‹œë®¬ë ˆì´ì…˜\n",
    "                if random.random() < 0.5:  # 50%ë¡œ í™•ë¥  ë‚®ì¶¤\n",
    "                    try:\n",
    "                        driver.execute_script(\"\"\"\n",
    "                            var event = new MouseEvent('mousemove', {\n",
    "                                clientX: Math.random() * 500,\n",
    "                                clientY: Math.random() * 300\n",
    "                            });\n",
    "                            document.dispatchEvent(event);\n",
    "                        \"\"\")\n",
    "                        time.sleep(random.uniform(0.5, 1.0))\n",
    "                    except:\n",
    "                        pass  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¬´ì‹œ\n",
    "\n",
    "        elif selected == \"hesitant_browsing\":\n",
    "            # ë§ì„¤ì´ë©° íƒìƒ‰í•˜ëŠ” íŒ¨í„´\n",
    "            for i in range(4, 8):\n",
    "                # ì¡°ê¸ˆ ìŠ¤í¬ë¡¤\n",
    "                hesitant_scroll = random.randint(200, 400)\n",
    "                driver.execute_script(f\"\"\"\n",
    "                    function smoothScroll(distance) {{\n",
    "                        const startY = window.pageYOffset;\n",
    "                        const targetY = startY + distance;\n",
    "                        const duration = 1000 + Math.random() * 500;\n",
    "                        let start = null;\n",
    "                        function step(timestamp) {{\n",
    "                            if (!start) start = timestamp;\n",
    "                            const progress = Math.min((timestamp - start) / duration, 1);\n",
    "                            const c1 = 1.70158;\n",
    "                            const c2 = c1 * 1.525;\n",
    "                            const easing = progress < 0.5\n",
    "                                ? (Math.pow(2 * progress, 2) * ((c2 + 1) * 2 * progress - c2)) / 2\n",
    "                                : (Math.pow(2 * progress - 2, 2) * ((c2 + 1) * (progress * 2 - 2) + c2) + 2) / 2;\n",
    "                            const currentY = startY + (targetY - startY) * easing;\n",
    "                            window.scrollTo(0, currentY);\n",
    "                            if (progress < 1) requestAnimationFrame(step);\n",
    "                        }}\n",
    "                        requestAnimationFrame(step);\n",
    "                    }}\n",
    "                    smoothScroll({hesitant_scroll});\n",
    "                \"\"\")\n",
    "                time.sleep(random.uniform(1.0, 2.0))\n",
    "\n",
    "                # 50% í™•ë¥ ë¡œ ë˜ëŒì•„ê°€ê¸°\n",
    "                if random.random() < 0.5:\n",
    "                    back_amount = random.randint(100, 200)\n",
    "                    driver.execute_script(f\"\"\"\n",
    "                        function smoothScroll(distance) {{\n",
    "                            const startY = window.pageYOffset;\n",
    "                            const targetY = startY - distance;\n",
    "                            const duration = 700 + Math.random() * 300;\n",
    "                            let start = null;\n",
    "                            function step(timestamp) {{\n",
    "                                if (!start) start = timestamp;\n",
    "                                const progress = Math.min((timestamp - start) / duration, 1);\n",
    "                                const easing = progress < 0.5 ? 2 * progress * progress : -1 + (4 - 2 * progress) * progress;\n",
    "                                const currentY = startY + (targetY - startY) * easing;\n",
    "                                window.scrollTo(0, currentY);\n",
    "                                if (progress < 1) requestAnimationFrame(step);\n",
    "                            }}\n",
    "                            requestAnimationFrame(step);\n",
    "                        }}\n",
    "                        smoothScroll({back_amount});\n",
    "                    \"\"\")\n",
    "                    time.sleep(random.uniform(0.8, 1.5))\n",
    "\n",
    "                    # ë‹¤ì‹œ ì•ìœ¼ë¡œ ì§„í–‰\n",
    "                    forward_again = random.randint(150, 350)\n",
    "                    driver.execute_script(f\"\"\"\n",
    "                        function smoothScroll(distance) {{\n",
    "                            const startY = window.pageYOffset;\n",
    "                            const targetY = startY + distance;\n",
    "                            const duration = 800 + Math.random() * 400;\n",
    "                            let start = null;\n",
    "                            function step(timestamp) {{\n",
    "                                if (!start) start = timestamp;\n",
    "                                const progress = Math.min((timestamp - start) / duration, 1);\n",
    "                                const easing = progress < 0.5 ? 2 * progress * progress : -1 + (4 - 2 * progress) * progress;\n",
    "                                const currentY = startY + (targetY - startY) * easing;\n",
    "                                window.scrollTo(0, currentY);\n",
    "                                if (progress < 1) requestAnimationFrame(step);\n",
    "                            }}\n",
    "                            requestAnimationFrame(step);\n",
    "                        }}\n",
    "                        smoothScroll({forward_again});\n",
    "                    \"\"\")\n",
    "                    time.sleep(random.uniform(1.2, 2.5))\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸ í–¥ìƒëœ ìŠ¤í¬ë¡¤ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "def smart_scroll_selector(driver):\n",
    "    \"\"\"ğŸ¯ ìŠ¤ë§ˆíŠ¸ ìŠ¤í¬ë¡¤ ì„ íƒê¸° - ë‘ í•¨ìˆ˜ ì¤‘ ëœë¤ ì„ íƒ (ë¡œê·¸ ê°„ì†Œí™”)\"\"\"\n",
    "    scroll_functions = [\n",
    "        (\"ê¸°ë³¸\", human_like_scroll_patterns),\n",
    "        (\"í–¥ìƒ\", enhanced_scroll_patterns)\n",
    "    ]\n",
    "\n",
    "    _, selected_function = random.choice(scroll_functions)\n",
    "    selected_function(driver)\n",
    "\n",
    "print(\"âœ… ê·¸ë£¹ 5 ì™„ë£Œ: ë¸Œë¼ìš°ì € ì œì–´ ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ì •ì˜ ì™„ë£Œ!\")\n",
    "print(\"   - setup_driver(): í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì •\")\n",
    "print(\"   - go_to_main_page(): ë©”ì¸ í˜ì´ì§€ ì´ë™\")\n",
    "print(\"   - find_and_fill_search(): ê²€ìƒ‰ì°½ ì…ë ¥\")\n",
    "print(\"   - click_search_button(): ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­\")\n",
    "print(\"   - handle_popup(): íŒì—… ì²˜ë¦¬\")\n",
    "print(\"   - click_view_all(): ì „ì²´ ìƒí’ˆ ë³´ê¸°\")\n",
    "print(\"   - safe_browser_restart(): ì•ˆì „í•œ ë¸Œë¼ìš°ì € ì¬ì‹œì‘\")\n",
    "print(\"   - human_like_scroll_patterns(): ìì—°ìŠ¤ëŸ¬ìš´ ìŠ¤í¬ë¡¤\")  # ğŸ†• ì¶”ê°€\n",
    "print(\"   - smart_scroll_selector(): ìŠ¤ë§ˆíŠ¸ ìŠ¤í¬ë¡¤ ì„ íƒ\")     # ğŸ†• ì¶”ê°€\n",
    "\n",
    "# ğŸ†• í˜ì´ì§€ ìµœì í™” í•¨ìˆ˜ë“¤ ì¶”ê°€\n",
    "print(\"   âš¡ smart_wait_for_page_load(): ë™ì  ëŒ€ê¸°ì‹œê°„\")\n",
    "print(\"   âš¡ wait_for_page_ready(): í˜ì´ì§€ ì¤€ë¹„ ëŒ€ê¸°\")\n",
    "print(\"   âš¡ adaptive_wait(): ì ì‘í˜• ëŒ€ê¸° ì‹œê°„\")\n",
    "print(\"   âš¡ safe_tab_operation(): ì•ˆì „í•œ íƒ­ ì‘ì—…\")\n",
    "# ê¸°ì¡´ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤\n",
    "print(\"   - print_progress(): ì§„í–‰ë¥  í‘œì‹œ\")\n",
    "print(\"   - retry_operation(): ì¬ì‹œë„ ë¡œì§\")\n",
    "print(\"   - make_safe_filename(): ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fa1b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ğŸš€ ê·¸ë£¹ 6: ë“œë¼ì´ë²„ ì´ˆê¸°í™” ë° ê¸°ë³¸ ì„¤ì •\n",
    "# - ë“œë¼ì´ë²„ ì‹œì‘, ì´ë¯¸ì§€ í´ë” ì„¤ì •, ê¸°ë³¸ í™˜ê²½ êµ¬ì¶•\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸš€ KLOOK í¬ë¡¤ë§ ì‹œìŠ¤í…œ ì‹œì‘!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥ì†Œ ì´ˆê¸°í™”\n",
    "all_results = []\n",
    "print(\"ğŸ”„ ê²°ê³¼ ì €ì¥ì†Œ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "\n",
    "# ë“œë¼ì´ë²„ ì´ˆê¸°í™”\n",
    "try:\n",
    "    # ê¸°ì¡´ ë“œë¼ì´ë²„ê°€ ìˆë‹¤ë©´ ìƒíƒœ í™•ì¸\n",
    "    try:\n",
    "        current_url = driver.current_url\n",
    "        print(\"âœ… ê¸°ì¡´ ë“œë¼ì´ë²„ ê°ì§€ë¨ - ì¬ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸ ì¤‘...\")\n",
    "        \n",
    "        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¡œ ë“œë¼ì´ë²„ ì‘ë™ í™•ì¸\n",
    "        driver.execute_script(\"return document.readyState;\")\n",
    "        print(\"âœ… ê¸°ì¡´ ë“œë¼ì´ë²„ ì •ìƒ ì‘ë™ ì¤‘! ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "        \n",
    "    except (NameError, WebDriverException):\n",
    "        print(\"ğŸ†• ìƒˆë¡œìš´ ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì¤‘...\")\n",
    "        driver = setup_driver()\n",
    "        print(\"âœ… ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ”„ ë“œë¼ì´ë²„ ì¬ìƒì„± ì‹œë„...\")\n",
    "    try:\n",
    "        driver = setup_driver()\n",
    "        print(\"âœ… ë“œë¼ì´ë²„ ì¬ìƒì„± ì„±ê³µ!\")\n",
    "    except Exception as retry_error:\n",
    "        print(f\"âŒ ë“œë¼ì´ë²„ ì¬ìƒì„±ë„ ì‹¤íŒ¨: {retry_error}\")\n",
    "        raise\n",
    "\n",
    "# âœ… ìˆ˜ì •: ì´ë¯¸ì§€ í´ë” ì—°ì†ì„± í™•ë³´ - ê¸°ì¡´ ì´ë¯¸ì§€ ë³´ì¡´\n",
    "if CONFIG[\"SAVE_IMAGES\"]:\n",
    "    img_folder_path = os.path.join(os.path.abspath(\"\"), \"klook_thumb_img\")\n",
    "    # âœ… í•µì‹¬ ìˆ˜ì •: ì´ë¯¸ì§€ í´ë” ì‚­ì œ ì½”ë“œ ì™„ì „ ì œê±° (ë°ì´í„° ì—°ì†ì„± í™•ë³´)\n",
    "    # shutil.rmtree(img_folder_path)  # ì´ ì¤„ì„ ì œê±°í•˜ì—¬ ê¸°ì¡´ ì´ë¯¸ì§€ ë³´ì¡´\n",
    "    os.makedirs(img_folder_path, exist_ok=True)\n",
    "    print(f\"ğŸ“ ì´ë¯¸ì§€ í´ë” í™•ì¸ ì™„ë£Œ (ê¸°ì¡´ ì´ë¯¸ì§€ ì—°ì†ì„± ë³´ì¥): {img_folder_path}\")\n",
    "\n",
    "# ğŸ†• ê·¸ë£¹ 1 ì„¤ì •ì—ì„œ ë„ì‹œ ê°€ì ¸ì˜¤ê¸°\n",
    "if not CITIES_TO_SEARCH:\n",
    "    print(\"âŒ CITIES_TO_SEARCHê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!\")\n",
    "    print(\"ğŸ’¡ ê·¸ë£¹ 1ì—ì„œ CITIES_TO_SEARCH = ['ë„ì‹œëª…']ì„ ì„¤ì •í•˜ì„¸ìš”!\")\n",
    "    raise ValueError(\"ê²€ìƒ‰í•  ë„ì‹œê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤\")\n",
    "\n",
    "city_name = CITIES_TO_SEARCH[0]  # ğŸ†• ì²« ë²ˆì§¸ ë„ì‹œ ì‚¬ìš©\n",
    "continent, country = get_city_info(city_name)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"ğŸŒ ì„¤ì •ëœ ê²€ìƒ‰ ë„ì‹œ: {city_name}\")\n",
    "print(f\"  ğŸŒ ëŒ€ë¥™: {continent}\")\n",
    "print(f\"  ğŸ›ï¸ êµ­ê°€: {country}\")  \n",
    "print(f\"  âœˆï¸ ê³µí•­ ì½”ë“œ: {get_city_code(city_name)}\")\n",
    "print(f\"âš™ï¸ í¬ë¡¤ë§ ì„¤ì •:\")\n",
    "print(f\"  ğŸ“Š ìµœëŒ€ ìƒí’ˆ ìˆ˜: {CONFIG['MAX_PRODUCTS_PER_CITY']}ê°œ\")\n",
    "print(f\"  â±ï¸ ì¬ì‹œë„ íšŸìˆ˜: {CONFIG['RETRY_COUNT']}íšŒ\")\n",
    "print(f\"  ğŸ”„ ëŒ€ê¸° ì‹œê°„: {CONFIG['MEDIUM_MIN_DELAY']}-{CONFIG['MEDIUM_MAX_DELAY']}ì´ˆ\")\n",
    "print(f\"  ğŸ–¼ï¸ ì´ë¯¸ì§€ ì €ì¥: {'âœ… í™œì„±í™”' if CONFIG['SAVE_IMAGES'] else 'âŒ ë¹„í™œì„±í™”'}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ë„ì‹œ ìœ íš¨ì„± ê²€ì¦\n",
    "is_valid, message = validate_city(city_name)\n",
    "if is_valid:\n",
    "    print(f\"âœ… ë„ì‹œ ìœ íš¨ì„± ê²€ì¦: {message}\")\n",
    "else:\n",
    "    print(f\"âš ï¸ ë„ì‹œ ìœ íš¨ì„± ê²½ê³ : {message}\")\n",
    "    print(\"ğŸ’¡ ê³„ì† ì§„í–‰í•˜ì§€ë§Œ ì˜ˆìƒì¹˜ ëª»í•œ ê²°ê³¼ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ë°ì´í„° ì €ì¥ ê²½ë¡œ ë¯¸ë¦¬ ìƒì„±\n",
    "try:\n",
    "    if city_name in [\"ë§ˆì¹´ì˜¤\", \"í™ì½©\", \"ì‹±ê°€í¬ë¥´\"]:\n",
    "        # ë„ì‹œêµ­ê°€: ëŒ€ë¥™ í´ë”ë§Œ ìƒì„±\n",
    "        data_dir = os.path.join(\"data\", continent)\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "        print(f\"ğŸ“ ë„ì‹œêµ­ê°€ ë°ì´í„° ê²½ë¡œ ìƒì„±: {data_dir}\")\n",
    "    else:\n",
    "        # ì¼ë°˜ ë„ì‹œ: ê¸°ì¡´ êµ¬ì¡°\n",
    "        data_dir = os.path.join(\"data\", continent, country, city_name)\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "        print(f\"ğŸ“ ë°ì´í„° ì €ì¥ ê²½ë¡œ ìƒì„± ì™„ë£Œ: {data_dir}\")\n",
    "        \n",
    "        # êµ­ê°€ë³„ í†µí•© í´ë”ë„ ìƒì„±\n",
    "        country_dir = os.path.join(\"data\", continent, country)\n",
    "        os.makedirs(country_dir, exist_ok=True)\n",
    "        print(f\"ğŸ“ êµ­ê°€ë³„ í†µí•© ê²½ë¡œ ìƒì„± ì™„ë£Œ: {country_dir}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ë°ì´í„° í´ë” ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ’¡ í¬ë¡¤ë§ì€ ê³„ì† ì§„í–‰ë˜ì§€ë§Œ ì €ì¥ ì‹œ ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "print(f\"\\nğŸ”„ ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...\")\n",
    "try:\n",
    "    crawler_state, completed_urls = load_crawler_state()\n",
    "    print(f\"âœ… ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ\")\n",
    "    print(f\"  ğŸ“Š ì´ì „ ìˆ˜ì§‘ ì™„ë£Œ: {crawler_state.get('total_collected_count', 0)}ê°œ\")\n",
    "    print(f\"  ğŸ“ ì™„ë£Œëœ URL: {len(completed_urls)}ê°œ\")\n",
    "    \n",
    "    # ğŸ†• ë²ˆí˜¸ ì—°ì†ì„± í™•ë³´: ê¸°ì¡´ CSV ë§ˆì§€ë§‰ ë²ˆí˜¸ í™•ì¸ (1ë¶€í„° ì‹œì‘ ë³´ì¥)\n",
    "    last_product_number = get_last_product_number(city_name)\n",
    "    start_number = max(1, last_product_number + 1)  # ë‹¤ìŒ ë²ˆí˜¸ë¶€í„°, ìµœì†Œ 1 ë³´ì¥\n",
    "\n",
    "    print(f\"ğŸ”¢ ë²ˆí˜¸ ì—°ì†ì„± ì„¤ì • (1ë¶€í„° ì‹œì‘):\")\n",
    "    print(f\"  ğŸ“Š ê¸°ì¡´ ë§ˆì§€ë§‰ ë²ˆí˜¸: {last_product_number}\")\n",
    "    print(f\"  ğŸ†• ì‹œì‘ ë²ˆí˜¸: {start_number}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ’¡ ê¸°ë³¸ ìƒíƒœë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
    "    crawler_state = {\n",
    "        \"total_collected_count\": 0,\n",
    "        \"last_crawled_page\": 1,\n",
    "        \"current_session_start\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"last_updated\": datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    completed_urls = set()\n",
    "    start_number = 0\n",
    "\n",
    "if city_name in [\"ë§ˆì¹´ì˜¤\", \"í™ì½©\", \"ì‹±ê°€í¬ë¥´\"]:\n",
    "    print(f\"ğŸ“ ì´ë¯¸ì§€ ì €ì¥ ê¸°ë³¸ ê²½ë¡œ: klook_thumb_img/{continent}/{city_name}/\")\n",
    "    print(f\"ğŸ“ ë°ì´í„° ì €ì¥ ê²½ë¡œ: data/{continent}/\")\n",
    "else:\n",
    "    print(f\"ğŸ“ ì´ë¯¸ì§€ ì €ì¥ ê¸°ë³¸ ê²½ë¡œ: klook_thumb_img/{continent}/{country}/{city_name}/\")\n",
    "    print(f\"ğŸ“ ë°ì´í„° ì €ì¥ ê²½ë¡œ: data/{continent}/{country}/{city_name}/\")\n",
    "print(f\"ğŸ”¢ ë²ˆí˜¸ ì‹œì‘ì : {start_number}\")\n",
    "print(\"ğŸš€ ë‹¤ìŒ: ê·¸ë£¹ 7ì„ ì‹¤í–‰í•˜ì—¬ ì›¹ì‚¬ì´íŠ¸ ê²€ìƒ‰ì„ ì‹œì‘í•˜ì„¸ìš”!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bcdaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê·¸ë£¹7 ğŸš€ í†µí•© KLOOK íƒ­ ì…€ë ‰í„° & ì „ëµ ì‹œìŠ¤í…œ (ê·¸ë£¹ 7 + Enhanced)============\n",
    "# - ê° íƒ­ë³„ ìƒìœ„ ìˆœìœ„ í¬ë¡¤ë§ + í–¥ìƒëœ ì•ˆì •ì„±\n",
    "# - sitemapê³¼ ë¸Œë¼ìš°ì € í¬ë¡¤ë§ ìµœì  ì¡°í•©\n",
    "# - ê°•í™”ëœ ì˜¤ë¥˜ ì²˜ë¦¬ ë° í´ë°± ë©”ì»¤ë‹ˆì¦˜\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ¯ í†µí•© KLOOK íƒ­ ì…€ë ‰í„° & ì „ëµ ì‹œìŠ¤í…œ ì‹œì‘!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ“Š KLOOK íƒ­ êµ¬ì¡° ì •ì˜ ë° í¬ë¡¤ë§ ì „ëµ (Enhanced)\n",
    "# =============================================================================\n",
    "\n",
    "KLOOK_TAB_STRUCTURE = {\n",
    "    \"ì „ì²´\": {\n",
    "        \"index\": 1,\n",
    "        \"xpath\": \"/html/body/div[1]/div/div/main/div/div/div[2]/div/div[1]/div/div[1]\",\n",
    "        \"css_selector\": \".klk-tabs-tab:nth-child(1)\",\n",
    "        \"text_patterns\": [\"ì „ì²´\", \"All\", \"ì „ì²´ë³´ê¸°\", \"ëª¨ë“ \"],\n",
    "        \"ranking_limit\": 100,\n",
    "        \"description\": \"ëª¨ë“  ì¹´í…Œê³ ë¦¬ ìƒí’ˆ\",\n",
    "        \"priority\": 1,\n",
    "        \"backup_selectors\": [\n",
    "            \"[data-testid*='all']\",\n",
    "            \"button[aria-label*='all']\",\n",
    "            \"a[href*='all']\"\n",
    "        ]\n",
    "    },\n",
    "    \"íˆ¬ì–´&ì•¡í‹°ë¹„í‹°\": {\n",
    "        \"index\": 2,\n",
    "        \"xpath\": \"/html/body/div[1]/div/div/main/div/div/div[2]/div/div[1]/div/div[2]\",\n",
    "        \"css_selector\": \".klk-tabs-tab:nth-child(2)\",\n",
    "        \"text_patterns\": [\"íˆ¬ì–´\", \"ì•¡í‹°ë¹„í‹°\", \"Tour\", \"Activity\", \"íˆ¬ì–´&ì•¡í‹°ë¹„í‹°\"],\n",
    "        \"ranking_limit\": 50,\n",
    "        \"description\": \"íˆ¬ì–´, ì•¡í‹°ë¹„í‹°, ì²´í—˜ ìƒí’ˆ\",\n",
    "        \"priority\": 2,\n",
    "        \"backup_selectors\": [\n",
    "            \"[data-testid*='tour']\",\n",
    "            \"[data-testid*='activity']\",\n",
    "            \"button[aria-label*='tour']\"\n",
    "        ]\n",
    "    },\n",
    "    \"í‹°ì¼“&ì…ì¥ê¶Œ\": {\n",
    "        \"index\": 3,\n",
    "        \"xpath\": \"/html/body/div[1]/div/div/main/div/div/div[2]/div/div[1]/div/div[3]\",\n",
    "        \"css_selector\": \".klk-tabs-tab:nth-child(3)\",\n",
    "        \"text_patterns\": [\"í‹°ì¼“\", \"ì…ì¥ê¶Œ\", \"Ticket\", \"Admission\", \"í‹°ì¼“&ì…ì¥ê¶Œ\"],\n",
    "        \"ranking_limit\": 50,\n",
    "        \"description\": \"ì…ì¥ê¶Œ, í‹°ì¼“ ìƒí’ˆ\",\n",
    "        \"priority\": 3,\n",
    "        \"backup_selectors\": [\n",
    "            \"[data-testid*='ticket']\",\n",
    "            \"[data-testid*='admission']\",\n",
    "            \"button[aria-label*='ticket']\"\n",
    "        ]\n",
    "    },\n",
    "    \"êµí†µ\": {\n",
    "        \"index\": 4,\n",
    "        \"xpath\": \"/html/body/div[1]/div/div/main/div/div/div[2]/div/div[1]/div/div[4]\",\n",
    "        \"css_selector\": \".klk-tabs-tab:nth-child(4)\",\n",
    "        \"text_patterns\": [\"êµí†µ\", \"Transport\", \"Transportation\", \"ì´ë™\"],\n",
    "        \"ranking_limit\": 30,\n",
    "        \"description\": \"êµí†µ, ì´ë™ ê´€ë ¨ ìƒí’ˆ\",\n",
    "        \"priority\": 4,\n",
    "        \"backup_selectors\": [\n",
    "            \"[data-testid*='transport']\",\n",
    "            \"[data-testid*='transfer']\",\n",
    "            \"button[aria-label*='transport']\"\n",
    "        ]\n",
    "    },\n",
    "    \"ê¸°íƒ€\": {\n",
    "        \"index\": 6,\n",
    "        \"xpath\": \"/html/body/div[1]/div/div/main/div/div/div[2]/div/div[1]/div/div[6]\",\n",
    "        \"css_selector\": \".klk-tabs-tab:nth-child(6)\",\n",
    "        \"text_patterns\": [\"ê¸°íƒ€\", \"Others\", \"ê¸°íƒ€ì„œë¹„ìŠ¤\", \"Miscellaneous\"],\n",
    "        \"ranking_limit\": 20,\n",
    "        \"description\": \"ê¸°íƒ€ ì¹´í…Œê³ ë¦¬ ìƒí’ˆ (í˜¸í…” ì œì™¸)\",\n",
    "        \"priority\": 5,\n",
    "        \"backup_selectors\": [\n",
    "            \"[data-testid*='other']\",\n",
    "            \"[data-testid*='misc']\",\n",
    "            \"button[aria-label*='other']\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "CRAWLING_STRATEGIES = {\n",
    "    \"ì „ì²´_sitemap\": {\n",
    "        \"name\": \"ì „ì²´ í¬ë¡¤ë§ (Sitemap ê¸°ë°˜)\",\n",
    "        \"description\": \"sitemapì—ì„œ ëª¨ë“  URLì„ ë¹ ë¥´ê²Œ ìˆ˜ì§‘\",\n",
    "        \"method\": \"sitemap_only\",\n",
    "        \"ranking_collection\": False,\n",
    "        \"speed\": \"ë§¤ìš° ë¹ ë¦„\",\n",
    "        \"ranking_info\": \"ì—†ìŒ\",\n",
    "        \"use_tabs\": False\n",
    "    },\n",
    "    \"ì „ì²´_hybrid\": {\n",
    "        \"name\": \"ì „ì²´ í¬ë¡¤ë§ (í•˜ì´ë¸Œë¦¬ë“œ)\",\n",
    "        \"description\": \"ìƒìœ„ 100ê°œëŠ” ìˆœìœ„ ì •ë³´, ë‚˜ë¨¸ì§€ëŠ” sitemap\",\n",
    "        \"method\": \"hybrid\",\n",
    "        \"ranking_collection\": True,\n",
    "        \"ranking_limit\": 100,\n",
    "        \"speed\": \"ë³´í†µ\",\n",
    "        \"ranking_info\": \"ìƒìœ„ 100ê°œë§Œ\",\n",
    "        \"use_tabs\": True\n",
    "    },\n",
    "    \"íƒ­ë³„_ì„ íƒ\": {\n",
    "        \"name\": \"íƒ­ë³„ ì„ íƒ í¬ë¡¤ë§\",\n",
    "        \"description\": \"ì„ íƒí•œ íƒ­ì˜ ìƒìœ„ Nê°œ + sitemap ë³´ì™„\",\n",
    "        \"method\": \"tab_specific\",\n",
    "        \"ranking_collection\": True,\n",
    "        \"speed\": \"ë¹ ë¦„\",\n",
    "        \"ranking_info\": \"ì„ íƒ íƒ­ë§Œ\",\n",
    "        \"use_tabs\": True\n",
    "    },\n",
    "    \"ìˆœìœ„ë§Œ_ìˆ˜ì§‘\": {\n",
    "        \"name\": \"ìˆœìœ„ ì •ë³´ë§Œ ìˆ˜ì§‘\",\n",
    "        \"description\": \"ê° íƒ­ë³„ ìƒìœ„ ìˆœìœ„ ì •ë³´ë§Œ ë¹ ë¥´ê²Œ ìˆ˜ì§‘\",\n",
    "        \"method\": \"ranking_only\",\n",
    "        \"ranking_collection\": True,\n",
    "        \"speed\": \"ë¹ ë¦„\",\n",
    "        \"ranking_info\": \"ëª¨ë“  íƒ­\",\n",
    "        \"use_tabs\": True\n",
    "    },\n",
    "    \"enhanced_full\": {\n",
    "        \"name\": \"í–¥ìƒëœ ì „ì²´ í¬ë¡¤ë§\",\n",
    "        \"description\": \"Enhanced ì‹œìŠ¤í…œìœ¼ë¡œ ëª¨ë“  íƒ­ì—ì„œ ìˆœìœ„ ì •ë³´ ìˆ˜ì§‘\",\n",
    "        \"method\": \"enhanced_full\",\n",
    "        \"ranking_collection\": True,\n",
    "        \"speed\": \"ë³´í†µ\",\n",
    "        \"ranking_info\": \"ëª¨ë“  íƒ­ ì „ì²´\",\n",
    "        \"use_tabs\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ›ï¸ í†µí•© íƒ­ ì…€ë ‰í„° í•¨ìˆ˜ë“¤ (Enhanced + Original)\n",
    "# =============================================================================\n",
    "\n",
    "def show_crawling_strategies():\n",
    "    \"\"\"í¬ë¡¤ë§ ì „ëµ ì˜µì…˜ í‘œì‹œ (í–¥ìƒëœ ë²„ì „)\"\"\"\n",
    "    print(\"\\nğŸ¯ ì‚¬ìš© ê°€ëŠ¥í•œ í¬ë¡¤ë§ ì „ëµ:\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    for i, (key, strategy) in enumerate(CRAWLING_STRATEGIES.items(), 1):\n",
    "        print(f\"{i}. {strategy['name']}\")\n",
    "        print(f\"   ğŸ“ ì„¤ëª…: {strategy['description']}\")\n",
    "        print(f\"   âš¡ ì†ë„: {strategy['speed']}\")\n",
    "        print(f\"   ğŸ“Š ìˆœìœ„ ì •ë³´: {strategy['ranking_info']}\")\n",
    "        print(f\"   ğŸ¯ íƒ­ ì‚¬ìš©: {'ì˜ˆ' if strategy['use_tabs'] else 'ì•„ë‹ˆì˜¤'}\")\n",
    "        print()\n",
    "\n",
    "def show_available_tabs():\n",
    "    \"\"\"ì‚¬ìš© ê°€ëŠ¥í•œ íƒ­ ëª©ë¡ í‘œì‹œ (í–¥ìƒëœ ë²„ì „)\"\"\"\n",
    "    print(\"\\nğŸ“‹ KLOOK ì¹´í…Œê³ ë¦¬ íƒ­:\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    for i, (tab_name, tab_info) in enumerate(KLOOK_TAB_STRUCTURE.items(), 1):\n",
    "        print(f\"{i}. {tab_name}\")\n",
    "        print(f\"   ğŸ“ {tab_info['description']}\")\n",
    "        print(f\"   ğŸ¯ ìˆœìœ„ ìˆ˜ì§‘: ìƒìœ„ {tab_info['ranking_limit']}ê°œ\")\n",
    "        print(f\"   ğŸ” ìš°ì„ ìˆœìœ„: {tab_info['priority']}\")\n",
    "        print()\n",
    "\n",
    "def select_crawling_strategy_interactive():\n",
    "    \"\"\"ëŒ€í™”í˜• í¬ë¡¤ë§ ì „ëµ ì„ íƒ\"\"\"\n",
    "    print(\"\\nğŸ¤– í¬ë¡¤ë§ ì „ëµì„ ì„ íƒí•˜ì„¸ìš”:\")\n",
    "    \n",
    "    strategies = list(CRAWLING_STRATEGIES.keys())\n",
    "    for i, strategy_key in enumerate(strategies, 1):\n",
    "        strategy = CRAWLING_STRATEGIES[strategy_key]\n",
    "        print(f\"{i}. {strategy['name']}\")\n",
    "    \n",
    "    try:\n",
    "        choice = input(\"\\nì„ íƒ (1-5, ê¸°ë³¸ê°’=2): \").strip()\n",
    "        if not choice:\n",
    "            choice = \"2\"\n",
    "        \n",
    "        choice_idx = int(choice) - 1\n",
    "        if 0 <= choice_idx < len(strategies):\n",
    "            selected_strategy = strategies[choice_idx]\n",
    "        else:\n",
    "            print(\"ì˜ëª»ëœ ì„ íƒ, ê¸°ë³¸ê°’ ì‚¬ìš©\")\n",
    "            selected_strategy = \"ì „ì²´_hybrid\"\n",
    "    except:\n",
    "        print(\"ì…ë ¥ ì˜¤ë¥˜, ê¸°ë³¸ê°’ ì‚¬ìš©\")\n",
    "        selected_strategy = \"ì „ì²´_hybrid\"\n",
    "    \n",
    "    # íƒ­ ì„ íƒ (íƒ­ ì‚¬ìš© ì „ëµì¸ ê²½ìš°)\n",
    "    if CRAWLING_STRATEGIES[selected_strategy][\"use_tabs\"]:\n",
    "        print(\"\\nğŸ“‹ í¬ë¡¤ë§í•  íƒ­ì„ ì„ íƒí•˜ì„¸ìš”:\")\n",
    "        tabs = list(KLOOK_TAB_STRUCTURE.keys())\n",
    "        for i, tab in enumerate(tabs, 1):\n",
    "            print(f\"{i}. {tab}\")\n",
    "        print(\"6. ëª¨ë“  íƒ­\")\n",
    "        \n",
    "        try:\n",
    "            tab_choice = input(\"\\nì„ íƒ (1-6, ê¸°ë³¸ê°’=1): \").strip()\n",
    "            if not tab_choice:\n",
    "                tab_choice = \"1\"\n",
    "            \n",
    "            tab_idx = int(tab_choice) - 1\n",
    "            if tab_idx == 5:  # ëª¨ë“  íƒ­\n",
    "                selected_tabs = list(KLOOK_TAB_STRUCTURE.keys())\n",
    "            elif 0 <= tab_idx < len(tabs):\n",
    "                selected_tabs = [tabs[tab_idx]]\n",
    "            else:\n",
    "                selected_tabs = [\"ì „ì²´\"]\n",
    "        except:\n",
    "            selected_tabs = [\"ì „ì²´\"]\n",
    "    else:\n",
    "        selected_tabs = [\"ì „ì²´\"]\n",
    "    \n",
    "    return selected_strategy, selected_tabs\n",
    "\n",
    "def select_crawling_strategy_auto():\n",
    "    \"\"\"ìë™ í¬ë¡¤ë§ ì „ëµ ì„ íƒ\"\"\"\n",
    "    print(\"ğŸ¤– ìë™ ì‹¤í–‰ ëª¨ë“œ: ê¸°ë³¸ ì „ëµì„ ì‚¬ìš©í•©ë‹ˆë‹¤\")\n",
    "    \n",
    "    selected_strategy = \"ì „ì²´_hybrid\"\n",
    "    selected_tabs = [\"ì „ì²´\"]\n",
    "    \n",
    "    return selected_strategy, selected_tabs\n",
    "\n",
    "def detect_tabs_with_enhanced_fallback(driver):\n",
    "    \"\"\"í–¥ìƒëœ íƒ­ ê°ì§€ (Enhanced + Original ê²°í•©)\"\"\"\n",
    "    print(\"ğŸ” Enhanced íƒ­ êµ¬ì¡° ê°ì§€ ì‹œì‘...\")\n",
    "    \n",
    "    detected_tabs = []\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    \n",
    "    # 1. Enhanced ë°©ì‹ìœ¼ë¡œ íƒ­ ê°ì§€\n",
    "    for tab_name, tab_info in KLOOK_TAB_STRUCTURE.items():\n",
    "        tab_detected = False\n",
    "        element = None\n",
    "        detection_method = \"\"\n",
    "        \n",
    "        # XPath ì‹œë„\n",
    "        try:\n",
    "            element = driver.find_element(By.XPATH, tab_info[\"xpath\"])\n",
    "            if element.is_displayed():\n",
    "                tab_detected = True\n",
    "                detection_method = \"XPath\"\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # CSS ì…€ë ‰í„° ì‹œë„\n",
    "        if not tab_detected:\n",
    "            try:\n",
    "                element = driver.find_element(By.CSS_SELECTOR, tab_info[\"css_selector\"])\n",
    "                if element.is_displayed():\n",
    "                    tab_detected = True\n",
    "                    detection_method = \"CSS\"\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # ë°±ì—… ì…€ë ‰í„° ì‹œë„\n",
    "        if not tab_detected:\n",
    "            for backup_selector in tab_info.get(\"backup_selectors\", []):\n",
    "                try:\n",
    "                    backup_elements = driver.find_elements(By.CSS_SELECTOR, backup_selector)\n",
    "                    for backup_element in backup_elements:\n",
    "                        if backup_element.is_displayed():\n",
    "                            backup_text = backup_element.text.strip().lower()\n",
    "                            for pattern in tab_info[\"text_patterns\"]:\n",
    "                                if pattern.lower() in backup_text:\n",
    "                                    element = backup_element\n",
    "                                    tab_detected = True\n",
    "                                    detection_method = f\"Backup: {backup_selector}\"\n",
    "                                    break\n",
    "                        if tab_detected:\n",
    "                            break\n",
    "                    if tab_detected:\n",
    "                        break\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        if tab_detected and element:\n",
    "            detected_tabs.append({\n",
    "                \"name\": tab_name,\n",
    "                \"element\": element,\n",
    "                \"text\": element.text.strip(),\n",
    "                \"tab_info\": tab_info,\n",
    "                \"detection_method\": detection_method\n",
    "            })\n",
    "            print(f\"    âœ… {tab_name}: '{element.text.strip()}' ({detection_method})\")\n",
    "        else:\n",
    "            print(f\"    âŒ {tab_name}: ê°ì§€ ì‹¤íŒ¨\")\n",
    "    \n",
    "    return detected_tabs\n",
    "\n",
    "def click_tab_enhanced(driver, tab_name, detected_tabs=None):\n",
    "    \"\"\"í–¥ìƒëœ íƒ­ í´ë¦­ í•¨ìˆ˜\"\"\"\n",
    "    print(f\"  ğŸ¯ '{tab_name}' íƒ­ ì²˜ë¦¬ ì‹œì‘...\")\n",
    "    \n",
    "    if tab_name == \"ì „ì²´\":\n",
    "        print(f\"    â„¹ï¸ ì „ì²´ íƒ­ì€ ë³„ë„ í´ë¦­ ì—†ì´ í˜„ì¬ í˜ì´ì§€ ì‚¬ìš©\")\n",
    "        return True\n",
    "    \n",
    "    # ê°ì§€ëœ íƒ­ì—ì„œ ì°¾ê¸°\n",
    "    target_tab = None\n",
    "    if detected_tabs:\n",
    "        for detected_tab in detected_tabs:\n",
    "            if detected_tab[\"name\"] == tab_name:\n",
    "                target_tab = detected_tab\n",
    "                break\n",
    "    \n",
    "    if not target_tab:\n",
    "        print(f\"    âŒ '{tab_name}' íƒ­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        element = target_tab[\"element\"]\n",
    "        \n",
    "        # í™”ë©´ ì¤‘ì•™ìœ¼ë¡œ ìŠ¤í¬ë¡¤\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", element)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # í´ë¦­ ê°€ëŠ¥ ìƒíƒœê¹Œì§€ ëŒ€ê¸°\n",
    "        try:\n",
    "            wait = WebDriverWait(driver, 10)\n",
    "            wait.until(EC.element_to_be_clickable(element))\n",
    "        except:\n",
    "            print(f\"    âš ï¸ í´ë¦­ ëŒ€ê¸° íƒ€ì„ì•„ì›ƒ, ê°•ì œ ì§„í–‰\")\n",
    "        \n",
    "        # ë‹¤ì¤‘ í´ë¦­ ì „ëµ\n",
    "        click_methods = [\n",
    "            (\"JavaScript í´ë¦­\", lambda: driver.execute_script(\"arguments[0].click();\", element)),\n",
    "            (\"ì¼ë°˜ í´ë¦­\", lambda: element.click()),\n",
    "            (\"ì´ë²¤íŠ¸ ë””ìŠ¤íŒ¨ì¹˜\", lambda: driver.execute_script(\"arguments[0].dispatchEvent(new MouseEvent('click', {bubbles: true}));\", element))\n",
    "        ]\n",
    "        \n",
    "        for method_name, click_method in click_methods:\n",
    "            try:\n",
    "                click_method()\n",
    "                print(f\"    âœ… '{tab_name}' íƒ­ í´ë¦­ ì„±ê³µ ({method_name})\")\n",
    "                \n",
    "                # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°\n",
    "                time.sleep(random.uniform(3, 5))\n",
    "                return True\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    âŒ {method_name} ì‹¤íŒ¨: {e}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"    âŒ '{tab_name}' íƒ­ í´ë¦­ ì™„ì „ ì‹¤íŒ¨\")\n",
    "        return False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    âŒ '{tab_name}' íƒ­ ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "def collect_ranking_urls_enhanced(driver, limit=50, tab_name=\"\"):\n",
    "    \"\"\"í–¥ìƒëœ ìˆœìœ„ URL ìˆ˜ì§‘\"\"\"\n",
    "    try:\n",
    "        print(f\"    ğŸ” '{tab_name}' íƒ­ì—ì„œ ìƒìœ„ {limit}ê°œ URL ìˆ˜ì§‘ ì¤‘...\")\n",
    "        \n",
    "        # í˜ì´ì§€ ì•ˆì •í™”ë¥¼ ìœ„í•œ ìŠ¤í¬ë¡¤\n",
    "        try:\n",
    "            # ì ì§„ì  ìŠ¤í¬ë¡¤ë¡œ ëª¨ë“  ì»¨í…ì¸  ë¡œë“œ\n",
    "            for i in range(3):\n",
    "                driver.execute_script(\"window.scrollBy(0, 1000);\")\n",
    "                time.sleep(1)\n",
    "            \n",
    "            # ë§¨ ìœ„ë¡œ ëŒì•„ê°€ê¸°\n",
    "            driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "            time.sleep(1)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # ë‹¤ì–‘í•œ KLOOK ìƒí’ˆ ë§í¬ ì…€ë ‰í„°ë“¤\n",
    "        product_selectors = [\n",
    "            \"a[href*='/activity/']\",\n",
    "            \".product-item a\",\n",
    "            \".experience-card a\",\n",
    "            \"[data-testid*='product'] a\",\n",
    "            \".product-card a\",\n",
    "            \".activity-card a\",\n",
    "            \".klk-product-card a\"\n",
    "        ]\n",
    "        \n",
    "        all_urls = []\n",
    "        \n",
    "        for selector in product_selectors:\n",
    "            try:\n",
    "                elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                print(f\"      ğŸ” {selector}: {len(elements)}ê°œ ìš”ì†Œ ë°œê²¬\")\n",
    "                \n",
    "                for element in elements:\n",
    "                    try:\n",
    "                        href = element.get_attribute('href')\n",
    "                        if href and '/activity/' in href and href.startswith('http'):\n",
    "                            # URL ì •ì œ\n",
    "                            clean_url = href.split('?')[0]  # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì œê±°\n",
    "                            all_urls.append(clean_url)\n",
    "                    except:\n",
    "                        continue\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"      âŒ {selector} ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ìˆœì„œ ìœ ì§€\n",
    "        unique_urls = []\n",
    "        seen = set()\n",
    "        for url in all_urls:\n",
    "            if url not in seen and len(unique_urls) < limit:\n",
    "                seen.add(url)\n",
    "                unique_urls.append(url)\n",
    "        \n",
    "        print(f\"    âœ… '{tab_name}' íƒ­ì—ì„œ {len(unique_urls)}ê°œ ìˆœìœ„ URL ìˆ˜ì§‘ ì™„ë£Œ\")\n",
    "        \n",
    "        # URL í’ˆì§ˆ ê²€ì¦\n",
    "        valid_urls = []\n",
    "        for url in unique_urls:\n",
    "            if 'klook.com' in url and '/activity/' in url:\n",
    "                valid_urls.append(url)\n",
    "        \n",
    "        print(f\"    ğŸ“Š ìœ íš¨í•œ URL: {len(valid_urls)}ê°œ\")\n",
    "        return valid_urls\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    âŒ '{tab_name}' íƒ­ URL ìˆ˜ì§‘ ì‹¤íŒ¨: {e}\")\n",
    "        return []\n",
    "\n",
    "def save_ranking_urls_enhanced(city_name, tab_name, urls, strategy, detection_info=None):\n",
    "    \"\"\"í–¥ìƒëœ ìˆœìœ„ URL ì €ì¥ (ë©”íƒ€ë°ì´í„° í¬í•¨)\"\"\"\n",
    "    try:\n",
    "        os.makedirs(\"ranking_urls\", exist_ok=True)\n",
    "        \n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f\"ranking_urls/{city_name}_{tab_name}_{strategy}_{timestamp}.json\"\n",
    "        \n",
    "        ranking_data = {\n",
    "            \"metadata\": {\n",
    "                \"city\": city_name,\n",
    "                \"tab\": tab_name,\n",
    "                \"strategy\": strategy,\n",
    "                \"collected_time\": datetime.now().isoformat(),\n",
    "                \"total_count\": len(urls),\n",
    "                \"detection_method\": detection_info.get(\"detection_method\", \"\") if detection_info else \"\",\n",
    "                \"system_version\": \"integrated_enhanced\"\n",
    "            },\n",
    "            \"ranking_urls\": urls,\n",
    "            \"url_analysis\": {\n",
    "                \"unique_domains\": list(set([url.split('/')[2] for url in urls if len(url.split('/')) > 2])),\n",
    "                \"avg_url_length\": sum(len(url) for url in urls) / len(urls) if urls else 0,\n",
    "                \"contains_klook\": sum(1 for url in urls if 'klook.com' in url)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(ranking_data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"    ğŸ’¾ ìˆœìœ„ URL ì €ì¥ ì™„ë£Œ: {filename}\")\n",
    "        print(f\"    ğŸ“Š ì €ì¥ëœ URL: {len(urls)}ê°œ (Klook: {ranking_data['url_analysis']['contains_klook']}ê°œ)\")\n",
    "        \n",
    "        return filename\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    âŒ ìˆœìœ„ URL ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸš€ í†µí•© ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜\n",
    "# =============================================================================\n",
    "\n",
    "def execute_integrated_tab_selector_system(city_name, driver, interactive_mode=False):\n",
    "    \"\"\"\n",
    "    ğŸ¯ í†µí•© íƒ­ ì…€ë ‰í„° ì‹œìŠ¤í…œ ì‹¤í–‰ (Enhanced + Original)\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ¯ '{city_name}' ë„ì‹œì˜ í†µí•© íƒ­ ì…€ë ‰í„° ì‹œìŠ¤í…œ ì‹œì‘!\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        # 1. í¬ë¡¤ë§ ì „ëµ ì„ íƒ\n",
    "        show_crawling_strategies()\n",
    "        show_available_tabs()\n",
    "        \n",
    "        if interactive_mode:\n",
    "            selected_strategy, selected_tabs = select_crawling_strategy_interactive()\n",
    "        else:\n",
    "            selected_strategy, selected_tabs = select_crawling_strategy_auto()\n",
    "        \n",
    "        print(f\"\\nğŸš€ ì„ íƒëœ ì „ëµ ì‹¤í–‰: {selected_strategy}\")\n",
    "        print(f\"ğŸ¯ ì„ íƒëœ íƒ­: {', '.join(selected_tabs)}\")\n",
    "        \n",
    "        # 2. ì „ëµ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "        strategy_info = CRAWLING_STRATEGIES[selected_strategy]\n",
    "        collected_ranking_urls = {}\n",
    "        \n",
    "        # 3. Sitemap ì „ìš© ëª¨ë“œ\n",
    "        if strategy_info[\"method\"] == \"sitemap_only\":\n",
    "            print(\"ğŸ“Š Sitemap ì „ìš© ëª¨ë“œ: ê·¸ë£¹ 8ì—ì„œ sitemap URLë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤\")\n",
    "            return {\n",
    "                \"strategy\": selected_strategy,\n",
    "                \"tabs\": selected_tabs,\n",
    "                \"ranking_urls\": {},\n",
    "                \"use_sitemap\": True,\n",
    "                \"use_ranking\": False,\n",
    "                \"execution_time\": datetime.now().isoformat(),\n",
    "                \"success\": True\n",
    "            }\n",
    "        \n",
    "        # 4. íƒ­ ê¸°ë°˜ ì „ëµ ì‹¤í–‰\n",
    "        if strategy_info[\"use_tabs\"]:\n",
    "            print(\"ğŸ” íƒ­ êµ¬ì¡° ê°ì§€ ë° ìˆœìœ„ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘...\")\n",
    "            \n",
    "            # Enhanced íƒ­ ê°ì§€\n",
    "            detected_tabs = detect_tabs_with_enhanced_fallback(driver)\n",
    "            \n",
    "            if not detected_tabs:\n",
    "                print(\"âŒ íƒ­ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Sitemap ëª¨ë“œë¡œ í´ë°±í•©ë‹ˆë‹¤.\")\n",
    "                return {\n",
    "                    \"strategy\": \"fallback_sitemap\",\n",
    "                    \"tabs\": [\"ì „ì²´\"],\n",
    "                    \"ranking_urls\": {},\n",
    "                    \"use_sitemap\": True,\n",
    "                    \"use_ranking\": False,\n",
    "                    \"error\": \"Tab detection failed\",\n",
    "                    \"execution_time\": datetime.now().isoformat(),\n",
    "                    \"success\": False\n",
    "                }\n",
    "            \n",
    "            # Enhanced ì „ì²´ í¬ë¡¤ë§ ëª¨ë“œ\n",
    "            if strategy_info[\"method\"] == \"enhanced_full\":\n",
    "                print(\"ğŸ¯ Enhanced ëª¨ë“œ: ëª¨ë“  íƒ­ì—ì„œ ìˆœìœ„ ìˆ˜ì§‘\")\n",
    "                selected_tabs = list(KLOOK_TAB_STRUCTURE.keys())\n",
    "            \n",
    "            # ê° ì„ íƒëœ íƒ­ì—ì„œ ìˆœìœ„ URL ìˆ˜ì§‘\n",
    "            for tab_name in selected_tabs:\n",
    "                if tab_name in KLOOK_TAB_STRUCTURE:\n",
    "                    tab_info = KLOOK_TAB_STRUCTURE[tab_name]\n",
    "                    ranking_limit = tab_info[\"ranking_limit\"]\n",
    "                    \n",
    "                    # ìˆœìœ„ë§Œ ìˆ˜ì§‘ ëª¨ë“œì—ì„œëŠ” ì œí•œ\n",
    "                    if strategy_info[\"method\"] == \"ranking_only\":\n",
    "                        ranking_limit = min(ranking_limit, 20)\n",
    "                    \n",
    "                    print(f\"\\nğŸ”„ '{tab_name}' íƒ­ ì²˜ë¦¬ ì¤‘...\")\n",
    "                    \n",
    "                    # íƒ­ í´ë¦­ (í–¥ìƒëœ ë°©ì‹)\n",
    "                    click_success = click_tab_enhanced(driver, tab_name, detected_tabs)\n",
    "                    \n",
    "                    if not click_success:\n",
    "                        print(f\"âŒ '{tab_name}' íƒ­ í´ë¦­ ì‹¤íŒ¨, ê±´ë„ˆëœ€\")\n",
    "                        continue\n",
    "                    \n",
    "                    # ìˆœìœ„ URL ìˆ˜ì§‘ (í–¥ìƒëœ ë°©ì‹)\n",
    "                    ranking_urls = collect_ranking_urls_enhanced(driver, ranking_limit, tab_name)\n",
    "                    \n",
    "                    if ranking_urls:\n",
    "                        collected_ranking_urls[tab_name] = ranking_urls\n",
    "                        \n",
    "                        # íƒ­ ê°ì§€ ì •ë³´ ì°¾ê¸°\n",
    "                        detection_info = None\n",
    "                        for detected_tab in detected_tabs:\n",
    "                            if detected_tab[\"name\"] == tab_name:\n",
    "                                detection_info = detected_tab\n",
    "                                break\n",
    "                        \n",
    "                        # ìˆœìœ„ URL ì €ì¥ (í–¥ìƒëœ ë°©ì‹)\n",
    "                        save_ranking_urls_enhanced(\n",
    "                            city_name, tab_name, ranking_urls, \n",
    "                            selected_strategy, detection_info\n",
    "                        )\n",
    "                    else:\n",
    "                        print(f\"âš ï¸ '{tab_name}' íƒ­ì—ì„œ URLì„ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤\")\n",
    "        \n",
    "        # 5. ê²°ê³¼ êµ¬ì„±\n",
    "        result = {\n",
    "            \"strategy\": selected_strategy,\n",
    "            \"strategy_info\": strategy_info,\n",
    "            \"tabs\": selected_tabs,\n",
    "            \"ranking_urls\": collected_ranking_urls,\n",
    "            \"use_sitemap\": strategy_info[\"method\"] in [\"hybrid\", \"tab_specific\"],\n",
    "            \"use_ranking\": strategy_info[\"ranking_collection\"],\n",
    "            \"execution_time\": datetime.now().isoformat(),\n",
    "            \"success\": True,\n",
    "            \"detected_tabs_count\": len(detected_tabs) if 'detected_tabs' in locals() else 0\n",
    "        }\n",
    "        \n",
    "        # 6. ê²°ê³¼ ìš”ì•½\n",
    "        total_ranking_urls = sum(len(urls) for urls in collected_ranking_urls.values())\n",
    "        successful_tabs = len(collected_ranking_urls)\n",
    "        \n",
    "        print(f\"\\nğŸ“Š í†µí•© íƒ­ ì…€ë ‰í„° ì‹œìŠ¤í…œ ì™„ë£Œ ìš”ì•½:\")\n",
    "        print(f\"   ğŸ¯ ì „ëµ: {strategy_info['name']}\")\n",
    "        print(f\"   ğŸ“‹ ì„ íƒ íƒ­: {', '.join(selected_tabs)}\")\n",
    "        print(f\"   âœ… ì„±ê³µ íƒ­: {successful_tabs}/{len(selected_tabs)}\")\n",
    "        print(f\"   ğŸ“ˆ ì´ ìˆœìœ„ URL: {total_ranking_urls}ê°œ\")\n",
    "        print(f\"   ğŸ—ºï¸ Sitemap ì‚¬ìš©: {'ì˜ˆ' if result['use_sitemap'] else 'ì•„ë‹ˆì˜¤'}\")\n",
    "        print(f\"   ğŸ† ìˆœìœ„ ì •ë³´: {'ì˜ˆ' if result['use_ranking'] else 'ì•„ë‹ˆì˜¤'}\")\n",
    "        \n",
    "        # íƒ­ë³„ ìƒì„¸ ì •ë³´\n",
    "        if collected_ranking_urls:\n",
    "            print(f\"\\nğŸ“ˆ íƒ­ë³„ ìˆ˜ì§‘ ê²°ê³¼:\")\n",
    "            for tab_name, urls in collected_ranking_urls.items():\n",
    "                print(f\"   - {tab_name}: {len(urls)}ê°œ\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í†µí•© íƒ­ ì…€ë ‰í„° ì‹œìŠ¤í…œ ì‹¤í–‰ ì‹¤íŒ¨: {e}\")\n",
    "        return {\n",
    "            \"strategy\": \"error_fallback\",\n",
    "            \"tabs\": [\"ì „ì²´\"],\n",
    "            \"ranking_urls\": {},\n",
    "            \"use_sitemap\": True,\n",
    "            \"use_ranking\": False,\n",
    "            \"error\": str(e),\n",
    "            \"execution_time\": datetime.now().isoformat(),\n",
    "            \"success\": False\n",
    "        }\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ¯ ìë™ ì‹¤í–‰ ë˜í¼ í•¨ìˆ˜ (ê¸°ì¡´ ê·¸ë£¹ 7 í˜¸í™˜)\n",
    "# =============================================================================\n",
    "\n",
    "def execute_tab_selector_system(city_name, driver):\n",
    "    \"\"\"ê¸°ì¡´ ê·¸ë£¹ 7 í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼\"\"\"\n",
    "    return execute_integrated_tab_selector_system(city_name, driver, interactive_mode=False)\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ¯ í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ í•¨ìˆ˜\n",
    "# =============================================================================\n",
    "\n",
    "def validate_system_integration(driver, test_city=\"ì„œìš¸\"):\n",
    "    \"\"\"í†µí•© ì‹œìŠ¤í…œ ê²€ì¦ í•¨ìˆ˜\"\"\"\n",
    "    print(\"ğŸ§ª í†µí•© ì‹œìŠ¤í…œ ê²€ì¦ ì‹œì‘...\")\n",
    "    \n",
    "    validation_results = {\n",
    "        \"tab_detection\": False,\n",
    "        \"strategy_selection\": False,\n",
    "        \"url_collection\": False,\n",
    "        \"file_saving\": False,\n",
    "        \"overall_success\": False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # 1. íƒ­ ê°ì§€ í…ŒìŠ¤íŠ¸\n",
    "        print(\"1ï¸âƒ£ íƒ­ ê°ì§€ í…ŒìŠ¤íŠ¸...\")\n",
    "        detected_tabs = detect_tabs_with_enhanced_fallback(driver)\n",
    "        validation_results[\"tab_detection\"] = len(detected_tabs) > 0\n",
    "        print(f\"   íƒ­ ê°ì§€ ê²°ê³¼: {len(detected_tabs)}ê°œ íƒ­ ë°œê²¬\")\n",
    "        \n",
    "        # 2. ì „ëµ ì„ íƒ í…ŒìŠ¤íŠ¸\n",
    "        print(\"2ï¸âƒ£ ì „ëµ ì„ íƒ í…ŒìŠ¤íŠ¸...\")\n",
    "        try:\n",
    "            strategy, tabs = select_crawling_strategy_auto()\n",
    "            validation_results[\"strategy_selection\"] = strategy in CRAWLING_STRATEGIES\n",
    "            print(f\"   ì „ëµ ì„ íƒ ê²°ê³¼: {strategy}, íƒ­: {tabs}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ì „ëµ ì„ íƒ ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        # 3. URL ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ (ì²« ë²ˆì§¸ íƒ­ë§Œ)\n",
    "        print(\"3ï¸âƒ£ URL ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸...\")\n",
    "        if detected_tabs:\n",
    "            try:\n",
    "                first_tab = detected_tabs[0][\"name\"]\n",
    "                test_urls = collect_ranking_urls_enhanced(driver, 5, first_tab)\n",
    "                validation_results[\"url_collection\"] = len(test_urls) > 0\n",
    "                print(f\"   URL ìˆ˜ì§‘ ê²°ê³¼: {len(test_urls)}ê°œ\")\n",
    "            except Exception as e:\n",
    "                print(f\"   URL ìˆ˜ì§‘ ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        # 4. íŒŒì¼ ì €ì¥ í…ŒìŠ¤íŠ¸\n",
    "        print(\"4ï¸âƒ£ íŒŒì¼ ì €ì¥ í…ŒìŠ¤íŠ¸...\")\n",
    "        try:\n",
    "            test_urls = [\"https://www.klook.com/activity/12345-test/\"]\n",
    "            filename = save_ranking_urls_enhanced(test_city, \"í…ŒìŠ¤íŠ¸\", test_urls, \"test_strategy\")\n",
    "            validation_results[\"file_saving\"] = filename is not None\n",
    "            print(f\"   íŒŒì¼ ì €ì¥ ê²°ê³¼: {'ì„±ê³µ' if filename else 'ì‹¤íŒ¨'}\")\n",
    "            \n",
    "            # í…ŒìŠ¤íŠ¸ íŒŒì¼ ì •ë¦¬\n",
    "            if filename and os.path.exists(filename):\n",
    "                os.remove(filename)\n",
    "        except Exception as e:\n",
    "            print(f\"   íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        # ì „ì²´ ê²€ì¦ ê²°ê³¼\n",
    "        validation_results[\"overall_success\"] = all([\n",
    "            validation_results[\"tab_detection\"],\n",
    "            validation_results[\"strategy_selection\"],\n",
    "            validation_results[\"url_collection\"] or validation_results[\"file_saving\"]  # ìµœì†Œ í•˜ë‚˜ëŠ” ì„±ê³µ\n",
    "        ])\n",
    "        \n",
    "        print(f\"\\nğŸ§ª ê²€ì¦ ì™„ë£Œ:\")\n",
    "        for test_name, result in validation_results.items():\n",
    "            status = \"âœ…\" if result else \"âŒ\"\n",
    "            print(f\"   {status} {test_name}: {'í†µê³¼' if result else 'ì‹¤íŒ¨'}\")\n",
    "        \n",
    "        return validation_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return validation_results\n",
    "\n",
    "def generate_system_report(city_name, execution_result):\n",
    "    \"\"\"ì‹œìŠ¤í…œ ì‹¤í–‰ ë³´ê³ ì„œ ìƒì„±\"\"\"\n",
    "    try:\n",
    "        os.makedirs(\"reports\", exist_ok=True)\n",
    "        \n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        report_filename = f\"reports/{city_name}_system_report_{timestamp}.json\"\n",
    "        \n",
    "        report_data = {\n",
    "            \"report_metadata\": {\n",
    "                \"city\": city_name,\n",
    "                \"generated_time\": datetime.now().isoformat(),\n",
    "                \"system_version\": \"integrated_enhanced_v1.0\",\n",
    "                \"report_type\": \"tab_selector_execution\"\n",
    "            },\n",
    "            \"execution_summary\": execution_result,\n",
    "            \"performance_metrics\": {\n",
    "                \"total_tabs_attempted\": len(execution_result.get(\"tabs\", [])),\n",
    "                \"successful_tabs\": len(execution_result.get(\"ranking_urls\", {})),\n",
    "                \"total_urls_collected\": sum(len(urls) for urls in execution_result.get(\"ranking_urls\", {}).values()),\n",
    "                \"success_rate\": len(execution_result.get(\"ranking_urls\", {})) / max(len(execution_result.get(\"tabs\", [])), 1) * 100\n",
    "            },\n",
    "            \"recommendations\": []\n",
    "        }\n",
    "        \n",
    "        # ì„±ëŠ¥ ê¸°ë°˜ ì¶”ì²œì‚¬í•­ ìƒì„±\n",
    "        success_rate = report_data[\"performance_metrics\"][\"success_rate\"]\n",
    "        total_urls = report_data[\"performance_metrics\"][\"total_urls_collected\"]\n",
    "        \n",
    "        if success_rate < 50:\n",
    "            report_data[\"recommendations\"].append(\"íƒ­ ê°ì§€ ì„±ê³µë¥ ì´ ë‚®ìŠµë‹ˆë‹¤. í˜ì´ì§€ êµ¬ì¡° ë³€ê²½ í™•ì¸ í•„ìš”\")\n",
    "        \n",
    "        if total_urls < 10:\n",
    "            report_data[\"recommendations\"].append(\"ìˆ˜ì§‘ëœ URLì´ ì ìŠµë‹ˆë‹¤. í˜ì´ì§€ ë¡œë”© ì‹œê°„ ì¦ê°€ ê³ ë ¤\")\n",
    "        \n",
    "        if execution_result.get(\"success\", False):\n",
    "            report_data[\"recommendations\"].append(\"ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™í–ˆìŠµë‹ˆë‹¤. ì •ê¸°ì ì¸ ëª¨ë‹ˆí„°ë§ ê¶Œì¥\")\n",
    "        \n",
    "        with open(report_filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(report_data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"ğŸ“Š ì‹œìŠ¤í…œ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {report_filename}\")\n",
    "        return report_filename\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ¯ í†µí•© ì‹œìŠ¤í…œ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (ëª¨ë“  ê¸°ëŠ¥ í¬í•¨)\n",
    "# =============================================================================\n",
    "\n",
    "def run_complete_klook_system(city_name, driver, config=None):\n",
    "    \"\"\"\n",
    "    ì™„ì „í•œ KLOOK ì‹œìŠ¤í…œ ì‹¤í–‰ (ê²€ì¦ + ì‹¤í–‰ + ë³´ê³ ì„œ)\n",
    "    \n",
    "    Args:\n",
    "        city_name: ë„ì‹œëª…\n",
    "        driver: WebDriver ì¸ìŠ¤í„´ìŠ¤\n",
    "        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬\n",
    "    \n",
    "    Returns:\n",
    "        dict: ì™„ì „í•œ ì‹¤í–‰ ê²°ê³¼\n",
    "    \"\"\"\n",
    "    print(f\"ğŸš€ ì™„ì „í•œ KLOOK ì‹œìŠ¤í…œ ì‹¤í–‰ ì‹œì‘: '{city_name}'\")\n",
    "    print(\"=\" * 90)\n",
    "    \n",
    "    # ê¸°ë³¸ ì„¤ì •\n",
    "    default_config = {\n",
    "        \"run_validation\": True,\n",
    "        \"interactive_mode\": False,\n",
    "        \"generate_report\": True,\n",
    "        \"cleanup_test_files\": True,\n",
    "        \"max_retries\": 3\n",
    "    }\n",
    "    \n",
    "    if config:\n",
    "        default_config.update(config)\n",
    "    \n",
    "    complete_result = {\n",
    "        \"city_name\": city_name,\n",
    "        \"config\": default_config,\n",
    "        \"start_time\": datetime.now().isoformat(),\n",
    "        \"validation_results\": None,\n",
    "        \"execution_results\": None,\n",
    "        \"report_filename\": None,\n",
    "        \"overall_success\": False,\n",
    "        \"errors\": []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # 1. ì‹œìŠ¤í…œ ê²€ì¦ (ì„ íƒì )\n",
    "        if default_config[\"run_validation\"]:\n",
    "            print(\"\\nğŸ§ª === 1ë‹¨ê³„: ì‹œìŠ¤í…œ ê²€ì¦ ===\")\n",
    "            validation_results = validate_system_integration(driver, city_name)\n",
    "            complete_result[\"validation_results\"] = validation_results\n",
    "            \n",
    "            if not validation_results[\"overall_success\"]:\n",
    "                print(\"âš ï¸ ê²€ì¦ì—ì„œ ì¼ë¶€ ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆì§€ë§Œ ì‹¤í–‰ì„ ê³„ì†í•©ë‹ˆë‹¤...\")\n",
    "        \n",
    "        # 2. ë©”ì¸ ì‹œìŠ¤í…œ ì‹¤í–‰\n",
    "        print(\"\\nğŸ¯ === 2ë‹¨ê³„: íƒ­ ì…€ë ‰í„° ì‹œìŠ¤í…œ ì‹¤í–‰ ===\")\n",
    "        execution_results = execute_integrated_tab_selector_system(\n",
    "            city_name, driver, default_config[\"interactive_mode\"]\n",
    "        )\n",
    "        complete_result[\"execution_results\"] = execution_results\n",
    "        \n",
    "        # 3. ë³´ê³ ì„œ ìƒì„± (ì„ íƒì )\n",
    "        if default_config[\"generate_report\"] and execution_results:\n",
    "            print(\"\\nğŸ“Š === 3ë‹¨ê³„: ë³´ê³ ì„œ ìƒì„± ===\")\n",
    "            report_filename = generate_system_report(city_name, execution_results)\n",
    "            complete_result[\"report_filename\"] = report_filename\n",
    "        \n",
    "        # 4. ì „ì²´ ì„±ê³µ ì—¬ë¶€ íŒë‹¨\n",
    "        complete_result[\"overall_success\"] = (\n",
    "            execution_results and \n",
    "            execution_results.get(\"success\", False) and\n",
    "            len(execution_results.get(\"ranking_urls\", {})) > 0\n",
    "        )\n",
    "        \n",
    "        complete_result[\"end_time\"] = datetime.now().isoformat()\n",
    "        \n",
    "        # 5. ìµœì¢… ìš”ì•½\n",
    "        print(f\"\\nğŸ‰ === ì™„ì „í•œ KLOOK ì‹œìŠ¤í…œ ì‹¤í–‰ ì™„ë£Œ ===\")\n",
    "        print(f\"ğŸ™ï¸ ë„ì‹œ: {city_name}\")\n",
    "        print(f\"âœ… ì „ì²´ ì„±ê³µ: {'ì˜ˆ' if complete_result['overall_success'] else 'ì•„ë‹ˆì˜¤'}\")\n",
    "        \n",
    "        if execution_results:\n",
    "            print(f\"ğŸ¯ ì‚¬ìš©ëœ ì „ëµ: {execution_results.get('strategy', 'N/A')}\")\n",
    "            print(f\"ğŸ“ˆ ìˆ˜ì§‘ëœ URL: {sum(len(urls) for urls in execution_results.get('ranking_urls', {}).values())}ê°œ\")\n",
    "            print(f\"ğŸª ì„±ê³µí•œ íƒ­: {len(execution_results.get('ranking_urls', {}))}ê°œ\")\n",
    "        \n",
    "        if complete_result[\"report_filename\"]:\n",
    "            print(f\"ğŸ“Š ë³´ê³ ì„œ: {complete_result['report_filename']}\")\n",
    "        \n",
    "        return complete_result\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"ì™„ì „í•œ ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}\"\n",
    "        print(f\"âŒ {error_msg}\")\n",
    "        complete_result[\"errors\"].append(error_msg)\n",
    "        complete_result[\"end_time\"] = datetime.now().isoformat()\n",
    "        return complete_result\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ¯ í¸ì˜ í•¨ìˆ˜ë“¤ (Quick Start)\n",
    "# =============================================================================\n",
    "\n",
    "def quick_start_ranking_collection(city_name, driver, strategy=\"ì „ì²´_hybrid\"):\n",
    "    \"\"\"ë¹ ë¥¸ ì‹œì‘: ìˆœìœ„ ìˆ˜ì§‘ë§Œ\"\"\"\n",
    "    print(f\"âš¡ ë¹ ë¥¸ ì‹œì‘: '{city_name}' ìˆœìœ„ ìˆ˜ì§‘\")\n",
    "    \n",
    "    config = {\n",
    "        \"run_validation\": False,\n",
    "        \"interactive_mode\": False,\n",
    "        \"generate_report\": False\n",
    "    }\n",
    "    \n",
    "    result = execute_integrated_tab_selector_system(city_name, driver, False)\n",
    "    \n",
    "    if result.get(\"success\"):\n",
    "        total_urls = sum(len(urls) for urls in result.get(\"ranking_urls\", {}).values())\n",
    "        print(f\"âœ… ë¹ ë¥¸ ìˆ˜ì§‘ ì™„ë£Œ: {total_urls}ê°œ URL\")\n",
    "    else:\n",
    "        print(\"âŒ ë¹ ë¥¸ ìˆ˜ì§‘ ì‹¤íŒ¨\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def quick_start_full_system(city_name, driver):\n",
    "    \"\"\"ë¹ ë¥¸ ì‹œì‘: ì „ì²´ ì‹œìŠ¤í…œ\"\"\"\n",
    "    print(f\"ğŸš€ ë¹ ë¥¸ ì‹œì‘: '{city_name}' ì „ì²´ ì‹œìŠ¤í…œ\")\n",
    "    \n",
    "    return run_complete_klook_system(city_name, driver)\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ë° ë””ë²„ê¹…\n",
    "# =============================================================================\n",
    "\n",
    "def check_system_health():\n",
    "    \"\"\"ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸\"\"\"\n",
    "    print(\"ğŸ©º ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸...\")\n",
    "    \n",
    "    health_status = {\n",
    "        \"directories\": {},\n",
    "        \"configurations\": {},\n",
    "        \"dependencies\": {},\n",
    "        \"overall_health\": \"unknown\"\n",
    "    }\n",
    "    \n",
    "    # ë””ë ‰í† ë¦¬ í™•ì¸\n",
    "    required_dirs = [\"ranking_urls\", \"reports\"]\n",
    "    for dir_name in required_dirs:\n",
    "        try:\n",
    "            os.makedirs(dir_name, exist_ok=True)\n",
    "            health_status[\"directories\"][dir_name] = \"ok\"\n",
    "        except Exception as e:\n",
    "            health_status[\"directories\"][dir_name] = f\"error: {e}\"\n",
    "    \n",
    "    # ì„¤ì • í™•ì¸\n",
    "    health_status[\"configurations\"][\"tab_structure\"] = \"ok\" if KLOOK_TAB_STRUCTURE else \"missing\"\n",
    "    health_status[\"configurations\"][\"strategies\"] = \"ok\" if CRAWLING_STRATEGIES else \"missing\"\n",
    "    \n",
    "    # ì˜ì¡´ì„± í™•ì¸\n",
    "    try:\n",
    "        import selenium\n",
    "        health_status[\"dependencies\"][\"selenium\"] = \"ok\"\n",
    "    except ImportError:\n",
    "        health_status[\"dependencies\"][\"selenium\"] = \"missing\"\n",
    "    \n",
    "    try:\n",
    "        import json\n",
    "        health_status[\"dependencies\"][\"json\"] = \"ok\"\n",
    "    except ImportError:\n",
    "        health_status[\"dependencies\"][\"json\"] = \"missing\"\n",
    "    \n",
    "    # ì „ì²´ ìƒíƒœ ê²°ì •\n",
    "    all_dirs_ok = all(status == \"ok\" for status in health_status[\"directories\"].values())\n",
    "    all_configs_ok = all(status == \"ok\" for status in health_status[\"configurations\"].values())\n",
    "    all_deps_ok = all(status == \"ok\" for status in health_status[\"dependencies\"].values())\n",
    "    \n",
    "    if all_dirs_ok and all_configs_ok and all_deps_ok:\n",
    "        health_status[\"overall_health\"] = \"healthy\"\n",
    "    elif all_configs_ok and all_deps_ok:\n",
    "        health_status[\"overall_health\"] = \"minor_issues\"\n",
    "    else:\n",
    "        health_status[\"overall_health\"] = \"unhealthy\"\n",
    "    \n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    print(f\"ğŸ“Š ì „ì²´ ìƒíƒœ: {health_status['overall_health']}\")\n",
    "    \n",
    "    for category, items in health_status.items():\n",
    "        if category != \"overall_health\":\n",
    "            print(f\"ğŸ” {category}:\")\n",
    "            for item, status in items.items():\n",
    "                status_icon = \"âœ…\" if status == \"ok\" else \"âŒ\"\n",
    "                print(f\"   {status_icon} {item}: {status}\")\n",
    "    \n",
    "    return health_status\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ¯ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ì™„ë£Œ ë©”ì‹œì§€\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"âœ… í†µí•© KLOOK íƒ­ ì…€ë ‰í„° & ì „ëµ ì‹œìŠ¤í…œ ì™„ë£Œ!\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "print(\"\\nğŸ”§ ì£¼ìš” ê¸°ëŠ¥:\")\n",
    "print(\"   ğŸ¯ detect_tabs_with_enhanced_fallback() - ê°•í™”ëœ íƒ­ ê°ì§€\")\n",
    "print(\"   ğŸ”„ click_tab_enhanced() - ë‹¤ì¤‘ ë°©ì‹ íƒ­ í´ë¦­\")\n",
    "print(\"   ğŸ“Š collect_ranking_urls_enhanced() - í–¥ìƒëœ URL ìˆ˜ì§‘\")\n",
    "print(\"   ğŸ’¾ save_ranking_urls_enhanced() - ë©”íƒ€ë°ì´í„° í¬í•¨ ì €ì¥\")\n",
    "print(\"   ğŸš€ execute_integrated_tab_selector_system() - í†µí•© ì‹¤í–‰\")\n",
    "print(\"   ğŸ“Š run_complete_klook_system() - ì™„ì „í•œ ì‹œìŠ¤í…œ ì‹¤í–‰\")\n",
    "\n",
    "print(\"\\nğŸ¯ ì§€ì› í¬ë¡¤ë§ ì „ëµ:\")\n",
    "print(\"   ğŸ“‹ ì „ì²´_sitemap - Sitemap ì „ìš©\")\n",
    "print(\"   ğŸ”€ ì „ì²´_hybrid - ìˆœìœ„ + Sitemap ì¡°í•©\")\n",
    "print(\"   ğŸª íƒ­ë³„_ì„ íƒ - íŠ¹ì • íƒ­ ì„ íƒ\")\n",
    "print(\"   ğŸ† ìˆœìœ„ë§Œ_ìˆ˜ì§‘ - ìˆœìœ„ ì •ë³´ë§Œ\")\n",
    "print(\"   âš¡ enhanced_full - ëª¨ë“  íƒ­ Enhanced ëª¨ë“œ\")\n",
    "\n",
    "print(\"\\nğŸš€ ë¹ ë¥¸ ì‹œì‘:\")\n",
    "print(\"   # ê¸°ë³¸ ì‚¬ìš©\")\n",
    "print(\"   result = execute_tab_selector_system(city_name, driver)\")\n",
    "print(\"\")\n",
    "print(\"   # ì „ì²´ ì‹œìŠ¤í…œ ì‹¤í–‰\")\n",
    "print(\"   result = run_complete_klook_system(city_name, driver)\")\n",
    "print(\"\")\n",
    "print(\"   # ë¹ ë¥¸ ìˆœìœ„ ìˆ˜ì§‘\")\n",
    "print(\"   result = quick_start_ranking_collection(city_name, driver)\")\n",
    "\n",
    "print(\"\\nğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸:\")\n",
    "print(\"   health = check_system_health()\")\n",
    "\n",
    "print(\"\\nğŸ‰ í†µí•© ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(\"ğŸ”— ê·¸ë£¹ 8 sitemap ì‹œìŠ¤í…œê³¼ì˜ ì—°ë™ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce66017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ğŸš€ ê·¸ë£¹ 8: ìµœì í™”ëœ URL ìˆ˜ì§‘ ë° í˜ì´ì§€ë„¤ì´ì…˜ ë¶„ì„ (ì¤‘ë³µ ì œê±° ë²„ì „ Â· ë“œë¡­ì¸ ì™„ì„±ë³¸)\n",
    "# - ê¸°ì¡´ ê·¸ë£¹ 1~7 í•¨ìˆ˜ 100% ì¬í™œìš©\n",
    "# - ì „ì—­ ì˜ì¡´ ìµœì†Œí™” / ì•ˆì „ í´ë°± / ê¹”ë” ë¡œê·¸\n",
    "# =============================================================================\n",
    "\n",
    "def _safe_get_config(local_config, key, default=None):\n",
    "    try:\n",
    "        if local_config and key in local_config:\n",
    "            return local_config[key]\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        return CONFIG.get(key, default)  # ê¸€ë¡œë²Œ CONFIG í´ë°±\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "def _safe_callable(name):\n",
    "    \"\"\"globals()ì—ì„œ nameì„ ì°¾ì•„ callableì´ë©´ ë°˜í™˜, ì•„ë‹ˆë©´ None\"\"\"\n",
    "    fn = globals().get(name)\n",
    "    return fn if callable(fn) else None\n",
    "\n",
    "def execute_optimized_url_collection(driver, city_name, start_number, completed_urls, config=None):\n",
    "    \"\"\"\n",
    "    ğŸ¯ ìµœì í™”ëœ URL ìˆ˜ì§‘ ë° ë¶„ì„ ì‹¤í–‰\n",
    "    - ê·¸ë£¹ 4: analyze_pagination / generate_crawling_plan / report_reconnaissance_results\n",
    "    - ê·¸ë£¹ 3: collect_urls_with_csv_safety / save_collected_urls\n",
    "    \"\"\"\n",
    "    print(\"ğŸ” ê·¸ë£¹ 8: ìµœì í™”ëœ URL ìˆ˜ì§‘ ë° í˜ì´ì§€ë„¤ì´ì…˜ ë¶„ì„ ì‹œì‘!\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # ========== 1ë‹¨ê³„: í˜ì´ì§€ë„¤ì´ì…˜ ë¶„ì„ (ê·¸ë£¹ 4 ì¬í™œìš©) ==========\n",
    "    print(\"ğŸ” === 1ë‹¨ê³„: í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„ ===\")\n",
    "\n",
    "    analyze_pagination = _safe_callable(\"analyze_pagination\")\n",
    "    generate_crawling_plan = _safe_callable(\"generate_crawling_plan\")\n",
    "    report_reconnaissance_results = _safe_callable(\"report_reconnaissance_results\")\n",
    "    check_next_button = _safe_callable(\"check_next_button\")\n",
    "\n",
    "    pagination_info = {'total_products': 0, 'total_pages': 1, 'products_per_page': 24}\n",
    "    strategy = \"ê¸°ë³¸\"\n",
    "    try:\n",
    "        if not (analyze_pagination and generate_crawling_plan and report_reconnaissance_results):\n",
    "            raise RuntimeError(\"í•„ìˆ˜ ë¶„ì„ í•¨ìˆ˜ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤ (Group 4)\")\n",
    "\n",
    "        pg_info = analyze_pagination(driver)\n",
    "        pagination_info.update(pg_info or {})\n",
    "        plan = generate_crawling_plan(pagination_info, city_name)\n",
    "        can_proceed = report_reconnaissance_results(plan)\n",
    "        button_ok = check_next_button(driver) if check_next_button else True\n",
    "\n",
    "        strategy = \"ë‹¤ì¤‘ í˜ì´ì§€\" if (can_proceed and button_ok) else \"ë‹¨ì¼ í˜ì´ì§€\"\n",
    "        print(f\"ğŸ“Š ì„ íƒëœ ì „ëµ: {strategy}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ í˜ì´ì§€ë„¤ì´ì…˜ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "        strategy = \"ê¸°ë³¸\"\n",
    "\n",
    "    # ========== 2ë‹¨ê³„: URL ìˆ˜ì§‘ (ê·¸ë£¹ 3 ì¬í™œìš©) ==========\n",
    "    print(\"ğŸ” === 2ë‹¨ê³„: URL ìˆ˜ì§‘ ===\")\n",
    "\n",
    "    collect_urls_with_csv_safety = _safe_callable(\"collect_urls_with_csv_safety\")\n",
    "    save_collected_urls = _safe_callable(\"save_collected_urls\")\n",
    "\n",
    "    if not collect_urls_with_csv_safety:\n",
    "        print(\"âŒ URL ìˆ˜ì§‘ í•¨ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤: collect_urls_with_csv_safety\")\n",
    "        return {\n",
    "            'success': False,\n",
    "            'strategy': strategy,\n",
    "            'pagination_info': pagination_info,\n",
    "            'urls_collected': 0,\n",
    "            'urls_to_process': [],\n",
    "            'city_name': city_name,\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        collected_urls = collect_urls_with_csv_safety(driver, city_name) or []\n",
    "        if collected_urls:\n",
    "            print(f\"ğŸ‰ ìƒˆë¡œìš´ URL {len(collected_urls)}ê°œ ìˆ˜ì§‘ ì„±ê³µ!\")\n",
    "\n",
    "            max_products = int(_safe_get_config(config, 'MAX_PRODUCTS_PER_CITY', 100))\n",
    "            urls_to_process = collected_urls[:max_products]\n",
    "\n",
    "            if save_collected_urls:\n",
    "                try:\n",
    "                    save_collected_urls(city_name, urls_to_process)\n",
    "                except Exception as se:\n",
    "                    print(f\"âš ï¸ URL ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {type(se).__name__}: {se}\")\n",
    "\n",
    "            return {\n",
    "                'success': True,\n",
    "                'strategy': strategy,\n",
    "                'pagination_info': pagination_info,\n",
    "                'urls_collected': len(collected_urls),\n",
    "                'urls_to_process': urls_to_process,\n",
    "                'city_name': city_name,\n",
    "                'start_number': start_number,\n",
    "            }\n",
    "        else:\n",
    "            print(\"âŒ ìƒˆë¡œìš´ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "            return {\n",
    "                'success': False,\n",
    "                'strategy': strategy,\n",
    "                'pagination_info': pagination_info,\n",
    "                'urls_collected': 0,\n",
    "                'urls_to_process': [],\n",
    "                'city_name': city_name,\n",
    "                'start_number': start_number,\n",
    "            }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ URL ìˆ˜ì§‘ ì‹¤íŒ¨: {e}\")\n",
    "        return {\n",
    "            'success': False,\n",
    "            'strategy': strategy,\n",
    "            'pagination_info': pagination_info,\n",
    "            'urls_collected': 0,\n",
    "            'urls_to_process': [],\n",
    "            'city_name': city_name,\n",
    "            'start_number': start_number,\n",
    "            'error': str(e),\n",
    "        }\n",
    "\n",
    "def display_collection_summary(result, completed_urls, config=None):\n",
    "    \"\"\"ğŸ” ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½ í‘œì‹œ (í•µì‹¬ ì •ë³´ë§Œ)\"\"\"\n",
    "    print(\"ğŸ” === 3ë‹¨ê³„: ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½ ===\")\n",
    "\n",
    "    get_city_info = _safe_callable(\"get_city_info\")\n",
    "\n",
    "    city_name = result.get('city_name', 'Unknown')\n",
    "    success = result.get('success', False)\n",
    "    strategy = result.get('strategy', 'Unknown')\n",
    "    start_number = result.get('start_number', 1)\n",
    "    urls_to_process = result.get('urls_to_process', [])\n",
    "\n",
    "    print(\"ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½:\")\n",
    "    print(f\"  ğŸ™ï¸ ëŒ€ìƒ ë„ì‹œ: {city_name}\")\n",
    "    print(f\"  ğŸ“„ í˜ì´ì§€ë„¤ì´ì…˜ ì „ëµ: {strategy}\")\n",
    "    print(f\"  ğŸ”¢ ìˆ˜ì§‘ëœ ì‹ ê·œ URL: {result.get('urls_collected', 0)}ê°œ\")\n",
    "    print(f\"  ğŸ¯ ì²˜ë¦¬í•  URL: {len(urls_to_process)}ê°œ\")\n",
    "\n",
    "    if success and urls_to_process:\n",
    "        print(f\"  ğŸ“ˆ ì˜ˆìƒ ë²ˆí˜¸ ë²”ìœ„: {start_number} ~ {start_number + len(urls_to_process) - 1}\")\n",
    "\n",
    "        continent, country = (\"\", \"\")\n",
    "        try:\n",
    "            if get_city_info:\n",
    "                continent, country = get_city_info(city_name)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        special_cities = {\"ë§ˆì¹´ì˜¤\", \"í™ì½©\", \"ì‹±ê°€í¬ë¥´\"}\n",
    "        if city_name in special_cities:\n",
    "            print(f\"  ğŸ“ ì´ë¯¸ì§€ ì €ì¥: klook_thumb_img/{continent}/{city_name}/\")\n",
    "            print(f\"  ğŸ“ ë°ì´í„° ì €ì¥: data/{continent}/\")\n",
    "        else:\n",
    "            print(f\"  ğŸ“ ì´ë¯¸ì§€ ì €ì¥: klook_thumb_img/{continent}/{country}/{city_name}/\")\n",
    "            print(f\"  ğŸ“ ë°ì´í„° ì €ì¥: data/{continent}/{country}/{city_name}/\")\n",
    "\n",
    "        print(\"âœ… ê·¸ë£¹ 8 ì™„ë£Œ: URL ìˆ˜ì§‘ ë° ë¶„ì„ ì„±ê³µ!\")\n",
    "        print(\"ğŸš€ ë‹¤ìŒ: ê·¸ë£¹ 9ë¥¼ ì‹¤í–‰í•˜ì—¬ ì‹¤ì œ í¬ë¡¤ë§ì„ ì‹œì‘í•˜ì„¸ìš”!\")\n",
    "    else:\n",
    "        print(\"âš ï¸ ê·¸ë£¹ 8 ì™„ë£Œ: í¬ë¡¤ë§í•  ìƒˆë¡œìš´ URLì´ ì—†ìŒ\")\n",
    "        print(\"ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„: ë‹¤ë¥¸ ë„ì‹œë¡œ ë³€ê²½í•˜ê±°ë‚˜ í˜ì´ì§€ë„¤ì´ì…˜ì„ í†µí•œ ë‹¤ìŒ í˜ì´ì§€ ì´ë™\")\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ¯ ë©”ì¸ ì‹¤í–‰ (ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜)\n",
    "# - ì „ì—­ ë³€ìˆ˜ ì¡´ì¬ ì‹œ ê·¸ëŒ€ë¡œ ì¬í™œìš©í•˜ë©°, ëˆ„ë½ ì‹œ ì•ˆì „ ì²˜ë¦¬\n",
    "# =============================================================================\n",
    "def run_optimized_group8():\n",
    "    \"\"\"\n",
    "    ìµœì í™”ëœ ê·¸ë£¹ 8 ì‹¤í–‰ (ì „ì—­ ë³€ìˆ˜ ì¬í™œìš©)\n",
    "    í•„ìš” ì „ì—­: driver, city_name, start_number, completed_urls, CONFIG(ì„ íƒ)\n",
    "    \"\"\"\n",
    "    global driver, city_name, start_number, completed_urls\n",
    "    try:\n",
    "        print(\"ğŸ“‹ í˜„ì¬ ìƒíƒœ í™•ì¸:\")\n",
    "        print(f\"  ğŸ™ï¸ ëŒ€ìƒ ë„ì‹œ: {city_name}\")\n",
    "        print(f\"  ğŸ“Š ì™„ë£Œëœ URL: {len(completed_urls)}ê°œ\")\n",
    "        print(f\"  ğŸ”¢ ì‹œì‘ ë²ˆí˜¸: {start_number}\")\n",
    "        print(f\"  ğŸ“± ë“œë¼ì´ë²„ ìƒíƒœ: í™œì„±\")\n",
    "    except NameError as e:\n",
    "        print(f\"âŒ í•„ìˆ˜ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}\")\n",
    "        print(\"ğŸ’¡ ê·¸ë£¹ 6ê³¼ ê·¸ë£¹ 7ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”!\")\n",
    "        return {'success': False, 'error': 'Missing variables'}\n",
    "\n",
    "    result = execute_optimized_url_collection(\n",
    "        driver=driver,\n",
    "        city_name=city_name,\n",
    "        start_number=start_number,\n",
    "        completed_urls=completed_urls,\n",
    "        config=globals().get(\"CONFIG\"),\n",
    "    )\n",
    "\n",
    "    display_collection_summary(result, completed_urls, config=globals().get(\"CONFIG\"))\n",
    "\n",
    "    # ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ í˜¸í™˜ì„ ìœ„í•´ ê²°ê³¼ë¥¼ ì¼ë¶€ ì „ì—­ìœ¼ë¡œë„ ì œê³µ\n",
    "    if result.get('success'):\n",
    "        globals()['urls_to_crawl'] = result['urls_to_process']\n",
    "        globals()['total_products_to_crawl'] = len(result['urls_to_process'])\n",
    "    else:\n",
    "        globals()['urls_to_crawl'] = []\n",
    "        globals()['total_products_to_crawl'] = 0\n",
    "\n",
    "    return result\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ¯ ìë™ ì‹¤í–‰ (ì›í•˜ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©)\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    r = run_optimized_group8()\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"âœ… ìµœì í™”ëœ ê·¸ë£¹ 8 ì™„ë£Œ!\")\n",
    "    print(\"ğŸ”§ ê°œì„ ì‚¬í•­:\")\n",
    "    print(\"   - âŒ ì¤‘ë³µ í•¨ìˆ˜ ì œê±° (ê·¸ë£¹ 3, 4 í•¨ìˆ˜ ì¬í™œìš©)\")\n",
    "    print(\"   - âŒ ì „ì—­ ì˜ì¡´ ì¶•ì†Œ (ëª…ì‹œ ì¸ì ì „ë‹¬)\")\n",
    "    print(\"   - âŒ ë¶ˆí•„ìš”í•œ ë¡œì§ ì œê±°\")\n",
    "    print(\"   - âœ… í•µì‹¬ ê¸°ëŠ¥ 100% ë³´ì¡´\")\n",
    "    print(\"   - âœ… ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ 100% í˜¸í™˜ì„±\")\n",
    "    print(\"ğŸ›¡ï¸ ë³´ì•ˆ ê¸°ëŠ¥:\")\n",
    "    print(\"   - CSV ê¸°ë°˜ URL ì¤‘ë³µ ë°©ì§€\")\n",
    "    print(\"   - ì™„ë£Œëœ ì‘ì—… ìë™ ì œì™¸\")\n",
    "    print(\"   - ë²ˆí˜¸ ì—°ì†ì„± ë³´ì¥\")\n",
    "    if r.get('success') and r.get('urls_to_process'):\n",
    "        print(f\"ğŸ¯ ë‹¤ìŒ ë‹¨ê³„: ê·¸ë£¹ 9ì—ì„œ {len(r['urls_to_process'])}ê°œ ìƒí’ˆ í¬ë¡¤ë§ ì‹œì‘\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe82a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ğŸš€ ê·¸ë£¹ 9-A: í˜ì´ì§€ë„¤ì´ì…˜ í•µì‹¬ ì‹œìŠ¤í…œ\n",
    "# - í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ê´€ë¦¬, URL ì €ì¥/ë³µê·€, í˜ì´ì§€ ì´ë™ í•¨ìˆ˜ë“¤\n",
    "# - ê¸°ì¡´ ê·¸ë£¹ 1-8ì˜ ëª¨ë“  ì—°ì†ì„± ë³´ì¥ ì‹œìŠ¤í…œ í™œìš©\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ”§ ê·¸ë£¹ 9-A: í˜ì´ì§€ë„¤ì´ì…˜ í•µì‹¬ ì‹œìŠ¤í…œ ë¡œë”©...\")\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ“Š í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ\n",
    "# =============================================================================\n",
    "\n",
    "def save_pagination_state(city_name, current_page, current_list_url, total_crawled, target_products):\n",
    "    \"\"\"\n",
    "    í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœë¥¼ ì €ì¥í•˜ì—¬ ì„¸ì…˜ ê°„ ì—°ì†ì„± ë³´ì¥\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(\"pagination_state\", exist_ok=True)\n",
    "        state_file = os.path.join(\"pagination_state\", f\"{city_name}_pagination.json\")\n",
    "        \n",
    "        pagination_state = {\n",
    "            \"city\": city_name,\n",
    "            \"current_page\": current_page,\n",
    "            \"current_list_url\": current_list_url,\n",
    "            \"total_crawled\": total_crawled,\n",
    "            \"target_products\": target_products,\n",
    "            \"last_updated\": datetime.now().isoformat(),\n",
    "            \"session_id\": datetime.now().strftime('%Y%m%d_%H%M%S'),\n",
    "            \"status\": \"active\"\n",
    "        }\n",
    "        \n",
    "        with open(state_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(pagination_state, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"      âœ… í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ì €ì¥: {current_page}í˜ì´ì§€, {total_crawled}ê°œ ì™„ë£Œ\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"      âŒ í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "def load_pagination_state(city_name):\n",
    "    \"\"\"\n",
    "    ì´ì „ ì„¸ì…˜ì˜ í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ë¡œë“œ\n",
    "    \"\"\"\n",
    "    try:\n",
    "        state_file = os.path.join(\"pagination_state\", f\"{city_name}_pagination.json\")\n",
    "        \n",
    "        if not os.path.exists(state_file):\n",
    "            print(f\"      â„¹ï¸ í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ íŒŒì¼ ì—†ìŒ - ìƒˆ ì„¸ì…˜ ì‹œì‘\")\n",
    "            return None\n",
    "        \n",
    "        with open(state_file, 'r', encoding='utf-8') as f:\n",
    "            state = json.load(f)\n",
    "        \n",
    "        print(f\"      âœ… í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ë¡œë“œ: {state.get('current_page', 1)}í˜ì´ì§€ë¶€í„° ì¬ê°œ\")\n",
    "        print(f\"      ğŸ“Š ì´ì „ ì§„í–‰: {state.get('total_crawled', 0)}ê°œ ì™„ë£Œ\")\n",
    "        \n",
    "        return state\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"      âš ï¸ í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "def clear_pagination_state(city_name):\n",
    "    \"\"\"\n",
    "    í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ì´ˆê¸°í™” (í¬ë¡¤ë§ ì™„ë£Œ ì‹œ)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        state_file = os.path.join(\"pagination_state\", f\"{city_name}_pagination.json\")\n",
    "        \n",
    "        if os.path.exists(state_file):\n",
    "            # ì™„ë£Œ ìƒíƒœë¡œ ë§ˆí‚¹\n",
    "            with open(state_file, 'r', encoding='utf-8') as f:\n",
    "                state = json.load(f)\n",
    "            \n",
    "            state[\"status\"] = \"completed\"\n",
    "            state[\"completed_time\"] = datetime.now().isoformat()\n",
    "            \n",
    "            with open(state_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(state, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            print(f\"      âœ… í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ì™„ë£Œ ì²˜ë¦¬\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"      âš ï¸ í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ì •ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ”— ëª©ë¡í˜ì´ì§€ URL ì €ì¥ ë° ë³µê·€ ì‹œìŠ¤í…œ\n",
    "# =============================================================================\n",
    "\n",
    "def save_list_page_url(driver, city_name, page_number):\n",
    "    \"\"\"\n",
    "    í˜„ì¬ ëª©ë¡í˜ì´ì§€ URLì„ ì €ì¥\n",
    "    \"\"\"\n",
    "    try:\n",
    "        current_url = driver.current_url\n",
    "        \n",
    "        # URL ê²€ì¦\n",
    "        if not is_valid_list_page_url(current_url, city_name):\n",
    "            print(f\"      âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ ëª©ë¡í˜ì´ì§€ URL: {current_url}\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"      ğŸ“ {page_number}í˜ì´ì§€ URL ì €ì¥: ...{current_url[-50:]}\")\n",
    "        return current_url\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"      âŒ ëª©ë¡í˜ì´ì§€ URL ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "def return_to_list_page(driver, saved_url, city_name, max_attempts=3):\n",
    "    \"\"\"\n",
    "    ì €ì¥ëœ ëª©ë¡í˜ì´ì§€ URLë¡œ ì•ˆì „í•˜ê²Œ ë³µê·€\n",
    "    \"\"\"\n",
    "    print(f\"      ğŸ”™ ëª©ë¡í˜ì´ì§€ë¡œ ë³µê·€ ì¤‘...\")\n",
    "    \n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            current_url = driver.current_url\n",
    "            \n",
    "            # ì´ë¯¸ ëª©ë¡í˜ì´ì§€ì— ìˆëŠ”ì§€ í™•ì¸\n",
    "            if is_valid_list_page_url(current_url, city_name):\n",
    "                # ìƒí’ˆ ë§í¬ ê°œìˆ˜ë¡œ í™•ì¸\n",
    "                product_links = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/products/'], a[href*='/offers/']\")\n",
    "                if len(product_links) >= 10:\n",
    "                    print(f\"      âœ… ì´ë¯¸ ì˜¬ë°”ë¥¸ ëª©ë¡í˜ì´ì§€ì— ìˆìŒ ({len(product_links)}ê°œ ìƒí’ˆ)\")\n",
    "                    return True, current_url\n",
    "            \n",
    "            print(f\"      ğŸ”„ ëª©ë¡í˜ì´ì§€ ë³µê·€ ì‹œë„ {attempt + 1}/{max_attempts}\")\n",
    "            \n",
    "            if saved_url:\n",
    "                # ì €ì¥ëœ URLë¡œ ì§ì ‘ ì´ë™\n",
    "                driver.get(saved_url)\n",
    "                print(f\"      ğŸ“ ì €ì¥ëœ URLë¡œ ì´ë™: ...{saved_url[-50:]}\")\n",
    "            else:\n",
    "                # ë’¤ë¡œê°€ê¸° ì‹œë„\n",
    "                driver.back()\n",
    "                print(f\"      â¬…ï¸ ë’¤ë¡œê°€ê¸° ì‹œë„\")\n",
    "            \n",
    "            time.sleep(random.uniform(3, 5))\n",
    "            \n",
    "            # ë³µê·€ í™•ì¸\n",
    "            new_url = driver.current_url\n",
    "            product_links = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/products/'], a[href*='/offers/']\")\n",
    "            \n",
    "            if len(product_links) >= 10:\n",
    "                print(f\"      âœ… ëª©ë¡í˜ì´ì§€ ë³µê·€ ì„±ê³µ! ({len(product_links)}ê°œ ìƒí’ˆ í™•ì¸)\")\n",
    "                return True, new_url\n",
    "            else:\n",
    "                print(f\"      âš ï¸ ë³µê·€í–ˆì§€ë§Œ ìƒí’ˆ ìˆ˜ ë¶€ì¡±: {len(product_links)}ê°œ\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"      âŒ ë³µê·€ ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}\")\n",
    "            \n",
    "        if attempt < max_attempts - 1:\n",
    "            print(f\"      â° 2ì´ˆ í›„ ì¬ì‹œë„...\")\n",
    "            time.sleep(2)\n",
    "    \n",
    "    print(f\"      ğŸš¨ ëª©ë¡í˜ì´ì§€ ë³µê·€ ìµœì¢… ì‹¤íŒ¨\")\n",
    "    return False, None\n",
    "\n",
    "def is_valid_list_page_url(url, city_name):\n",
    "    \"\"\"\n",
    "    ìœ íš¨í•œ ëª©ë¡í˜ì´ì§€ URLì¸ì§€ í™•ì¸\n",
    "    \"\"\"\n",
    "    if not url:\n",
    "        return False\n",
    "    \n",
    "    # ìƒí’ˆ ìƒì„¸í˜ì´ì§€ê°€ ì•„ë‹Œì§€ í™•ì¸\n",
    "    if \"/products/\" in url and url.count(\"/\") > 5:\n",
    "        return False\n",
    "    if \"/offers/\" in url and url.count(\"/\") > 5:\n",
    "        return False\n",
    "    \n",
    "    # ê¸°ë³¸ ëª©ë¡í˜ì´ì§€ íŒ¨í„´ í™•ì¸\n",
    "    valid_patterns = [\n",
    "        \"/experiences\",\n",
    "        \"/offers\",\n",
    "        \"/search\"\n",
    "    ]\n",
    "    \n",
    "    return any(pattern in url for pattern in valid_patterns)\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ”„ í˜ì´ì§€ ì´ë™ ë° ë³µêµ¬ ì‹œìŠ¤í…œ\n",
    "# =============================================================================\n",
    "\n",
    "def click_next_page_enhanced(driver, current_page=None):\n",
    "    \"\"\"\n",
    "    KLOOK ì „ìš© ë‹¤ìŒ í˜ì´ì§€ë¡œ ì•ˆì „í•˜ê²Œ ì´ë™ (ê°•í™”ëœ ë²„ì „)\n",
    "    \"\"\"\n",
    "    print(f\"    ğŸ” ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ì°¾ëŠ” ì¤‘...\")\n",
    "\n",
    "    # ğŸ†• ë§ˆì§€ë§‰ í˜ì´ì§€ í™•ì¸ (ë§¨ ì•ì— ì¶”ê°€)\n",
    "    if not check_next_button(driver):\n",
    "        print(\"ğŸ ë§ˆì§€ë§‰ í˜ì´ì§€ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ë„¤ì´ì…˜ ì¢…ë£Œ\")\n",
    "        return False, \"ë§ˆì§€ë§‰ í˜ì´ì§€\", driver.current_url\n",
    "\n",
    "    try:\n",
    "        # í˜„ì¬ ìƒíƒœ ì €ì¥\n",
    "        current_url = driver.current_url\n",
    "        current_products = len(collect_all_24_urls(driver))\n",
    "\n",
    "        # ğŸ”§ KLOOK ì „ìš© ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ì…€ë ‰í„°ë“¤\n",
    "        next_button_selectors = [\n",
    "            (By.CSS_SELECTOR, \".klk-pagination-next-btn:not(.klk-pagination-next-btn-disabled)\"),\n",
    "            (By.CSS_SELECTOR, \".filter-pagination .klk-pagination-next-btn:not(.klk-pagination-next-btn-disabled)\"),\n",
    "            (By.XPATH, \"//span[@class='klk-pagination-next-btn' and not(contains(@class, 'disabled'))]\"),\n",
    "        ]\n",
    "\n",
    "        next_button = None\n",
    "        used_selector = None\n",
    "\n",
    "        # ë²„íŠ¼ ì°¾ê¸°\n",
    "        for selector_type, selector in next_button_selectors:\n",
    "            try:\n",
    "                buttons = driver.find_elements(selector_type, selector)\n",
    "                for button in buttons:\n",
    "                    if button.is_displayed() and button.is_enabled():\n",
    "                        next_button = button\n",
    "                        used_selector = selector\n",
    "                        print(f\"    âœ… ë‹¤ìŒ ë²„íŠ¼ ì°¾ê¸° ì„±ê³µ: {used_selector}\")\n",
    "                        break\n",
    "                if next_button:\n",
    "                    break\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        if not next_button:\n",
    "            print(f\"    âŒ ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "            return False, \"ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ì—†ìŒ\", current_url\n",
    "\n",
    "        print(f\"    âœ… ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ë°œê²¬!\")\n",
    "\n",
    "        # ì•ˆì „í•œ í´ë¦­ ì‹¤í–‰\n",
    "        for click_attempt in range(3):\n",
    "            try:\n",
    "                print(f\"    ğŸ–±ï¸ ë‹¤ìŒ í˜ì´ì§€ í´ë¦­ ì‹œë„ {click_attempt + 1}/3...\")\n",
    "\n",
    "                # ìŠ¤í¬ë¡¤ í›„ í´ë¦­\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", next_button)\n",
    "                time.sleep(1)\n",
    "\n",
    "                # JavaScript í´ë¦­\n",
    "                driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "\n",
    "                # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°\n",
    "                print(f\"    â° í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° ì¤‘...\")\n",
    "                time.sleep(random.uniform(4, 7))\n",
    "\n",
    "                # ë³€í™” ê²€ì¦\n",
    "                new_url = driver.current_url\n",
    "                new_products = len(collect_all_24_urls(driver))\n",
    "\n",
    "                # ì„±ê³µ ì¡°ê±´ í™•ì¸\n",
    "                if new_url != current_url:\n",
    "                    print(f\"    âœ… URL ë³€í™” ê°ì§€: í˜ì´ì§€ ì´ë™ ì„±ê³µ!\")\n",
    "                    print(f\"    ğŸ“ ìƒˆ URL: ...{new_url[-60:]}\")\n",
    "                    return True, \"í˜ì´ì§€ ì´ë™ ì„±ê³µ\", new_url\n",
    "\n",
    "                elif new_products != current_products and new_products > 0:\n",
    "                    print(f\"    âœ… ìƒí’ˆ ìˆ˜ ë³€í™” ê°ì§€: {current_products} â†’ {new_products}\")\n",
    "                    return True, \"ìƒí’ˆ ë³€í™”ë¡œ ì´ë™ í™•ì¸\", new_url\n",
    "\n",
    "                else:\n",
    "                    print(f\"    âš ï¸ í´ë¦­ {click_attempt+1}: í˜ì´ì§€ ë³€í™” ë¯¸ê°ì§€\")\n",
    "                    if click_attempt < 2:\n",
    "                        time.sleep(2)\n",
    "                        continue\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"    âŒ í´ë¦­ ì‹œë„ {click_attempt+1} ì‹¤íŒ¨: {e}\")\n",
    "                if click_attempt < 2:\n",
    "                    time.sleep(2)\n",
    "                    continue\n",
    "\n",
    "        # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨\n",
    "        print(f\"    ğŸ ë§ˆì§€ë§‰ í˜ì´ì§€ì´ê±°ë‚˜ í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨\")\n",
    "        return False, \"í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨ (3íšŒ ì‹œë„ í›„)\", current_url\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    âŒ ë‹¤ìŒ í˜ì´ì§€ ì´ë™ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        return False, f\"ì˜¤ë¥˜: {type(e).__name__}\", driver.current_url\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ§° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤\n",
    "# =============================================================================\n",
    "\n",
    "def validate_pagination_environment():\n",
    "    \"\"\"\n",
    "    í˜ì´ì§€ë„¤ì´ì…˜ ì‹¤í–‰ í™˜ê²½ ê²€ì¦\n",
    "    \"\"\"\n",
    "    print(\"ğŸ” í˜ì´ì§€ë„¤ì´ì…˜ í™˜ê²½ ê²€ì¦ ì¤‘...\")\n",
    "    \n",
    "    # í•„ìˆ˜ ë³€ìˆ˜ë“¤ í™•ì¸\n",
    "    required_vars = ['driver', 'city_name', 'start_number', 'completed_urls', 'continent', 'country']\n",
    "    missing_vars = []\n",
    "    \n",
    "    for var_name in required_vars:\n",
    "        if var_name not in globals():\n",
    "            missing_vars.append(var_name)\n",
    "    \n",
    "    if missing_vars:\n",
    "        print(f\"âŒ í•„ìˆ˜ ë³€ìˆ˜ ëˆ„ë½: {', '.join(missing_vars)}\")\n",
    "        print(\"ğŸ’¡ ê·¸ë£¹ 6-8ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”!\")\n",
    "        return False, missing_vars\n",
    "    \n",
    "    # ë“œë¼ì´ë²„ ìƒíƒœ í™•ì¸\n",
    "    try:\n",
    "        current_url = driver.current_url\n",
    "        print(f\"âœ… ë“œë¼ì´ë²„ ìƒíƒœ: ì •ìƒ ({current_url[:50]}...)\")\n",
    "    except:\n",
    "        print(f\"âŒ ë“œë¼ì´ë²„ ìƒíƒœ: ë¹„ì •ìƒ\")\n",
    "        return False, [\"driver_inactive\"]\n",
    "    \n",
    "    # í˜„ì¬ í˜ì´ì§€ê°€ ëª©ë¡í˜ì´ì§€ì¸ì§€ í™•ì¸\n",
    "    try:\n",
    "        product_links = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/products/'], a[href*='/offers/']\")\n",
    "        if len(product_links) >= 5:\n",
    "            print(f\"âœ… ëª©ë¡í˜ì´ì§€ í™•ì¸: {len(product_links)}ê°œ ìƒí’ˆ ë§í¬\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ ëª©ë¡í˜ì´ì§€ ì˜ì‹¬: {len(product_links)}ê°œ ìƒí’ˆ ë§í¬ë§Œ ë°œê²¬\")\n",
    "    except:\n",
    "        print(f\"âš ï¸ í˜ì´ì§€ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨\")\n",
    "    \n",
    "    print(f\"âœ… í˜ì´ì§€ë„¤ì´ì…˜ í™˜ê²½ ê²€ì¦ ì™„ë£Œ!\")\n",
    "    return True, []\n",
    "\n",
    "def get_pagination_progress_info(total_crawled, target_products, current_page):\n",
    "    \"\"\"\n",
    "    í˜ì´ì§€ë„¤ì´ì…˜ ì§„í–‰ ìƒí™© ì •ë³´ ìƒì„±\n",
    "    \"\"\"\n",
    "    progress_percentage = (total_crawled / target_products * 100) if target_products > 0 else 0\n",
    "    remaining = max(0, target_products - total_crawled)\n",
    "    \n",
    "    return {\n",
    "        'total_crawled': total_crawled,\n",
    "        'target_products': target_products,\n",
    "        'remaining': remaining,\n",
    "        'progress_percentage': progress_percentage,\n",
    "        'current_page': current_page,\n",
    "        'estimated_pages': (target_products // 24) + (1 if target_products % 24 > 0 else 0)\n",
    "    }\n",
    "\n",
    "def print_pagination_progress(progress_info):\n",
    "    \"\"\"\n",
    "    í˜ì´ì§€ë„¤ì´ì…˜ ì§„í–‰ë¥  ì‹œê°ì  í‘œì‹œ\n",
    "    \"\"\"\n",
    "    percentage = progress_info['progress_percentage']\n",
    "    bar_length = 30\n",
    "    filled_length = int(bar_length * progress_info['total_crawled'] // progress_info['target_products'])\n",
    "    bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š í˜ì´ì§€ë„¤ì´ì…˜ ì§„í–‰ë¥ : [{bar}] {percentage:.1f}%\")\n",
    "    print(f\"   ğŸ¯ ì§„í–‰: {progress_info['total_crawled']}/{progress_info['target_products']}ê°œ\")\n",
    "    print(f\"   ğŸ“„ í˜ì´ì§€: {progress_info['current_page']}í˜ì´ì§€\")\n",
    "    print(f\"   â±ï¸ ë‚¨ì€ ìƒí’ˆ: {progress_info['remaining']}ê°œ\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ¯ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ\n",
    "# =============================================================================\n",
    "\n",
    "print(\"âœ… ê·¸ë£¹ 9-A: í˜ì´ì§€ë„¤ì´ì…˜ í•µì‹¬ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ!\")\n",
    "print(\"   ğŸ“Š save_pagination_state() - í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ì €ì¥\")\n",
    "print(\"   ğŸ“Š load_pagination_state() - í˜ì´ì§€ë„¤ì´ì…˜ ìƒíƒœ ë¡œë“œ\")\n",
    "print(\"   ğŸ”— save_list_page_url() - ëª©ë¡í˜ì´ì§€ URL ì €ì¥\")\n",
    "print(\"   ğŸ”™ return_to_list_page() - ëª©ë¡í˜ì´ì§€ ì•ˆì „ ë³µê·€\")\n",
    "print(\"   ğŸ”„ click_next_page_enhanced() - ê°•í™”ëœ ë‹¤ìŒí˜ì´ì§€ ì´ë™\")\n",
    "print(\"   ğŸ§° validate_pagination_environment() - í™˜ê²½ ê²€ì¦\")\n",
    "print()\n",
    "print(\"ğŸš€ ë‹¤ìŒ: ê·¸ë£¹ 9-Bë¥¼ ì‹¤í–‰í•˜ì—¬ ì™„ì „í•œ í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ ì‹œì‘!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f836a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ğŸš€ ê·¸ë£¹ 9-B: ì™„ì „í•œ í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ ì‹¤í–‰\n",
    "# - ë©”ì¸ í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ ë£¨í”„, ë‹¨ì¼ ìƒí’ˆ í¬ë¡¤ë§, í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤\n",
    "# - ê·¸ë£¹ 9-Aì˜ í•µì‹¬ ì‹œìŠ¤í…œ + ê¸°ì¡´ ê·¸ë£¹ 1-8ì˜ ëª¨ë“  í•¨ìˆ˜ë“¤ í™œìš©\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ”§ ê·¸ë£¹ 9-B: ì™„ì „í•œ í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ ì‹¤í–‰ ë¡œë”©...\")\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ¯ ë©”ì¸ í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ ì‹œìŠ¤í…œ\n",
    "# =============================================================================\n",
    "\n",
    "def crawl_with_full_pagination(city_name, target_products=100, resume_session=True, pre_collected_urls=None):\n",
    "    \"\"\"\n",
    "    ğŸ¯ [ìµœì¢… ì™„ì„±ë³¸] URL ìºì‹œë¥¼ ì™„ë²½í•˜ê²Œ ì‚¬ìš©í•˜ëŠ” ì§€ëŠ¥í˜• í¬ë¡¤ë§ ì—”ì§„\n",
    "    - pre_collected_urls ì¸ìë¥¼ ë°›ì•„, ìºì‹œëœ URL ëª©ë¡ìœ¼ë¡œ ì§ì ‘ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "    - ìºì‹œê°€ ì—†ì„ ë•Œë§Œ ê¸°ì¡´ì˜ í˜ì´ì§€ë„¤ì´ì…˜ ë°©ì‹ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    print(f\"ğŸš€ ìµœì¢… í¬ë¡¤ë§ ì—”ì§„ ì‹œì‘: '{city_name}' ë„ì‹œì˜ ìƒí’ˆ {target_products}ê°œ ëª©í‘œ\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. í™˜ê²½ ë° ì „ì—­ ë³€ìˆ˜ ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)\n",
    "    env_valid, missing = validate_pagination_environment()\n",
    "    if not env_valid: return False\n",
    "    global start_number, completed_urls, continent, country, driver\n",
    "    \n",
    "    # 2. í¬ë¡¤ë§ ìƒíƒœ ì´ˆê¸°í™” (ê¸°ì¡´ê³¼ ë™ì¼)\n",
    "    total_crawled_this_session = 0\n",
    "    current_product_number = start_number \n",
    "    all_results = []\n",
    "\n",
    "    print(f\"ğŸ“Š í¬ë¡¤ë§ ì„¤ì •:\")\n",
    "    print(f\"   ğŸ™ï¸ ë„ì‹œ: {city_name} ({continent}/{country})\")\n",
    "    print(f\"   ğŸ¯ ëª©í‘œ ìˆ˜ëŸ‰: {target_products}ê°œ\")\n",
    "    print(f\"   ğŸ”¢ ì‹œì‘ ë²ˆí˜¸: {current_product_number}\")\n",
    "    print(f\"   ğŸ”— ê¸°ì™„ë£Œ URL: {len(completed_urls)}ê°œ\")\n",
    "\n",
    "    # =================================================================\n",
    "    # ğŸ‘‘ 3. (í•µì‹¬ ë¡œì§) ì‘ì—… ë°©ì‹ ê²°ì •: ìºì‹œ ì‚¬ìš© vs. ì‹ ê·œ íƒìƒ‰\n",
    "    # =================================================================\n",
    "    \n",
    "    urls_to_process = []\n",
    "    is_cache_mode = False\n",
    "\n",
    "    if pre_collected_urls:\n",
    "        print(\"\\nâœ… URL ìºì‹œ ëª¨ë“œë¡œ ì‹¤í–‰: ì œê³µëœ ëª©ë¡ì„ ìš°ì„  ì²˜ë¦¬í•©ë‹ˆë‹¤.\")\n",
    "        urls_to_process = pre_collected_urls\n",
    "        is_cache_mode = True\n",
    "    \n",
    "    # --- ìºì‹œ ëª¨ë“œ ë˜ëŠ” ë¼ì´ë¸Œ(í˜ì´ì§€ë„¤ì´ì…˜) ëª¨ë“œ ì‹¤í–‰ ---\n",
    "\n",
    "    page_results = [] # ìˆ˜ì§‘ëœ ê²°ê³¼ë¥¼ ì„ì‹œ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "    \n",
    "    # is_cache_modeê°€ Trueì´ë©´ í•œ ë²ˆë§Œ ì‹¤í–‰, Falseì´ë©´ í˜ì´ì§€ë„¤ì´ì…˜ ë£¨í”„ ì‹¤í–‰\n",
    "    current_page = 1\n",
    "    while True:\n",
    "        if not is_cache_mode: # ë¼ì´ë¸Œ ëª¨ë“œì¼ ë•Œë§Œ URLì„ ìƒˆë¡œ ìˆ˜ì§‘\n",
    "            print(f\"\\nğŸ“„ === {current_page}í˜ì´ì§€ ì²˜ë¦¬ ì‹œì‘ ===\")\n",
    "            page_urls = collect_all_24_urls(driver)\n",
    "            if not page_urls:\n",
    "                print(f\"ğŸ {current_page}í˜ì´ì§€ì—ì„œ ë” ì´ìƒ ìƒí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‘ì—…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "                break\n",
    "            print(f\"âœ… {current_page}í˜ì´ì§€ì—ì„œ {len(page_urls)}ê°œì˜ URLì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.\")\n",
    "            urls_to_process = page_urls\n",
    "        \n",
    "        # --- ê³µí†µ ìƒí’ˆ ì²˜ë¦¬ ë¡œì§ ---\n",
    "        for url_index, product_url in enumerate(urls_to_process):\n",
    "            if total_crawled_this_session >= target_products:\n",
    "                break\n",
    "\n",
    "            if product_url in completed_urls:\n",
    "                print(f\"â­ï¸ [ë‚´ë¶€ ê²€ì¦] ì´ë¯¸ ì™„ë£Œëœ URLì´ë¯€ë¡œ ê±´ë„ˆëœë‹ˆë‹¤: {product_url[:50]}...\")\n",
    "                continue\n",
    "\n",
    "            print(f\"   ğŸ“¦ ìƒí’ˆ {current_product_number} ì²˜ë¦¬ ì‹œì‘...\")\n",
    "            \n",
    "            result = crawl_single_product_optimized(\n",
    "                driver, product_url, current_product_number, \n",
    "                city_name, continent, country, current_page\n",
    "            )\n",
    "            \n",
    "            if result:\n",
    "                save_url_to_log(city_name, product_url)\n",
    "                completed_urls.add(product_url)\n",
    "                page_results.append(result)\n",
    "                all_results.append(result)\n",
    "                total_crawled_this_session += 1\n",
    "                current_product_number += 1\n",
    "                print(f\"   âœ… ìƒí’ˆ {current_product_number-1} ì™„ë£Œ: {result.get('ìƒí’ˆëª…', '')[:30]}...\")\n",
    "        \n",
    "        # --- ë£¨í”„ ì œì–´ ---\n",
    "        if total_crawled_this_session >= target_products:\n",
    "            print(f\"   ğŸ‰ ëª©í‘œ {target_products}ê°œ ë‹¬ì„±! ì´ë²ˆ ì„¸ì…˜ì˜ í¬ë¡¤ë§ì„ ì™„ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            break\n",
    "            \n",
    "        if is_cache_mode: # ìºì‹œ ëª¨ë“œëŠ” í•œ ë²ˆë§Œ ì‹¤í–‰í•˜ê³  ì¢…ë£Œ\n",
    "            break\n",
    "        \n",
    "        # ë¼ì´ë¸Œ ëª¨ë“œì¼ ë•Œë§Œ ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™\n",
    "        print(\"ğŸ”„ ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤...\")\n",
    "        next_success, _, _ = click_next_page_enhanced(driver, current_page)\n",
    "        if next_success:\n",
    "            current_page += 1\n",
    "            if page_results: # ë‹¤ìŒ í˜ì´ì§€ë¡œ ë„˜ì–´ê°€ê¸° ì „, í˜„ì¬ í˜ì´ì§€ ê²°ê³¼ ì €ì¥\n",
    "                save_batch_data(page_results, city_name)\n",
    "                page_results = [] # ì´ˆê¸°í™”\n",
    "        else:\n",
    "            print(\"ğŸ ë” ì´ìƒ ë‹¤ìŒ í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. í˜ì´ì§€ë„¤ì´ì…˜ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            break\n",
    "            \n",
    "    # ìµœì¢…ì ìœ¼ë¡œ ë‚¨ì€ ë°ì´í„° ì €ì¥\n",
    "    if page_results:\n",
    "        save_batch_data(page_results, city_name)\n",
    "\n",
    "    print(f\"\\nğŸ‰ í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ ì—”ì§„ì´ ì‘ì—…ì„ ë§ˆì³¤ìŠµë‹ˆë‹¤.\")\n",
    "    print(f\"ğŸ“Š ì´ë²ˆ ì„¸ì…˜ì—ì„œ ì´ {total_crawled_this_session}ê°œì˜ ìƒí’ˆì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    return all_results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ”§ ë‹¨ì¼ ìƒí’ˆ í¬ë¡¤ë§ í•¨ìˆ˜ (ê¸°ì¡´ ê·¸ë£¹ 1-2 í•¨ìˆ˜ë“¤ í™œìš©)\n",
    "# =============================================================================\n",
    "\n",
    "def crawl_single_product_optimized(driver, product_url, product_number, city_name, continent,\n",
    "                                   country, page_num):\n",
    "    \"\"\"\n",
    "    ë‹¨ì¼ ìƒí’ˆ í¬ë¡¤ë§ ìµœì í™” ë²„ì „ - KLOOK ë©”ì¸+ì¸ë„¤ì¼ ì´ë¯¸ì§€ (ë„ì‹œID ì¶”ê°€)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ìƒí’ˆ í˜ì´ì§€ ì´ë™\n",
    "        driver.get(product_url)\n",
    "        time.sleep(random.uniform(CONFIG[\"MEDIUM_MIN_DELAY\"], CONFIG[\"MEDIUM_MAX_DELAY\"]))\n",
    "\n",
    "        # ğŸ†• ìƒí’ˆ ìƒì„¸í˜ì´ì§€ ìì—°ìŠ¤ëŸ¬ìš´ ìŠ¤í¬ë¡¤ (ë´‡ íšŒí”¼ ê°•í™”)\n",
    "        print(f\"      ğŸ“œ ìƒí’ˆ í˜ì´ì§€ ìì—°ìŠ¤ëŸ¬ìš´ íƒìƒ‰ ì¤‘...\")\n",
    "        smart_scroll_selector(driver)\n",
    "\n",
    "        # URL íƒ€ì… íŒë³„\n",
    "        url_type = \"Activity\" if \"/activity/\" in product_url else \"Product\"\n",
    "\n",
    "        # ì •ë³´ ìˆ˜ì§‘ (ê¸°ì¡´ ê·¸ë£¹ 1-2 í•¨ìˆ˜ë“¤ í™œìš©)\n",
    "        product_name = get_product_name(driver, url_type)\n",
    "        price_raw = get_price(driver)\n",
    "        price_clean = clean_price(price_raw)\n",
    "        rating_raw = get_rating(driver)\n",
    "        rating_clean = clean_rating(rating_raw)\n",
    "        review_count = get_review_count(driver)\n",
    "        language = get_language(driver)\n",
    "        category = get_categories(driver)\n",
    "        highlights = get_highlights(driver)\n",
    "\n",
    "        # ğŸ†• ë„ì‹œID ìƒì„± (1ë¶€í„° ì‹œì‘)\n",
    "        city_code = get_city_code(city_name)\n",
    "        city_id = f\"{city_code}_{product_number}\"\n",
    "\n",
    "        # ğŸ–¼ï¸ ë©”ì¸+ì¸ë„¤ì¼ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ì‹ ê·œ 2ê°œ ì´ë¯¸ì§€ ì‹œìŠ¤í…œ)\n",
    "        if CONFIG[\"SAVE_IMAGES\"]:\n",
    "            img_results = download_image(driver, product_name, city_name, product_number)\n",
    "            main_img = img_results.get('main_image', {})\n",
    "            thumb_img = img_results.get('thumbnail_image', {})\n",
    "        else:\n",
    "            main_img = {'filename': '', 'relative_path': '', 'path': '', 'status': 'skipped'}\n",
    "            thumb_img = {'filename': '', 'relative_path': '', 'path': '', 'status': 'skipped'}\n",
    "\n",
    "        # ê²°ê³¼ ë°˜í™˜ (ë„ì‹œID + 2ê°œ ì´ë¯¸ì§€ í•„ë“œ - 8ê°œ ì»¬ëŸ¼)\n",
    "        return {\n",
    "            'ë²ˆí˜¸': product_number,\n",
    "            'ë„ì‹œID': city_id,  # ğŸ†• ì¶”ê°€\n",
    "            'í˜ì´ì§€': page_num,\n",
    "            'ëŒ€ë¥™': continent,\n",
    "            'êµ­ê°€': country,\n",
    "            'ë„ì‹œ': city_name,\n",
    "            'ê³µí•­ì½”ë“œ': city_code,\n",
    "            'ìƒí’ˆíƒ€ì…': url_type,\n",
    "            'ìƒí’ˆëª…': product_name,\n",
    "            'ê°€ê²©_ì›ë³¸': price_raw,\n",
    "            'ê°€ê²©_ì •ì œ': price_clean,\n",
    "            'í‰ì _ì›ë³¸': rating_raw,\n",
    "            'í‰ì _ì •ì œ': rating_clean,\n",
    "            'ë¦¬ë·°ìˆ˜': review_count,\n",
    "            'ì–¸ì–´': language,\n",
    "            'ì¹´í…Œê³ ë¦¬': category,\n",
    "            'í•˜ì´ë¼ì´íŠ¸': highlights,\n",
    "\n",
    "            # ğŸ–¼ï¸ ë©”ì¸ ì´ë¯¸ì§€ ì •ë³´ (4ê°œ ì»¬ëŸ¼)\n",
    "            'ë©”ì¸ì´ë¯¸ì§€_íŒŒì¼ëª…': main_img.get('filename', ''),\n",
    "            'ë©”ì¸ì´ë¯¸ì§€_ìƒëŒ€ê²½ë¡œ': main_img.get('relative_path', ''),\n",
    "            'ë©”ì¸ì´ë¯¸ì§€_ì „ì²´ê²½ë¡œ': main_img.get('path', ''),\n",
    "            'ë©”ì¸ì´ë¯¸ì§€_ìƒíƒœ': main_img.get('status', ''),\n",
    "\n",
    "            # ğŸ–¼ï¸ ì¸ë„¤ì¼ ì´ë¯¸ì§€ ì •ë³´ (4ê°œ ì»¬ëŸ¼)\n",
    "            'ì¸ë„¤ì¼ì´ë¯¸ì§€_íŒŒì¼ëª…': thumb_img.get('filename', ''),\n",
    "            'ì¸ë„¤ì¼ì´ë¯¸ì§€_ìƒëŒ€ê²½ë¡œ': thumb_img.get('relative_path', ''),\n",
    "            'ì¸ë„¤ì¼ì´ë¯¸ì§€_ì „ì²´ê²½ë¡œ': thumb_img.get('path', ''),\n",
    "            'ì¸ë„¤ì¼ì´ë¯¸ì§€_ìƒíƒœ': thumb_img.get('status', ''),\n",
    "\n",
    "            'URL': product_url,\n",
    "            'ìˆ˜ì§‘_ì‹œê°„': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'ìƒíƒœ': 'ì™„ì „ìˆ˜ì§‘'\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"      âŒ ìƒí’ˆ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ¯ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ\n",
    "# =============================================================================\n",
    "\n",
    "print(\"âœ… ê·¸ë£¹ 9-B: í¬ë¡¤ë§ ì—”ì§„ ë¡œë“œ ì™„ë£Œ!\")\n",
    "print(\"   âš™ï¸ ì´ ì…€ì€ ì‹¤ì œ í¬ë¡¤ë§ì„ ìˆ˜í–‰í•˜ëŠ” í•µì‹¬ ì—”ì§„ì„ ì •ì˜í•©ë‹ˆë‹¤.\")\n",
    "print(\"\\nğŸš€ ë‹¤ìŒ: ê·¸ë£¹ 10ì„ ì‹¤í–‰í•˜ì—¬ ì œì–´íŒì„ ì‚¬ìš©í•˜ì„¸ìš”.\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab853b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ğŸš€ ê·¸ë£¹ 10: KLOOK ì „ìš© ì ì‘í˜• ì¹´í…Œê³ ë¦¬ ì‹œìŠ¤í…œ (ì •ë¦¬Â·ì•ˆì •í™” ë²„ì „)\n",
    "# - ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ ì½”ë“œ ì™„ì „ ì œê±°\n",
    "# - KLOOK ì „ìš© ì…€ë ‰í„° ë° ë¡œì§\n",
    "# - ê²¬ê³ í•œ ëŒ€ê¸°/í´ë¦­/ì¤‘ë³µì œê±°/ìŠ¤ì½”ì–´ë§\n",
    "\n",
    "\n",
    "# ---- ê³µí†µ ì„¤ì • ---------------------------------------------------------------\n",
    "DEFAULT_WAIT_SEC = 8\n",
    "POST_CLICK_SLEEP_RANGE = (3.0, 5.0)\n",
    "\n",
    "# KLOOK íƒ­/ëª©ë¡ì—ì„œ ìì£¼ ë“±ì¥í•˜ëŠ” í‚¤ì›Œë“œ ìŠ¤ì½”ì–´\n",
    "KLOOK_TAB_KEYWORDS: List[Tuple[re.Pattern, int]] = [\n",
    "    (re.compile(r\"\\b(tour|tours|íˆ¬ì–´)\\b\", re.I), 40),\n",
    "    (re.compile(r\"\\b(activity|activities|ì•¡í‹°ë¹„í‹°)\\b\", re.I), 35),\n",
    "    (re.compile(r\"\\b(ticket|tickets|í‹°ì¼“|ì…ì¥ê¶Œ|admission)\\b\", re.I), 30),\n",
    "    (re.compile(r\"\\b(transport|transportation|êµí†µ)\\b\", re.I), 20),\n",
    "    (re.compile(r\"\\b(all|show all|ì „ì²´)\\b\", re.I), 15),\n",
    "]\n",
    "\n",
    "# ëª©ë¡Â·ìƒì„¸ íŒë‹¨ì— ì‚¬ìš©í•  ì…€ë ‰í„° ë¬¶ìŒ\n",
    "KLOOK_PRODUCT_LINK_SEL = \"a[href*='/activity/'], a[href*='/en/activity/']\"\n",
    "KLOOK_PRODUCT_CARD_SEL = (\n",
    "    \".klk-card, [class*='Card'], a[href*='/activity/'] img, \"\n",
    "    \"div[data-testid*='product-card']\"\n",
    ")\n",
    "\n",
    "# íƒ­ í›„ë³´ ì…€ë ‰í„°\n",
    "KLOOK_TAB_SELECTORS = [\n",
    "    \".klk-tabs-tab\",\n",
    "    \"[class*='tab'][role='tab']\",\n",
    "    \"button[class*='tab']\",\n",
    "    \"a[class*='tab']\",\n",
    "    \"[data-testid*='tab']\",\n",
    "    \".tab-button\",\n",
    "]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ìœ í‹¸\n",
    "# -----------------------------------------------------------------------------\n",
    "def _wait(driver, timeout: int = DEFAULT_WAIT_SEC) -> WebDriverWait:\n",
    "    return WebDriverWait(driver, timeout)\n",
    "\n",
    "def _sleep_after_click() -> None:\n",
    "    time.sleep(random.uniform(*POST_CLICK_SLEEP_RANGE))\n",
    "\n",
    "def _visible(e: WebElement) -> bool:\n",
    "    try:\n",
    "        return e.is_displayed()\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def _clickable(driver, e: WebElement, timeout: int = DEFAULT_WAIT_SEC) -> bool:\n",
    "    try:\n",
    "        _wait(driver, timeout).until(EC.element_to_be_clickable(e))\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def _uniq_by_text_href(elems: List[WebElement]) -> List[WebElement]:\n",
    "    \"\"\"í…ìŠ¤íŠ¸+href ì¡°í•©ìœ¼ë¡œ ì¤‘ë³µ ì œê±° (WebElementëŠ” í•´ì‹œë¶ˆê°€)\"\"\"\n",
    "    seen = set()\n",
    "    out: List[WebElement] = []\n",
    "    for el in elems:\n",
    "        try:\n",
    "            t = (el.text or \"\").strip()\n",
    "            h = el.get_attribute(\"href\") or \"\"\n",
    "            key = (t, h)\n",
    "            if key not in seen:\n",
    "                seen.add(key)\n",
    "                out.append(el)\n",
    "        except Exception:\n",
    "            # ë¬¸ì œê°€ ìˆì–´ë„ ë‹¤ë¥¸ ìš”ì†ŒëŠ” ì§„í–‰\n",
    "            continue\n",
    "    return out\n",
    "\n",
    "def _score_tab(elem: WebElement) -> Tuple[int, List[str]]:\n",
    "    score = 0\n",
    "    reasons: List[str] = []\n",
    "    txt = (elem.text or \"\").strip()\n",
    "    href = elem.get_attribute(\"href\") or \"\"\n",
    "    role = elem.get_attribute(\"role\") or \"\"\n",
    "    cls = elem.get_attribute(\"class\") or \"\"\n",
    "\n",
    "    # í‚¤ì›Œë“œ\n",
    "    for pat, pt in KLOOK_TAB_KEYWORDS:\n",
    "        if pat.search(txt):\n",
    "            score += pt\n",
    "            reasons.append(f\"í‚¤ì›Œë“œ ë§¤ì¹­(+{pt}): {pat.pattern}\")\n",
    "            break\n",
    "\n",
    "    # URL íŠ¹ì„±\n",
    "    if \"klook.com\" in href:\n",
    "        score += 20\n",
    "        reasons.append(\"klook ë„ë©”ì¸(+20)\")\n",
    "    if any(s in href for s in (\"/activity/\", \"/things-to-do/\", \"/attractions/\")):\n",
    "        score += 15\n",
    "        reasons.append(\"ìƒí’ˆ/íƒìƒ‰ URL íŒ¨í„´(+15)\")\n",
    "\n",
    "    # í‘œì‹œ/í´ë¦­ ê°€ëŠ¥\n",
    "    if _visible(elem):\n",
    "        score += 10\n",
    "        reasons.append(\"í™”ë©´ í‘œì‹œ(+10)\")\n",
    "    if elem.is_enabled():\n",
    "        score += 10\n",
    "        reasons.append(\"í´ë¦­ ê°€ëŠ¥(+10)\")\n",
    "\n",
    "    # íƒ­ ì—­í• /í™œì„± ê°€ì \n",
    "    if role.lower() == \"tab\":\n",
    "        score += 15\n",
    "        reasons.append(\"role=tab(+15)\")\n",
    "    if re.search(r\"\\b(active|selected)\\b\", cls, flags=re.I):\n",
    "        score += 5\n",
    "        reasons.append(\"í™œì„± ìƒíƒœ(+5)\")\n",
    "\n",
    "    return score, reasons\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) KLOOK í˜ì´ì§€ íƒ€ì… íƒì§€\n",
    "# -----------------------------------------------------------------------------\n",
    "def detect_klook_page_type(driver) -> str:\n",
    "    \"\"\"KLOOK í˜ì´ì§€ íƒ€ì… íƒì§€ (KLOOK ì „ìš©) -> product_detail / product_list / destination_page / tab_based / non_klook / unknown_klook / error\"\"\"\n",
    "    print(\"  ğŸ” KLOOK í˜ì´ì§€ íƒ€ì… íƒì§€ ì¤‘...\")\n",
    "    try:\n",
    "        current_url = driver.current_url\n",
    "        print(f\"    ğŸ“ í˜„ì¬ URL: {current_url}\")\n",
    "\n",
    "        if \"klook.com\" not in current_url:\n",
    "            print(\"  âŒ KLOOK ë„ë©”ì¸ì´ ì•„ë‹™ë‹ˆë‹¤\")\n",
    "            return \"non_klook\"\n",
    "\n",
    "        if \"/activity/\" in current_url:\n",
    "            print(\"  âœ… ê°ì§€: KLOOK ìƒí’ˆ ìƒì„¸ í˜ì´ì§€\")\n",
    "            return \"product_detail\"\n",
    "\n",
    "        if any(p in current_url for p in (\"/things-to-do/\", \"/city/\", \"/country/\")):\n",
    "            print(\"  âœ… ê°ì§€: KLOOK ë„ì‹œ/êµ­ê°€ íƒìƒ‰ í˜ì´ì§€\")\n",
    "            return \"destination_page\"\n",
    "\n",
    "        # íƒ­/ëª©ë¡ íŒíŠ¸\n",
    "        time.sleep(2)\n",
    "        tabs = []\n",
    "        for sel in KLOOK_TAB_SELECTORS:\n",
    "            try:\n",
    "                tabs.extend(driver.find_elements(By.CSS_SELECTOR, sel))\n",
    "            except Exception:\n",
    "                pass\n",
    "        tabs = _uniq_by_text_href(tabs)\n",
    "\n",
    "        if tabs:\n",
    "            print(f\"  âœ… ê°ì§€: KLOOK íƒ­ ê¸°ë°˜ í˜ì´ì§€ (íƒ­ {len(tabs)}ê°œ)\")\n",
    "            return \"tab_based\"\n",
    "\n",
    "        links = driver.find_elements(By.CSS_SELECTOR, KLOOK_PRODUCT_LINK_SEL)\n",
    "        cards = driver.find_elements(By.CSS_SELECTOR, KLOOK_PRODUCT_CARD_SEL)\n",
    "        if len(links) + len(cards) >= 10:\n",
    "            print(f\"  âœ… ê°ì§€: KLOOK ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ (ìš”ì†Œ {len(links)+len(cards)}ê°œ)\")\n",
    "            return \"product_list\"\n",
    "\n",
    "        print(\"  âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” KLOOK í˜ì´ì§€ íƒ€ì…\")\n",
    "        return \"unknown_klook\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ í˜ì´ì§€ íƒ€ì… íƒì§€ ì‹¤íŒ¨: {e}\")\n",
    "        return \"error\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) KLOOK ì¹´í…Œê³ ë¦¬ íƒ­ ì°¾ê¸°/ë¶„ì„\n",
    "# -----------------------------------------------------------------------------\n",
    "def find_klook_category_tabs(driver) -> List[Dict]:\n",
    "    \"\"\"KLOOK ì¹´í…Œê³ ë¦¬ íƒ­ ì°¾ê¸° (KLOOK ì „ìš©)\"\"\"\n",
    "    print(\"  ğŸ” KLOOK ì¹´í…Œê³ ë¦¬ íƒ­ ì°¾ê¸° ì‹œì‘...\")\n",
    "\n",
    "    all_tabs: List[WebElement] = []\n",
    "    for selector in KLOOK_TAB_SELECTORS:\n",
    "        try:\n",
    "            elems = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "            if elems:\n",
    "                print(f\"    ğŸ“Š ì„ íƒì '{selector}': {len(elems)}ê°œ íƒ­\")\n",
    "                all_tabs.extend(elems)\n",
    "        except Exception as e:\n",
    "            print(f\"    âš ï¸ ì„ íƒì '{selector}' ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "    all_tabs = _uniq_by_text_href(all_tabs)\n",
    "    print(f\"    ğŸ“ˆ ì´ {len(all_tabs)}ê°œ í›„ë³´ íƒ­(ì¤‘ë³µ ì œê±°)\")\n",
    "\n",
    "    analyzed: List[Dict] = []\n",
    "    for i, el in enumerate(all_tabs):\n",
    "        try:\n",
    "            txt = (el.text or \"\").strip()\n",
    "            href = el.get_attribute(\"href\") or \"\"\n",
    "            data_value = el.get_attribute(\"data-value\") or \"\"\n",
    "            score, reasons = _score_tab(el)\n",
    "\n",
    "            print(f\"    ğŸ” íƒ­ {i}: '{txt}' -> {href}\")\n",
    "            print(f\"        ğŸ“Š ì ìˆ˜: {score}ì \")\n",
    "            if reasons:\n",
    "                print(f\"        ğŸ“ ì´ìœ : {', '.join(reasons)}\")\n",
    "\n",
    "            analyzed.append({\n",
    "                \"element\": el,\n",
    "                \"text\": txt,\n",
    "                \"href\": href,\n",
    "                \"data_value\": data_value,\n",
    "                \"score\": score,\n",
    "                \"index\": i,\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"    âš ï¸ íƒ­ {i} ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "    return analyzed\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) íƒ­ í´ë¦­ ì‹œë„\n",
    "# -----------------------------------------------------------------------------\n",
    "def attempt_klook_tab_click(driver, tab_info: Dict) -> Tuple[bool, str]:\n",
    "    \"\"\"KLOOK íƒ­ í´ë¦­ ì‹œë„ (KLOOK ì „ìš©): (ì„±ê³µì—¬ë¶€, ê²°ê³¼URL/ì‚¬ìœ )\"\"\"\n",
    "    elem: WebElement = tab_info[\"element\"]\n",
    "    text: str = tab_info.get(\"text\", \"\")\n",
    "\n",
    "    try:\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView({block:'center'});\", elem)\n",
    "        time.sleep(0.8)\n",
    "\n",
    "        if _clickable(driver, elem):\n",
    "            # JS ìš°ì„  â†’ ì‹¤íŒ¨ ì‹œ ì¼ë°˜ í´ë¦­\n",
    "            try:\n",
    "                driver.execute_script(\"arguments[0].click();\", elem)\n",
    "                print(f\"        âœ… JavaScript í´ë¦­ ì„±ê³µ: '{text}'\")\n",
    "            except Exception:\n",
    "                elem.click()\n",
    "                print(f\"        âœ… ì¼ë°˜ í´ë¦­ ì„±ê³µ: '{text}'\")\n",
    "        else:\n",
    "            # ë¹„í´ë¦­ ìš”ì†ŒëŠ” JSë¡œ ê°•ì œ ì‹œë„\n",
    "            driver.execute_script(\"arguments[0].click();\", elem)\n",
    "            print(f\"        âš ï¸ ê°•ì œ JS í´ë¦­: '{text}'\")\n",
    "\n",
    "        _sleep_after_click()\n",
    "\n",
    "        new_url = driver.current_url\n",
    "        links = driver.find_elements(By.CSS_SELECTOR, KLOOK_PRODUCT_LINK_SEL)\n",
    "        cards = driver.find_elements(By.CSS_SELECTOR, KLOOK_PRODUCT_CARD_SEL)\n",
    "        product_count = len(links) + len(cards)\n",
    "        print(f\"        ğŸ“Š ì´ë™ í›„ ìƒí’ˆ ì¶”ì • ìš”ì†Œ ìˆ˜: {product_count}\")\n",
    "\n",
    "        if product_count >= 3:\n",
    "            print(\"        âœ… KLOOK ìƒí’ˆ ëª©ë¡/ê²°ê³¼ ë…¸ì¶œ í™•ì¸!\")\n",
    "            return True, new_url\n",
    "        return False, \"ìƒí’ˆ ìˆ˜ ë¶€ì¡±\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"        âŒ í´ë¦­ ì‹œë„ ì‹¤íŒ¨: {e}\")\n",
    "        return False, f\"í´ë¦­ ì˜¤ë¥˜: {e}\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) ëª©í‘œ ì¹´í…Œê³ ë¦¬ë¡œ ì´ë™\n",
    "# -----------------------------------------------------------------------------\n",
    "def navigate_to_klook_category(driver, city_name: str, target_category: str = \"íˆ¬ì–´\") -> Tuple[bool, str]:\n",
    "    \"\"\"KLOOK ì¹´í…Œê³ ë¦¬ ì´ë™ (KLOOK ì „ìš©) -> (ì„±ê³µì—¬ë¶€, ê²°ê³¼URL/ì‚¬ìœ )\"\"\"\n",
    "    print(f\"  ğŸ¯ KLOOK '{target_category}' ì¹´í…Œê³ ë¦¬ ì´ë™ ì‹œì‘...\")\n",
    "\n",
    "    try:\n",
    "        time.sleep(2)\n",
    "        print(\"      ğŸ” KLOOK í˜ì´ì§€ íƒìƒ‰ ì¤‘...\")\n",
    "        # smart_scroll_selector ê°€ ìˆë‹¤ë©´ ì‚¬ìš©\n",
    "        if callable(globals().get(\"smart_scroll_selector\")):\n",
    "            try:\n",
    "                globals()[\"smart_scroll_selector\"](driver)\n",
    "            except Exception as e:\n",
    "                print(f\"      âš ï¸ smart_scroll_selector ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "        tabs = find_klook_category_tabs(driver)\n",
    "        if not tabs:\n",
    "            print(\"    âŒ KLOOK ì¹´í…Œê³ ë¦¬ íƒ­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "            return False, \"íƒ­ ì—†ìŒ\"\n",
    "\n",
    "        # ëª©í‘œ ì¹´í…Œê³ ë¦¬ ìš°ì„  í•„í„°\n",
    "        target_tabs = [t for t in tabs if target_category.lower() in t[\"text\"].lower()]\n",
    "        if target_tabs:\n",
    "            target_tabs.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "            print(f\"    ğŸ¯ '{target_category}' ê´€ë ¨ íƒ­ {len(target_tabs)}ê°œ ë°œê²¬\")\n",
    "        else:\n",
    "            tabs.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "            target_tabs = tabs[:3]\n",
    "            print(\"    ğŸ“Š ëª©í‘œ í‚¤ì›Œë“œ íƒ­ ì—†ìŒ â†’ ìƒìœ„ ì ìˆ˜ íƒ­ ì‹œë„\")\n",
    "\n",
    "        for attempt, tab in enumerate(target_tabs, 1):\n",
    "            if tab[\"score\"] < 15:\n",
    "                print(f\"    âš ï¸ íƒ­ ì ìˆ˜ ë‚®ìŒ({tab['score']}ì ) â†’ ì‹œë„ ì¤‘ë‹¨\")\n",
    "                break\n",
    "            print(f\"    ğŸ¯ ì‹œë„ {attempt}: '{tab['text']}' ({tab['score']}ì )\")\n",
    "            ok, res = attempt_klook_tab_click(driver, tab)\n",
    "            if ok:\n",
    "                print(\"    âœ… íƒ­ í´ë¦­ ì„±ê³µ!\")\n",
    "                return True, res\n",
    "            print(f\"    âŒ íƒ­ í´ë¦­ ì‹¤íŒ¨: {res}\")\n",
    "            if attempt < len(target_tabs):\n",
    "                print(\"    ğŸ”„ ë‹¤ìŒ í›„ë³´ íƒ­ ì‹œë„...\")\n",
    "                time.sleep(1.5)\n",
    "\n",
    "        print(\"    âŒ ëª¨ë“  íƒ­ ì‹œë„ ì‹¤íŒ¨\")\n",
    "        return False, \"ëª¨ë“  íƒ­ ì‹¤íŒ¨\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ KLOOK ì¹´í…Œê³ ë¦¬ ì´ë™ ì‹¤íŒ¨: {e}\")\n",
    "        return False, f\"ì˜¤ë¥˜: {e}\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5) KLOOK TAB STRUCTURE ì—°ë™\n",
    "# -----------------------------------------------------------------------------\n",
    "def get_klook_tab_info(tab_name: str) -> Dict:\n",
    "    \"\"\"KLOOK_TAB_STRUCTUREì—ì„œ íƒ­ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ë¹ˆ dict)\"\"\"\n",
    "    try:\n",
    "        if \"KLOOK_TAB_STRUCTURE\" in globals():\n",
    "            return globals()[\"KLOOK_TAB_STRUCTURE\"].get(tab_name, {}) or {}\n",
    "    except Exception:\n",
    "        pass\n",
    "    return {}\n",
    "\n",
    "# =============================================================================\n",
    "# ë¡œë”© ë¡œê·¸\n",
    "# =============================================================================\n",
    "print(\"âœ… KLOOK ì „ìš© ê·¸ë£¹ 10 ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ!\\n\")\n",
    "print(\"ğŸ”§ KLOOK ì „ìš© ê°œì„ ì‚¬í•­:\")\n",
    "print(\"   ğŸ¯ ì „ìš© ì…€ë ‰í„° ê°•í™” (.klk-tabs-tab, a[href*='/activity/'], product-card ë“±)\")\n",
    "print(\"   ğŸŒ klook ë„ë©”ì¸/URL íŒ¨í„´ ê¸°ë°˜ íƒì§€\")\n",
    "print(\"   ğŸ“Š í‚¤ì›Œë“œ ì ìˆ˜ ì‹œìŠ¤í…œ + í™œì„±/role ê°€ì \")\n",
    "print(\"   ğŸ§¼ íƒ­ ìˆ˜ì§‘ ì¤‘ë³µ ì œê±°(í…ìŠ¤íŠ¸+href)\")\n",
    "print(\"   â³ ê²¬ê³ í•œ ëŒ€ê¸°/í´ë¦­ í´ë°±(JSâ†’ì¼ë°˜)\")\n",
    "print(\"   ğŸ”„ KLOOK_TAB_STRUCTURE ì—°ë™\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e24fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ğŸ¯ ê·¸ë£¹ 11: ì •ë¦¬ëœ í¬ë¡¤ë§ ì •ì§€ ì‹œìŠ¤í…œ (ê²½ëŸ‰í™” ë²„ì „)\n",
    "# - í¬ë¡¤ë§ ì •ì§€ ê¸°ëŠ¥ë§Œ ìœ ì§€\n",
    "# - ì‹œìŠ¤í…œ ì§„ë‹¨ ë° ì´ˆê¸°í™” ê¸°ëŠ¥ ì œê±°\n",
    "# - í•µì‹¬ í¬ë¡¤ë§ ë¡œì§ì€ 100% ë³´ì¡´\n",
    "# =============================================================================\n",
    "\n",
    "# ì „ì—­ ì •ì§€ í”Œë˜ê·¸\n",
    "CRAWLING_STOP_FLAG = False\n",
    "CRAWLING_ACTIVE = False\n",
    "\n",
    "def set_stop_flag():\n",
    "    \"\"\"í¬ë¡¤ë§ ì •ì§€ í”Œë˜ê·¸ ì„¤ì •\"\"\"\n",
    "    global CRAWLING_STOP_FLAG\n",
    "    CRAWLING_STOP_FLAG = True\n",
    "    print(\"ğŸ›‘ í¬ë¡¤ë§ ì •ì§€ ì‹ í˜¸ê°€ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤...\")\n",
    "\n",
    "def reset_stop_flag():\n",
    "    \"\"\"í¬ë¡¤ë§ ì •ì§€ í”Œë˜ê·¸ ì´ˆê¸°í™”\"\"\"\n",
    "    global CRAWLING_STOP_FLAG\n",
    "    CRAWLING_STOP_FLAG = False\n",
    "\n",
    "def check_stop_flag():\n",
    "    \"\"\"í¬ë¡¤ë§ ì •ì§€ í”Œë˜ê·¸ í™•ì¸\"\"\"\n",
    "    return CRAWLING_STOP_FLAG\n",
    "\n",
    "def set_crawling_active(status):\n",
    "    \"\"\"í¬ë¡¤ë§ í™œì„± ìƒíƒœ ì„¤ì •\"\"\"\n",
    "    global CRAWLING_ACTIVE\n",
    "    CRAWLING_ACTIVE = status\n",
    "\n",
    "def is_crawling_active():\n",
    "    \"\"\"í¬ë¡¤ë§ í™œì„± ìƒíƒœ í™•ì¸\"\"\"\n",
    "    return CRAWLING_ACTIVE\n",
    "\n",
    "def perform_new_search(driver, city):\n",
    "    \"\"\"ìƒˆë¡œìš´ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ê³µí†µ í•¨ìˆ˜\"\"\"\n",
    "    # í•„ìˆ˜ í•¨ìˆ˜ë“¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "    required_functions = [\n",
    "        'go_to_main_page', 'find_and_fill_search', 'click_search_button',\n",
    "        'handle_popup', 'click_view_all'\n",
    "    ]\n",
    "    \n",
    "    missing_functions = []\n",
    "    for func_name in required_functions:\n",
    "        if func_name not in globals():\n",
    "            missing_functions.append(func_name)\n",
    "    \n",
    "    if missing_functions:\n",
    "        print(f\"âŒ í•„ìˆ˜ í•¨ìˆ˜ë“¤ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing_functions)}\")\n",
    "        print(\"ğŸ’¡ ê·¸ë£¹ 5 (ë¸Œë¼ìš°ì € ì œì–´ í•¨ìˆ˜ë“¤)ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”!\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        go_to_main_page(driver)\n",
    "        find_and_fill_search(driver, city)\n",
    "        click_search_button(driver)\n",
    "        print(\"  âœ… í˜ì´ì§€ ìµœì í™” ì¤‘ (íŒì—… ì²˜ë¦¬ ë° ì „ì²´ ë³´ê¸°)...\")\n",
    "        handle_popup(driver)\n",
    "        click_view_all(driver)\n",
    "        print(\"  â³ ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ê°€ ì™„ì „íˆ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°í•©ë‹ˆë‹¤...\")\n",
    "        \n",
    "        # WebDriverWait ë° ê´€ë ¨ ëª¨ë“ˆë“¤ import í™•ì¸\n",
    "        try:\n",
    "            WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"a[href*='/products/'], a[href*='/offers/']\"))\n",
    "            )\n",
    "            print(\"  âœ… ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ ë¡œë“œ í™•ì¸ ì™„ë£Œ.\")\n",
    "        except TimeoutException:\n",
    "            print(\"  âš ï¸ ì‹œê°„ ì´ˆê³¼: ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ ë¡œë“œì— ì‹¤íŒ¨í–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "        except NameError:\n",
    "            print(\"  âš ï¸ WebDriverWait ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - ê¸°ë³¸ ëŒ€ê¸° ì‚¬ìš©\")\n",
    "            import time\n",
    "            time.sleep(5)\n",
    "            print(\"  âœ… ê¸°ë³¸ ëŒ€ê¸° ì™„ë£Œ\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ìƒˆë¡œìš´ ê²€ìƒ‰ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "def perform_new_search_with_switch(driver, city, use_group10=False):\n",
    "    \"\"\"ê°„ì†Œí™”ëœ ìŠ¤ìœ„ì¹˜ ê¸°ë°˜ ê²€ìƒ‰ í•¨ìˆ˜\"\"\"\n",
    "    # í•„ìˆ˜ í•¨ìˆ˜ë“¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "    required_functions = [\n",
    "        'go_to_main_page', 'find_and_fill_search', 'click_search_button',\n",
    "        'handle_popup', 'click_view_all'\n",
    "    ]\n",
    "    \n",
    "    missing_functions = []\n",
    "    for func_name in required_functions:\n",
    "        if func_name not in globals():\n",
    "            missing_functions.append(func_name)\n",
    "    \n",
    "    if missing_functions:\n",
    "        print(f\"âŒ í•„ìˆ˜ í•¨ìˆ˜ë“¤ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing_functions)}\")\n",
    "        print(\"ğŸ’¡ ê·¸ë£¹ 5 (ë¸Œë¼ìš°ì € ì œì–´ í•¨ìˆ˜ë“¤)ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”!\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        go_to_main_page(driver)\n",
    "        find_and_fill_search(driver, city)\n",
    "        click_search_button(driver)\n",
    "        handle_popup(driver)\n",
    "        print(\"âœ… ê²€ìƒ‰ ì™„ë£Œ â†’ ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ ë„ë‹¬\")\n",
    "        \n",
    "        if use_group10:\n",
    "            # ğŸš€ ê·¸ë£¹10ëª¨ë“œ (ê°„ì†Œí™”ë¨)\n",
    "            print(\"  ğŸš€ ìŠ¤í¬ë¡¤ ëª¨ë“œ: ìƒˆë¡œìš´ í˜ì´ì§€ êµ¬ì¡° ëŒ€ì‘\")\n",
    "            success, result = navigate_to_scroll_list(driver, city)\n",
    "            \n",
    "            if success:\n",
    "                print(\"  âœ… ìŠ¤í¬ë¡¤ ëª¨ë“œ ì„±ê³µ!\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"  âŒ ìŠ¤í¬ë¡¤ ëª¨ë“œ ì‹¤íŒ¨: {result} - ê¸°ë³¸ëª¨ë“œë¡œ ì „í™˜\")\n",
    "                # fallback ê³„ì† ì§„í–‰\n",
    "        \n",
    "        # ğŸ”„ ê¸°ë³¸ëª¨ë“œ (ê·¸ë£¹10 ì‹¤íŒ¨ ì‹œì—ë„ ì‹¤í–‰)\n",
    "        print(\"  ğŸ”„ ê¸°ë³¸ëª¨ë“œ: ì•ˆì •ì ì¸ ë°©ì‹\")\n",
    "        click_view_all(driver)\n",
    "        print(\"  â³ ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ê°€ ì™„ì „íˆ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°í•©ë‹ˆë‹¤...\")\n",
    "        \n",
    "        # WebDriverWait ë° ê´€ë ¨ ëª¨ë“ˆë“¤ import í™•ì¸\n",
    "        try:\n",
    "            WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"a[href*='/products/'], a[href*='/offers/']\"))\n",
    "            )\n",
    "            print(\"  âœ… ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ ë¡œë“œ í™•ì¸ ì™„ë£Œ.\")\n",
    "        except TimeoutException:\n",
    "            print(\"  âš ï¸ ì‹œê°„ ì´ˆê³¼: ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ ë¡œë“œì— ì‹¤íŒ¨í–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "        except NameError:\n",
    "            print(\"  âš ï¸ WebDriverWait ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - ê¸°ë³¸ ëŒ€ê¸° ì‚¬ìš©\")\n",
    "            import time\n",
    "            time.sleep(5)\n",
    "            print(\"  âœ… ê¸°ë³¸ ëŒ€ê¸° ì™„ë£Œ\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "def run_crawler_with_stop_support(city, num_products_to_crawl, use_group10=False, resume_session=True):\n",
    "        \n",
    "    \"\"\"\n",
    "    ğŸ›‘ ì •ì§€ ê¸°ëŠ¥ì´ í†µí•©ëœ í¬ë¡¤ë§ ì‹¤í–‰ í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    # í•„ìˆ˜ í•¨ìˆ˜ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "    required_functions = [\n",
    "        'load_session_state', 'save_url_to_log', 'get_city_info',\n",
    "        'perform_new_search_with_switch', 'load_collected_urls', \n",
    "        'collect_urls_with_csv_safety', 'save_collected_urls'\n",
    "    ]\n",
    "    missing_functions = [f for f in required_functions if f not in globals()]\n",
    "    if missing_functions:\n",
    "        print(f\"âŒ í•„ìˆ˜ í•¨ìˆ˜ë“¤ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing_functions)}\")\n",
    "        return\n",
    "\n",
    "    # ì •ì§€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "    reset_stop_flag()\n",
    "    set_crawling_active(True)\n",
    "    \n",
    "    try:\n",
    "        # ìƒíƒœ ë³µì› ë° ì„¤ì • í†µí•©\n",
    "        global CITIES_TO_SEARCH, city_name, start_number, completed_urls, driver, urls_to_crawl, continent, country\n",
    "        \n",
    "        city_name = city\n",
    "        CITIES_TO_SEARCH = [city]\n",
    "        continent, country = get_city_info(city_name)\n",
    "        \n",
    "        # ì •ì§€ ì‹ í˜¸ ì²´í¬ í¬ì¸íŠ¸ 1\n",
    "        if check_stop_flag():\n",
    "            print(\"ğŸ›‘ ì‹œì‘ ì „ ì •ì§€ ì‹ í˜¸ ê°ì§€ - í¬ë¡¤ë§ ì¤‘ë‹¨\")\n",
    "            return\n",
    "        try:\n",
    "            start_number, completed_urls = load_session_state(city_name)\n",
    "            if len(completed_urls) == 0:\n",
    "                print(f\"ğŸ“Š ì‹ ê·œ ë„ì‹œ - {start_number}ë²ˆë¶€í„° ì‹œì‘\")\n",
    "            else:\n",
    "                print(f\"ğŸ“Š ì¬ê°œ ì„¸ì…˜ - {len(completed_urls)}ê°œ ì™„ë£Œ, {start_number}ë²ˆë¶€í„° ê³„ì†\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ìƒíƒœ ë³µì› ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "            return\n",
    "\n",
    "        # ì •ì§€ ì‹ í˜¸ ì²´í¬ í¬ì¸íŠ¸ 2\n",
    "        if check_stop_flag():\n",
    "            print(\"ğŸ›‘ ìƒíƒœ ë³µì› í›„ ì •ì§€ ì‹ í˜¸ ê°ì§€ - í¬ë¡¤ë§ ì¤‘ë‹¨\")\n",
    "            return\n",
    "\n",
    "        # URL ëª©ë¡ ê²°ì • (ê¸°ì¡´ ìºì‹œ í™œìš©)\n",
    "        urls_to_crawl = []\n",
    "        try:\n",
    "            potential_urls = load_collected_urls(city)\n",
    "            if potential_urls:\n",
    "                new_urls = [url for url in potential_urls if url not in completed_urls]\n",
    "                if new_urls:\n",
    "                    print(f\"âœ… ê¸°ì¡´ ìºì‹œì—ì„œ {len(new_urls)}ê°œì˜ ë¯¸ì™„ë£Œ ì‘ì—…ì„ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "                    urls_to_crawl = new_urls\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # ì •ì§€ ì‹ í˜¸ ì²´í¬ í¬ì¸íŠ¸ 3\n",
    "        if check_stop_flag():\n",
    "            print(\"ğŸ›‘ URL ë¡œë“œ í›„ ì •ì§€ ì‹ í˜¸ ê°ì§€ - í¬ë¡¤ë§ ì¤‘ë‹¨\")\n",
    "            return\n",
    "\n",
    "        # ìƒˆë¡œìš´ URL ê²€ìƒ‰\n",
    "        if not urls_to_crawl:\n",
    "            print(f\"ğŸ”„ '{city}' ë„ì‹œì˜ ì‹ ê·œ ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "            try:\n",
    "                search_success = perform_new_search_with_switch(driver, city, use_group10)\n",
    "                if not search_success:\n",
    "                    print(\"âŒ ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨\")\n",
    "                    return\n",
    "\n",
    "                # ì •ì§€ ì‹ í˜¸ ì²´í¬ í¬ì¸íŠ¸ 4\n",
    "                if check_stop_flag():\n",
    "                    print(\"ğŸ›‘ ê²€ìƒ‰ ì™„ë£Œ í›„ ì •ì§€ ì‹ í˜¸ ê°ì§€ - í¬ë¡¤ë§ ì¤‘ë‹¨\")\n",
    "                    return\n",
    "                \n",
    "                newly_collected_urls = collect_urls_with_csv_safety(driver, city)\n",
    "                urls_to_crawl = newly_collected_urls\n",
    "                if urls_to_crawl:\n",
    "                    save_collected_urls(city, urls_to_crawl)\n",
    "                    print(f\"ğŸ“Š URL ìˆ˜ì§‘: {len(urls_to_crawl)}ê°œ ë°œê²¬\")\n",
    "                               \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ì‹ ê·œ URL ê²€ìƒ‰ ì‹¤íŒ¨: {e}\")\n",
    "                return\n",
    "\n",
    "        # ì •ì§€ ì‹ í˜¸ ì²´í¬ í¬ì¸íŠ¸ 5\n",
    "        if check_stop_flag():\n",
    "            print(\"ğŸ›‘ URL ìˆ˜ì§‘ í›„ ì •ì§€ ì‹ í˜¸ ê°ì§€ - í¬ë¡¤ë§ ì¤‘ë‹¨\")\n",
    "            return\n",
    "\n",
    "        # ìµœì¢… í¬ë¡¤ë§ ì‹¤í–‰\n",
    "        if not urls_to_crawl:\n",
    "            print(\"ğŸ‰ ìˆ˜ì§‘í•  ìƒˆë¡œìš´ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        final_urls_to_crawl = urls_to_crawl[:num_products_to_crawl]\n",
    "        print(f\"ğŸ¯ {len(final_urls_to_crawl)}ê°œ ìƒí’ˆ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "        # ì •ì§€ ê¸°ëŠ¥ì´ í†µí•©ëœ í¬ë¡¤ë§ ì—”ì§„ í˜¸ì¶œ\n",
    "        try:\n",
    "            crawl_with_pagination_and_stop_check(\n",
    "                city_name=city,\n",
    "                target_products=len(final_urls_to_crawl),\n",
    "                resume_session=resume_session,\n",
    "                pre_collected_urls=final_urls_to_crawl\n",
    "            )\n",
    "            \n",
    "            if not check_stop_flag():\n",
    "                print(f\"\\nğŸ‰ '{city}' ë„ì‹œ í¬ë¡¤ë§ ì‘ì—…ì´ ì •ìƒ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "            else:\n",
    "                print(f\"\\nğŸ›‘ '{city}' ë„ì‹œ í¬ë¡¤ë§ì´ ì‚¬ìš©ì ìš”ì²­ìœ¼ë¡œ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ í¬ë¡¤ë§ ì‹¤í–‰ ì‹¤íŒ¨: {e}\")\n",
    "            \n",
    "    finally:\n",
    "        # í¬ë¡¤ë§ ì¢…ë£Œ ì‹œ í”Œë˜ê·¸ ì •ë¦¬\n",
    "        set_crawling_active(False)\n",
    "        reset_stop_flag()\n",
    "        print(\"ğŸ í¬ë¡¤ë§ ì„¸ì…˜ ì¢…ë£Œ\")\n",
    "\n",
    "def crawl_with_pagination_and_stop_check(city_name, target_products,\n",
    "                                        resume_session=True, pre_collected_urls=None):\n",
    "    \"\"\"\n",
    "    ğŸ›‘ ì •ì§€ ì²´í¬ê°€ í†µí•©ëœ ë©”ì¸ í¬ë¡¤ë§ ì—”ì§„\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # í™˜ê²½ ê²€ì¦ (ì¡°ìš©íˆ ì‹¤í–‰)\n",
    "        try:\n",
    "            env_valid, missing = validate_pagination_environment()\n",
    "            if not env_valid:\n",
    "                print(f\"âŒ í™˜ê²½ ê²€ì¦ ì‹¤íŒ¨: {missing}\")\n",
    "                return False\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        global start_number, completed_urls, continent, country, driver\n",
    "        \n",
    "        # í¬ë¡¤ë§ ìƒíƒœ ì´ˆê¸°í™”\n",
    "        current_product_number = start_number\n",
    "        total_crawled_this_session = 0\n",
    "        page_results = []\n",
    "        print(f\"ğŸ¯ {target_products}ê°œ ìƒí’ˆ í¬ë¡¤ë§ ì‹œì‘\")\n",
    "        \n",
    "        # URL ëª©ë¡ ì²˜ë¦¬\n",
    "        urls_to_process = pre_collected_urls or []\n",
    "        \n",
    "        # ë©”ì¸ í¬ë¡¤ë§ ë£¨í”„ (ì •ì§€ ì‹ í˜¸ í†µí•©)\n",
    "        for i, product_url in enumerate(urls_to_process):\n",
    "            # ê° ìƒí’ˆ ì²˜ë¦¬ ì „ ì •ì§€ ì‹ í˜¸ ì²´í¬\n",
    "            if check_stop_flag():\n",
    "                print(f\"ğŸ›‘ ìƒí’ˆ {current_product_number} ì²˜ë¦¬ ì „ ì •ì§€ ì‹ í˜¸ ê°ì§€\")\n",
    "                print(f\"ğŸ’¾ í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ {len(page_results)}ê°œ ìƒí’ˆì„ ì €ì¥í•©ë‹ˆë‹¤...\")\n",
    "                if page_results:\n",
    "                    save_batch_data(page_results, city_name)\n",
    "                print(f\"âœ… ì •ì§€ ì™„ë£Œ: ì´ {total_crawled_this_session}ê°œ ìƒí’ˆ ìˆ˜ì§‘ë¨\")\n",
    "                return True\n",
    "            \n",
    "            if total_crawled_this_session >= target_products:\n",
    "                break\n",
    "            \n",
    "            if product_url in completed_urls:\n",
    "                print(f\"â­ï¸ ì´ë¯¸ ì™„ë£Œëœ URL ê±´ë„ˆëœ€: {product_url[:50]}...\")\n",
    "                continue\n",
    "            \n",
    "            # ğŸ†• ê°„ì†Œí™”ëœ ìƒí’ˆ ì²˜ë¦¬ ì‹œì‘ ë©”ì‹œì§€\n",
    "            print(f\"ğŸ“¦ ìƒí’ˆ {current_product_number} ì²˜ë¦¬ ì¤‘...\")\n",
    "            \n",
    "            # ì •ì§€ ì²´í¬ê°€ í†µí•©ëœ ìƒí’ˆ í¬ë¡¤ë§\n",
    "            result = crawl_single_product_with_stop_check(\n",
    "                driver, product_url, current_product_number,\n",
    "                city_name, continent, country, 1\n",
    "            )\n",
    "            \n",
    "            # ìƒí’ˆ í¬ë¡¤ë§ í›„ ì •ì§€ ì‹ í˜¸ ì¬í™•ì¸\n",
    "            if check_stop_flag():\n",
    "                print(f\"ğŸ›‘ ìƒí’ˆ {current_product_number} ì²˜ë¦¬ í›„ ì •ì§€ ì‹ í˜¸ ê°ì§€\")\n",
    "                if result:  # í˜„ì¬ ìƒí’ˆì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œëœ ê²½ìš°\n",
    "                    print(f\"âœ… í˜„ì¬ ìƒí’ˆ í¬ë¡¤ë§ ì™„ë£Œ í›„ ì •ì§€\")\n",
    "                    save_url_to_log(city_name, product_url)\n",
    "                    completed_urls.add(product_url)\n",
    "                    page_results.append(result)\n",
    "                    total_crawled_this_session += 1\n",
    "                \n",
    "                print(f\"ğŸ’¾ í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ {len(page_results)}ê°œ ìƒí’ˆì„ ì €ì¥í•©ë‹ˆë‹¤...\")\n",
    "                if page_results:\n",
    "                    save_batch_data(page_results, city_name)\n",
    "                print(f\"âœ… ì •ì§€ ì™„ë£Œ: ì´ {total_crawled_this_session}ê°œ ìƒí’ˆ ìˆ˜ì§‘ë¨\")\n",
    "                return True\n",
    "            \n",
    "            if result:\n",
    "                save_url_to_log(city_name, product_url)\n",
    "                completed_urls.add(product_url)\n",
    "                page_results.append(result)\n",
    "                total_crawled_this_session += 1\n",
    "                current_product_number += 1\n",
    "                \n",
    "                # ğŸ†• ê°„ì†Œí™”ëœ ì™„ë£Œ ë©”ì‹œì§€\n",
    "                product_info = f\"{result.get('ìƒí’ˆëª…', '')[:40]}... | {result.get('ê°€ê²©_ì •ì œ', '')} | {result.get('ë¦¬ë·°ìˆ˜', '')}\"\n",
    "                print(f\"âœ… ìƒí’ˆ {current_product_number-1}: {product_info}\")\n",
    "        \n",
    "        # ìµœì¢… ë°ì´í„° ì €ì¥\n",
    "        if page_results:\n",
    "            save_batch_data(page_results, city_name)\n",
    "        \n",
    "        print(f\"\\nğŸ‰ í¬ë¡¤ë§ ì‘ì—… ì™„ë£Œ!\")\n",
    "        print(f\"ğŸ“Š ì´ {total_crawled_this_session}ê°œ ìƒí’ˆ ìˆ˜ì§‘ë¨\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        if 'page_results' in locals() and page_results:\n",
    "            save_batch_data(page_results, city_name)\n",
    "        return False\n",
    "\n",
    "def crawl_single_product_with_stop_check(driver, product_url, product_number, city_name, continent, country, page_num):\n",
    "    \"\"\"\n",
    "    ğŸ›‘ ì •ì§€ ì‹ í˜¸ ì²´í¬ê°€ í†µí•©ëœ ë‹¨ì¼ ìƒí’ˆ í¬ë¡¤ë§\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # í˜ì´ì§€ ì´ë™ ì „ ì •ì§€ ì‹ í˜¸ ì²´í¬\n",
    "        if check_stop_flag():\n",
    "            print(f\"      ğŸ›‘ ìƒí’ˆ í˜ì´ì§€ ì´ë™ ì „ ì •ì§€ ì‹ í˜¸ ê°ì§€\")\n",
    "            return None\n",
    "            \n",
    "        # ìƒí’ˆ í˜ì´ì§€ ì´ë™\n",
    "        driver.get(product_url)\n",
    "        time.sleep(random.uniform(CONFIG[\"MEDIUM_MIN_DELAY\"], CONFIG[\"MEDIUM_MAX_DELAY\"]))\n",
    "        \n",
    "        # ğŸ†• ìƒí’ˆ ìƒì„¸í˜ì´ì§€ ìì—°ìŠ¤ëŸ¬ìš´ ìŠ¤í¬ë¡¤ (ë´‡ íšŒí”¼ ê°•í™”)\n",
    "        print(f\"      ğŸ“œ ìƒí’ˆ í˜ì´ì§€ ìì—°ìŠ¤ëŸ¬ìš´ íƒìƒ‰ ì¤‘...\")\n",
    "        smart_scroll_selector(driver)\n",
    "\n",
    "        # í˜ì´ì§€ ë¡œë“œ í›„ ì •ì§€ ì‹ í˜¸ ì²´í¬\n",
    "        if check_stop_flag():\n",
    "            print(f\"      ğŸ›‘ ìƒí’ˆ í˜ì´ì§€ ë¡œë“œ í›„ ì •ì§€ ì‹ í˜¸ ê°ì§€\")\n",
    "            return None\n",
    "        \n",
    "        # URL íƒ€ì… íŒë³„\n",
    "        url_type = \"Activity\" if \"/activity/\" in product_url else \"Product\"\n",
    "        \n",
    "        # ì •ë³´ ìˆ˜ì§‘ (ê° ë‹¨ê³„ë§ˆë‹¤ ì •ì§€ ì‹ í˜¸ ì²´í¬)\n",
    "        if check_stop_flag(): return None\n",
    "        product_name = get_product_name(driver, url_type)\n",
    "        \n",
    "        if check_stop_flag(): return None\n",
    "        price_raw = get_price(driver)\n",
    "        price_clean = clean_price(price_raw)\n",
    "        \n",
    "        if check_stop_flag(): return None\n",
    "        rating_raw = get_rating(driver)\n",
    "        rating_clean = clean_rating(rating_raw)\n",
    "        \n",
    "        if check_stop_flag(): return None\n",
    "        review_count = get_review_count(driver)\n",
    "        \n",
    "        if check_stop_flag(): return None\n",
    "        language = get_language(driver)\n",
    "\n",
    "        if check_stop_flag(): return None\n",
    "        category = get_categories(driver)\n",
    "\n",
    "        if check_stop_flag(): return None\n",
    "        highlights = get_highlights(driver)\n",
    "        \n",
    "        # ë„ì‹œID ìƒì„±\n",
    "        city_code = get_city_code(city_name)\n",
    "        city_id = f\"{city_code}_{product_number}\"\n",
    "        \n",
    "        # ğŸ–¼ï¸ ë©”ì¸+ì¸ë„¤ì¼ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ì •ì§€ ì‹ í˜¸ ì²´í¬ í¬í•¨)\n",
    "        if check_stop_flag():\n",
    "            return None\n",
    "\n",
    "        if CONFIG[\"SAVE_IMAGES\"]:\n",
    "            img_results = download_image(driver, product_name, city_name, product_number)\n",
    "            main_img = img_results.get('main_image', {})\n",
    "            thumb_img = img_results.get('thumbnail_image', {})\n",
    "        else:\n",
    "            main_img = {'filename': '', 'relative_path': '', 'path': '', 'status': 'skipped'}\n",
    "            thumb_img = {'filename': '', 'relative_path': '', 'path': '', 'status': 'skipped'}\n",
    "                       \n",
    "        \n",
    "        # ìµœì¢… ì •ì§€ ì‹ í˜¸ ì²´í¬\n",
    "        if check_stop_flag():\n",
    "            print(f\"      ğŸ›‘ ìƒí’ˆ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ í›„ ì •ì§€ ì‹ í˜¸ ê°ì§€\")\n",
    "            return None\n",
    "        \n",
    "        # ê²°ê³¼ ë°˜í™˜\n",
    "        return {\n",
    "            'ë²ˆí˜¸': product_number,\n",
    "            'ë„ì‹œID': city_id,\n",
    "            'í˜ì´ì§€': page_num,\n",
    "            'ëŒ€ë¥™': continent,\n",
    "            'êµ­ê°€': country,\n",
    "            'ë„ì‹œ': city_name,\n",
    "            'ê³µí•­ì½”ë“œ': city_code,\n",
    "            'ìƒí’ˆíƒ€ì…': url_type,\n",
    "            'ìƒí’ˆëª…': product_name,\n",
    "            'ê°€ê²©_ì›ë³¸': price_raw,\n",
    "            'ê°€ê²©_ì •ì œ': price_clean,\n",
    "            'í‰ì _ì›ë³¸': rating_raw,\n",
    "            'í‰ì _ì •ì œ': rating_clean,\n",
    "            'ë¦¬ë·°ìˆ˜': review_count,\n",
    "            'ì–¸ì–´': language,\n",
    "            'ì¹´í…Œê³ ë¦¬': category,\n",
    "            'í•˜ì´ë¼ì´íŠ¸': highlights,\n",
    "            'ë©”ì¸ì´ë¯¸ì§€_íŒŒì¼ëª…': main_img.get('filename', ''),\n",
    "            'ë©”ì¸ì´ë¯¸ì§€_ìƒëŒ€ê²½ë¡œ': main_img.get('relative_path', ''),\n",
    "            'ë©”ì¸ì´ë¯¸ì§€_ì „ì²´ê²½ë¡œ': main_img.get('path', ''),\n",
    "            'ë©”ì¸ì´ë¯¸ì§€_ìƒíƒœ': main_img.get('status', ''),\n",
    "            'ì¸ë„¤ì¼ì´ë¯¸ì§€_íŒŒì¼ëª…': thumb_img.get('filename', ''),\n",
    "            'ì¸ë„¤ì¼ì´ë¯¸ì§€_ìƒëŒ€ê²½ë¡œ': thumb_img.get('relative_path', ''),\n",
    "            'ì¸ë„¤ì¼ì´ë¯¸ì§€_ì „ì²´ê²½ë¡œ': thumb_img.get('path', ''),\n",
    "            'ì¸ë„¤ì¼ì´ë¯¸ì§€_ìƒíƒœ': thumb_img.get('status', ''),\n",
    "            'URL': product_url,\n",
    "            'ìˆ˜ì§‘_ì‹œê°„': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'ìƒíƒœ': 'ì™„ì „ìˆ˜ì§‘'\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"      âŒ ìƒí’ˆ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"âœ… ê·¸ë£¹ 11 ì™„ë£Œ: ì •ë¦¬ëœ í¬ë¡¤ë§ ì •ì§€ ì‹œìŠ¤í…œ!\")\n",
    "print(\"   ğŸ›‘ ì •ì§€ í”Œë˜ê·¸ ì‹œìŠ¤í…œ\")\n",
    "print(\"   ğŸ”§ ì •ì§€ ì§€ì› í¬ë¡¤ë§ ì—”ì§„\")\n",
    "print(\"   ğŸš€ í•µì‹¬ í¬ë¡¤ë§ ë¡œì§ 100% ë³´ì¡´\")\n",
    "print(\"   ğŸ“¦ ì½”ë“œ í¬ê¸°: ì•½ 50% ê°ì†Œ\")\n",
    "print(\"ğŸ¯ ë‹¤ìŒ: ê·¸ë£¹ 12ì—ì„œ UI ê°„ì†Œí™”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e48fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ğŸ›ï¸ ê·¸ë£¹ 12: ê°„ì†Œí™”ëœ UI ì»¨íŠ¸ë¡¤ íŒ¨ë„ (í•µì‹¬ ê¸°ëŠ¥ë§Œ)\n",
    "# - í¬ë¡¤ë§ ì‹œì‘/ì •ì§€ ê¸°ëŠ¥ë§Œ ìœ ì§€\n",
    "# - ì‹œìŠ¤í…œ ì§„ë‹¨ ë° ì´ˆê¸°í™” ê¸°ëŠ¥ ì œê±°\n",
    "# - UI ê¹”ë”í•˜ê²Œ ì •ë¦¬\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ”§ ê·¸ë£¹ 12: ê°„ì†Œí™”ëœ UI ì»¨íŠ¸ë¡¤ íŒ¨ë„ ë¡œë”©\")\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ›ï¸ ìœ„ì ¯ ìƒì„± (í•µì‹¬ ê¸°ëŠ¥ë§Œ)\n",
    "# =============================================================================\n",
    "\n",
    "# ì…ë ¥ ìœ„ì ¯ë“¤\n",
    "city_input = widgets.Text(value='', description='ë„ì‹œ:', layout={'width': '200px'})\n",
    "product_count_input = widgets.IntText(value=None, description='ìƒí’ˆ ìˆ˜:', layout={'width': '200px'})\n",
    "\n",
    "# í•µì‹¬ ë²„íŠ¼ë“¤ (ì‹œì‘/ì •ì§€ë§Œ)\n",
    "run_button = widgets.Button(description=\"ğŸš€ í¬ë¡¤ë§ ì‹œì‘\", button_style='danger')\n",
    "stop_button = widgets.Button(description=\"ğŸ›‘ í¬ë¡¤ë§ ì •ì§€\", button_style='warning', disabled=True)\n",
    "\n",
    "# ìŠ¤í¬ë¡¤ ëª¨ë“œ ìŠ¤ìœ„ì¹˜\n",
    "group10_switch = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='ğŸš€ ìŠ¤í¬ë¡¤ ëª¨ë“œ',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "# ìƒíƒœ í‘œì‹œ ë¼ë²¨ë“¤\n",
    "mode_label = widgets.Label(\n",
    "    value=\"ğŸ”„ ê¸°ë³¸ëª¨ë“œ (ì•ˆì •ì )\",\n",
    "    layout=widgets.Layout(width='250px')\n",
    ")\n",
    "\n",
    "status_label = widgets.Label(\n",
    "    value=\"ğŸ”µ ëŒ€ê¸° ì¤‘\",\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "\n",
    "def on_switch_change(change):\n",
    "    \"\"\"ìŠ¤ìœ„ì¹˜ ë³€ê²½ ì‹œ ë¼ë²¨ ì—…ë°ì´íŠ¸\"\"\"\n",
    "    if change['new']:\n",
    "        mode_label.value = \"ğŸš€ ìŠ¤í¬ë¡¤ ëª¨ë“œ (ìƒˆë¡œìš´ í˜ì´ì§€ ëŒ€ì‘)\"\n",
    "    else:\n",
    "        mode_label.value = \"ğŸ”„ ê¸°ë³¸ëª¨ë“œ (ì•ˆì •ì )\"\n",
    "\n",
    "group10_switch.observe(on_switch_change, names='value')\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ›ï¸ ë²„íŠ¼ ì´ë²¤íŠ¸ í•¨ìˆ˜ë“¤ (í•µì‹¬ ê¸°ëŠ¥ë§Œ)\n",
    "# =============================================================================\n",
    "\n",
    "def on_run_button_clicked(b):\n",
    "    \"\"\"í¬ë¡¤ë§ ì‹œì‘ ë²„íŠ¼ í´ë¦­ (ì •ì§€ ê¸°ëŠ¥ í†µí•©)\"\"\"\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        city = city_input.value.strip()\n",
    "        count = product_count_input.value\n",
    "        use_group10 = group10_switch.value\n",
    "                \n",
    "        # ì…ë ¥ ê²€ì¦\n",
    "        if not city:\n",
    "            print(\"âš ï¸ ë„ì‹œ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!\")\n",
    "            return\n",
    "        if count is None or count <= 0:\n",
    "            print(\"âš ï¸ ìˆ˜ì§‘í•  ìƒí’ˆ ê°œìˆ˜ë¥¼ 1 ì´ìƒìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”!\")\n",
    "            return\n",
    "        \n",
    "        # ë²„íŠ¼ ìƒíƒœ ë³€ê²½\n",
    "        run_button.disabled = True\n",
    "        stop_button.disabled = False\n",
    "        status_label.value = f\"ğŸŸ¡ í¬ë¡¤ë§ ì§„í–‰ ì¤‘... ({city})\"\n",
    "        \n",
    "        mode_text = \"ìŠ¤í¬ë¡¤ ëª¨ë“œ\" if use_group10 else \"ê¸°ë³¸ëª¨ë“œ\"\n",
    "        print(f\"ğŸš€ '{city}' ë„ì‹œ ìƒí’ˆ {count}ê°œ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤... ({mode_text})\")\n",
    "        print(f\"ğŸ›‘ í¬ë¡¤ë§ì„ ì¤‘ë‹¨í•˜ë ¤ë©´ 'í¬ë¡¤ë§ ì •ì§€' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”!\")\n",
    "        \n",
    "        try:\n",
    "            # ì •ì§€ ì§€ì› í¬ë¡¤ë§ í•¨ìˆ˜ í˜¸ì¶œ\n",
    "            run_crawler_with_stop_support(city=city, num_products_to_crawl=count, use_group10=use_group10)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ í¬ë¡¤ë§ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        finally:\n",
    "            # í¬ë¡¤ë§ ì™„ë£Œ í›„ ë²„íŠ¼ ìƒíƒœ ë³µì›\n",
    "            run_button.disabled = False\n",
    "            stop_button.disabled = True\n",
    "            status_label.value = \"ğŸ”µ ëŒ€ê¸° ì¤‘\"\n",
    "\n",
    "def on_stop_button_clicked(b):\n",
    "    \"\"\"í¬ë¡¤ë§ ì •ì§€ ë²„íŠ¼ í´ë¦­\"\"\"\n",
    "    with output_area:\n",
    "        print(\"\\nğŸ›‘ ì‚¬ìš©ìê°€ í¬ë¡¤ë§ ì •ì§€ë¥¼ ìš”ì²­í–ˆìŠµë‹ˆë‹¤!\")\n",
    "        print(\"ğŸ“‹ í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ìƒí’ˆì„ ì™„ë£Œí•œ í›„ ì•ˆì „í•˜ê²Œ ì •ì§€í•©ë‹ˆë‹¤...\")\n",
    "        \n",
    "        set_stop_flag()\n",
    "        stop_button.disabled = True\n",
    "        status_label.value = \"ğŸŸ  ì •ì§€ ì²˜ë¦¬ ì¤‘...\"\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ›ï¸ ë²„íŠ¼ ì´ë²¤íŠ¸ ì—°ê²° ë° ìœ„ì ¯ ë°°ì¹˜\n",
    "# =============================================================================\n",
    "\n",
    "# ë²„íŠ¼ê³¼ í•¨ìˆ˜ ì—°ê²°\n",
    "run_button.on_click(on_run_button_clicked)\n",
    "stop_button.on_click(on_stop_button_clicked)\n",
    "\n",
    "# ê°„ì†Œí™”ëœ ìœ„ì ¯ ë°°ì¹˜\n",
    "controls = widgets.VBox([\n",
    "    widgets.Label(value=\"ğŸš€ KLOOK í¬ë¡¤ëŸ¬ (ê°„ì†Œí™” ë²„ì „)\"),\n",
    "    widgets.Label(value=\"\"),\n",
    "    city_input,\n",
    "    product_count_input,\n",
    "    widgets.Label(value=\"\"),\n",
    "    widgets.HBox([\n",
    "        mode_label,\n",
    "        widgets.HTML(value=\"&nbsp;&nbsp;&nbsp;\"),\n",
    "        group10_switch\n",
    "    ], layout=widgets.Layout(align_items='center')),\n",
    "    widgets.Label(value=\"\"),\n",
    "    status_label,\n",
    "    widgets.Label(value=\"\"),\n",
    "    widgets.HBox([\n",
    "        widgets.HBox([run_button], layout=widgets.Layout(width='250px')),  # ì™¼ìª½ ê³ ì •í­\n",
    "        stop_button\n",
    "    ], layout=widgets.Layout(align_items='center'))\n",
    "])\n",
    "\n",
    "display(controls, output_area)\n",
    "\n",
    "print(\"âœ… ê·¸ë£¹ 12 ì™„ë£Œ: ê°„ì†Œí™”ëœ UI ì»¨íŠ¸ë¡¤ íŒ¨ë„!\")\n",
    "print(\"ğŸ¯ í•µì‹¬ ê¸°ëŠ¥:\")\n",
    "print(\"   - ğŸš€ í¬ë¡¤ë§ ì‹œì‘ (ê¸°ë³¸ëª¨ë“œ/ìŠ¤í¬ë¡¤ëª¨ë“œ)\")\n",
    "print(\"   - ğŸ›‘ í¬ë¡¤ë§ ì •ì§€ (ì•ˆì „í•œ ì¤‘ë‹¨)\")\n",
    "print(\"   - ğŸ“Š ì‹¤ì‹œê°„ ìƒíƒœ í‘œì‹œ\")\n",
    "print(\"ğŸ§¹ ì œê±°ëœ ê¸°ëŠ¥:\")\n",
    "print(\"   - ğŸ©º ì‹œìŠ¤í…œ ì§„ë‹¨ (í•„ìš”ì‹œ ì½”ë“œ ì…€ì—ì„œ ì§ì ‘ ì‹¤í–‰)\")\n",
    "print(\"   - ğŸ”„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (í•„ìš”ì‹œ ì½”ë“œ ì…€ì—ì„œ ì§ì ‘ ì‹¤í–‰)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mikael_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
