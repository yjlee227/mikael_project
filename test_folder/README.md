# 마이리얼트립 크롤링 시스템 개발 프로젝트

## 📊 프로젝트 개요
안정적이고 확장 가능한 대용량 크롤링 시스템을 구축하여, 중단 없이 모든 페이지의 상품 정보를 수집하고 체계적으로 저장하는 시스템입니다.

## ✅ 완료된 작업 (2025-07-23)

### 1순위: 9셀 크롤링 시스템 구축 완료 ✅
- **test73.ipynb**: 리팩토링된 9개 셀 구조로 완전한 크롤링 파이프라인 구현
- **UNIFIED_CITY_INFO**: 116개 도시를 단일 소스로 통합 관리
- **통일된 함수명**: 기존 함수들을 명확한 이름으로 리팩토링
- **실행 검증 완료**: 오사카 2개 상품 크롤링 성공

### 2순위: 상태 관리 및 데이터 연속성 시스템 ✅
- **URL 재사용 방지**: completed_urls.log 기반 중복 방지 시스템
- **세션 안전성**: 세션 간 URL 중복 체크 및 안전한 재시작
- **번호 연속성**: 이미지 파일명 충돌 방지 (KIX_0000.jpg, KIX_0001.jpg)
- **안전한 CSV 저장**: Permission denied 오류 해결
- **계층 구조 저장**: data/{대륙}/{국가}/{도시}/ 체계적 관리
- **🆕 url_history 구조**: url_history/{도시명}.json으로 세션 기록 개선

### 3순위: 브라우저 안정성 및 확장성 ✅
- **안전한 브라우저 재시작**: 3번 재시도 메커니즘
- **배치 처리**: 메모리 효율성 및 I/O 최적화
- **페이지네이션 분석**: 자동 페이지 구조 분석 기능
- **도시 관리 시스템**: 새 도시 추가 및 유효성 검사
- **진행률 표시**: 사용자 친화적 크롤링 진행 상황 표시

### 실제 테스트 결과 (오사카)
- **수집 성공**: 2개 상품 완전 수집 완료
- **상품 유형**: Offers (할인 상품) 위주
- **이미지 저장**: 계층 구조로 정상 저장 완료
- **데이터 저장**: 도시별/국가별 CSV 파일 생성
- **페이지네이션**: 현재는 단일 페이지 방식 (추후 개선 예정)

## 🚀 다음 작업 우선순위

### 5순위: 페이지네이션 자동화 시스템 개발 🔄
- **다중 페이지 순회**: 자동 페이지 이동 및 전체 상품 수집
- **페이지네이션 버튼 감지**: 다음 페이지 버튼 자동 인식 및 클릭
- **대용량 크롤링**: 수백 개 상품 안정적 수집 시스템
- **페이지별 상태 관리**: 페이지 단위 진행 상황 저장 및 복원
- **브라우저 최적화**: 페이지 이동 시 안정성 확보

### 6순위: 성능 최적화 및 확장성 개선 (예정)
- **멀티 스레드 처리**: 동시 다중 상품 처리
- **다중 도시 병렬 크롤링**: 여러 도시 동시 처리
- **메모리 최적화**: 대용량 데이터 효율적 처리
- **속도 개선**: 크롤링 시간 단축 최적화

## 📁 주요 파일 구조

```
test_folder/
├── test73.ipynb          # 메인 작업 파일 (9개 셀 구조)
├── .claude/              # Claude Code 설정 폴더
├── config/               # 상태 관리 폴더 ✅
│   ├── crawler_meta.json # 크롤링 메타데이터
│   ├── completed_urls.log# 완료된 URL 목록
│   └── city_codes.json   # 도시 코드 관리 (116개 도시)
├── url_history/          # 세션 히스토리 폴더 🆕
│   ├── 방콕.json         # 방콕 세션 기록
│   └── 오사카.json       # 오사카 세션 기록
├── data/                 # 계층 구조 데이터 폴더
│   └── {대륙}/{국가}/{도시}/
│       ├── myrealtrip_{도시명}_products.csv      # 도시별 데이터
│       └── {국가}_myrealtrip_products_all.csv   # 국가별 통합 데이터
├── myrealtripthumb_img/  # 이미지 저장 폴더
│   └── {대륙}/{국가}/{도시}/
│       └── {도시코드}_XXXX.jpg                   # 순차적 이미지 파일
└── 지침/                 # 개발 지침 폴더
    ├── enhancement.txt   # 미래 발전방향 및 개발 계획
    └── 클로드코드 공유.txt   # 로드맵 상세
```

## 🔧 현재 시스템 설정

- **검색 도시**: 오사카 (CITIES_TO_SEARCH에서 변경 가능)
- **크롤링 개수**: 2개 상품 (CONFIG['MAX_PRODUCTS_PER_CITY']에서 조정)
- **지원 도시**: 116개 도시
- **셀 구조**: 9개 셀 (그룹 1-9)

## 💡 다음 세션 시작 방법

```bash
# 다음 Claude Code 세션에서는 이렇게 시작하세요:
# "test73.ipynb 기준으로 페이지네이션 자동화 시스템 개발 시작"
```

## 🏗️ 기술 스택

- **언어**: Python
- **라이브러리**: Selenium, Pandas, undetected-chromedriver
- **저장**: CSV, JSON, 이미지 파일
- **구조**: Jupyter Notebook (9셀 구조)

## 📝 작업 기록

### 2025-07-23 (9셀 시스템 완전 구축) 🎉
- ✅ **test73.ipynb 완성**: 9개 셀로 구성된 완전한 크롤링 파이프라인
- ✅ **함수 리팩토링**: 통일된 함수명으로 코드 구조 개선
- ✅ **데이터 연속성 완전 확보**: URL 재사용 방지, 번호 연속성, 세션 안전성
- ✅ **브라우저 안정성**: 자동 재시작, 오류 복구, 상태 복원 시스템
- ✅ **실제 동작 검증**: 오사카 2개 상품 크롤링 성공 완료
- ✅ **확장성 확보**: 116개 도시 지원, 새 도시 추가 기능

### 다음 예정
- 🔄 5순위: 페이지네이션 자동화 시스템 개발
- 📋 6순위: 성능 최적화 및 확장성 개선

## 📋 그룹별 상세 기능

### **✅ 그룹 1 (통일된 함수명 - 기본 설정)**: 
- UNIFIED_CITY_INFO로 116개 도시 통합 관리
- 리팩토링된 핵심 함수들 (get_product_name, clean_price 등)
- 검증 완료된 안정적인 기반 시스템

### **✅ 그룹 2 (이미지 처리 및 데이터 저장)**: 
- 계층 구조 이미지 다운로드 시스템
- 안전한 CSV 저장 (Permission denied 해결)
- 배치 데이터 처리 및 저장 최적화

### **✅ 그룹 3 (상태 관리 시스템 - url_history 구조 적용)**: 
- URL 재사용 방지 및 세션 안전성 확보
- completed_urls.log 기반 중복 방지
- 크롤링 상태 실시간 저장 및 복원
- 🆕 url_history/{도시명}.json 형태로 세션 기록 관리

### **✅ 그룹 4 (확장성 개선 시스템)**: 
- 페이지네이션 정보 분석 기능
- 크롤링 계획 수립 및 보고 시스템
- 도시 코드 관리 및 유효성 검사

### **✅ 그룹 5 (브라우저 제어 및 유틸리티)**: 
- 안정적인 드라이버 설정 및 관리
- 안전한 브라우저 재시작 메커니즘
- 진행률 표시 및 재시도 로직

### **✅ 그룹 6-9 (실행 파이프라인)**: 
- 시스템 초기화 → 웹사이트 검색 → URL 수집 → 메인 크롤링
- **실행 테스트 완료**: 오사카 2개 상품 성공 수집
- 모든 연속성 문제 해결 완료

### 중요 발견사항
- 페이지네이션 분석 기능이 그룹 4에서 이미 구현됨
- 다음 페이지 버튼 자동화만 추가하면 대용량 크롤링 가능
- 현재 시스템은 완전히 자동화되어 9개 셀 순차 실행으로 전체 크롤링 완료

## 🔧 현재 개발 상태

### 완성된 시스템
- ✅ **9셀 크롤링 파이프라인**: 완전 자동화된 크롤링 시스템
- ✅ **데이터 연속성**: URL 재사용 방지, 번호 연속성, 세션 안전성
- ✅ **브라우저 안정성**: 자동 재시작, 오류 복구, 상태 복원
- ✅ **확장성**: 116개 도시 지원, 새 도시 추가 기능
- ✅ **페이지네이션 분석**: 자동 페이지 구조 분석 (그룹 4에서 구현)
- ✅ **실행 검증**: 오사카 2개 상품 성공 수집

### 수집 성능
- **실제 테스트**: 2개 상품 완전 수집
- **상품 정보**: 오사카 아베노 하루카스 300 전망대 입장권(17,000원), 난카이 라피트 편도 E-티켓(11,700원)
- **이미지**: 계층 구조로 정상 저장 (KIX_0000.jpg, KIX_0001.jpg)
- **데이터**: 도시별/국가별 CSV 파일 2개 생성

---
**Last Updated**: 2025-07-24  
**Status**: test74.ipynb 생성 완료, 페이지네이션 자동화 개발 진행중 (F12 버튼 분석 단계)  
**Next Session**: "F12 개발자 도구로 페이지네이션 버튼 분석 → click_next_page() 함수 구현"

## 🔜 다음 작업 계획 (2025-07-24)

### 4순위: url_history 구조 테스트 완료 ✅ (2025-07-24)
- ✅ **test74.ipynb 생성**: test73.ipynb 기반 마닐라 크롤링 시스템 구축
- ✅ **url_history 구조 검증**: 그룹 6-9 실행으로 세션 히스토리 기능 정상 작동 확인
- ✅ **마닐라 2개 상품 수집**: MNL_0003.jpg, MNL_0004.jpg 연속성 확보
- ✅ **시스템 안정성 검증**: 기존 기능과 호환성 문제 없음 확인

### 5순위: 페이지네이션 자동화 시스템 개발 🔄 (진행중)
**현재 진행 단계**: F12 개발자 도구를 통한 페이지네이션 버튼 분석

#### 🔍 1단계: 다음 페이지 버튼 분석 (진행중)
- **F12 개발자 도구 사용법**:
  1. 마이리얼트립 검색 결과 페이지에서 F12 → Elements 탭
  2. Ctrl + F로 검색: "pagination", "page", "next", "다음"
  3. 다음 페이지 버튼 우클릭 → "검사"로 정확한 HTML 요소 찾기

- **수집할 정보**:
  - CSS 선택자 (class, id 속성)
  - 버튼 타입 (`<button>` 또는 `<a>` 링크)
  - 버튼 텍스트 및 비활성화 상태 패턴

#### 📋 다음 단계 계획:
1. **click_next_page() 함수 구현**: 버튼 분석 완료 후 자동 클릭 함수 개발
2. **페이지 순회 메인 루프**: 전체 페이지 자동 순회 시스템
3. **상태 관리 확장**: crawler_meta.json에 페이지 정보 추가
4. **실제 테스트**: 다중 페이지 크롤링 검증

### 6순위: 성능 최적화 및 확장성 개선 (예정)
