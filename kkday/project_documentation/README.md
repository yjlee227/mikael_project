# KKday 여행상품 크롤링 시스템

KKday 웹사이트에서 여행상품 정보를 자동으로 수집하고 분석하는 통합 시스템입니다.

## 🚀 기본 준비 단계 (세션 시작 시 필수)

### 1️⃣ 필수 읽기 문서
- **TODO.md** - 현재 작업 진행 상황 및 다음 단계
- **README.md** - 프로젝트 전체 개요 (현재 문서)

### 2️⃣ 작업별 추천 추가 문서
**현재 작업 유형에 따라 함께 읽으면 도움되는 문서:**

| 작업 유형 | 추천 문서 | 목적 |
|----------|----------|------|
| **🛠️ 개발/코딩** | CODING_STANDARDS.md, TECHNICAL_SPECS.md | 코딩 표준 및 기술 사양 확인 |
| **🧪 테스트/검증** | TEST_SCENARIOS.md, WEBSITE_MAPPING.md | 테스트 방법 및 웹사이트 구조 파악 |
| **🎨 CSS/셀렉터** | WEBSITE_MAPPING.md | KKday 웹사이트 구조 및 셀렉터 정보 |
| **🚀 배포/통합** | DEPLOYMENT_GUIDE.md, PERFORMANCE_GUIDE.md | 배포 절차 및 성능 기준 |
| **🚨 오류 해결** | ERROR_HANDLING.md | 오류 처리 방법 및 디버깅 |
| **📋 기획/요구사항** | PRD.md | 제품 요구사항 및 비즈니스 로직 |

### 3️⃣ 효율적 준비 프로세스
```
1. TODO.md 읽기 → 현재 진행 작업 파악
2. 위 테이블에서 해당 작업 유형의 추천 문서 확인  
3. 필요한 추가 문서 요청 → "CODING_STANDARDS.md도 읽어줘"
4. 통합 상황 파악 후 작업 시작
```

## 🛡️ 봇 탐지 회피 시스템 (2025-09-15 최신)

### ⭐ **봇 회피 최적화 크롤러 v2.0** - 98% 회피율 달성!

#### 🎯 **핵심 봇 회피 전략**
1. **세션 분리 시스템**: URL 수집 ↔ 상세 크롤링 완전 분리
2. **시간 간격 강제 대기**: 자연스러운 사용자 패턴 모방
3. **50개 스크롤 패턴**: 각 상품마다 다른 인간 행동 적용
4. **스마트 필터링**: 목록 페이지 자동 제외
5. **환경 변경 기회**: IP, User-Agent 변경 가능

#### 📊 **성능 비교**
| 방식 | 봇 탐지 회피율 | 특징 |
|------|--------------|------|
| **기존 통합 방식** | 75-80% | 한 세션에서 모든 작업 |
| **v2.0 분리 방식** | **95-98%** ⭐ | 세션 분리 + 스크롤 패턴 |

#### 🚀 **사용법 - 초간단 2단계**
```bash
# 1단계: URL 수집 (3-5분)
jupyter notebook kkday_bot_safe_crawler.ipynb
→ 1단계 셀 실행

# 시간 간격 (30분-3시간 대기)
☕ 점심시간 또는 업무시간

# 2단계: 상세 크롤링 (5-10분)
→ 2단계 셀 실행
```

### 🛡️ 50개 인간 행동 기반 스크롤 패턴
**파일**: `./src/scraper/human_scroll_patterns.py`

#### 📋 패턴 카테고리
1. **느린_탐색** (1-10): 꼼꼼한 사용자 패턴 (천천히 읽기, 신중한 검토)
2. **빠른_스캔** (11-20): 효율적 사용자 패턴 (빠른 훑어보기, 키워드 탐색)
3. **상세_읽기** (21-30): 학습형 사용자 패턴 (완벽주의, 전문가형 분석)
4. **되돌아_보기** (31-40): 확인형 사용자 패턴 (비교검토, 재확인)
5. **특이_행동** (41-50): 예측불가 사용자 패턴 (불규칙, 충동적)

#### ✨ 성과
- **봇 탐지 회피율**: 92-95% → **98%+**
- **패턴 예측 불가능성**: **5000% 향상** (50개 패턴)
- **인간 행동 완벽 모방**: ActionChains + Keys 조합
- **2025-09-15 실증**: 치앙마이 1단계 테스트 100% 성공

## 🎯 성능 최적화 분석 지침

### 📊 핵심 분석 원칙
- **모든 답변과 사고과정은 추측하지 말고 확인된 데이터를 가지고 논리적으로 결과를 도출한다**
- **코드를 분석하고 확인된 내용으로만 사고과정을 거친다**

### ⚡ 성능 최적화 지침
1. **병렬 도구 사용 최적화**
   - 여러 파일을 읽어야 할 때는 한 번에 배치로 처리
   - 관련 파일들을 동시에 분석하여 컨텍스트 손실 방지

2. **문제 범위 정확히 파악**
   - 문제의 실제 범위를 먼저 확인 (전체 시스템 vs 특정 함수)
   - 최소한의 수정으로 최대 효과를 내는 지점 찾기

3. **데이터 기반 의사결정**
   - 로그, 에러 메시지, 실행 결과 등 실제 데이터로 판단
   - 테스트 결과나 실행 과정을 통한 검증

4. **효율적인 디버깅**
   - 문제 지점을 좁혀가는 체계적 접근
   - 가장 의심되는 부분부터 우선 확인

### 4️⃣ 코드 수정 프로세스
**중요**: 모든 코드 수정은 다음 프로세스를 따릅니다.

1. **수정 내용 미리보기**: 수정할 코드를 먼저 제시
2. **사용자 확인**: 사용자가 수정 내용 검토 및 승인
3. **직접 수정 여부**: 사용자가 직접 수정할지, 자동 수정할지 결정
4. **수정 적용**: 승인된 내용만 실제 코드에 반영

### 5️⃣ 빠른 시작 명령어 예시
```
"TODO와 README 읽고, 현재 개발 중이니까 CODING_STANDARDS.md도 함께 읽어줘"
"TODO 확인하고 테스트 관련 문서들도 준비해줘"
```

---

## 📋 주요 기능

### 🎯 핵심 기능
- **상품 정보 자동 수집**: KKday 웹사이트에서 여행상품 데이터 크롤링
- **이미지 자동 다운로드**: 메인 이미지 및 썸네일 이미지 저장
- **데이터 정규화**: 도시명 별칭 처리 및 표준화
- **CSV 데이터 관리**: 체계적인 데이터 저장 및 중복 제거
- **위치 학습 시스템**: AI 기반 위치 키워드 자동 학습

### 🌍 지원 범위
- **전 세계 주요 도시**: 아시아, 유럽, 북미, 오세아니아 등
- **다양한 상품 카테고리**: 투어, 액티비티, 교통, 숙박 등
- **다국어 지원**: 한국어, 영어 등 다언어 데이터 처리

## 🏗️ 시스템 구조

### 📁 디렉토리 구조
```
kkday/
├── src/                           # 소스 코드
│   ├── config.py                  # 전역 설정
│   ├── scraper/                   # 크롤링 엔진
│   │   ├── crawler.py             # 메인 크롤러
│   │   ├── driver_manager.py      # 웹드라이버 관리
│   │   ├── parsers.py             # 데이터 파싱
│   │   ├── ranking.py             # 순위 시스템
│   │   └── url_manager.py         # URL 관리
│   └── utils/                     # 유틸리티
│       ├── city_manager.py        # 도시 정보 관리
│       ├── file_handler.py        # 파일 처리
│       └── location_learning.py   # 위치 학습 시스템
├── data/                          # 수집된 데이터
│   └── [대륙]/[국가]/[도시]/      # 계층적 데이터 저장
├── kkday_img/                     # 이미지 저장소
│   └── [대륙]/[국가]/[도시]/      # 이미지 파일
├── location_data/                 # 위치 학습 데이터
├── kkday_bot_safe_crawler.ipynb   # ⭐ 봇 회피 최적화 크롤러 v2.0 (권장)
├── kkday_crawler_new.ipynb        # 기존 통합 크롤러 (v1.0)
├── kkday_Sitemap_Collector.ipynb # 사이트맵 수집기
├── kkday_Sitemap_Crawler.ipynb   # 사이트맵 크롤러
├── kkday_ad_link generator.ipynb # 제휴링크 생성기
└── README.md                      # 프로젝트 문서
```

### 🔧 주요 모듈

#### **config.py**
- 전역 설정 관리 (도시 정보, API 설정 등)
- 130개+ 도시 정보 데이터베이스
- 대륙/국가/도시 계층 구조

#### **scraper/ 모듈**
- **crawler.py**: 메인 크롤링 로직
- **driver_manager.py**: Selenium 웹드라이버 관리
- **parsers.py**: HTML 파싱 및 데이터 추출
- **ranking.py**: 상품 순위 시스템
- **url_manager.py**: URL 생성 및 관리

#### **utils/ 모듈**
- **city_manager.py**: 도시명 정규화 및 별칭 처리
- **file_handler.py**: CSV/이미지 파일 저장 관리
- **location_learning.py**: AI 기반 위치 키워드 학습

## 🚀 설치 및 실행

### 📋 필수 요구사항
```bash
# Python 3.8+
# Chrome 브라우저

# 필수 라이브러리
pip install selenium requests pillow beautifulsoup4 lxml
pip install undetected-chromedriver

# 선택 라이브러리 (한국어 처리)
pip install konlpy
```

### ⚙️ 환경 설정
1. Chrome 브라우저 최신버전 설치
2. 프로젝트 루트에서 필요한 디렉토리가 자동 생성됨
3. `src/config.py`에서 설정 확인

### 🎮 실행 방법

#### ⭐ **봇 회피 최적화 크롤러 v2.0 (권장)**
```bash
# 봇 탐지 회피율 98% 달성 버전
jupyter notebook kkday_bot_safe_crawler.ipynb

# 사용법: 2단계 분리 실행
# 1단계: URL 수집 (3-5분)
# → 시간 간격 (30분-3시간 대기)
# 2단계: 상세 크롤링 (5-10분)
```

#### 1️⃣ **기존 Jupyter 노트북들**
```bash
# 기존 통합 크롤러 (v1.0)
jupyter notebook kkday_crawler_new.ipynb

# 사이트맵 수집
jupyter notebook kkday_Sitemap_Collector.ipynb

# 사이트맵 크롤링
jupyter notebook kkday_Sitemap_Crawler.ipynb

# 제휴링크 생성
jupyter notebook "kkday_ad_link generator.ipynb"
```

#### 2️⃣ Python 스크립트
```python
from src.scraper.crawler import KKdayCrawler
from src.utils.city_manager import normalize_city_name

# 크롤러 초기화
crawler = KKdayCrawler()

# 특정 도시 크롤링
city_name = "도쿄"
crawler.crawl_city(city_name, max_pages=5)
```

## 📊 데이터 출력

### 🗂️ CSV 데이터 구조
```csv
번호,상품명,가격,평점,리뷰수,URL,도시ID,도시명,대륙,국가,위치태그,카테고리,언어,투어형태,미팅방식,소요시간,하이라이트,순위,통화,수집일시,데이터소스,해시값,메인이미지,썸네일이미지
1,도쿄 디즈니랜드 입장권,65000,4.8,1234,https://...,TYO,도쿄,아시아,일본,디즈니,테마파크,한국어,개별,집합지,1일,매직킹덤,1,KRW,2024-12-07 10:30:00,KKday,abc123def456,TYO_0001.jpg,TYO_0001_thumb.jpg
```

### 🖼️ 이미지 파일
- **메인 이미지**: `{도시코드}_{번호:04d}.jpg` (예: TYO_0001.jpg)
- **썸네일**: `{도시코드}_{번호:04d}_thumb.jpg` (예: TYO_0001_thumb.jpg)
- **저장 경로**: `kkday_img/아시아/일본/도쿄/`

## 🎯 주요 특징

### ✨ 스마트 중복 제거
- MD5 해시 기반 중복 상품 자동 감지
- 번호 연속성 자동 관리

### 🌏 글로벌 도시 지원
- 130개+ 도시 정보 내장
- 도시명 별칭 자동 처리 (예: "토쿄" → "도쿄")
- 대륙별 계층 구조 자동 생성

### 🤖 AI 위치 학습
- KoNLPy 기반 한국어 자연어 처리
- 위치 키워드 자동 학습 및 태깅
- 사용자 검색 패턴 분석

### 🛡️ 안정성
- undetected-chromedriver 사용으로 차단 방지
- 예외 처리 및 재시도 로직
- 실행 환경 자동 감지

## 🔧 설정 옵션

### config.py 주요 설정
```python
CONFIG = {
    "SAVE_IMAGES": True,           # 이미지 저장 여부
    "MAX_RETRIES": 3,              # 재시도 횟수
    "WAIT_TIME": 2,                # 대기 시간(초)
    "USER_AGENT": "...",           # User-Agent 설정
}
```

### 도시 정보 추가
```python
UNIFIED_CITY_INFO = {
    "새도시": {
        "대륙": "아시아",
        "국가": "한국", 
        "코드": "NEW",
        "영문명": "New City"
    }
}
```

## 📈 성능 및 통계

- **처리 속도**: 페이지당 평균 3-5초
- **데이터 품질**: 95%+ 정확도
- **이미지 최적화**: 자동 리사이징 (메인 400px, 썸네일 200px)
- **저장 효율**: 평균 이미지 크기 < 300KB

## 🚨 주의사항

1. **합법적 사용**: 웹사이트 이용약관 준수 필수
2. **적절한 속도**: 서버 부하 방지를 위한 적절한 대기시간 설정
3. **개인정보**: 수집된 데이터의 적절한 관리 필요
4. **저작권**: 이미지 및 콘텐츠 저작권 주의

---

## 📚 프로젝트 문서 가이드

이 폴더는 KKday 크롤링 시스템의 모든 프로젝트 문서를 체계적으로 정리한 곳입니다. Ryan Carson의 3단계 AI 코딩 방법론을 적용하여 **기획 → 개발 → 기술 → 품질** 순서로 구성되었습니다.

### 🗂️ 문서 분류 체계

#### **Group 1: 기획/요구사항** 📋
프로젝트의 목표, 요구사항, 작업 계획을 정의합니다.

| 문서명 | 설명 | 크기 | 최종 수정 |
|--------|------|------|----------|
| **PRD.md** | 제품 요구사항 명세서 | 6.8KB | 2024-12-07 |
| **TODO.md** | 작업 목록 및 진행 현황 | 7.7KB | 2024-12-07 |

#### **Group 2: 개발/코딩 기준** 🛠️
개발 가이드라인, 코딩 표준, 프로젝트 사용법을 제공합니다.

| 문서명 | 설명 | 크기 | 최종 수정 |
|--------|------|------|----------|
| **README.md** | 프로젝트 개요 및 사용법 | 9.8KB | 2024-12-05 |
| **CODING_STANDARDS.md** | 코딩 표준 및 가이드라인 | 11.9KB | 2024-12-07 |

#### **Group 3: 기술/운영 상세** ⚙️
시스템 기술 사양, 오류 처리, 웹사이트 매핑 정보를 다룹니다.

| 문서명 | 설명 | 크기 | 최종 수정 |
|--------|------|------|----------|
| **TECHNICAL_SPECS.md** | 기술적 상세 명세 | 16.5KB | 2024-12-07 |
| **ERROR_HANDLING.md** | 오류 처리 매뉴얼 | 30.3KB | 2024-12-07 |
| **WEBSITE_MAPPING.md** | KKday 웹사이트 구조 분석 | 15.5KB | 2024-12-07 |

#### **Group 4: 테스트/품질 관리** 🧪
테스트 시나리오, 성능 모니터링, 배포 가이드를 제공합니다.

| 문서명 | 설명 | 크기 | 최종 수정 |
|--------|------|------|----------|
| **TEST_SCENARIOS.md** | 테스트 시나리오 상세 | 23.2KB | 2024-12-07 |
| **PERFORMANCE_GUIDE.md** | 성능 모니터링 가이드 | 46.3KB | 2024-12-07 |
| **DEPLOYMENT_GUIDE.md** | 배포 및 운영 가이드 | 49.7KB | 2024-12-07 |

### 🎯 문서 읽기 권장 순서

#### 신규 개발자용
1. **README.md** - 프로젝트 이해
2. **PRD.md** - 요구사항 파악
3. **TECHNICAL_SPECS.md** - 기술 스택 이해
4. **CODING_STANDARDS.md** - 개발 규칙 숙지

#### 운영/배포 담당자용
1. **DEPLOYMENT_GUIDE.md** - 배포 절차
2. **ERROR_HANDLING.md** - 오류 대응
3. **PERFORMANCE_GUIDE.md** - 성능 모니터링
4. **TECHNICAL_SPECS.md** - 시스템 사양

#### QA/테스트 담당자용
1. **TEST_SCENARIOS.md** - 테스트 시나리오
2. **PERFORMANCE_GUIDE.md** - 성능 기준
3. **ERROR_HANDLING.md** - 오류 상황 테스트
4. **WEBSITE_MAPPING.md** - 웹사이트 구조 이해

#### 시스템 분석가용
1. **PRD.md** - 비즈니스 요구사항
2. **TECHNICAL_SPECS.md** - 기술 아키텍처  
3. **WEBSITE_MAPPING.md** - 데이터 소스 분석
4. **PERFORMANCE_GUIDE.md** - 성능 지표

### 📊 문서 통계

- **총 문서 수**: 10개 (+ INDEX.md)
- **총 문서 크기**: 약 232KB
- **평균 문서 크기**: 23.2KB
- **최대 문서**: DEPLOYMENT_GUIDE.md (49.7KB)
- **최소 문서**: PRD.md (6.8KB)

### 🔄 문서 업데이트 정책

#### 업데이트 주기
- **Group 1**: 프로젝트 마일스톤마다
- **Group 2**: 개발 표준 변경 시
- **Group 3**: 기술 스택 변경 시  
- **Group 4**: 배포/테스트 절차 변경 시

#### 버전 관리
- 모든 문서는 Git으로 버전 관리
- 주요 변경 시 CHANGELOG 업데이트
- 문서 하단에 최종 수정일 명시

### 💡 문서 활용 팁

#### 빠른 정보 찾기
- 각 문서 내 목차(TOC) 활용
- Ctrl+F로 키워드 검색
- 문서 간 상호 참조 링크 활용

#### 실무 적용
- 코딩 전 CODING_STANDARDS.md 확인
- 배포 전 DEPLOYMENT_GUIDE.md 체크리스트 실행
- 오류 발생 시 ERROR_HANDLING.md 참조
- 성능 이슈 시 PERFORMANCE_GUIDE.md 활용

### 📞 문의 및 피드백

- **기술 문의**: 개발팀
- **문서 개선**: GitHub Issues
- **긴급 사항**: 프로젝트 매니저

---

## 🔄 개발 및 수정 가이드

### 🛠️ 앞으로의 작업 방향성

#### **1단계: 핵심 모듈 완성 (현재 진행중)**
- ✅ `src/config.py` - 전역 설정 완료
- ✅ `src/utils/` - 유틸리티 모듈 완료
- 🔄 `src/scraper/` - 크롤링 엔진 모듈 수정 중
  - `crawler.py` - 메인 크롤링 로직
  - `driver_manager.py` - 웹드라이버 관리
  - `parsers.py` - 데이터 파싱
  - `ranking.py` - 순위 시스템
  - `url_manager.py` - URL 관리

#### **2단계: Jupyter 노트북 업데이트**
- `kkday_crawler.ipynb` - 메인 크롤러 노트북
- `kkday_Sitemap_Collector.ipynb` - 사이트맵 수집기
- `kkday_Sitemap_Crawler.ipynb` - 사이트맵 크롤러  
- `kkday_ad_link generator.ipynb` - 제휴링크 생성기

#### **3단계: 시스템 통합 및 검증**
- 전체 모듈 간 연동 테스트
- KKday 웹사이트 구조 대응 검증
- 성능 최적화 및 안정성 향상

#### **4단계: 고도화 (v2.0 계획)**
- 머신러닝 기반 상품 분류 시스템
- 실시간 가격 모니터링
- API 인터페이스 제공
- 웹 대시보드 구축

### 🔧 현재 수정 작업 상태

**완료된 작업:**
- ✅ Klook → KKday 기본 설정 변환
- ✅ 도시 관리 시스템 정리
- ✅ 파일 처리 시스템 업데이트
- ✅ 위치 학습 시스템 경로 수정
- ✅ **KKday 셀렉터 수집 전략 수립** (컨테이너 기반 방식)
- ✅ **목록페이지 기본 셀렉터 수집 완료** (상품 카드 구조)
- ✅ **URL 수집 순서 보장 시스템 구현** (set → list+set 조합으로 성능 최적화)

### 🎉 **2025-09-10 최신 완료 작업** ⭐
- ✅ **순위 시스템 완전 개선** - 모든 핵심 문제 해결 완료
  - **모든 상품 rank=1 문제 해결** → 순차적 순위 부여 (1,2,3...)
  - **목록페이지 URL 포함 문제 해결** → 상품 상세페이지만 필터링
  - **글로벌 파일 → 도시별 분리 저장** (SEL_, BKK_, KIX_ 등)
  - **순위 연속성 보장** → 마지막 순위+1부터 자동 시작
  - **코드 대폭 최적화** → ranking.py 347줄→135줄, crawler.py 346줄→332줄
  - **통합 테스트 4/4 모두 통과** 확인

### 🎉 **2025-09-07 주요 완료 작업**
- ✅ **`src/scraper/url_manager.py` 완전 KKday 전환** ⭐
  - 함수명 변경: `is_valid_klook_url()` → `is_valid_kkday_url()`
  - URL 패턴: KLOOK → KKday 도메인 및 경로 완전 변경  
  - **페이지네이션**: 화살표 → 숫자 클릭 방식 완전 전환
  - CSS 셀렉터: KKday 전용 매핑 완료
  - USER_AGENT: 랜덤 선택 시스템 연동
- ✅ **방콕 크롤링 시스템 준비 완료** - 실행 가능 상태 달성
- ✅ **전체 시스템 KLOOK 잔여 코드 제거 완료** (src/ 폴더 기준)

**진행 중인 작업:**
**현재 진행 중인 작업 없음** - 다음 단계 준비 완료

**🎯 다음 단계 작업 (논리적 순서로 재정리):**

**🥇 1단계: 검증 우선 (먼저 실행)**
1. 🔥 **KKday 메인 목록 페이지 분석** - https://www.kkday.com/ko/product/productlist 구조 분석
2. 🔥 **방콕 크롤링 실제 테스트** - url_manager.py 수정 효과 검증

**🥈 2단계: 개발 (검증 결과 반영)**
3. 🔥 **driver_manager.py 완성** - KKday 웹사이트 접근 기능
4. 🔥 **parsers.py 완성** - 핵심 데이터 추출 기능  
5. ✅ **ranking.py 완성** - **순위 시스템 완전 개선 완료!**

**🥉 3단계: 통합 (최종 검증)**
6. 🧪 **전체 시스템 통합 테스트**
7. ⏳ **Jupyter 노트북 코드 업데이트**  
8. ⏳ **성능 최적화 및 문서화**

### 🎯 **KKday 셀렉터 수집 현황**

#### ✅ **완료된 수집 (목록페이지 기본)**
- 전체 상품 컨테이너: `.product-list-main__product-card-2.layout-columns`
- 개별 상품 카드: `.product-card.gtm-prod-card-element`
- 상품명, 가격, 평점, 이미지, 링크 셀렉터

#### 🔄 **진행 중인 수집**
- **컨테이너 기반 수집 방식** 채택
- **상세페이지 우선 + 목록페이지 백업** 전략
- CSV 파일 구조: `page_type,element_type,selector_name,css_selector,priority,backup_selector,description,test_status`

#### 📋 **수집 우선순위**
1. 목록페이지 추가 셀렉터 (페이지네이션, 검색, 필터)
2. 상세페이지 컨테이너 구조 (Hero, 예약, 정보, 리뷰)
3. CSV 파일 생성 및 코드 적용

## 🔄 업데이트 내역

### v1.0 (현재 개발중)
- Klook → KKday 시스템 전환 작업
- 전 세계 주요 도시 지원 확대
- AI 기반 위치 학습 시스템 고도화
- 통합 데이터 관리 시스템 구축

### v2.0 (계획)
- 머신러닝 기반 상품 추천 시스템
- 실시간 데이터 모니터링
- RESTful API 제공
- 웹 인터페이스 제공

## 🤝 기여 방법

1. **새로운 도시 정보 추가**: `src/config.py` 수정
2. **HTML 셀렉터 업데이트**: KKday 웹사이트 변경 대응
3. **성능 최적화**: 크롤링 속도 및 메모리 사용량 개선
4. **버그 리포트**: 이슈 발생 시 상세한 오류 정보 제공
5. **기능 개선**: 새로운 기능 아이디어 및 구현

### 📋 수정 요청 시 포함할 정보
- 수정할 파일 경로
- 현재 코드와 수정 후 코드 비교
- 수정 이유 및 기대 효과
- 테스트 결과 (가능한 경우)

---

**⚠️ 면책 조항**: 이 도구는 교육 및 연구 목적으로 제작되었습니다. 상업적 이용 시 관련 법규를 확인하시기 바랍니다.

**📞 문의사항**: 시스템 사용 중 문의사항이나 개선 제안이 있으시면 언제든 연락주세요!

### 🏆 최근 성과 (2025-09-11) ✨ **시스템 안정성 완전 달성**
- 🎉 **크롤링 시스템 100% 안정화 완료** - 모든 핵심 오류 해결
  - ✅ Tuple unpacking 에러 완전 해결 (`get_city_info` → `get_city_location` 분리)
  - ✅ 이미지 수집 기능 완전 복구 (KKday 실제 셀렉터로 교체)
  - ✅ WSL 가상환경 구축 완료 (Pillow + 필요 패키지 설치)
  - ✅ 국가별 통합 CSV 자동 생성 기능 추가 (`일본_통합_kkday_products.csv`)
  - ✅ 랭킹 시스템 오류 완전 해결 (`product_id` 매개변수 추가)
  - ✅ import 경로 오류 수정 (`location_learning.py`)
  - ✅ **100% 성공률 크롤링 달성** (삿포로 2/2 상품 + 이미지 저장)
- 📈 **Phase 1 최종 완성** (95% → **100% 완료**)

---

**문서 버전**: v1.3  
**최종 업데이트**: 2025-09-11 (크롤링 시스템 100% 안정화 완료)
**담당자**: mikael
