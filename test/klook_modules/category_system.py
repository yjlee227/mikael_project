"""
ğŸš€ ê·¸ë£¹ 10: KLOOK ì¹´í…Œê³ ë¦¬ ì‹œìŠ¤í…œ
- ì¹´í…Œê³ ë¦¬ë³„ ìƒí’ˆ ë¶„ë¥˜ ë° ê´€ë¦¬
- ë™ì  ì¹´í…Œê³ ë¦¬ ê°ì§€ ë° ë§¤í•‘
- ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ í¬ë¡¤ë§ ì „ëµ
"""

import os
import json
import re
from datetime import datetime
from collections import defaultdict

# ì¡°ê±´ë¶€ import
try:
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.common.exceptions import TimeoutException, NoSuchElementException
    SELENIUM_AVAILABLE = True
except ImportError:
    print("âš ï¸ Seleniumì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¹´í…Œê³ ë¦¬ ì‹œìŠ¤í…œ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")
    SELENIUM_AVAILABLE = False

# config ëª¨ë“ˆì—ì„œ í•„ìš”í•œ í•¨ìˆ˜ë“¤ import
from .config import CONFIG, get_city_code, get_city_info

# =============================================================================
# ğŸ“‚ KLOOK ì¹´í…Œê³ ë¦¬ ì •ì˜ ë° ë§¤í•‘
# =============================================================================

KLOOK_CATEGORY_MAPPING = {
    # í•œêµ­ì–´ ì¹´í…Œê³ ë¦¬
    "íˆ¬ì–´&ì•¡í‹°ë¹„í‹°": {
        "english": "Tours & Activities",
        "keywords": ["íˆ¬ì–´", "ì•¡í‹°ë¹„í‹°", "ì²´í—˜", "ê´€ê´‘", "tour", "activity", "experience"],
        "priority": 1,
        "subcategories": ["ì‹œí‹°íˆ¬ì–´", "ìì—°ì²´í—˜", "ë¬¸í™”ì²´í—˜", "ì–´ë“œë²¤ì²˜"]
    },
    "í‹°ì¼“&ì…ì¥ê¶Œ": {
        "english": "Tickets & Admission",
        "keywords": ["í‹°ì¼“", "ì…ì¥ê¶Œ", "í‘œ", "ticket", "admission", "entrance"],
        "priority": 2,
        "subcategories": ["í…Œë§ˆíŒŒí¬", "ë°•ë¬¼ê´€", "ì „ë§ëŒ€", "ê³µì—°"]
    },
    "êµí†µ": {
        "english": "Transportation",
        "keywords": ["êµí†µ", "ë²„ìŠ¤", "ê¸°ì°¨", "ì§€í•˜ì² ", "íƒì‹œ", "transport", "bus", "train"],
        "priority": 3,
        "subcategories": ["ê³µí•­ì…”í‹€", "ì‹œí‹°íŒ¨ìŠ¤", "ë Œí„°ì¹´", "í¬ë£¨ì¦ˆ"]
    },
    "ìˆ™ë°•": {
        "english": "Accommodation",
        "keywords": ["ìˆ™ë°•", "í˜¸í…”", "íœì…˜", "accommodation", "hotel", "stay"],
        "priority": 4,
        "subcategories": ["í˜¸í…”", "ë¦¬ì¡°íŠ¸", "íœì…˜", "ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤"]
    },
    "ìŒì‹&ìŒë£Œ": {
        "english": "Food & Drinks",
        "keywords": ["ìŒì‹", "ìŒë£Œ", "ë ˆìŠ¤í† ë‘", "ì¹´í˜", "food", "drink", "restaurant"],
        "priority": 5,
        "subcategories": ["íŒŒì¸ë‹¤ì´ë‹", "ë¡œì»¬í‘¸ë“œ", "ë””ì €íŠ¸", "ë°”"]
    },
    "ì‡¼í•‘": {
        "english": "Shopping",
        "keywords": ["ì‡¼í•‘", "ì‡¼í•‘ëª°", "ë§ˆì¼“", "shopping", "market", "mall"],
        "priority": 6,
        "subcategories": ["ë©´ì„¸ì ", "ì•„ìš¸ë ›", "ë¡œì»¬ë§ˆì¼“", "ì „í†µì‹œì¥"]
    },
    "ìŠ¤íŒŒ&ì›°ë‹ˆìŠ¤": {
        "english": "Spa & Wellness",
        "keywords": ["ìŠ¤íŒŒ", "ë§ˆì‚¬ì§€", "ì›°ë‹ˆìŠ¤", "ì‚¬ìš°ë‚˜", "spa", "massage", "wellness"],
        "priority": 7,
        "subcategories": ["ì „í†µìŠ¤íŒŒ", "ë°ì´ìŠ¤íŒŒ", "ë§ˆì‚¬ì§€", "ì°œì§ˆë°©"]
    },
    "ê¸°íƒ€": {
        "english": "Others",
        "keywords": ["ê¸°íƒ€", "íŠ¹ë³„", "ì´ë²¤íŠ¸", "others", "special", "event"],
        "priority": 8,
        "subcategories": ["íŠ¹ë³„ì´ë²¤íŠ¸", "ì‹œì¦Œìƒí’ˆ", "íŒ¨í‚¤ì§€"]
    }
}

CATEGORY_DETECTION_PATTERNS = {
    # URL ê¸°ë°˜ íŒ¨í„´
    "url_patterns": {
        "íˆ¬ì–´&ì•¡í‹°ë¹„í‹°": [r"tour", r"activity", r"experience", r"sightseeing"],
        "í‹°ì¼“&ì…ì¥ê¶Œ": [r"ticket", r"admission", r"entrance", r"pass"],
        "êµí†µ": [r"transport", r"transfer", r"bus", r"train", r"subway"],
        "ìˆ™ë°•": [r"hotel", r"accommodation", r"stay", r"lodge"],
        "ìŒì‹&ìŒë£Œ": [r"food", r"dining", r"restaurant", r"meal"],
        "ì‡¼í•‘": [r"shopping", r"market", r"mall", r"shop"],
        "ìŠ¤íŒŒ&ì›°ë‹ˆìŠ¤": [r"spa", r"massage", r"wellness", r"relax"]
    },
    
    # ì œëª© ê¸°ë°˜ íŒ¨í„´
    "title_patterns": {
        "íˆ¬ì–´&ì•¡í‹°ë¹„í‹°": [r"íˆ¬ì–´", r"ì²´í—˜", r"ê´€ê´‘", r"ì•¡í‹°ë¹„í‹°"],
        "í‹°ì¼“&ì…ì¥ê¶Œ": [r"í‹°ì¼“", r"ì…ì¥ê¶Œ", r"íŒ¨ìŠ¤", r"í‘œ"],
        "êµí†µ": [r"ì…”í‹€", r"ë²„ìŠ¤", r"ê¸°ì°¨", r"êµí†µ"],
        "ìˆ™ë°•": [r"í˜¸í…”", r"ìˆ™ë°•", r"íœì…˜", r"ë¦¬ì¡°íŠ¸"],
        "ìŒì‹&ìŒë£Œ": [r"ë ˆìŠ¤í† ë‘", r"ìŒì‹", r"ë””ë„ˆ", r"ëŸ°ì¹˜"],
        "ì‡¼í•‘": [r"ì‡¼í•‘", r"ì‹œì¥", r"ë§ˆì¼“", r"ëª°"],
        "ìŠ¤íŒŒ&ì›°ë‹ˆìŠ¤": [r"ìŠ¤íŒŒ", r"ë§ˆì‚¬ì§€", r"ì‚¬ìš°ë‚˜", r"ì˜¨ì²œ"]
    }
}

# =============================================================================
# ğŸ” ì¹´í…Œê³ ë¦¬ ê°ì§€ ë° ë¶„ë¥˜ ì‹œìŠ¤í…œ
# =============================================================================

class KlookCategoryDetector:
    """KLOOK ì¹´í…Œê³ ë¦¬ ê°ì§€ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.detected_categories = {}
        self.category_stats = defaultdict(int)
        
    def detect_category_from_url(self, url):
        """URLì—ì„œ ì¹´í…Œê³ ë¦¬ ê°ì§€"""
        if not url:
            return "ê¸°íƒ€"
        
        url_lower = url.lower()
        
        for category, patterns in CATEGORY_DETECTION_PATTERNS["url_patterns"].items():
            for pattern in patterns:
                if re.search(pattern, url_lower):
                    return category
        
        return "ê¸°íƒ€"
    
    def detect_category_from_title(self, title):
        """ì œëª©ì—ì„œ ì¹´í…Œê³ ë¦¬ ê°ì§€"""
        if not title:
            return "ê¸°íƒ€"
        
        title_lower = title.lower()
        
        # í•œêµ­ì–´ íŒ¨í„´ ìš°ì„  ê²€ì‚¬
        for category, patterns in CATEGORY_DETECTION_PATTERNS["title_patterns"].items():
            for pattern in patterns:
                if re.search(pattern, title_lower):
                    return category
        
        # ì˜ì–´ íŒ¨í„´ ê²€ì‚¬
        for category, patterns in CATEGORY_DETECTION_PATTERNS["url_patterns"].items():
            for pattern in patterns:
                if re.search(pattern, title_lower):
                    return category
        
        return "ê¸°íƒ€"
    
    def detect_category_from_page(self, driver):
        """í˜ì´ì§€ì—ì„œ ì¹´í…Œê³ ë¦¬ ê°ì§€"""
        if not SELENIUM_AVAILABLE:
            return "ê¸°íƒ€"
        
        try:
            # 1. ë¸Œë ˆë“œí¬ëŸ¼ì—ì„œ ì¹´í…Œê³ ë¦¬ ê°ì§€
            breadcrumb_category = self._detect_from_breadcrumb(driver)
            if breadcrumb_category != "ê¸°íƒ€":
                return breadcrumb_category
            
            # 2. ë©”íƒ€ë°ì´í„°ì—ì„œ ì¹´í…Œê³ ë¦¬ ê°ì§€
            meta_category = self._detect_from_metadata(driver)
            if meta_category != "ê¸°íƒ€":
                return meta_category
            
            # 3. í˜ì´ì§€ ì œëª©ì—ì„œ ì¹´í…Œê³ ë¦¬ ê°ì§€
            title = driver.title
            title_category = self.detect_category_from_title(title)
            if title_category != "ê¸°íƒ€":
                return title_category
            
            # 4. URLì—ì„œ ì¹´í…Œê³ ë¦¬ ê°ì§€
            current_url = driver.current_url
            url_category = self.detect_category_from_url(current_url)
            return url_category
            
        except Exception as e:
            print(f"âš ï¸ í˜ì´ì§€ ì¹´í…Œê³ ë¦¬ ê°ì§€ ì‹¤íŒ¨: {e}")
            return "ê¸°íƒ€"
    
    def _detect_from_breadcrumb(self, driver):
        """ë¸Œë ˆë“œí¬ëŸ¼ì—ì„œ ì¹´í…Œê³ ë¦¬ ê°ì§€"""
        breadcrumb_selectors = [
            ".breadcrumb a",
            "[data-testid='breadcrumb'] a",
            ".breadcrumb-item",
            ".navigation-path a"
        ]
        
        for selector in breadcrumb_selectors:
            try:
                elements = driver.find_elements(By.CSS_SELECTOR, selector)
                for element in elements:
                    text = element.text.strip()
                    if text:
                        category = self.detect_category_from_title(text)
                        if category != "ê¸°íƒ€":
                            return category
            except:
                continue
        
        return "ê¸°íƒ€"
    
    def _detect_from_metadata(self, driver):
        """ë©”íƒ€ë°ì´í„°ì—ì„œ ì¹´í…Œê³ ë¦¬ ê°ì§€"""
        try:
            # ë©”íƒ€íƒœê·¸ í™•ì¸
            meta_selectors = [
                "meta[name='category']",
                "meta[property='product:category']",
                "meta[name='keywords']"
            ]
            
            for selector in meta_selectors:
                try:
                    element = driver.find_element(By.CSS_SELECTOR, selector)
                    content = element.get_attribute("content")
                    if content:
                        category = self.detect_category_from_title(content)
                        if category != "ê¸°íƒ€":
                            return category
                except:
                    continue
                    
        except:
            pass
        
        return "ê¸°íƒ€"
    
    def classify_product_data(self, product_data):
        """ìƒí’ˆ ë°ì´í„° ë¶„ë¥˜"""
        if not product_data:
            return "ê¸°íƒ€"
        
        # 1. URL ê¸°ë°˜ ë¶„ë¥˜
        url = product_data.get("URL", "")
        url_category = self.detect_category_from_url(url)
        
        # 2. ì œëª© ê¸°ë°˜ ë¶„ë¥˜
        title = product_data.get("ìƒí’ˆëª…", "")
        title_category = self.detect_category_from_title(title)
        
        # 3. ê¸°ì¡´ ì¹´í…Œê³ ë¦¬ ì •ë³´ í™•ì¸
        existing_category = product_data.get("ì¹´í…Œê³ ë¦¬", "")
        if existing_category and existing_category != "ê¸°íƒ€":
            mapped_category = self._map_to_standard_category(existing_category)
            if mapped_category != "ê¸°íƒ€":
                return mapped_category
        
        # ìš°ì„ ìˆœìœ„: ì œëª© > URL
        if title_category != "ê¸°íƒ€":
            return title_category
        elif url_category != "ê¸°íƒ€":
            return url_category
        else:
            return "ê¸°íƒ€"
    
    def _map_to_standard_category(self, category_text):
        """ì„ì˜ ì¹´í…Œê³ ë¦¬ í…ìŠ¤íŠ¸ë¥¼ í‘œì¤€ ì¹´í…Œê³ ë¦¬ë¡œ ë§¤í•‘"""
        if not category_text:
            return "ê¸°íƒ€"
        
        category_lower = category_text.lower()
        
        for standard_category, info in KLOOK_CATEGORY_MAPPING.items():
            keywords = info["keywords"]
            for keyword in keywords:
                if keyword in category_lower:
                    return standard_category
        
        return "ê¸°íƒ€"

# =============================================================================
# ğŸ“Š ì¹´í…Œê³ ë¦¬ í†µê³„ ë° ë¶„ì„
# =============================================================================

class CategoryAnalyzer:
    """ì¹´í…Œê³ ë¦¬ ë¶„ì„ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.category_stats = defaultdict(lambda: {
            "count": 0,
            "urls": [],
            "price_range": {"min": float('inf'), "max": 0, "avg": 0},
            "ratings": []
        })
    
    def analyze_city_categories(self, city_name):
        """ë„ì‹œë³„ ì¹´í…Œê³ ë¦¬ ë¶„ì„"""
        try:
            from .data_handler import get_csv_stats
            
            csv_stats = get_csv_stats(city_name)
            if not csv_stats.get("exists", False):
                return {"error": "CSV ë°ì´í„° ì—†ìŒ"}
            
            # CSV ë°ì´í„° ì½ê¸°
            continent, country = get_city_info(city_name)
            
            if city_name in ["ë§ˆì¹´ì˜¤", "í™ì½©", "ì‹±ê°€í¬ë¥´"]:
                csv_path = os.path.join("data", continent, f"klook_{city_name}_products.csv")
            else:
                csv_path = os.path.join("data", continent, country, city_name, f"klook_{city_name}_products.csv")
            
            if not os.path.exists(csv_path):
                return {"error": "CSV íŒŒì¼ ì—†ìŒ"}
            
            # pandasë¡œ ë°ì´í„° ë¶„ì„
            try:
                import pandas as pd
                df = pd.read_csv(csv_path, encoding='utf-8-sig')
                
                # ì¹´í…Œê³ ë¦¬ ê°ì§€ê¸° ì´ˆê¸°í™”
                detector = KlookCategoryDetector()
                
                # ê° ìƒí’ˆì— ëŒ€í•´ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
                categories = []
                for _, row in df.iterrows():
                    product_data = row.to_dict()
                    category = detector.classify_product_data(product_data)
                    categories.append(category)
                    
                    # í†µê³„ ì—…ë°ì´íŠ¸
                    self._update_category_stats(category, product_data)
                
                # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„ ìƒì„±
                category_summary = self._generate_category_summary()
                
                return {
                    "city_name": city_name,
                    "total_products": len(df),
                    "category_distribution": dict(pd.Series(categories).value_counts()),
                    "category_details": category_summary,
                    "analysis_time": datetime.now().isoformat()
                }
                
            except ImportError:
                return {"error": "pandas ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤"}
                
        except Exception as e:
            return {"error": f"ë¶„ì„ ì‹¤íŒ¨: {e}"}
    
    def _update_category_stats(self, category, product_data):
        """ì¹´í…Œê³ ë¦¬ í†µê³„ ì—…ë°ì´íŠ¸"""
        stats = self.category_stats[category]
        stats["count"] += 1
        
        # URL ì¶”ê°€
        url = product_data.get("URL", "")
        if url:
            stats["urls"].append(url)
        
        # ê°€ê²© ë¶„ì„
        price_text = product_data.get("ê°€ê²©", "")
        if price_text and price_text != "ì •ë³´ ì—†ìŒ":
            try:
                # ê°€ê²©ì—ì„œ ìˆ«ì ì¶”ì¶œ
                price_numbers = re.findall(r'\d+', price_text.replace(',', ''))
                if price_numbers:
                    price = int(price_numbers[0])
                    stats["price_range"]["min"] = min(stats["price_range"]["min"], price)
                    stats["price_range"]["max"] = max(stats["price_range"]["max"], price)
            except:
                pass
        
        # í‰ì  ë¶„ì„
        rating = product_data.get("í‰ì ", "")
        if rating and rating != "ì •ë³´ ì—†ìŒ":
            try:
                rating_value = float(rating)
                stats["ratings"].append(rating_value)
            except:
                pass
    
    def _generate_category_summary(self):
        """ì¹´í…Œê³ ë¦¬ ìš”ì•½ ìƒì„±"""
        summary = {}
        
        for category, stats in self.category_stats.items():
            if stats["count"] > 0:
                # í‰ê·  ê°€ê²© ê³„ì‚°
                if stats["price_range"]["min"] != float('inf'):
                    avg_price = (stats["price_range"]["min"] + stats["price_range"]["max"]) / 2
                    stats["price_range"]["avg"] = avg_price
                else:
                    stats["price_range"] = {"min": 0, "max": 0, "avg": 0}
                
                # í‰ê·  í‰ì  ê³„ì‚°
                if stats["ratings"]:
                    avg_rating = sum(stats["ratings"]) / len(stats["ratings"])
                    stats["avg_rating"] = round(avg_rating, 2)
                else:
                    stats["avg_rating"] = 0
                
                # URLì€ ìƒ˜í”Œë§Œ ì €ì¥ (ìµœëŒ€ 5ê°œ)
                stats["sample_urls"] = stats["urls"][:5]
                del stats["urls"]  # ë©”ëª¨ë¦¬ ì ˆì•½
                
                summary[category] = stats
        
        return summary

# =============================================================================
# ğŸ¯ ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ í¬ë¡¤ë§ ì „ëµ
# =============================================================================

def get_category_crawling_strategy(category):
    """ì¹´í…Œê³ ë¦¬ë³„ í¬ë¡¤ë§ ì „ëµ ë°˜í™˜"""
    strategies = {
        "íˆ¬ì–´&ì•¡í‹°ë¹„í‹°": {
            "priority": "ë†’ìŒ",
            "image_required": True,
            "max_pages": 10,
            "wait_time_multiplier": 1.0,
            "retry_count": 3
        },
        "í‹°ì¼“&ì…ì¥ê¶Œ": {
            "priority": "ë†’ìŒ",
            "image_required": True,
            "max_pages": 8,
            "wait_time_multiplier": 1.0,
            "retry_count": 3
        },
        "êµí†µ": {
            "priority": "ì¤‘ê°„",
            "image_required": False,
            "max_pages": 5,
            "wait_time_multiplier": 0.8,
            "retry_count": 2
        },
        "ìˆ™ë°•": {
            "priority": "ì¤‘ê°„",
            "image_required": True,
            "max_pages": 6,
            "wait_time_multiplier": 1.2,
            "retry_count": 3
        },
        "ìŒì‹&ìŒë£Œ": {
            "priority": "ì¤‘ê°„",
            "image_required": True,
            "max_pages": 5,
            "wait_time_multiplier": 1.0,
            "retry_count": 2
        },
        "ì‡¼í•‘": {
            "priority": "ë‚®ìŒ",
            "image_required": False,
            "max_pages": 3,
            "wait_time_multiplier": 0.8,
            "retry_count": 2
        },
        "ìŠ¤íŒŒ&ì›°ë‹ˆìŠ¤": {
            "priority": "ë‚®ìŒ",
            "image_required": True,
            "max_pages": 3,
            "wait_time_multiplier": 1.0,
            "retry_count": 2
        },
        "ê¸°íƒ€": {
            "priority": "ë‚®ìŒ",
            "image_required": False,
            "max_pages": 2,
            "wait_time_multiplier": 0.8,
            "retry_count": 1
        }
    }
    
    return strategies.get(category, strategies["ê¸°íƒ€"])

def save_category_analysis(analysis_data, city_name):
    """ì¹´í…Œê³ ë¦¬ ë¶„ì„ ê²°ê³¼ ì €ì¥"""
    try:
        analysis_dir = "category_analysis"
        os.makedirs(analysis_dir, exist_ok=True)
        
        city_code = get_city_code(city_name)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{city_code}_category_analysis_{timestamp}.json"
        filepath = os.path.join(analysis_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(analysis_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“Š ì¹´í…Œê³ ë¦¬ ë¶„ì„ ì €ì¥: {filename}")
        return True
        
    except Exception as e:
        print(f"âŒ ì¹´í…Œê³ ë¦¬ ë¶„ì„ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def execute_category_analysis_system(city_name):
    """ì¹´í…Œê³ ë¦¬ ë¶„ì„ ì‹œìŠ¤í…œ ì‹¤í–‰"""
    print(f"ğŸ“‚ '{city_name}' ì¹´í…Œê³ ë¦¬ ë¶„ì„ ì‹œì‘!")
    print("=" * 60)
    
    # ì¹´í…Œê³ ë¦¬ ë¶„ì„ ì‹¤í–‰
    analyzer = CategoryAnalyzer()
    analysis_result = analyzer.analyze_city_categories(city_name)
    
    if "error" in analysis_result:
        print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {analysis_result['error']}")
        return analysis_result
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"ğŸ™ï¸ ë„ì‹œ: {city_name}")
    print(f"ğŸ“Š ì´ ìƒí’ˆ ìˆ˜: {analysis_result['total_products']}ê°œ")
    print(f"\nğŸ“‚ ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:")
    
    for category, count in analysis_result["category_distribution"].items():
        percentage = (count / analysis_result["total_products"]) * 100
        print(f"   {category}: {count}ê°œ ({percentage:.1f}%)")
    
    # ë¶„ì„ ê²°ê³¼ ì €ì¥
    save_success = save_category_analysis(analysis_result, city_name)
    
    print(f"\nğŸ‰ ì¹´í…Œê³ ë¦¬ ë¶„ì„ ì™„ë£Œ!")
    print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {'ì„±ê³µ' if save_success else 'ì‹¤íŒ¨'}")
    
    return analysis_result

print("âœ… ê·¸ë£¹ 10 ì™„ë£Œ: KLOOK ì¹´í…Œê³ ë¦¬ ì‹œìŠ¤í…œ!")
print("   ğŸ“‚ ì¹´í…Œê³ ë¦¬ ê°ì§€:")
print("   - KlookCategoryDetector: ë™ì  ì¹´í…Œê³ ë¦¬ ê°ì§€")
print("   - detect_category_from_url(): URL ê¸°ë°˜ ë¶„ë¥˜")
print("   - detect_category_from_title(): ì œëª© ê¸°ë°˜ ë¶„ë¥˜")
print("   - detect_category_from_page(): í˜ì´ì§€ ê¸°ë°˜ ë¶„ë¥˜")
print("   ğŸ“Š ì¹´í…Œê³ ë¦¬ ë¶„ì„:")
print("   - CategoryAnalyzer: ì¹´í…Œê³ ë¦¬ í†µê³„ ë¶„ì„")
print("   - analyze_city_categories(): ë„ì‹œë³„ ì¹´í…Œê³ ë¦¬ ë¶„ì„")
print("   ğŸ¯ í¬ë¡¤ë§ ì „ëµ:")
print("   - get_category_crawling_strategy(): ì¹´í…Œê³ ë¦¬ë³„ ìµœì í™” ì „ëµ")
print("   - execute_category_analysis_system(): í†µí•© ë¶„ì„ ì‹¤í–‰")
print("   ğŸ“‚ ì§€ì› ì¹´í…Œê³ ë¦¬: íˆ¬ì–´&ì•¡í‹°ë¹„í‹°, í‹°ì¼“&ì…ì¥ê¶Œ, êµí†µ, ìˆ™ë°•, ìŒì‹&ìŒë£Œ, ì‡¼í•‘, ìŠ¤íŒŒ&ì›°ë‹ˆìŠ¤, ê¸°íƒ€")