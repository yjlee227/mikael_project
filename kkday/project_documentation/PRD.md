# KKday 크롤링 시스템 - PRD (제품 요구사항 명세서)

## 📋 프로젝트 개요

**프로젝트명**: KKday 여행상품 크롤링 시스템  
**작업 유형**: 기존 Klook 시스템을 KKday 전용으로 전환 (리팩토링)  
**목표**: Klook 웹사이트 전용 크롤링 시스템을 KKday 웹사이트용으로 완전히 변환

## 🎯 프로젝트 목표

### 주요 목표
1. **플랫폼 전환**: Klook → KKday 웹사이트 대응
2. **코드 일관성**: 모든 Klook 관련 코드를 KKday로 통일
3. **기능 유지**: 기존 크롤링 기능과 성능 수준 유지
4. **확장성**: 향후 KKday 기능 추가 시 쉬운 확장 가능

### 성공 기준
- [ ] 모든 Klook 관련 코드 제거 (0개 남김)
- [ ] KKday 웹사이트에서 정상 데이터 수집
- [ ] 기존 CSV/이미지 저장 기능 정상 작동
- [ ] 전체 시스템 통합 테스트 통과

## 🔧 핵심 기능 요구사항

### 1. 웹 크롤링 엔진
- **URL 관리**: KKday 상품 URL 수집 및 중복 처리
- **데이터 파싱**: 상품명, 가격, 평점, 리뷰수, 카테고리 등 추출
- **이미지 처리**: 메인/썸네일 이미지 자동 다운로드 및 최적화
- **페이지네이션**: 다중 페이지 자동 순회

### 2. 데이터 관리
- **CSV 저장**: 체계적인 상품 정보 저장 (대륙/국가/도시 구조)
- **중복 제거**: 해시 기반 중복 상품 자동 감지
- **번호 관리**: 연속성 있는 상품 번호 자동 할당
- **통합 CSV**: 국가별 통합 파일 자동 생성

### 3. 위치 지능화
- **도시명 정규화**: 130개+ 도시의 별칭 자동 처리
- **AI 학습**: KoNLPy 기반 위치 키워드 학습
- **지역 구조**: 대륙/국가/도시 계층 구조 관리

### 4. 시스템 안정성
- **브라우저 제어**: undetected-chromedriver 기반 차단 회피
- **오류 처리**: 예외 상황 자동 복구 및 재시도
- **성능 최적화**: 자연스러운 대기시간 및 속도 제어

## 👥 사용자 및 사용 시나리오

### 주요 사용자
- **데이터 분석가**: 여행 시장 분석용 데이터 수집
- **마케팅 팀**: 경쟁사 상품 모니터링
- **개발자**: 여행 상품 데이터 기반 서비스 개발

### 사용 시나리오
1. **일괄 크롤링**: 특정 도시의 모든 상품 수집
2. **실시간 모니터링**: 신규/변경 상품 추적
3. **데이터 분석**: 수집된 데이터 통계 및 분석
4. **이미지 수집**: 상품 이미지 자동 다운로드

## 💻 기술 스택

### 현재 사용 기술
- **언어**: Python 3.8+
- **웹 크롤링**: Selenium, undetected-chromedriver, BeautifulSoup4
- **데이터 처리**: CSV (내장), hashlib, PIL
- **자연어 처리**: KoNLPy (선택적)
- **실행 환경**: Jupyter Notebook + Python 모듈

### 아키텍처 구조
```
kkday/
├── src/                    # 핵심 모듈
│   ├── config.py          # 전역 설정 (130개 도시 정보)
│   ├── scraper/           # 크롤링 엔진
│   └── utils/             # 유틸리티
├── data/                  # 수집 데이터
├── kkday_img/            # 이미지 저장소
└── *.ipynb               # 실행 노트북
```

## 📋 상세 요구사항

### 1. 코드 전환 요구사항
- **함수명**: 모든 `*_klook` → `*_kkday` 변경
- **클래스명**: `KlookCrawler` → `KKdayCrawler`
- **URL**: `www.klook.com` → `www.kkday.com`
- **주석/메시지**: 모든 "Klook" → "KKday" 변경
- **CSS 셀렉터**: Klook 웹사이트 → KKday 웹사이트 구조 대응

### 2. 데이터 품질 요구사항
- **정확성**: 95% 이상 데이터 추출 성공률
- **완전성**: 필수 필드 (상품명, 가격, URL) 100% 수집
- **일관성**: 동일한 데이터 포맷 및 구조 유지
- **최신성**: 실시간 웹사이트 변경사항 대응

### 3. 성능 요구사항
- **속도**: 페이지당 평균 3-5초 처리
- **메모리**: 대용량 데이터 처리 시 메모리 효율성
- **안정성**: 24시간 연속 실행 가능
- **확장성**: 새로운 도시 추가 시 쉬운 확장

### 4. 사용성 요구사항
- **직관성**: 간단한 설정으로 즉시 실행 가능
- **모니터링**: 실시간 진행상황 및 통계 표시
- **오류 처리**: 명확한 오류 메시지 및 해결 방안 제시
- **문서화**: 완전한 README 및 코드 주석

## 🚨 제약사항 및 고려사항

### 기술적 제약사항
- **웹사이트 의존성**: KKday 웹사이트 구조 변경 시 수정 필요
- **차단 위험**: 과도한 요청 시 IP 차단 가능성
- **라이브러리 의존성**: Selenium 등 외부 라이브러리 버전 호환성

### 법적/윤리적 고려사항
- **이용약관 준수**: KKday 웹사이트 이용약관 확인 필요
- **저작권**: 이미지 및 콘텐츠 저작권 주의
- **개인정보**: 개인정보 수집 금지
- **서버 부하**: 적절한 대기시간으로 서버 부하 최소화

### 운영 고려사항
- **유지보수**: 정기적인 셀렉터 업데이트 필요
- **모니터링**: 크롤링 성공률 및 데이터 품질 모니터링
- **백업**: 수집 데이터 정기 백업 필요

## 📊 성공 지표 (KPI)

### 기능적 지표
- **코드 전환률**: 100% (모든 Klook 코드 제거)
- **데이터 수집 성공률**: 95% 이상
- **시스템 가용성**: 99% 이상

### 성능 지표
- **처리 속도**: 페이지당 5초 이내
- **메모리 사용량**: 2GB 이내
- **오류 발생률**: 5% 미만

### 사용성 지표
- **설정 시간**: 초기 설정 10분 이내
- **학습 시간**: 사용법 습득 30분 이내
- **문제 해결 시간**: 일반 오류 해결 5분 이내

## 🗓️ 개발 일정 (예상)

### Phase 1: 핵심 모듈 전환 (진행중)
- [x] config.py 수정
- [x] utils/ 폴더 전환
- [ ] scraper/ 폴더 전환

### Phase 2: Jupyter 노트북 업데이트
- [ ] kkday_crawler.ipynb
- [ ] kkday_Sitemap_Collector.ipynb
- [ ] kkday_Sitemap_Crawler.ipynb
- [ ] kkday_ad_link generator.ipynb

### Phase 3: 통합 테스트 및 검증
- [ ] 전체 시스템 통합 테스트
- [ ] 성능 최적화
- [ ] 문서화 완료

## 📝 향후 확장 계획

### v2.0 기능 (계획)
- **머신러닝**: 상품 추천 및 분류 시스템
- **실시간 모니터링**: 가격 변동 추적
- **API 서비스**: RESTful API 제공
- **웹 대시보드**: 관리 인터페이스

### 기술적 발전 방향
- **클라우드 배포**: AWS/GCP 기반 자동화
- **데이터베이스**: PostgreSQL/MongoDB 연동
- **분산 처리**: 다중 서버 크롤링
- **AI 고도화**: GPT 기반 데이터 분석

---

**문서 버전**: v1.0  
**작성일**: 2024-12-07  
**최종 수정**: 2024-12-07  
**승인자**: 프로젝트 매니저