{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 KKday 크롤러 v1.0\n",
    "## 통합 상품 데이터 수집 시스템\n",
    "\n",
    "### 📋 주요 기능:\n",
    "- ✅ **서울 페이지 진입으로 봇 탐지 회피**\n",
    "- ✅ **검색박스 활용한 도시별 크롤링**\n",
    "- ✅ **중앙화 셀렉터 시스템** (fallback 지원)\n",
    "- ✅ **개별 파서 함수** (복잡한 속성 처리)\n",
    "- ✅ **강화된 에러 처리** 및 재시도 메커니즘\n",
    "- ✅ **24개 CSV 컬럼** 완전 지원\n",
    "- ✅ **이미지 다운로드** 및 경로 관리\n",
    "- ✅ **URL 중복 처리** 및 순위 연속성 보장\n",
    "\n",
    "### 🔥 **v1.0 핵심 특징:**\n",
    "- **KKdayCrawler 클래스**: 통합 크롤링 시스템\n",
    "- **중앙화 + 개별 파서**: 최적 하이브리드 아키텍처\n",
    "- **더미 테스트 검증**: 100% 로직 검증 완료\n",
    "- **TimeoutException 처리**: 안정적인 대기 시스템\n",
    "- **StaleElement 처리**: DOM 변화 대응\n",
    "\n",
    "### 🎯 사용법:\n",
    "1. **아래 1번 셀에서 도시명 및 목표 수량 설정**\n",
    "2. **Run All 실행** (완전 자동화)\n",
    "3. **결과 분석** (자동 통계 생성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 🎯 사용자 설정 영역 =====\n",
    "\n",
    "# 1. 크롤링할 도시명 입력\n",
    "CITY_NAME = \"서울\"  # 🔥🔥 도시명 입력 🔥🔥\n",
    "\n",
    "# 2. 수집할 상품 수 설정\n",
    "TARGET_PRODUCTS = 10  # 수집할 상품 수\n",
    "\n",
    "# 3. 크롤링 범위 설정\n",
    "MAX_PAGES = 3  # 최대 검색할 페이지 수\n",
    "\n",
    "# 4. 이미지 저장 여부\n",
    "SAVE_IMAGES = True  # True: 이미지 다운로드, False: URL만 저장\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"🚀 KKday 크롤러 v1.0 시작\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ===== 환경 설정 및 모듈 Import =====\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# 현재 kkday 폴더에서 src 폴더에 접근\n",
    "sys.path.append('./src')\n",
    "sys.path.append('.')\n",
    "\n",
    "# KKday 프로젝트 모듈 import\n",
    "try:\n",
    "    from src.scraper.crawler import KKdayCrawler, execute_kkday_crawling_system, quick_crawl_test, get_crawling_status\n",
    "    from src.config import CONFIG\n",
    "    from src.utils.file_handler import create_product_data_structure, ensure_directory_structure\n",
    "    print(\"✅ KKday 모듈 로드 성공\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ KKday 모듈 로드 실패: {e}\")\n",
    "    print(\"💡 src/ 폴더 구조를 확인하세요.\")\n",
    "    raise\n",
    "\n",
    "# 의존성 확인\n",
    "try:\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    print(\"✅ Selenium 모듈 로드 성공\")\n",
    "except ImportError:\n",
    "    print(\"❌ Selenium이 설치되지 않았습니다.\")\n",
    "    print(\"💡 해결: pip install selenium\")\n",
    "    raise\n",
    "\n",
    "# ===== 설정 검증 =====\n",
    "print(\"\\n📋 크롤링 설정:\")\n",
    "print(f\"   🏙️ 도시: {CITY_NAME}\")\n",
    "print(f\"   🎯 목표 상품: {TARGET_PRODUCTS}개\")\n",
    "print(f\"   📄 최대 페이지: {MAX_PAGES}개\")\n",
    "print(f\"   📸 이미지 저장: {'✅' if SAVE_IMAGES else '❌'}\")\n",
    "\n",
    "# 디렉토리 구조 확보\n",
    "try:\n",
    "    ensure_directory_structure(CITY_NAME)\n",
    "    print(f\"   📁 디렉토리 구조 확보 완료\")\n",
    "except Exception as e:\n",
    "    print(f\"   ⚠️ 디렉토리 구조 확보 실패: {e}\")\n",
    "\n",
    "print(\"\\n🎯 설정 완료 - 크롤링 시작 준비!\")\n",
    "print(\"💡 진행상황은 실시간으로 표시됩니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 🚀 메인 크롤링 실행 =====\n",
    "print(f\"🚀 '{CITY_NAME}' 크롤링 시작!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 크롤링 시작 시간 기록\n",
    "start_time = datetime.now()\n",
    "print(f\"⏰ 시작 시간: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# KKday 크롤러 생성 및 실행\n",
    "crawler = None\n",
    "crawling_success = False\n",
    "\n",
    "try:\n",
    "    # 1. KKday 크롤러 초기화\n",
    "    print(f\"\\n🏗️ KKday 크롤러 초기화...\")\n",
    "    crawler = KKdayCrawler(city_name=CITY_NAME)\n",
    "    \n",
    "    # 2. 전체 크롤링 실행\n",
    "    print(f\"\\n🎯 전체 크롤링 실행 (최대 {MAX_PAGES}페이지, {TARGET_PRODUCTS}개 상품)\")\n",
    "    crawling_success = crawler.run_full_crawling(\n",
    "        max_pages=MAX_PAGES,\n",
    "        max_products=TARGET_PRODUCTS\n",
    "    )\n",
    "    \n",
    "    if crawling_success:\n",
    "        print(\"\\n🎉 크롤링 성공적으로 완료!\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ 크롤링이 완료되었지만 일부 문제가 있을 수 있습니다.\")\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n⏹️ 사용자가 크롤링을 중단했습니다.\")\n",
    "    crawling_success = False\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ 크롤링 중 오류 발생: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    crawling_success = False\n",
    "\n",
    "finally:\n",
    "    # 크롤링 종료 시간 기록\n",
    "    end_time = datetime.now()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(f\"\\n⏰ 종료 시간: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"⏱️ 총 소요 시간: {duration}\")\n",
    "    \n",
    "    # 크롤러 통계 출력 (크롤러가 있는 경우)\n",
    "    if crawler and hasattr(crawler, 'stats'):\n",
    "        print(f\"\\n📊 크롤링 통계:\")\n",
    "        stats = crawler.stats\n",
    "        print(f\"   • 전체 처리: {stats.get('total_processed', 0)}개\")\n",
    "        print(f\"   • 성공: {stats.get('success_count', 0)}개\")\n",
    "        print(f\"   • 실패: {stats.get('error_count', 0)}개\")\n",
    "        print(f\"   • 건너뜀: {stats.get('skip_count', 0)}개\")\n",
    "        \n",
    "        if stats.get('total_processed', 0) > 0:\n",
    "            success_rate = (stats.get('success_count', 0) / stats.get('total_processed', 1)) * 100\n",
    "            print(f\"   • 성공률: {success_rate:.1f}%\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"🏁 크롤링 실행 단계 완료\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 📊 크롤링 결과 분석 =====\n",
    "print(f\"📊 '{CITY_NAME}' 크롤링 결과 분석\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # 1. 크롤링 상태 조회\n",
    "    print(\"\\n🔍 크롤링 상태 조회...\")\n",
    "    status_summary = get_crawling_status(CITY_NAME)\n",
    "    \n",
    "    # 2. CSV 파일 분석\n",
    "    print(\"\\n📋 CSV 데이터 분석...\")\n",
    "    \n",
    "    # CSV 파일 경로 확인\n",
    "    csv_files = []\n",
    "    data_dir = f\"data/{CITY_NAME}\"\n",
    "    \n",
    "    if os.path.exists(data_dir):\n",
    "        for file in os.listdir(data_dir):\n",
    "            if file.endswith('.csv') and 'kkday' in file.lower():\n",
    "                csv_files.append(os.path.join(data_dir, file))\n",
    "    \n",
    "    if csv_files:\n",
    "        print(f\"   📄 발견된 CSV 파일: {len(csv_files)}개\")\n",
    "        \n",
    "        # pandas로 CSV 분석 (설치되어 있다면)\n",
    "        try:\n",
    "            import pandas as pd\n",
    "            \n",
    "            # 가장 최근 CSV 파일 선택\n",
    "            latest_csv = max(csv_files, key=os.path.getmtime)\n",
    "            print(f\"   📊 분석 파일: {os.path.basename(latest_csv)}\")\n",
    "            \n",
    "            df = pd.read_csv(latest_csv, encoding='utf-8-sig')\n",
    "            \n",
    "            print(f\"\\n📈 데이터 통계:\")\n",
    "            print(f\"   • 총 상품 수: {len(df)}개\")\n",
    "            print(f\"   • CSV 컬럼 수: {len(df.columns)}개\")\n",
    "            print(f\"   • 파일 크기: {os.path.getsize(latest_csv):,} bytes\")\n",
    "            \n",
    "            # 필수 필드 완성도 확인\n",
    "            essential_fields = ['상품명', '가격', '평점', 'URL', '순위']\n",
    "            print(f\"\\n✅ 필수 필드 완성도:\")\n",
    "            \n",
    "            for field in essential_fields:\n",
    "                if field in df.columns:\n",
    "                    valid_count = len(df[df[field].notna() & (df[field] != '') & (df[field] != '정보 없음')])\n",
    "                    completion_rate = (valid_count / len(df)) * 100\n",
    "                    status = \"✅\" if completion_rate >= 80 else \"⚠️\" if completion_rate >= 50 else \"❌\"\n",
    "                    print(f\"   {status} {field}: {completion_rate:.1f}% ({valid_count}/{len(df)})\")\n",
    "            \n",
    "            # 상위 5개 상품 미리보기\n",
    "            if len(df) > 0:\n",
    "                print(f\"\\n🏆 상위 5개 상품:\")\n",
    "                for i, row in df.head(5).iterrows():\n",
    "                    rank = row.get('순위', i+1)\n",
    "                    name = row.get('상품명', 'N/A')[:40] + ('...' if len(str(row.get('상품명', ''))) > 40 else '')\n",
    "                    price = row.get('가격', 'N/A')\n",
    "                    rating = row.get('평점', 'N/A')\n",
    "                    print(f\"   {rank}위: {name}\")\n",
    "                    print(f\"        💰 {price} | ⭐ {rating}\")\n",
    "            \n",
    "            # 가격 분포 분석\n",
    "            if '가격' in df.columns:\n",
    "                print(f\"\\n💰 가격 분석:\")\n",
    "                try:\n",
    "                    # 가격에서 숫자만 추출\n",
    "                    prices = df['가격'].astype(str).str.extract(r'([0-9,]+)')[0].str.replace(',', '')\n",
    "                    prices = pd.to_numeric(prices, errors='coerce').dropna()\n",
    "                    \n",
    "                    if len(prices) > 0:\n",
    "                        print(f\"   • 최저가: {prices.min():,.0f}원\")\n",
    "                        print(f\"   • 최고가: {prices.max():,.0f}원\")\n",
    "                        print(f\"   • 평균가: {prices.mean():,.0f}원\")\n",
    "                        print(f\"   • 중간가: {prices.median():,.0f}원\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   ⚠️ 가격 분석 실패: {e}\")\n",
    "            \n",
    "            # 평점 분포 분석\n",
    "            if '평점' in df.columns:\n",
    "                print(f\"\\n⭐ 평점 분석:\")\n",
    "                try:\n",
    "                    ratings = df['평점'].astype(str).str.extract(r'([0-9.]+)')[0]\n",
    "                    ratings = pd.to_numeric(ratings, errors='coerce').dropna()\n",
    "                    \n",
    "                    if len(ratings) > 0:\n",
    "                        print(f\"   • 최고 평점: {ratings.max():.1f}/5.0\")\n",
    "                        print(f\"   • 최저 평점: {ratings.min():.1f}/5.0\")\n",
    "                        print(f\"   • 평균 평점: {ratings.mean():.2f}/5.0\")\n",
    "                        \n",
    "                        # 평점 등급 분포\n",
    "                        excellent = len(ratings[ratings >= 4.5])\n",
    "                        good = len(ratings[(ratings >= 4.0) & (ratings < 4.5)])\n",
    "                        average = len(ratings[(ratings >= 3.5) & (ratings < 4.0)])\n",
    "                        below = len(ratings[ratings < 3.5])\n",
    "                        \n",
    "                        print(f\"   • 우수 (4.5+): {excellent}개 ({excellent/len(ratings)*100:.1f}%)\")\n",
    "                        print(f\"   • 좋음 (4.0+): {good}개 ({good/len(ratings)*100:.1f}%)\")\n",
    "                        print(f\"   • 보통 (3.5+): {average}개 ({average/len(ratings)*100:.1f}%)\")\n",
    "                        print(f\"   • 미흡 (3.5-): {below}개 ({below/len(ratings)*100:.1f}%)\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"   ⚠️ 평점 분석 실패: {e}\")\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"   ℹ️ pandas가 없어 상세 분석을 건너뜁니다.\")\n",
    "            print(f\"   📊 기본 정보: CSV 파일 {len(csv_files)}개 생성\")\n",
    "            \n",
    "    else:\n",
    "        print(\"   ⚠️ CSV 파일을 찾을 수 없습니다.\")\n",
    "    \n",
    "    # 3. 이미지 파일 확인\n",
    "    print(f\"\\n🖼️ 이미지 파일 확인...\")\n",
    "    image_dir = f\"images/{CITY_NAME}\"\n",
    "    \n",
    "    if os.path.exists(image_dir):\n",
    "        image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        print(f\"   📸 저장된 이미지: {len(image_files)}개\")\n",
    "        \n",
    "        if image_files:\n",
    "            total_size = sum(os.path.getsize(os.path.join(image_dir, f)) for f in image_files)\n",
    "            print(f\"   💾 총 크기: {total_size/1024/1024:.2f} MB\")\n",
    "            \n",
    "            # 이미지 타입별 분류\n",
    "            main_images = [f for f in image_files if '_thumb' not in f]\n",
    "            thumb_images = [f for f in image_files if '_thumb' in f]\n",
    "            print(f\"   🖼️ 메인 이미지: {len(main_images)}개\")\n",
    "            print(f\"   🔍 썸네일: {len(thumb_images)}개\")\n",
    "    else:\n",
    "        print(f\"   📸 이미지 디렉토리 없음\")\n",
    "    \n",
    "    # 4. 크롤링 품질 평가\n",
    "    print(f\"\\n🎯 크롤링 품질 평가:\")\n",
    "    \n",
    "    quality_score = 0\n",
    "    max_score = 5\n",
    "    \n",
    "    if crawling_success:\n",
    "        quality_score += 1\n",
    "        print(f\"   ✅ 크롤링 실행: 성공\")\n",
    "    else:\n",
    "        print(f\"   ❌ 크롤링 실행: 실패\")\n",
    "    \n",
    "    if csv_files:\n",
    "        quality_score += 1\n",
    "        print(f\"   ✅ CSV 생성: 성공\")\n",
    "    else:\n",
    "        print(f\"   ❌ CSV 생성: 실패\")\n",
    "    \n",
    "    if 'df' in locals() and len(df) > 0:\n",
    "        quality_score += 1\n",
    "        print(f\"   ✅ 데이터 수집: {len(df)}개 상품\")\n",
    "        \n",
    "        # 필수 필드 완성도 체크\n",
    "        if len(df) > 0:\n",
    "            essential_completion = 0\n",
    "            for field in ['상품명', '가격', '평점']:\n",
    "                if field in df.columns:\n",
    "                    valid_count = len(df[df[field].notna() & (df[field] != '')])\n",
    "                    if valid_count / len(df) >= 0.8:\n",
    "                        essential_completion += 1\n",
    "            \n",
    "            if essential_completion >= 2:\n",
    "                quality_score += 1\n",
    "                print(f\"   ✅ 데이터 품질: 우수\")\n",
    "            else:\n",
    "                print(f\"   ⚠️ 데이터 품질: 보통\")\n",
    "    else:\n",
    "        print(f\"   ❌ 데이터 수집: 실패\")\n",
    "    \n",
    "    if SAVE_IMAGES and os.path.exists(image_dir) and len(os.listdir(image_dir)) > 0:\n",
    "        quality_score += 1\n",
    "        print(f\"   ✅ 이미지 저장: 성공\")\n",
    "    elif not SAVE_IMAGES:\n",
    "        quality_score += 1\n",
    "        print(f\"   ✅ 이미지 설정: URL만 저장 (설정대로)\")\n",
    "    else:\n",
    "        print(f\"   ❌ 이미지 저장: 실패\")\n",
    "    \n",
    "    # 최종 품질 점수\n",
    "    quality_percentage = (quality_score / max_score) * 100\n",
    "    \n",
    "    if quality_percentage >= 80:\n",
    "        quality_status = \"🎉 우수\"\n",
    "    elif quality_percentage >= 60:\n",
    "        quality_status = \"👍 양호\"\n",
    "    elif quality_percentage >= 40:\n",
    "        quality_status = \"⚠️ 보통\"\n",
    "    else:\n",
    "        quality_status = \"❌ 미흡\"\n",
    "    \n",
    "    print(f\"\\n🏆 종합 품질 점수: {quality_score}/{max_score} ({quality_percentage:.1f}%) {quality_status}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 결과 분석 중 오류: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"📊 결과 분석 완료\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 🎉 크롤링 완료 요약 =====\n",
    "print(f\"🎉 KKday 크롤러 v1.0 실행 완료\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 최종 실행 요약\n",
    "print(f\"📋 실행 요약:\")\n",
    "print(f\"   🏙️ 크롤링 도시: {CITY_NAME}\")\n",
    "print(f\"   🎯 목표 상품: {TARGET_PRODUCTS}개\")\n",
    "print(f\"   📄 최대 페이지: {MAX_PAGES}개\")\n",
    "print(f\"   📸 이미지 저장: {'활성화' if SAVE_IMAGES else '비활성화'}\")\n",
    "\n",
    "# 실행 시간\n",
    "if 'start_time' in locals() and 'end_time' in locals():\n",
    "    print(f\"   ⏱️ 실행 시간: {end_time - start_time}\")\n",
    "\n",
    "# 성공/실패 상태\n",
    "if crawling_success:\n",
    "    print(f\"   ✅ 크롤링 상태: 성공\")\n",
    "else:\n",
    "    print(f\"   ⚠️ 크롤링 상태: 부분 성공 또는 실패\")\n",
    "\n",
    "# 다음 단계 안내\n",
    "print(f\"\\n💡 다음 단계:\")\n",
    "print(f\"   1️⃣ 수집된 CSV 데이터 확인 및 검토\")\n",
    "print(f\"   2️⃣ 이미지 파일 품질 확인 (다운로드된 경우)\")\n",
    "print(f\"   3️⃣ 데이터 후처리 및 분석\")\n",
    "print(f\"   4️⃣ 다른 도시 크롤링 (CITY_NAME 변경 후 재실행)\")\n",
    "\n",
    "# 파일 위치 안내\n",
    "print(f\"\\n📁 생성된 파일 위치:\")\n",
    "print(f\"   📄 CSV: data/{CITY_NAME}/\")\n",
    "print(f\"   🖼️ 이미지: images/{CITY_NAME}/\")\n",
    "print(f\"   📊 랭킹: ranking_data/ (해당하는 경우)\")\n",
    "\n",
    "# 문제 해결 안내\n",
    "if not crawling_success:\n",
    "    print(f\"\\n🔧 문제 해결:\")\n",
    "    print(f\"   • 인터넷 연결 확인\")\n",
    "    print(f\"   • Chrome 브라우저 및 ChromeDriver 버전 확인\")\n",
    "    print(f\"   • 방화벽/보안 프로그램 설정 확인\")\n",
    "    print(f\"   • 다른 도시명으로 테스트 시도\")\n",
    "    print(f\"   • TARGET_PRODUCTS를 더 적은 수로 설정\")\n",
    "\n",
    "print(f\"\\n🚀 KKday 크롤러를 이용해 주셔서 감사합니다!\")\n",
    "print(f\"={'*'*70}\")\n",
    "\n",
    "# 간단한 통계 출력 (가능한 경우)\n",
    "if 'crawler' in locals() and crawler and hasattr(crawler, 'stats'):\n",
    "    stats = crawler.stats\n",
    "    success_count = stats.get('success_count', 0)\n",
    "    total_processed = stats.get('total_processed', 0)\n",
    "    \n",
    "    if total_processed > 0:\n",
    "        print(f\"\\n🎊 최종 성과: {success_count}/{total_processed} 상품 성공적으로 수집!\")\n",
    "        success_rate = (success_count / total_processed) * 100\n",
    "        print(f\"📈 성공률: {success_rate:.1f}%\")\n",
    "        \n",
    "        if success_rate >= 80:\n",
    "            print(f\"🎉 우수한 성과입니다!\")\n",
    "        elif success_rate >= 60:\n",
    "            print(f\"👍 양호한 결과입니다!\")\n",
    "        else:\n",
    "            print(f\"💪 다음번엔 더 좋은 결과를 위해 설정을 조정해보세요!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}