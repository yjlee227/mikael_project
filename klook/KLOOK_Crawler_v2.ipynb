{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ KLOOK í¬ë¡¤ëŸ¬ v2.0\n",
    "## Activity ì¹´í…Œê³ ë¦¬ ì „ìš© ìˆœìœ„ ê¸°ë°˜ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ\n",
    "\n",
    "### ğŸ“‹ ì£¼ìš” ê¸°ëŠ¥:\n",
    "- âœ… Activity ì¹´í…Œê³ ë¦¬ë§Œ ì„ ë³„ ìˆ˜ì§‘ (í˜¸í…”, ë Œí„°ì¹´ ì œì™¸)\n",
    "- âœ… íƒ­ë³„ ìˆœìœ„ ê¸°ë°˜ í¬ë¡¤ë§ (ì „ì²´, íˆ¬ì–´&ì•¡í‹°ë¹„í‹°, í‹°ì¼“&ì…ì¥ê¶Œ, êµí†µ, ê¸°íƒ€)\n",
    "- âœ… ëª©ë¡í˜ì´ì§€ URL ë°±ì—…ìœ¼ë¡œ ì•ˆì •ì  í˜ì´ì§€ë„¤ì´ì…˜\n",
    "- âœ… **ğŸ—ºï¸ Sitemap ê¸°ë°˜ ì¶”ê°€ ìˆ˜ì§‘** (í˜ì´ì§€ë„¤ì´ì…˜ ë³´ì™„)\n",
    "- âœ… **âœ¨ í•˜ì´ë¼ì´íŠ¸ í† ê¸€ ëª¨ë‹¬** (í¼ì¹˜ê¸° ë²„íŠ¼ â†’ ìˆ˜ì§‘ â†’ Xë²„íŠ¼ ë‹«ê¸°)\n",
    "- âœ… **ğŸŒ ì–¸ì–´ ì •ë³´ ìë™ ê°ì§€** (URL/HTML/ë‚´ìš© ê¸°ë°˜)\n",
    "- âœ… **ğŸ¯ ì›ë³¸ ì •êµí•œ ì…€ë ‰í„°** (100% ì‘ë™ ë³´ì¥)\n",
    "- âœ… 3ê°€ì§€ ë…ë¦½ ë°ì´í„° ì €ì¥: CSV, ë­í‚¹JSON, ì´ë¯¸ì§€\n",
    "- âœ… ì—°ì†ì„± ë³´ì¥: 1ìœ„ë¶€í„° ìˆœì°¨ì  ìˆœìœ„ ë§¤ê¹€\n",
    "\n",
    "### ğŸ”¥ **v2.0 ì‹ ê·œ ê¸°ëŠ¥:**\n",
    "- **í† ê¸€ ëª¨ë‹¬ í•˜ì´ë¼ì´íŠ¸**: í¼ì¹˜ê¸° ë²„íŠ¼ í´ë¦­ â†’ í•˜ì´ë¼ì´íŠ¸ ìˆ˜ì§‘ â†’ ìë™ ë‹«ê¸°\n",
    "- **ì–¸ì–´ ì •ë³´ ìˆ˜ì§‘**: í•œêµ­ì–´/ì˜ì–´/ì¼ë³¸ì–´/ì¤‘êµ­ì–´ ìë™ ê°ì§€\n",
    "- **Sitemap ë³´ì™„ ìˆ˜ì§‘**: í˜ì´ì§€ë„¤ì´ì…˜ìœ¼ë¡œ ë†“ì¹œ ìƒí’ˆë“¤ ì¶”ê°€ ìˆ˜ì§‘\n",
    "- **ì›ë³¸ ì…€ë ‰í„° ì ìš©**: KLOOK ì „ìš© ì •êµí•œ ì…€ë ‰í„°ë¡œ ì¶”ì¶œ ì„±ê³µë¥  ê·¹ëŒ€í™”\n",
    "\n",
    "### ğŸ¯ ì‚¬ìš©ë²•:\n",
    "1. **ì•„ë˜ 1ë²ˆ ì…€ì—ì„œ ì„¤ì • ë³€ê²½**\n",
    "2. **Run All ì‹¤í–‰** (ì „ì²´ ìë™ ì‹¤í–‰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸš€ KLOOK í¬ë¡¤ëŸ¬ v2.0 ì‹œì‘\n",
      "======================================================================\n",
      "âœ… í”„ë¡œì íŠ¸ ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ (ì´ˆê³ ì† ì¤‘ë³µ ì²´í¬ í¬í•¨)\n",
      "âœ… Selenium ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ\n",
      "\n",
      "ğŸ“‹ í¬ë¡¤ë§ ì„¤ì •:\n",
      "   ğŸ¯ ëª©í‘œ ìƒí’ˆ: 2ê°œ\n",
      "   ğŸ™ï¸ ë„ì‹œ: ë¡œë§ˆ\n",
      "   ğŸ“‘ íƒ­: ì „ì²´\n",
      "   ğŸ“¸ ì´ë¯¸ì§€ ì €ì¥: âœ…\n",
      "   ğŸ“„ ìµœëŒ€ í˜ì´ì§€: 10\n",
      "ğŸŒ ë„ì‹œëª… ì •ê·œí™”: 'ë¡œë§ˆ' â†’ 'ë¡œë§ˆ'\n",
      "ğŸŒ ë„ì‹œëª… ì •ê·œí™”: 'ë¡œë§ˆ' â†’ 'ë¡œë§ˆ'\n",
      "   âœ… ë„ì‹œ í™•ì¸ ì™„ë£Œ: ë¡œë§ˆ\n",
      "\n",
      "ğŸ¯ ì„¤ì • ì™„ë£Œ - í¬ë¡¤ë§ ì‹œì‘ ì¤€ë¹„!\n"
     ]
    }
   ],
   "source": [
    "# ê·¸ë£¹ 1===== ğŸ¯ ì‚¬ìš©ì ì„¤ì • ì˜ì—­ =====\n",
    "\n",
    "# 1. ìˆ˜ì§‘í•  ìƒí’ˆ ìˆ˜ ì„¤ì •\n",
    "TARGET_PRODUCTS = 2  # ìˆ˜ì§‘í•  ìƒí’ˆ ìˆ˜ ì…ë ¥\n",
    "\n",
    "# 2. ë„ì‹œëª… ì…ë ¥\n",
    "CITY_NAME = \"ë¡œë§ˆ\"  # #ğŸ”¥ğŸ”¥ë„ì‹œ ì…ë ¥ ğŸ”¥ğŸ”¥# #\n",
    "\n",
    "# 3. í¬ë¡¤ë§í•  íƒ­ ì„¤ì • (íƒ­ë³„ ë­í‚¹ ìˆ˜ì§‘ìš©)\n",
    "TARGET_TAB = \"ì „ì²´\"  # ì˜µì…˜: \"ì „ì²´\", \"íˆ¬ì–´&ì•¡í‹°ë¹„í‹°\", \"í‹°ì¼“&ì…ì¥ê¶Œ\", \"êµí†µ\", \"ê¸°íƒ€\"\n",
    "\n",
    "# 4. ì´ë¯¸ì§€ ì €ì¥ ì—¬ë¶€\n",
    "SAVE_IMAGES = True  # True: ì´ë¯¸ì§€ ì €ì¥, False: URLë§Œ ì €ì¥\n",
    "\n",
    "# ===== ì‹œìŠ¤í…œ ì„¤ì • =====\n",
    "MAX_PAGES = 10  # ìµœëŒ€ ê²€ìƒ‰í•  í˜ì´ì§€ ìˆ˜ (ì•ˆì „ì¥ì¹˜)\n",
    "PRODUCTS_PER_PAGE = 15  # KLOOK í˜ì´ì§€ë‹¹ ìƒí’ˆ ìˆ˜ (ì°¸ê³ ìš©)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸš€ KLOOK í¬ë¡¤ëŸ¬ v2.0 ì‹œì‘\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ===== í™˜ê²½ ì„¤ì • ë° ëª¨ë“ˆ Import =====\n",
    "import sys\n",
    "import os\n",
    "# í˜„ì¬ klook í´ë”ì—ì„œ src í´ë”ì— ì ‘ê·¼\n",
    "sys.path.append('./src')\n",
    "\n",
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ëª¨ë“ˆ import\n",
    "try:\n",
    "    from src.config import CONFIG, UNIFIED_CITY_INFO, is_url_processed_fast, mark_url_processed_fast\n",
    "    from src.utils.city_manager import normalize_city_name, is_city_supported\n",
    "    from src.scraper.driver_manager import setup_driver, go_to_main_page, find_and_fill_search, click_search_button, handle_popup\n",
    "    from src.scraper.parsers import extract_all_product_data\n",
    "    from src.utils.file_handler import create_product_data_structure, save_to_csv_klook, get_dual_image_urls_klook, download_dual_images_klook, auto_create_country_csv_after_crawling, get_next_product_number\n",
    "    print(\"âœ… í”„ë¡œì íŠ¸ ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ (ì´ˆê³ ì† ì¤‘ë³µ ì²´í¬ í¬í•¨)\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ í”„ë¡œì íŠ¸ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ’¡ src/ í´ë” êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "    raise\n",
    "\n",
    "# Selenium import\n",
    "try:\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "    print(\"âœ… Selenium ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ\")\n",
    "except ImportError:\n",
    "    print(\"âŒ Seleniumì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ’¡ í•´ê²°: pip install selenium\")\n",
    "    raise\n",
    "\n",
    "# ===== ì„¤ì • ê²€ì¦ =====\n",
    "print(\"\\nğŸ“‹ í¬ë¡¤ë§ ì„¤ì •:\")\n",
    "print(f\"   ğŸ¯ ëª©í‘œ ìƒí’ˆ: {TARGET_PRODUCTS}ê°œ\")\n",
    "print(f\"   ğŸ™ï¸ ë„ì‹œ: {CITY_NAME}\")\n",
    "print(f\"   ğŸ“‘ íƒ­: {TARGET_TAB}\")\n",
    "print(f\"   ğŸ“¸ ì´ë¯¸ì§€ ì €ì¥: {'âœ…' if SAVE_IMAGES else 'âŒ'}\")\n",
    "print(f\"   ğŸ“„ ìµœëŒ€ í˜ì´ì§€: {MAX_PAGES}\")\n",
    "\n",
    "# ë„ì‹œ ì§€ì› ì—¬ë¶€ í™•ì¸\n",
    "normalized_city = normalize_city_name(CITY_NAME)\n",
    "if not is_city_supported(normalized_city):\n",
    "    print(f\"\\nâŒ ì§€ì›ë˜ì§€ ì•ŠëŠ” ë„ì‹œ: {CITY_NAME}\")\n",
    "    print(\"ğŸ“‹ ì§€ì› ë„ì‹œ ëª©ë¡ (ì¼ë¶€):\")\n",
    "    for city in list(UNIFIED_CITY_INFO.keys())[:10]:\n",
    "        print(f\"   â€¢ {city}\")\n",
    "    raise ValueError(f\"ì§€ì›ë˜ì§€ ì•ŠëŠ” ë„ì‹œ: {CITY_NAME}\")\n",
    "else:\n",
    "    CITY_NAME = normalized_city\n",
    "    print(f\"   âœ… ë„ì‹œ í™•ì¸ ì™„ë£Œ: {CITY_NAME}\")\n",
    "\n",
    "print(\"\\nğŸ¯ ì„¤ì • ì™„ë£Œ - í¬ë¡¤ë§ ì‹œì‘ ì¤€ë¹„!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ í•µì‹¬ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ê·¸ë£¹ 2 ===== í•µì‹¬ í•¨ìˆ˜ ì •ì˜ =====\n",
    "\n",
    "def select_target_tab(driver, tab_name):\n",
    "    \"\"\"ì§€ì •ëœ íƒ­ ì„ íƒ\"\"\"\n",
    "    print(f\"ğŸ“‘ '{tab_name}' íƒ­ ì„ íƒ ì¤‘...\")\n",
    "    \n",
    "    # íƒ­ ì„ íƒì ë§¤í•‘\n",
    "    tab_selectors = {\n",
    "        \"ì „ì²´\": [\n",
    "            \"//button[contains(text(), 'ì „ì²´')]\",\n",
    "            \"//a[contains(text(), 'ì „ì²´')]\",\n",
    "            \"//div[contains(@class, 'tab') and contains(text(), 'ì „ì²´')]\"\n",
    "        ],\n",
    "        \"íˆ¬ì–´&ì•¡í‹°ë¹„í‹°\": [\n",
    "            \"//button[contains(text(), 'íˆ¬ì–´') or contains(text(), 'ì•¡í‹°ë¹„í‹°')]\",\n",
    "            \"//a[contains(text(), 'íˆ¬ì–´') or contains(text(), 'ì•¡í‹°ë¹„í‹°')]\"\n",
    "        ],\n",
    "        \"í‹°ì¼“&ì…ì¥ê¶Œ\": [\n",
    "            \"//button[contains(text(), 'í‹°ì¼“') or contains(text(), 'ì…ì¥ê¶Œ')]\",\n",
    "            \"//a[contains(text(), 'í‹°ì¼“') or contains(text(), 'ì…ì¥ê¶Œ')]\"\n",
    "        ],\n",
    "        \"êµí†µ\": [\n",
    "            \"//button[contains(text(), 'êµí†µ')]\",\n",
    "            \"//a[contains(text(), 'êµí†µ')]\"\n",
    "        ],\n",
    "        \"ê¸°íƒ€\": [\n",
    "            \"//button[contains(text(), 'ê¸°íƒ€')]\",\n",
    "            \"//a[contains(text(), 'ê¸°íƒ€')]\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    if tab_name == \"ì „ì²´\":\n",
    "        print(\"   â„¹ï¸ ê¸°ë³¸ íƒ­(ì „ì²´) ì‚¬ìš© - ë³„ë„ í´ë¦­ ë¶ˆí•„ìš”\")\n",
    "        return True\n",
    "    \n",
    "    selectors = tab_selectors.get(tab_name, [])\n",
    "    \n",
    "    for selector in selectors:\n",
    "        try:\n",
    "            tab_element = driver.find_element(By.XPATH, selector)\n",
    "            if tab_element.is_displayed() and tab_element.is_enabled():\n",
    "                tab_element.click()\n",
    "                time.sleep(2)\n",
    "                print(f\"   âœ… '{tab_name}' íƒ­ ì„ íƒ ì™„ë£Œ\")\n",
    "                return True\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    print(f\"   âš ï¸ '{tab_name}' íƒ­ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ - ê¸°ë³¸ íƒ­ ì‚¬ìš©\")\n",
    "    return False\n",
    "\n",
    "def collect_activity_urls_only(driver):\n",
    "    \"\"\"í˜„ì¬ í˜ì´ì§€ì—ì„œ Activity URLë§Œ ìˆœìœ„ëŒ€ë¡œ ìˆ˜ì§‘ (í˜¸í…”, ë Œí„°ì¹´ ì œì™¸)\"\"\"\n",
    "    print(\"ğŸ”— Activity URL ìˆ˜ì§‘ ì¤‘...\")\n",
    "    \n",
    "    # KLOOK Activity URL íŒ¨í„´\n",
    "    activity_selectors = [\n",
    "        \"a[href*='/activity/']\",\n",
    "        \"a[href*='/ko/activity/']\",\n",
    "        \".product-card a[href*='activity']\",\n",
    "        \".activity-card a\"\n",
    "    ]\n",
    "    \n",
    "    activity_urls = []\n",
    "    \n",
    "    for selector in activity_selectors:\n",
    "        try:\n",
    "            elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "            \n",
    "            for element in elements:\n",
    "                try:\n",
    "                    url = element.get_attribute(\"href\")\n",
    "                    if url and '/activity/' in url and url not in activity_urls:\n",
    "                        # í˜¸í…”, ë Œí„°ì¹´ ì œì™¸ í•„í„°ë§\n",
    "                        if not any(keyword in url.lower() for keyword in ['hotel', 'car-rental', 'transport', 'transfer']):\n",
    "                            activity_urls.append(url)\n",
    "                except Exception:\n",
    "                    continue\n",
    "                    \n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    print(f\"   âœ… Activity URL {len(activity_urls)}ê°œ ìˆ˜ì§‘\")\n",
    "    return activity_urls[:15]  # í˜ì´ì§€ë‹¹ ìµœëŒ€ 15ê°œ\n",
    "\n",
    "def go_to_next_page(driver, current_listing_url):\n",
    "    \"\"\"ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™ (í™”ì‚´í‘œ í´ë¦­ or URL ë³€ê²½)\"\"\"\n",
    "    print(\"â¡ï¸ ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™...\")\n",
    "    \n",
    "    # 1ë‹¨ê³„: í™”ì‚´í‘œ í´ë¦­ ì‹œë„\n",
    "    arrow_selectors = [\n",
    "        \".klk-pagination-next-btn:not(.klk-pagination-next-btn-disabled)\",\n",
    "        \"button[class*='pagination-next']:not([disabled])\",\n",
    "        \"//button[contains(@aria-label, 'ë‹¤ìŒ')]\",\n",
    "        \"//a[contains(@aria-label, 'ë‹¤ìŒ')]\",\n",
    "        \"//button[contains(@class, 'next')]\"\n",
    "    ]\n",
    "    \n",
    "    for selector in arrow_selectors:\n",
    "        try:\n",
    "            if selector.startswith('//'):\n",
    "                arrow_button = driver.find_element(By.XPATH, selector)\n",
    "            else:\n",
    "                arrow_button = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "            \n",
    "            if arrow_button.is_displayed() and arrow_button.is_enabled():\n",
    "                # ë²„íŠ¼ì´ ë³´ì´ë„ë¡ ìŠ¤í¬ë¡¤\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});\", arrow_button)\n",
    "                time.sleep(1)\n",
    "                \n",
    "                # í´ë¦­\n",
    "                driver.execute_script(\"arguments[0].click();\", arrow_button)\n",
    "                print(\"   ğŸ–±ï¸ í™”ì‚´í‘œ í´ë¦­ ì™„ë£Œ\")\n",
    "                \n",
    "                # í˜ì´ì§€ ë³€í™” í™•ì¸\n",
    "                time.sleep(3)\n",
    "                new_url = driver.current_url\n",
    "                if new_url != current_listing_url and ('page=' in new_url or len(new_url) > len(current_listing_url)):\n",
    "                    print(\"   âœ… í˜ì´ì§€ ì´ë™ í™•ì¸\")\n",
    "                    return True, new_url\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    # 2ë‹¨ê³„: URL ì§ì ‘ ë³€ê²½\n",
    "    print(\"   ğŸ”„ í™”ì‚´í‘œ í´ë¦­ ì‹¤íŒ¨ - URL ì§ì ‘ ë³€ê²½\")\n",
    "    try:\n",
    "        # í˜„ì¬ í˜ì´ì§€ ë²ˆí˜¸ í™•ì¸\n",
    "        if 'page=' in current_listing_url:\n",
    "            import re\n",
    "            current_page = int(re.search(r'page=(\\d+)', current_listing_url).group(1))\n",
    "            next_page_url = current_listing_url.replace(f'page={current_page}', f'page={current_page + 1}')\n",
    "        else:\n",
    "            separator = '&' if '?' in current_listing_url else '?'\n",
    "            next_page_url = current_listing_url + f'{separator}page=2'\n",
    "        \n",
    "        driver.get(next_page_url)\n",
    "        time.sleep(3)\n",
    "        print(f\"   âœ… URL ë³€ê²½ìœ¼ë¡œ ì´ë™: {next_page_url[:60]}...\")\n",
    "        return True, next_page_url\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨: {e}\")\n",
    "        return False, current_listing_url\n",
    "\n",
    "print(\"ğŸ”§ í•µì‹¬ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™”...\n",
      "ğŸš€ Chrome ë“œë¼ì´ë²„ ì„¤ì • ì¤‘...\n",
      "   ğŸ­ User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) Ap...\n",
      "âœ… ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì™„ë£Œ\n",
      "âœ… ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì„±ê³µ\n",
      "ğŸŒ KLOOK ë©”ì¸ í˜ì´ì§€ ì´ë™...\n",
      "ğŸ”” íŒì—… í™•ì¸ ì¤‘...\n",
      "â„¹ï¸ íŒì—… ì—†ìŒ\n",
      "ğŸ” 'ë¡œë§ˆ' ê²€ìƒ‰...\n",
      "  ğŸ” 'ë¡œë§ˆ' ê²€ìƒ‰ì°½ ì°¾ëŠ” ì¤‘...\n",
      "  âœ… ê²€ìƒ‰ì°½ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!\n",
      "  âœ… 'ë¡œë§ˆ' ì…ë ¥ ì™„ë£Œ!\n",
      "  ğŸ” ê²€ìƒ‰ ë²„íŠ¼ ì°¾ëŠ” ì¤‘...\n",
      "  âœ… ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­ ì„±ê³µ!\n",
      "âœ… ê²€ìƒ‰ ì™„ë£Œ - ê²°ê³¼ í˜ì´ì§€ ë„ì°©\n",
      "ğŸ“‘ 'ì „ì²´' íƒ­ ì„ íƒ ì¤‘...\n",
      "   â„¹ï¸ ê¸°ë³¸ íƒ­(ì „ì²´) ì‚¬ìš© - ë³„ë„ í´ë¦­ ë¶ˆí•„ìš”\n",
      "ğŸ“ ëª©ë¡ í˜ì´ì§€ URL ì €ì¥: https://www.klook.com/ko/search/result/?query=%EB%A1%9C%EB%A...\n",
      "ğŸ¯ í¬ë¡¤ë§ ì¤€ë¹„ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ê·¸ë£¹ 3 ===== ë“œë¼ì´ë²„ ì´ˆê¸°í™” ë° ê²€ìƒ‰ =====\n",
    "print(\"ğŸš€ Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™”...\")\n",
    "driver = setup_driver()\n",
    "\n",
    "if not driver:\n",
    "    print(\"âŒ ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹¤íŒ¨\")\n",
    "    raise Exception(\"ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹¤íŒ¨\")\n",
    "\n",
    "print(\"âœ… ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì„±ê³µ\")\n",
    "\n",
    "try:\n",
    "    # 1. KLOOK ë©”ì¸ í˜ì´ì§€ ì´ë™\n",
    "    print(\"ğŸŒ KLOOK ë©”ì¸ í˜ì´ì§€ ì´ë™...\")\n",
    "    if not go_to_main_page(driver):\n",
    "        raise Exception(\"ë©”ì¸ í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨\")\n",
    "    \n",
    "    # 2. íŒì—… ì²˜ë¦¬\n",
    "    handle_popup(driver)\n",
    "    \n",
    "    # 3. ë„ì‹œ ê²€ìƒ‰\n",
    "    print(f\"ğŸ” '{CITY_NAME}' ê²€ìƒ‰...\")\n",
    "    search_input = find_and_fill_search(driver, CITY_NAME)\n",
    "    if not search_input:\n",
    "        raise Exception(\"ê²€ìƒ‰ì°½ ì…ë ¥ ì‹¤íŒ¨\")\n",
    "    \n",
    "    # 4. ê²€ìƒ‰ ì‹¤í–‰\n",
    "    if not click_search_button(driver):\n",
    "        raise Exception(\"ê²€ìƒ‰ ì‹¤í–‰ ì‹¤íŒ¨\")\n",
    "    \n",
    "    # 5. ê²€ìƒ‰ ê²°ê³¼ ë¡œë”© ëŒ€ê¸°\n",
    "    time.sleep(5)\n",
    "    print(\"âœ… ê²€ìƒ‰ ì™„ë£Œ - ê²°ê³¼ í˜ì´ì§€ ë„ì°©\")\n",
    "    \n",
    "    # 6. íƒ­ ì„ íƒ\n",
    "    select_target_tab(driver, TARGET_TAB)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # 7. ëª©ë¡ í˜ì´ì§€ URL ì €ì¥ (ë°±ì—…ìš©)\n",
    "    listing_page_url = driver.current_url\n",
    "    print(f\"ğŸ“ ëª©ë¡ í˜ì´ì§€ URL ì €ì¥: {listing_page_url[:60]}...\")\n",
    "    \n",
    "    print(\"ğŸ¯ í¬ë¡¤ë§ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    if driver:\n",
    "        # ë¸Œë¼ìš°ì € ìœ ì§€ë¥¼ ìœ„í•´ driver.quit() ì£¼ì„ ì²˜ë¦¬\n",
    "        pass\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ 'ë¡œë§ˆ' ì „ì²´ íƒ­ í¬ë¡¤ë§ ì‹œì‘!\n",
      "======================================================================\n",
      "\n",
      "ğŸ“„ 1í˜ì´ì§€ ì²˜ë¦¬ ì¤‘... (ëª©í‘œ: 2ê°œ ë‚¨ìŒ)\n",
      "--------------------------------------------------\n",
      "ğŸ”— Activity URL ìˆ˜ì§‘ ì¤‘...\n",
      "   âœ… Activity URL 14ê°œ ìˆ˜ì§‘\n",
      "   ğŸ“Š 1í˜ì´ì§€ì—ì„œ Activity 14ê°œ ë°œê²¬\n",
      "\n",
      "   ğŸ” 1ìœ„ í¬ë¡¤ë§ ì¤‘... (1/14)\n",
      "      URL: https://www.klook.com/ko/activity/15699-colosseum-skip-line-...\n",
      "ğŸ“Š ìƒí’ˆ ë°ì´í„° ì¶”ì¶œ ì‹œì‘ (ìˆœìœ„: 1)\n",
      "  ğŸ“ ìƒí’ˆëª… ì¶”ì¶œ ì¤‘...\n",
      "    âœ… ìƒí’ˆëª…: ë¡œë§ˆ ì½œë¡œì„¸ì›€ & í¬ë¡œ ë¡œë§ˆë…¸ & íŒ”ë¼í‹°ë…¸ ì–¸ë• ì…ì¥ê¶Œ (ì½œë¡œì„¸ì›€ í†µí•©ê¶Œ)...\n",
      "  ğŸ’° ê°€ê²© ì¶”ì¶œ ì¤‘...\n",
      "    âœ… ê°€ê²©: â‚©42,300\n",
      "  â­ í‰ì  ì¶”ì¶œ ì¤‘...\n",
      "    âœ… í‰ì : 4.3/5\n",
      "  ğŸ’¬ ë¦¬ë·° ìˆ˜ ì¶”ì¶œ ì¤‘...\n",
      "    âœ… ë¦¬ë·° ìˆ˜: 2\n",
      "  ğŸ·ï¸ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ ì¤‘...\n",
      "    âœ… ì¹´í…Œê³ ë¦¬: Klook Travel > ë¡œë§ˆ > ì´íƒˆë¦¬ì•„\n",
      "  âœ¨ í•˜ì´ë¼ì´íŠ¸ ì •ë³´ ìˆ˜ì§‘ ì¤‘...\n",
      "    ğŸ“Š í¼ì¹˜ê¸° ë²„íŠ¼ ìƒíƒœ: ìˆìŒ\n",
      "    ğŸ”½ ê¸´ ë‚´ìš© - í¼ì¹˜ê¸° ë²„íŠ¼ í´ë¦­ í›„ ëª¨ë‹¬ ìˆ˜ì§‘\n",
      "    âœ… ì „ì²´ í•˜ì´ë¼ì´íŠ¸ ìˆ˜ì§‘ ì™„ë£Œ (ê¸¸ì´: 206ì)\n",
      "  âœ¨ ìƒí’ˆ íŠ¹ì§• ì¶”ì¶œ ì¤‘...\n",
      "    âš ï¸ íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨\n",
      "  ğŸŒ ì–¸ì–´ ì •ë³´ ìˆ˜ì§‘ ì¤‘...\n",
      "    âœ… ì–¸ì–´: í•œêµ­ì–´ (URL ê¸°ë°˜)\n",
      "âœ… ìƒí’ˆ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ\n",
      "    ğŸ“¥ ë©”ì¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...\n",
      "      âœ… main ì´ë¯¸ì§€ ì €ì¥: FCO_0001.jpg (26.5KB)\n",
      "    ğŸ“¥ ì¸ë„¤ì¼ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...\n",
      "      âœ… thumb ì´ë¯¸ì§€ ì €ì¥: FCO_0001_thumb.jpg (7.4KB)\n",
      "    âœ… ë“€ì–¼ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: ë©”ì¸ + ì¸ë„¤ì¼\n",
      "      âœ… 1ìœ„ ìˆ˜ì§‘ ì™„ë£Œ (ë²ˆí˜¸: 1, ì´ 1/2)\n",
      "\n",
      "   ğŸ” 2ìœ„ í¬ë¡¤ë§ ì¤‘... (2/14)\n",
      "      URL: https://www.klook.com/ko/activity/75019-vatican-tour-italy/...\n",
      "ğŸ“Š ìƒí’ˆ ë°ì´í„° ì¶”ì¶œ ì‹œì‘ (ìˆœìœ„: 2)\n",
      "  ğŸ“ ìƒí’ˆëª… ì¶”ì¶œ ì¤‘...\n",
      "    âœ… ìƒí’ˆëª…: [í•œêµ­ì–´ ê°€ì´ë“œ & ë¦¬ë·° ì´ë²¤íŠ¸][í—¬ë¡œìš°íŠ¸ë˜ë¸”] ì´íƒˆë¦¬ì•„ ë°”í‹°ì¹¸ ì˜¤ì „ ë°˜ì¼ íŒ¨ìŠ¤íŠ¸íŠ¸ë™ íˆ¬ì–´...\n",
      "  ğŸ’° ê°€ê²© ì¶”ì¶œ ì¤‘...\n",
      "    âœ… ê°€ê²©: â‚©65,000\n",
      "  â­ í‰ì  ì¶”ì¶œ ì¤‘...\n",
      "    âœ… í‰ì : 4.8/5\n",
      "  ğŸ’¬ ë¦¬ë·° ìˆ˜ ì¶”ì¶œ ì¤‘...\n",
      "    âœ… ë¦¬ë·° ìˆ˜: 141\n",
      "  ğŸ·ï¸ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ ì¤‘...\n",
      "    âœ… ì¹´í…Œê³ ë¦¬: ì¼ì¼ íˆ¬ì–´ > íˆ¬ì–´ & ì²´í—˜ > ì´íƒˆë¦¬ì•„\n",
      "  âœ¨ í•˜ì´ë¼ì´íŠ¸ ì •ë³´ ìˆ˜ì§‘ ì¤‘...\n",
      "    ğŸ“Š í¼ì¹˜ê¸° ë²„íŠ¼ ìƒíƒœ: ìˆìŒ\n",
      "    ğŸ”½ ê¸´ ë‚´ìš© - í¼ì¹˜ê¸° ë²„íŠ¼ í´ë¦­ í›„ ëª¨ë‹¬ ìˆ˜ì§‘\n",
      "    âœ… ì „ì²´ í•˜ì´ë¼ì´íŠ¸ ìˆ˜ì§‘ ì™„ë£Œ (ê¸¸ì´: 144ì)\n",
      "  âœ¨ ìƒí’ˆ íŠ¹ì§• ì¶”ì¶œ ì¤‘...\n",
      "    âš ï¸ íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨\n",
      "  ğŸŒ ì–¸ì–´ ì •ë³´ ìˆ˜ì§‘ ì¤‘...\n",
      "    âœ… ì–¸ì–´: í•œêµ­ì–´ (URL ê¸°ë°˜)\n",
      "âœ… ìƒí’ˆ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ\n",
      "    ğŸ“¥ ë©”ì¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...\n",
      "      âœ… main ì´ë¯¸ì§€ ì €ì¥: FCO_0002.jpg (27.3KB)\n",
      "    ğŸ“¥ ì¸ë„¤ì¼ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...\n",
      "      âœ… thumb ì´ë¯¸ì§€ ì €ì¥: FCO_0002_thumb.jpg (9.0KB)\n",
      "    âœ… ë“€ì–¼ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: ë©”ì¸ + ì¸ë„¤ì¼\n",
      "      âœ… 2ìœ„ ìˆ˜ì§‘ ì™„ë£Œ (ë²ˆí˜¸: 2, ì´ 2/2)\n",
      "\n",
      "ğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ!\n",
      "\n",
      "ğŸŒ 'ë¡œë§ˆ' í¬ë¡¤ë§ ì™„ë£Œ í›„ 'ì´íƒˆë¦¬ì•„' êµ­ê°€ë³„ í†µí•© CSV ìë™ ìƒì„±...\n",
      "\n",
      "ğŸŒ 'ì´íƒˆë¦¬ì•„' êµ­ê°€ë³„ í†µí•© CSV ìƒì„± ì¤‘...\n",
      "   ğŸ—ºï¸ 'ì´íƒˆë¦¬ì•„' ëŒ€ë¥™: ìœ ëŸ½\n",
      "   ğŸ“‚ 'ìœ ëŸ½/ì´íƒˆë¦¬ì•„' ê²½ë¡œ ë°œê²¬\n",
      "   ğŸ“Š ë°œê²¬ëœ ë„ì‹œ: 1ê°œ\n",
      "      - ë¡œë§ˆ\n",
      "      ğŸ“„ ë¡œë§ˆ: 2ê°œ ìƒí’ˆ\n",
      "   âœ… í†µí•© CSV ìƒì„± ì™„ë£Œ!\n",
      "      ğŸ“Š ì´ ìƒí’ˆ: 2ê°œ\n",
      "      ğŸ“ ì €ì¥ ìœ„ì¹˜: c:\\Users\\redsk\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\mikael_project\\klook\\data\\ìœ ëŸ½\\ì´íƒˆë¦¬ì•„\\ì´íƒˆë¦¬ì•„_í†µí•©_klook_products.csv\n",
      "   âœ… 'ì´íƒˆë¦¬ì•„' êµ­ê°€ë³„ í†µí•© CSV ìë™ ìƒì„± ì™„ë£Œ!\n",
      "ğŸ”š ë“œë¼ì´ë²„ ì¢…ë£Œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ê·¸ë£¹ 4 ===== ë©”ì¸ í¬ë¡¤ë§ ì‹¤í–‰ (ì™„ë²½í•œ ë²ˆí˜¸ ì—°ì†ì„± ë³´ì¥) =====\n",
    "print(f\"ğŸš€ '{CITY_NAME}' {TARGET_TAB} íƒ­ í¬ë¡¤ë§ ì‹œì‘!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥ìš© ë³€ìˆ˜\n",
    "crawled_products = []  # í¬ë¡¤ë§ëœ ìƒí’ˆ ë°ì´í„°\n",
    "ranking_data = []      # ìˆœìœ„ ì •ë³´\n",
    "collected_images = []  # ì´ë¯¸ì§€ ì •ë³´\n",
    "\n",
    "# í¬ë¡¤ë§ ìƒíƒœ ë³€ìˆ˜\n",
    "current_rank = 1\n",
    "current_page = 1\n",
    "total_collected = 0\n",
    "current_listing_url = listing_page_url\n",
    "\n",
    "try:\n",
    "    while total_collected < TARGET_PRODUCTS and current_page <= MAX_PAGES:\n",
    "        print(f\"\\nğŸ“„ {current_page}í˜ì´ì§€ ì²˜ë¦¬ ì¤‘... (ëª©í‘œ: {TARGET_PRODUCTS - total_collected}ê°œ ë‚¨ìŒ)\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # 1. í˜„ì¬ í˜ì´ì§€ì—ì„œ Activity URL ìˆ˜ì§‘\n",
    "        activity_urls = collect_activity_urls_only(driver)\n",
    "\n",
    "        if not activity_urls:\n",
    "            print(\"   âš ï¸ Activity URLì´ ì—†ìŒ - ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™\")\n",
    "            success, current_listing_url = go_to_next_page(driver, current_listing_url)\n",
    "            if not success:\n",
    "                print(\"   âŒ ë” ì´ìƒ í˜ì´ì§€ê°€ ì—†ìŒ\")\n",
    "                break\n",
    "            current_page += 1\n",
    "            continue\n",
    "\n",
    "        print(f\"   ğŸ“Š {current_page}í˜ì´ì§€ì—ì„œ Activity {len(activity_urls)}ê°œ ë°œê²¬\")\n",
    "\n",
    "        # 2. ê° Activity ìˆœì°¨ì ìœ¼ë¡œ í¬ë¡¤ë§\n",
    "        page_products = []  # í˜„ì¬ í˜ì´ì§€ì—ì„œ ìˆ˜ì§‘í•œ ìƒí’ˆë“¤\n",
    "        for i, url in enumerate(activity_urls):\n",
    "            if total_collected >= TARGET_PRODUCTS:\n",
    "                break\n",
    "\n",
    "            print(f\"\\n   ğŸ” {current_rank}ìœ„ í¬ë¡¤ë§ ì¤‘... ({i+1}/{len(activity_urls)})\")\n",
    "            print(f\"      URL: {url[:60]}...\")\n",
    "\n",
    "            # ì´ˆê³ ì† ì¤‘ë³µ ì²´í¬ (íŒŒì¼ ì¡´ì¬ í™•ì¸)\n",
    "            if is_url_processed_fast(url, CITY_NAME):\n",
    "                print(f\"      â­ï¸ {current_rank}ìœ„ ì¤‘ë³µ URL ê±´ë„ˆë›°ê¸°: {url[:50]}...\")\n",
    "                current_rank += 1\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # 2-1. ìƒí’ˆ í˜ì´ì§€ ì´ë™\n",
    "                driver.get(url)\n",
    "                time.sleep(random.uniform(2, 4))\n",
    "\n",
    "                # 2-2. ìƒí’ˆ ë°ì´í„° ì¶”ì¶œ\n",
    "                product_data = extract_all_product_data(driver, url, current_rank)\n",
    "\n",
    "                # ì˜¬ë°”ë¥¸ ë²ˆí˜¸ í• ë‹¹ (CSV ì—°ì†ì„± ë³´ì¥)\n",
    "                next_num = get_next_product_number(CITY_NAME)\n",
    "\n",
    "                # 2-3. ê¸°ë³¸ êµ¬ì¡° ìƒì„± ë° ë³‘í•©\n",
    "                base_data = create_product_data_structure(CITY_NAME, next_num, current_rank)\n",
    "                base_data.update(product_data)\n",
    "                base_data['íƒ­'] = TARGET_TAB\n",
    "\n",
    "                # 2-4. ì´ë¯¸ì§€ ì²˜ë¦¬ (ë„ì‹œì½”ë“œ ê¸°ë°˜ íŒŒì¼ëª… ì ìš©)\n",
    "                try:\n",
    "                    main_img, thumb_img = get_dual_image_urls_klook(driver)\n",
    "                    base_data['ë©”ì¸ì´ë¯¸ì§€'] = main_img or \"ì´ë¯¸ì§€ ì—†ìŒ\"\n",
    "                    base_data['ì¸ë„¤ì¼ì´ë¯¸ì§€'] = thumb_img or \"ì´ë¯¸ì§€ ì—†ìŒ\"\n",
    "\n",
    "                    # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ë„ì‹œì½”ë“œ ê¸°ë°˜ íŒŒì¼ëª…: KMJ_0001.jpg)\n",
    "                    if SAVE_IMAGES and (main_img or thumb_img):\n",
    "                        image_urls = {\"main\": main_img, \"thumb\": thumb_img}\n",
    "                        download_results = download_dual_images_klook(image_urls, next_num, CITY_NAME)\n",
    "\n",
    "                        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ê²°ê³¼ë¥¼ ë°ì´í„°ì— ë°˜ì˜\n",
    "                        if download_results.get(\"main\"):\n",
    "                            base_data['ë©”ì¸ì´ë¯¸ì§€_íŒŒì¼ëª…'] = download_results[\"main\"]\n",
    "                        if download_results.get(\"thumb\"):\n",
    "                            base_data['ì¸ë„¤ì¼ì´ë¯¸ì§€_íŒŒì¼ëª…'] = download_results[\"thumb\"]\n",
    "                except Exception as e:\n",
    "                    print(f\"      âš ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "                    base_data['ë©”ì¸ì´ë¯¸ì§€'] = \"ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨\"\n",
    "                    base_data['ì¸ë„¤ì¼ì´ë¯¸ì§€'] = \"ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨\"\n",
    "\n",
    "                # 2-5. CSV ì €ì¥ (êµ­ê°€ë³„ í†µí•© CSV ìë™ ìƒì„± í¬í•¨)\n",
    "                if save_to_csv_klook(base_data, CITY_NAME):\n",
    "                    page_products.append(base_data)\n",
    "\n",
    "                    # ì´ˆê³ ì† ì¤‘ë³µ ì²´í¬ ë§ˆí‚¹ (ì„±ê³µ ì‹œì—ë§Œ)\n",
    "                    mark_url_processed_fast(url, CITY_NAME, next_num, current_rank)\n",
    "\n",
    "                    # ë­í‚¹ ì •ë³´ ì €ì¥\n",
    "                    ranking_info = {\n",
    "                        \"url\": url,\n",
    "                        \"rank\": current_rank,\n",
    "                        \"tab\": TARGET_TAB,\n",
    "                        \"city\": CITY_NAME,\n",
    "                        \"page\": current_page,\n",
    "                        \"product_number\": next_num,  # ì‹¤ì œ í• ë‹¹ëœ ë²ˆí˜¸ ì €ì¥\n",
    "                        \"collected_at\": datetime.now().isoformat()\n",
    "                    }\n",
    "                    ranking_data.append(ranking_info)\n",
    "                    total_collected += 1\n",
    "                    print(f\"      âœ… {current_rank}ìœ„ ìˆ˜ì§‘ ì™„ë£Œ (ë²ˆí˜¸: {next_num}, ì´ {total_collected}/{TARGET_PRODUCTS})\")\n",
    "                else:\n",
    "                    print(f\"      âŒ {current_rank}ìœ„ ì €ì¥ ì‹¤íŒ¨\")\n",
    "\n",
    "                current_rank += 1\n",
    "\n",
    "                # ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€ê¸°\n",
    "                time.sleep(random.uniform(1, 3))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"      âŒ {current_rank}ìœ„ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}\")\n",
    "                current_rank += 1\n",
    "                continue\n",
    "\n",
    "        # 3. í˜ì´ì§€ ì™„ë£Œ í›„ ëª©ë¡í˜ì´ì§€ë¡œ ë³µê·€\n",
    "        if total_collected < TARGET_PRODUCTS and current_page < MAX_PAGES:\n",
    "            print(f\"\\nğŸ”„ {current_page}í˜ì´ì§€ ì™„ë£Œ - ëª©ë¡í˜ì´ì§€ë¡œ ë³µê·€...\")\n",
    "            driver.get(current_listing_url)\n",
    "            time.sleep(2)\n",
    "\n",
    "            # 4. ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™\n",
    "            success, new_listing_url = go_to_next_page(driver, current_listing_url)\n",
    "            if success:\n",
    "                current_listing_url = new_listing_url\n",
    "                current_page += 1\n",
    "                time.sleep(3)  # ë‹¤ìŒ í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°\n",
    "            else:\n",
    "                print(\"   âŒ ë” ì´ìƒ í˜ì´ì§€ê°€ ì—†ìŒ\")\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print(f\"\\nğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ!\")\n",
    "\n",
    "    # êµ­ê°€ë³„ í†µí•© CSV ìë™ ìƒì„±\n",
    "    try:\n",
    "        from src.utils.file_handler import auto_create_country_csv_after_crawling\n",
    "        auto_create_country_csv_after_crawling(CITY_NAME)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ êµ­ê°€ë³„ í†µí•© CSV ìë™ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "finally:\n",
    "    # ë“œë¼ì´ë²„ ì¢…ë£Œ\n",
    "    if driver:\n",
    "        # ë¸Œë¼ìš°ì € ìœ ì§€ë¥¼ ìœ„í•´ driver.quit() ì£¼ì„ ì²˜ë¦¬\n",
    "        print(\"ğŸ”š ë“œë¼ì´ë²„ ì¢…ë£Œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ—ºï¸ Sitemap ê¸°ë°˜ ì¶”ê°€ URL ìˆ˜ì§‘ ì‹œì‘!\n",
      "======================================================================\n",
      "ğŸ“Š í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ URL: 2ê°œ\n",
      "ğŸ—ºï¸ 'ë¡œë§ˆ' Sitemap URL ìˆ˜ì§‘ ì‹œì‘...\n",
      "   ğŸš« ì œì™¸í•  URL: 2ê°œ\n",
      "  ğŸ“‹ Sitemap ì²˜ë¦¬ ì¤‘: https://www.klook.com/sitemap.xml\n",
      "    âš ï¸ Sitemap ì ‘ê·¼ ì‹¤íŒ¨: HTTP 404\n",
      "  ğŸ“‹ Sitemap ì²˜ë¦¬ ì¤‘: https://www.klook.com/sitemap-activities.xml\n",
      "    âš ï¸ Sitemap ì ‘ê·¼ ì‹¤íŒ¨: HTTP 404\n",
      "  ğŸ“‹ Sitemap ì²˜ë¦¬ ì¤‘: https://www.klook.com/sitemap-ko.xml\n",
      "    âš ï¸ Sitemap ì ‘ê·¼ ì‹¤íŒ¨: HTTP 404\n",
      "  ğŸ“‹ Sitemap ì²˜ë¦¬ ì¤‘: https://www.klook.com/sitemap-ë¡œë§ˆ.xml\n",
      "    âš ï¸ Sitemap ì ‘ê·¼ ì‹¤íŒ¨: HTTP 404\n",
      "ğŸ‰ Sitemap ìˆ˜ì§‘ ì™„ë£Œ: 0ê°œ ìƒˆë¡œìš´ URL\n",
      "âš ï¸ Sitemapì—ì„œ ìƒˆë¡œìš´ URLì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ Sitemap ìˆ˜ì§‘ ë‹¨ê³„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ê·¸ë£¹ 4.5 ===== Sitemap ê¸°ë°˜ ì¶”ê°€ ìˆ˜ì§‘ (ì™„ì „í•œ ì¤‘ë³µ ì²´í¬ í¬í•¨) =====\n",
    "print(f\"\\nğŸ—ºï¸ Sitemap ê¸°ë°˜ ì¶”ê°€ URL ìˆ˜ì§‘ ì‹œì‘!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# í˜ì´ì§€ë„¤ì´ì…˜ìœ¼ë¡œ ìˆ˜ì§‘í•œ URLë“¤ ì •ë¦¬ (ì¤‘ë³µ ì œì™¸ìš©)\n",
    "collected_urls = set()\n",
    "for item in ranking_data:\n",
    "    collected_urls.add(item['url'])\n",
    "\n",
    "print(f\"ğŸ“Š í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ URL: {len(collected_urls)}ê°œ\")\n",
    "\n",
    "try:\n",
    "    # Sitemap ê¸°ëŠ¥ import\n",
    "    from src.scraper.url_manager import collect_urls_from_sitemap, save_urls_to_collection\n",
    "\n",
    "    # Sitemapì—ì„œ ìƒˆë¡œìš´ URL ìˆ˜ì§‘ (ì¤‘ë³µ ì œì™¸)\n",
    "    sitemap_urls = collect_urls_from_sitemap(\n",
    "        city_name=CITY_NAME,\n",
    "        exclude_urls=list(collected_urls),  # ì´ë¯¸ ìˆ˜ì§‘í•œ URL ì œì™¸\n",
    "        limit=200  # Sitemapì—ì„œ ìµœëŒ€ 200ê°œê¹Œì§€\n",
    "    )\n",
    "\n",
    "    if sitemap_urls:\n",
    "        print(f\"ğŸ‰ Sitemapì—ì„œ {len(sitemap_urls)}ê°œ ìƒˆë¡œìš´ URL ë°œê²¬!\")\n",
    "\n",
    "        # Sitemap URL ì»¬ë ‰ì…˜ ì €ì¥\n",
    "        save_urls_to_collection(sitemap_urls, CITY_NAME, \"sitemap_additional\")\n",
    "\n",
    "        # ëª©í‘œ ìˆ˜ëŸ‰ì— ë„ë‹¬í•˜ì§€ ëª»í–ˆë‹¤ë©´ Sitemap URLë¡œ ì¶”ê°€ ìˆ˜ì§‘\n",
    "        remaining_target = TARGET_PRODUCTS - total_collected\n",
    "\n",
    "        if remaining_target > 0 and sitemap_urls:\n",
    "            print(f\"\\nğŸš€ Sitemap URLë¡œ ì¶”ê°€ í¬ë¡¤ë§ ì‹œì‘!\")\n",
    "            print(f\"   ğŸ¯ ë‚¨ì€ ëª©í‘œ: {remaining_target}ê°œ\")\n",
    "            print(f\"   ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ Sitemap URL: {len(sitemap_urls)}ê°œ\")\n",
    "\n",
    "            # ë“œë¼ì´ë²„ ì¬ì´ˆê¸°í™” (ì´ì „ì— ì¢…ë£Œë˜ì—ˆì„ ìˆ˜ ìˆìŒ)\n",
    "            driver = setup_driver()\n",
    "            if not driver:\n",
    "                print(\"âŒ ë“œë¼ì´ë²„ ì¬ì´ˆê¸°í™” ì‹¤íŒ¨\")\n",
    "                raise Exception(\"ë“œë¼ì´ë²„ ì¬ì´ˆê¸°í™” ì‹¤íŒ¨\")\n",
    "\n",
    "            print(\"âœ… ë“œë¼ì´ë²„ ì¬ì´ˆê¸°í™” ì„±ê³µ\")\n",
    "\n",
    "            # Sitemap URLë“¤ë¡œ ì¶”ê°€ ìˆ˜ì§‘\n",
    "            sitemap_collected = 0\n",
    "            for i, url in enumerate(sitemap_urls):\n",
    "                if sitemap_collected >= remaining_target:\n",
    "                    break\n",
    "\n",
    "                print(f\"\\n   ğŸ” Sitemap {current_rank}ìœ„ í¬ë¡¤ë§ ì¤‘... ({i+1}/{len(sitemap_urls)})\")\n",
    "                print(f\"      URL: {url[:60]}...\")\n",
    "\n",
    "                # ë°©ë¬¸ ì „ ì¤‘ë³µ ì²´í¬ ì¶”ê°€ (ì´ˆê³ ì†)\n",
    "                if is_url_processed_fast(url, CITY_NAME):\n",
    "                    print(f\"      â­ï¸ Sitemap {current_rank}ìœ„ ì¤‘ë³µ URL ê±´ë„ˆë›°ê¸°: {url[:50]}...\")\n",
    "                    current_rank += 1\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    # ìƒí’ˆ í˜ì´ì§€ ì´ë™\n",
    "                    driver.get(url)\n",
    "                    time.sleep(random.uniform(2, 4))\n",
    "\n",
    "                    # Activity URLì¸ì§€ í™•ì¸ (í˜¸í…”, ë Œí„°ì¹´ ì œì™¸)\n",
    "                    excluded_keywords = ['hotel', 'car-rental', 'transport', 'transfer']\n",
    "                    if any(keyword in url.lower() for keyword in excluded_keywords):\n",
    "                        print(f\"      â­ï¸ ë¹„Activity URL ê±´ë„ˆëœ€\")\n",
    "                        continue\n",
    "\n",
    "                    # ìƒí’ˆ ë°ì´í„° ì¶”ì¶œ\n",
    "                    product_data = extract_all_product_data(driver, url, current_rank)\n",
    "\n",
    "                    # ì˜¬ë°”ë¥¸ ë²ˆí˜¸ í• ë‹¹ (Sitemapë„ CSV ì—°ì†ì„± ë³´ì¥)\n",
    "                    next_num = get_next_product_number(CITY_NAME)\n",
    "\n",
    "                    # ê¸°ë³¸ êµ¬ì¡° ìƒì„± ë° ë³‘í•©\n",
    "                    base_data = create_product_data_structure(CITY_NAME, next_num, current_rank)\n",
    "                    base_data.update(product_data)\n",
    "                    base_data['íƒ­'] = f\"{TARGET_TAB} (Sitemap)\"  # Sitemap ì¶œì²˜ í‘œì‹œ\n",
    "\n",
    "                    # ì´ë¯¸ì§€ ì²˜ë¦¬ (ë„ì‹œì½”ë“œ ê¸°ë°˜ íŒŒì¼ëª… ì ìš©)\n",
    "                    try:\n",
    "                        main_img, thumb_img = get_dual_image_urls_klook(driver)\n",
    "                        base_data['ë©”ì¸ì´ë¯¸ì§€'] = main_img or \"ì´ë¯¸ì§€ ì—†ìŒ\"\n",
    "                        base_data['ì¸ë„¤ì¼ì´ë¯¸ì§€'] = thumb_img or \"ì´ë¯¸ì§€ ì—†ìŒ\"\n",
    "\n",
    "                        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë²ˆí˜¸ ìˆ˜ì •\n",
    "                        if SAVE_IMAGES and (main_img or thumb_img):\n",
    "                            image_urls = {\"main\": main_img, \"thumb\": thumb_img}\n",
    "                            download_results = download_dual_images_klook(image_urls, next_num, CITY_NAME)\n",
    "\n",
    "                            # Sitemap ì¶œì²˜ í‘œì‹œë¥¼ ìœ„í•œ íŒŒì¼ëª… ì—…ë°ì´íŠ¸\n",
    "                            if download_results.get(\"main\"):\n",
    "                                base_data['ë©”ì¸ì´ë¯¸ì§€_íŒŒì¼ëª…'] = download_results[\"main\"]\n",
    "                            if download_results.get(\"thumb\"):\n",
    "                                base_data['ì¸ë„¤ì¼ì´ë¯¸ì§€_íŒŒì¼ëª…'] = download_results[\"thumb\"]\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"      âš ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "                        base_data['ë©”ì¸ì´ë¯¸ì§€'] = \"ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨\"\n",
    "                        base_data['ì¸ë„¤ì¼ì´ë¯¸ì§€'] = \"ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨\"\n",
    "\n",
    "                    # CSV ì €ì¥\n",
    "                    if save_to_csv_klook(base_data, CITY_NAME):\n",
    "                        # ì²˜ë¦¬ í›„ ìºì‹œ ë§ˆí‚¹ ì¶”ê°€ (ì„±ê³µ ì‹œì—ë§Œ)\n",
    "                        mark_url_processed_fast(url, CITY_NAME, next_num, current_rank)\n",
    "\n",
    "                        # ë­í‚¹ ì •ë³´ ì €ì¥ (Sitemap ì¶œì²˜)\n",
    "                        ranking_info = {\n",
    "                            \"url\": url,\n",
    "                            \"rank\": current_rank,\n",
    "                            \"tab\": f\"{TARGET_TAB} (Sitemap)\",\n",
    "                            \"city\": CITY_NAME,\n",
    "                            \"source\": \"sitemap\",\n",
    "                            \"product_number\": next_num,  # ì‹¤ì œ í• ë‹¹ëœ ë²ˆí˜¸ ì €ì¥\n",
    "                            \"collected_at\": datetime.now().isoformat()\n",
    "                        }\n",
    "                        ranking_data.append(ranking_info)\n",
    "\n",
    "                        sitemap_collected += 1\n",
    "                        total_collected += 1\n",
    "                        print(f\"      âœ… Sitemap {current_rank}ìœ„ ìˆ˜ì§‘ ì™„ë£Œ (ë²ˆí˜¸: {next_num}, ì´ {total_collected}/{TARGET_PRODUCTS})\")\n",
    "                    else:\n",
    "                        print(f\"      âŒ Sitemap {current_rank}ìœ„ ì €ì¥ ì‹¤íŒ¨\")\n",
    "\n",
    "                    current_rank += 1\n",
    "\n",
    "                    # ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€ê¸°\n",
    "                    time.sleep(random.uniform(2, 4))\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"      âŒ Sitemap {current_rank}ìœ„ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}\")\n",
    "                    current_rank += 1\n",
    "                    continue\n",
    "\n",
    "            # ë“œë¼ì´ë²„ ì¢…ë£Œ\n",
    "            if driver:\n",
    "                # ë¸Œë¼ìš°ì € ìœ ì§€ë¥¼ ìœ„í•´ driver.quit() ì£¼ì„ ì²˜ë¦¬\n",
    "                print(\"ğŸ”š Sitemap í¬ë¡¤ë§ ë“œë¼ì´ë²„ ì¢…ë£Œ ì™„ë£Œ\")\n",
    "\n",
    "            print(f\"\\nğŸ‰ Sitemap ì¶”ê°€ ìˆ˜ì§‘ ì™„ë£Œ!\")\n",
    "            print(f\"   ğŸ“Š Sitemapìœ¼ë¡œ {sitemap_collected}ê°œ ì¶”ê°€ ìˆ˜ì§‘\")\n",
    "            print(f\"   ğŸ¯ ì „ì²´ ìˆ˜ì§‘ëŸ‰: {total_collected}/{TARGET_PRODUCTS}\")\n",
    "\n",
    "            # Sitemap ìˆ˜ì§‘ í›„ì—ë„ êµ­ê°€ë³„ í†µí•© CSV ìë™ ìƒì„±\n",
    "            try:\n",
    "                from src.utils.file_handler import auto_create_country_csv_after_crawling\n",
    "                auto_create_country_csv_after_crawling(CITY_NAME)\n",
    "                print(\"   âœ… êµ­ê°€ë³„ í†µí•© CSV ì—…ë°ì´íŠ¸ ì™„ë£Œ\")\n",
    "            except Exception as e:\n",
    "                print(f\"   âš ï¸ êµ­ê°€ë³„ í†µí•© CSV ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"\\nâœ… ëª©í‘œ ìˆ˜ëŸ‰ ë‹¬ì„±ìœ¼ë¡œ Sitemap ì¶”ê°€ ìˆ˜ì§‘ ìƒëµ\")\n",
    "\n",
    "    else:\n",
    "        print(f\"âš ï¸ Sitemapì—ì„œ ìƒˆë¡œìš´ URLì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Sitemap ê¸°ëŠ¥ import ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ’¡ requests, beautifulsoup4ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Sitemap ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    if 'driver' in locals():\n",
    "        # ë¸Œë¼ìš°ì € ìœ ì§€ë¥¼ ìœ„í•´ driver.quit() ì£¼ì„ ì²˜ë¦¬\n",
    "        pass\n",
    "\n",
    "print(f\"\\nğŸ Sitemap ìˆ˜ì§‘ ë‹¨ê³„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë­í‚¹ ë°ì´í„° ì €ì¥ ì¤‘...\n",
      "âœ… ë­í‚¹ ë°ì´í„° ì €ì¥ ì™„ë£Œ: ranking_data\\FCO_ì „ì²´_ranking_20250827_004929.json\n",
      "   ğŸ“Š ì €ì¥ëœ ë­í‚¹: 2ê°œ\n"
     ]
    }
   ],
   "source": [
    "# ê·¸ë£¹ 5 ==== ë­í‚¹ ë°ì´í„° ì €ì¥ =====\n",
    "if ranking_data:\n",
    "    print(\"ğŸ“Š ë­í‚¹ ë°ì´í„° ì €ì¥ ì¤‘...\")\n",
    "    \n",
    "    # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "    ranking_dir = \"ranking_data\"\n",
    "    os.makedirs(ranking_dir, exist_ok=True)\n",
    "    \n",
    "    # íŒŒì¼ëª… ìƒì„±\n",
    "    from src.config import get_city_code\n",
    "    city_code = get_city_code(CITY_NAME)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    tab_safe = TARGET_TAB.replace(\"&\", \"and\").replace(\" \", \"_\")\n",
    "    filename = f\"{city_code}_{tab_safe}_ranking_{timestamp}.json\"\n",
    "    filepath = os.path.join(ranking_dir, filename)\n",
    "    \n",
    "    # ë­í‚¹ ì •ë³´ êµ¬ì¡°í™”\n",
    "    ranking_summary = {\n",
    "        \"city_name\": CITY_NAME,\n",
    "        \"city_code\": city_code,\n",
    "        \"tab_name\": TARGET_TAB,\n",
    "        \"target_products\": TARGET_PRODUCTS,\n",
    "        \"total_collected\": len(ranking_data),\n",
    "        \"pages_processed\": current_page,\n",
    "        \"collected_at\": datetime.now().isoformat(),\n",
    "        \"ranking_data\": ranking_data\n",
    "    }\n",
    "    \n",
    "    # JSON ì €ì¥\n",
    "    try:\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(ranking_summary, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"âœ… ë­í‚¹ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filepath}\")\n",
    "        print(f\"   ğŸ“Š ì €ì¥ëœ ë­í‚¹: {len(ranking_data)}ê°œ\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë­í‚¹ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "else:\n",
    "    print(\"âš ï¸ ì €ì¥í•  ë­í‚¹ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ‰ KLOOK í¬ë¡¤ë§ ì™„ë£Œ - ë¡œë§ˆ (ì „ì²´ íƒ­)\n",
      "======================================================================\n",
      "ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼:\n",
      "   ğŸ¯ ëª©í‘œ: 2ê°œ\n",
      "   âœ… ì‹¤ì œ ìˆ˜ì§‘: 2ê°œ\n",
      "   ğŸ“„ ì²˜ë¦¬í•œ í˜ì´ì§€: 1ê°œ\n",
      "   ğŸ† ìˆœìœ„ ë²”ìœ„: 1ìœ„ ~ 2ìœ„\n",
      "\n",
      "ğŸ“ ì €ì¥ëœ íŒŒì¼:\n",
      "   ğŸ“„ CSV: 2ê°œ ìƒí’ˆ ì €ì¥ë¨\n",
      "   ğŸ’¾ í¬ê¸°: 2713 bytes\n",
      "   ğŸ† ë­í‚¹ JSON: 2ê°œ ìˆœìœ„ ì •ë³´ ì €ì¥ë¨\n",
      "   ğŸ“¸ ì´ë¯¸ì§€: ì €ì¥ëœ íŒŒì¼ ì—†ìŒ\n",
      "\n",
      "ğŸ¯ ì„±ê³µë¥ : 100.0%\n",
      "\n",
      "âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ - ê°€ê³µ ë‹¨ê³„ë¡œ ì§„í–‰ ê°€ëŠ¥!\n"
     ]
    }
   ],
   "source": [
    "# ===== í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½ =====\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"ğŸ‰ KLOOK í¬ë¡¤ë§ ì™„ë£Œ - {CITY_NAME} ({TARGET_TAB} íƒ­)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼:\")\n",
    "print(f\"   ğŸ¯ ëª©í‘œ: {TARGET_PRODUCTS}ê°œ\")\n",
    "print(f\"   âœ… ì‹¤ì œ ìˆ˜ì§‘: {total_collected}ê°œ\")\n",
    "print(f\"   ğŸ“„ ì²˜ë¦¬í•œ í˜ì´ì§€: {current_page}ê°œ\")\n",
    "print(f\"   ğŸ† ìˆœìœ„ ë²”ìœ„: 1ìœ„ ~ {current_rank-1}ìœ„\")\n",
    "\n",
    "print(f\"\\nğŸ“ ì €ì¥ëœ íŒŒì¼:\")\n",
    "\n",
    "# CSV íŒŒì¼ í™•ì¸\n",
    "try:\n",
    "    from src.utils.file_handler import get_csv_stats\n",
    "    csv_stats = get_csv_stats(CITY_NAME)\n",
    "    if isinstance(csv_stats, dict) and 'error' not in csv_stats:\n",
    "        print(f\"   ğŸ“„ CSV: {csv_stats.get('total_products', 0)}ê°œ ìƒí’ˆ ì €ì¥ë¨\")\n",
    "        print(f\"   ğŸ’¾ í¬ê¸°: {csv_stats.get('file_size', 0)} bytes\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸ CSV: íŒŒì¼ í™•ì¸ ì‹¤íŒ¨\")\n",
    "except Exception as e:\n",
    "    print(f\"   âŒ CSV ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# ë­í‚¹ íŒŒì¼ í™•ì¸\n",
    "if ranking_data:\n",
    "    print(f\"   ğŸ† ë­í‚¹ JSON: {len(ranking_data)}ê°œ ìˆœìœ„ ì •ë³´ ì €ì¥ë¨\")\n",
    "\n",
    "# ì´ë¯¸ì§€ ì €ì¥ ê²°ê³¼ (klook_img í´ë” ì‚¬ìš©)\n",
    "if SAVE_IMAGES:\n",
    "    image_dir = f\"klook_img/{CITY_NAME}\"\n",
    "    if os.path.exists(image_dir):\n",
    "        image_count = len([f for f in os.listdir(image_dir) if f.endswith('.jpg')])\n",
    "        print(f\"   ğŸ“¸ ì´ë¯¸ì§€: {image_count}ê°œ ì €ì¥ë¨\")\n",
    "    else:\n",
    "        print(f\"   ğŸ“¸ ì´ë¯¸ì§€: ì €ì¥ëœ íŒŒì¼ ì—†ìŒ\")\n",
    "else:\n",
    "    print(f\"   ğŸ“¸ ì´ë¯¸ì§€: URLë§Œ ì €ì¥ (ë‹¤ìš´ë¡œë“œ ì•ˆí•¨)\")\n",
    "\n",
    "print(f\"\\nğŸ¯ ì„±ê³µë¥ : {(total_collected/TARGET_PRODUCTS*100):.1f}%\")\n",
    "\n",
    "if total_collected < TARGET_PRODUCTS:\n",
    "    print(f\"\\nğŸ’¡ ì°¸ê³ ì‚¬í•­:\")\n",
    "    print(f\"   â€¢ ëª©í‘œë³´ë‹¤ ì ê²Œ ìˆ˜ì§‘ëœ ì´ìœ : Activity ìƒí’ˆ ë¶€ì¡± ë˜ëŠ” í˜ì´ì§€ í•œê³„\")\n",
    "    print(f\"   â€¢ í˜¸í…”, ë Œí„°ì¹´ëŠ” ì œì™¸í•˜ê³  Activityë§Œ ìˆ˜ì§‘í•¨\")\n",
    "    print(f\"   â€¢ ë‹¤ë¥¸ íƒ­ì—ì„œ ì¶”ê°€ ìˆ˜ì§‘ì„ ì›í•˜ë©´ TARGET_TABì„ ë³€ê²½í•˜ì—¬ ì¬ì‹¤í–‰\")\n",
    "\n",
    "print(f\"\\nâœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ - ê°€ê³µ ë‹¨ê³„ë¡œ ì§„í–‰ ê°€ëŠ¥!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ ìˆ˜ì§‘ëœ ìƒí’ˆ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 5ê°œ):\n",
      "--------------------------------------------------\n",
      "1ìœ„: https://www.klook.com/ko/activity/15699-colosseum-...\n",
      "      íƒ­: ì „ì²´, í˜ì´ì§€: 1\n",
      "      ìˆ˜ì§‘ì‹œê°„: 2025-08-27T00:49:12\n",
      "\n",
      "2ìœ„: https://www.klook.com/ko/activity/75019-vatican-to...\n",
      "      íƒ­: ì „ì²´, í˜ì´ì§€: 1\n",
      "      ìˆ˜ì§‘ì‹œê°„: 2025-08-27T00:49:25\n",
      "\n",
      "\n",
      "ğŸ“Š CSV ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\n",
      "   ì»¬ëŸ¼: ['ë²ˆí˜¸', 'ë„ì‹œID', 'ë„ì‹œëª…', 'ëŒ€ë¥™', 'êµ­ê°€', 'ìˆœìœ„', 'ìˆ˜ì§‘ì¼ì‹œ', 'ìƒí’ˆëª…', 'ê°€ê²©', 'í†µí™”', 'í‰ì ', 'ë¦¬ë·°ìˆ˜', 'ì¹´í…Œê³ ë¦¬', 'í•˜ì´ë¼ì´íŠ¸', 'íŠ¹ì§•', 'ì–¸ì–´', 'íƒœê·¸', 'ì„¤ëª…', 'URL', 'ìƒí’ˆë²ˆí˜¸', 'ë©”ì¸ì´ë¯¸ì§€', 'ì¸ë„¤ì¼ì´ë¯¸ì§€', 'ì£¼ì†Œ', 'ìœ„ë„', 'ê²½ë„', 'ì˜ˆì•½ê°€ëŠ¥ì—¬ë¶€', 'ì·¨ì†Œì •ì±…', 'ì†Œìš”ì‹œê°„', 'í¬í•¨ì‚¬í•­', 'ì œì™¸ì‚¬í•­', 'ì£¼ì˜ì‚¬í•­', 'ë°ì´í„°ì†ŒìŠ¤', 'í¬ë¡¤ë§ë²„ì „', 'í•´ì‹œê°’', 'íƒ­', 'ë©”ì¸ì´ë¯¸ì§€_íŒŒì¼ëª…', 'ì¸ë„¤ì¼ì´ë¯¸ì§€_íŒŒì¼ëª…']\n",
      "   í–‰ ìˆ˜: 2\n",
      "\n",
      "ìƒìœ„ 3ê°œ ìƒí’ˆ:\n",
      "   1ìœ„: ë¡œë§ˆ ì½œë¡œì„¸ì›€ & í¬ë¡œ ë¡œë§ˆë…¸ & íŒ”ë¼í‹°ë…¸ ì–¸ë• ì…ì¥ê¶Œ...\n",
      "         ê°€ê²©: â‚©42,300, í‰ì : 4.3/5\n",
      "         í•˜ì´ë¼ì´íŠ¸: ì½œë¡œì„¸ì›€, í¬ë¡œ ë¡œë§ˆë…¸, íŒ”ë¼í‹°ë…¸ ì–¸ë• ë“± ë¡œë§ˆì—ì„œ ê°€ì¥ ìœ ëª…í•œ ê³ ëŒ€ ìœ ì ì§€ë¥¼ ë°©ë¬¸í•´ë³´ì„¸ìš”...\n",
      "         ì–¸ì–´: í•œêµ­ì–´\n",
      "\n",
      "   2ìœ„: [í•œêµ­ì–´ ê°€ì´ë“œ & ë¦¬ë·° ì´ë²¤íŠ¸][í—¬ë¡œìš°íŠ¸ë˜ë¸”] ì´íƒˆë¦¬...\n",
      "         ê°€ê²©: â‚©65,000, í‰ì : 4.8/5\n",
      "         í•˜ì´ë¼ì´íŠ¸: ìœ ëŸ½ ì—¬í–‰ ì˜ˆì •ì´ë¼ë©´, ë¦¬ë·° ì´ë²¤íŠ¸ í˜œíƒë„ í•¨ê»˜ ì±™ê¸°ì„¸ìš”! âœ¨ íˆ¬ì–´ ì°¸ì—¬ í›„ ë¦¬ë·°ë¥¼ ì‘ì„±í•´...\n",
      "         ì–¸ì–´: í•œêµ­ì–´\n",
      "\n",
      "\n",
      "ğŸ“ˆ ë°ì´í„° í’ˆì§ˆ ë¶„ì„:\n",
      "   ìƒí’ˆëª…: 100.0% ì™„ì„±ë„ (2/2)\n",
      "   ê°€ê²©: 100.0% ì™„ì„±ë„ (2/2)\n",
      "   í‰ì : 100.0% ì™„ì„±ë„ (2/2)\n",
      "   URL: 100.0% ì™„ì„±ë„ (2/2)\n",
      "   í•˜ì´ë¼ì´íŠ¸ (ì‹ ê·œ): 100.0% ì™„ì„±ë„ (2/2)\n",
      "   ì–¸ì–´ (ì‹ ê·œ): 100.0% ì™„ì„±ë„ (2/2)\n",
      "\n",
      "ğŸŒ ì–¸ì–´ë³„ ë¶„í¬ (ìƒìœ„ 3ê°œ):\n",
      "   í•œêµ­ì–´: 2ê°œ (100.0%)\n",
      "\n",
      "ğŸ’° ê°€ê²© ë¶„í¬:\n",
      "   ìµœì €ê°€: 42,300ì›\n",
      "   ìµœê³ ê°€: 65,000ì›\n",
      "   í‰ê· ê°€: 53,650ì›\n",
      "   ì¤‘ê°„ê°€: 53,650ì›\n",
      "\n",
      "ğŸ† ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼:\n",
      "   ğŸ“Š ì „ì²´ ìƒí’ˆ: 2ê°œ ìˆ˜ì§‘\n",
      "   ğŸ¯ ëª©í‘œ ë‹¬ì„±ë¥ : 100.0%\n",
      "   ğŸ—ºï¸ Sitemap ë³´ì™„: âŒ ë¯¸ì‚¬ìš©\n",
      "   âœ¨ í•˜ì´ë¼ì´íŠ¸ ìˆ˜ì§‘: âŒ ê¸°ë³¸ ìˆ˜ì§‘ë§Œ\n",
      "   ğŸŒ ì–¸ì–´ ì •ë³´ ìˆ˜ì§‘: âŒ ê¸°ë³¸ ìˆ˜ì§‘ë§Œ\n",
      "\n",
      "ğŸš€ KLOOK í¬ë¡¤ëŸ¬ v2.0 ì‹¤í–‰ ì™„ë£Œ! ğŸ‰\n",
      "   ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„: ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ í™œìš©í•œ ë­í‚¹ ì ìˆ˜ ë¶€ì—¬ ë° ê°€ê²© ë¹„êµ\n"
     ]
    }
   ],
   "source": [
    "# ê·¸ë£¹ 6 ===== ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ì„ íƒì ) =====\n",
    "try:\n",
    "    if ranking_data:\n",
    "        print(\"ğŸ“‹ ìˆ˜ì§‘ëœ ìƒí’ˆ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 5ê°œ):\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for i, item in enumerate(ranking_data[:5]):\n",
    "            print(f\"{item['rank']}ìœ„: {item['url'][:50]}...\")\n",
    "            print(f\"      íƒ­: {item['tab']}, í˜ì´ì§€: {item['page']}\")\n",
    "            print(f\"      ìˆ˜ì§‘ì‹œê°„: {item['collected_at'][:19]}\")\n",
    "            print()\n",
    "        \n",
    "        if len(ranking_data) > 5:\n",
    "            print(f\"... ì™¸ {len(ranking_data) - 5}ê°œ ë”\")\n",
    "    \n",
    "    # CSV íŒŒì¼ì„ pandasë¡œ ì½ì–´ì„œ ë¯¸ë¦¬ë³´ê¸°\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        from src.config import get_city_info\n",
    "        \n",
    "        continent, country = get_city_info(CITY_NAME)\n",
    "        \n",
    "        # CSV íŒŒì¼ ê²½ë¡œ ê²°ì • (ë²”ìš©ì ìœ¼ë¡œ ìˆ˜ì • - ì „ì²´ ëŒ€ë¥™ ì§€ì›)\n",
    "        if CITY_NAME == country:\n",
    "            # ë„ì‹œêµ­ê°€: ëŒ€ë¥™ ì§í•˜ì— ì €ì¥\n",
    "            csv_path = os.path.join(\"data\", continent, f\"klook_{CITY_NAME}_products.csv\")\n",
    "        else:\n",
    "            # ì¼ë°˜ ë„ì‹œ: ëŒ€ë¥™/êµ­ê°€/ë„ì‹œ êµ¬ì¡°\n",
    "            csv_path = os.path.join(\"data\", continent, country, CITY_NAME, f\"klook_{CITY_NAME}_products.csv\")\n",
    "        \n",
    "        if os.path.exists(csv_path):\n",
    "            df = pd.read_csv(csv_path, encoding='utf-8-sig')\n",
    "            print(f\"\\nğŸ“Š CSV ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "            print(f\"   ì»¬ëŸ¼: {list(df.columns)}\")\n",
    "            print(f\"   í–‰ ìˆ˜: {len(df)}\")\n",
    "            \n",
    "            if len(df) > 0:\n",
    "                print(f\"\\nìƒìœ„ 3ê°œ ìƒí’ˆ:\")\n",
    "                for i, row in df.head(3).iterrows():\n",
    "                    print(f\"   {row.get('ìˆœìœ„', i+1)}ìœ„: {row.get('ìƒí’ˆëª…', 'N/A')[:30]}...\")\n",
    "                    print(f\"         ê°€ê²©: {row.get('ê°€ê²©', 'N/A')}, í‰ì : {row.get('í‰ì ', 'N/A')}\")\n",
    "                    \n",
    "                    # ğŸ†• v2.0 ì‹ ê·œ í•„ë“œ ë¯¸ë¦¬ë³´ê¸°\n",
    "                    highlights = row.get('í•˜ì´ë¼ì´íŠ¸', '')\n",
    "                    language = row.get('ì–¸ì–´', '')\n",
    "                    if highlights and highlights != 'ì •ë³´ ì—†ìŒ':\n",
    "                        print(f\"         í•˜ì´ë¼ì´íŠ¸: {highlights[:50]}...\")\n",
    "                    if language and language != 'ì •ë³´ ì—†ìŒ':\n",
    "                        print(f\"         ì–¸ì–´: {language}\")\n",
    "                    print()\n",
    "        else:\n",
    "            print(f\"âš ï¸ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {csv_path}\")\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"â„¹ï¸ pandasê°€ ì—†ì–´ CSV ë¯¸ë¦¬ë³´ê¸°ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ CSV ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ë¯¸ë¦¬ë³´ê¸° ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# ğŸ¯ ë°ì´í„° í’ˆì§ˆ ë¶„ì„\n",
    "try:\n",
    "    if os.path.exists(csv_path) and len(df) > 0:\n",
    "        print(f\"\\nğŸ“ˆ ë°ì´í„° í’ˆì§ˆ ë¶„ì„:\")\n",
    "        \n",
    "        # í•„ìˆ˜ ë°ì´í„° ì™„ì„±ë„ í™•ì¸\n",
    "        essential_fields = ['ìƒí’ˆëª…', 'ê°€ê²©', 'í‰ì ', 'URL']\n",
    "        for field in essential_fields:\n",
    "            if field in df.columns:\n",
    "                valid_count = len(df[df[field].notna() & (df[field] != '') & (df[field] != 'ì •ë³´ ì—†ìŒ') & (df[field] != 'ì¶”ì¶œ ì‹¤íŒ¨')])\n",
    "                completion_rate = (valid_count / len(df)) * 100\n",
    "                print(f\"   {field}: {completion_rate:.1f}% ì™„ì„±ë„ ({valid_count}/{len(df)})\")\n",
    "        \n",
    "        # ğŸ†• v2.0 ì‹ ê·œ í•„ë“œ ì™„ì„±ë„\n",
    "        new_fields = ['í•˜ì´ë¼ì´íŠ¸', 'ì–¸ì–´']\n",
    "        for field in new_fields:\n",
    "            if field in df.columns:\n",
    "                valid_count = len(df[df[field].notna() & (df[field] != '') & (df[field] != 'ì •ë³´ ì—†ìŒ') & (df[field] != 'ì¶”ì¶œ ì‹¤íŒ¨')])\n",
    "                completion_rate = (valid_count / len(df)) * 100\n",
    "                print(f\"   {field} (ì‹ ê·œ): {completion_rate:.1f}% ì™„ì„±ë„ ({valid_count}/{len(df)})\")\n",
    "        \n",
    "        # ì–¸ì–´ë³„ ë¶„í¬ (ì–¸ì–´ í•„ë“œê°€ ìˆë‹¤ë©´)\n",
    "        if 'ì–¸ì–´' in df.columns:\n",
    "            language_counts = df['ì–¸ì–´'].value_counts().head(3)\n",
    "            print(f\"\\nğŸŒ ì–¸ì–´ë³„ ë¶„í¬ (ìƒìœ„ 3ê°œ):\")\n",
    "            for lang, count in language_counts.items():\n",
    "                if lang and lang != 'ì •ë³´ ì—†ìŒ':\n",
    "                    percentage = (count / len(df)) * 100\n",
    "                    print(f\"   {lang}: {count}ê°œ ({percentage:.1f}%)\")\n",
    "        \n",
    "        # ê°€ê²© ë²”ìœ„ ë¶„ì„\n",
    "        if 'ê°€ê²©' in df.columns:\n",
    "            price_data = df['ê°€ê²©'].str.extract(r'(\\d+,?\\d*)', expand=False).str.replace(',', '').astype(float, errors='ignore')\n",
    "            valid_prices = price_data.dropna()\n",
    "            if len(valid_prices) > 0:\n",
    "                print(f\"\\nğŸ’° ê°€ê²© ë¶„í¬:\")\n",
    "                print(f\"   ìµœì €ê°€: {valid_prices.min():,.0f}ì›\")\n",
    "                print(f\"   ìµœê³ ê°€: {valid_prices.max():,.0f}ì›\")\n",
    "                print(f\"   í‰ê· ê°€: {valid_prices.mean():,.0f}ì›\")\n",
    "                print(f\"   ì¤‘ê°„ê°€: {valid_prices.median():,.0f}ì›\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ† ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼:\")\n",
    "print(f\"   ğŸ“Š ì „ì²´ ìƒí’ˆ: {total_collected}ê°œ ìˆ˜ì§‘\")\n",
    "print(f\"   ğŸ¯ ëª©í‘œ ë‹¬ì„±ë¥ : {(total_collected/TARGET_PRODUCTS*100):.1f}%\")\n",
    "print(f\"   ğŸ—ºï¸ Sitemap ë³´ì™„: {'âœ… í™œìš©ë¨' if 'sitemap' in [item.get('source', '') for item in ranking_data] else 'âŒ ë¯¸ì‚¬ìš©'}\")\n",
    "print(f\"   âœ¨ í•˜ì´ë¼ì´íŠ¸ ìˆ˜ì§‘: {'âœ… v2.0 ê¸°ëŠ¥ ì ìš©' if any('í•˜ì´ë¼ì´íŠ¸' in str(item) for item in ranking_data) else 'âŒ ê¸°ë³¸ ìˆ˜ì§‘ë§Œ'}\")\n",
    "print(f\"   ğŸŒ ì–¸ì–´ ì •ë³´ ìˆ˜ì§‘: {'âœ… v2.0 ê¸°ëŠ¥ ì ìš©' if any('ì–¸ì–´' in str(item) for item in ranking_data) else 'âŒ ê¸°ë³¸ ìˆ˜ì§‘ë§Œ'}\")\n",
    "\n",
    "print(f\"\\nğŸš€ KLOOK í¬ë¡¤ëŸ¬ v2.0 ì‹¤í–‰ ì™„ë£Œ! ğŸ‰\")\n",
    "print(f\"   ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„: ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ í™œìš©í•œ ë­í‚¹ ì ìˆ˜ ë¶€ì—¬ ë° ê°€ê²© ë¹„êµ\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mikael_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
