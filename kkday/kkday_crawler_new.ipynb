{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ KKday í¬ë¡¤ëŸ¬ v1.0\n",
    "## í†µí•© ìƒí’ˆ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ\n",
    "\n",
    "### ğŸ“‹ ì£¼ìš” ê¸°ëŠ¥:\n",
    "- âœ… **ì„œìš¸ í˜ì´ì§€ ì§„ì…ìœ¼ë¡œ ë´‡ íƒì§€ íšŒí”¼**\n",
    "- âœ… **ê²€ìƒ‰ë°•ìŠ¤ í™œìš©í•œ ë„ì‹œë³„ í¬ë¡¤ë§**\n",
    "- âœ… **ì¤‘ì•™í™” ì…€ë ‰í„° ì‹œìŠ¤í…œ** (fallback ì§€ì›)\n",
    "- âœ… **ê°œë³„ íŒŒì„œ í•¨ìˆ˜** (ë³µì¡í•œ ì†ì„± ì²˜ë¦¬)\n",
    "- âœ… **ê°•í™”ëœ ì—ëŸ¬ ì²˜ë¦¬** ë° ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜\n",
    "- âœ… **24ê°œ CSV ì»¬ëŸ¼** ì™„ì „ ì§€ì›\n",
    "- âœ… **ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ** ë° ê²½ë¡œ ê´€ë¦¬\n",
    "- âœ… **URL ì¤‘ë³µ ì²˜ë¦¬** ë° ìˆœìœ„ ì—°ì†ì„± ë³´ì¥\n",
    "\n",
    "### ğŸ”¥ **v1.0 í•µì‹¬ íŠ¹ì§•:**\n",
    "- **KKdayCrawler í´ë˜ìŠ¤**: í†µí•© í¬ë¡¤ë§ ì‹œìŠ¤í…œ\n",
    "- **ì¤‘ì•™í™” + ê°œë³„ íŒŒì„œ**: ìµœì  í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜\n",
    "- **ë”ë¯¸ í…ŒìŠ¤íŠ¸ ê²€ì¦**: 100% ë¡œì§ ê²€ì¦ ì™„ë£Œ\n",
    "- **TimeoutException ì²˜ë¦¬**: ì•ˆì •ì ì¸ ëŒ€ê¸° ì‹œìŠ¤í…œ\n",
    "- **StaleElement ì²˜ë¦¬**: DOM ë³€í™” ëŒ€ì‘\n",
    "\n",
    "### ğŸ¯ ì‚¬ìš©ë²•:\n",
    "1. **ì•„ë˜ 1ë²ˆ ì…€ì—ì„œ ë„ì‹œëª… ë° ëª©í‘œ ìˆ˜ëŸ‰ ì„¤ì •**\n",
    "2. **Run All ì‹¤í–‰** (ì™„ì „ ìë™í™”)\n",
    "3. **ê²°ê³¼ ë¶„ì„** (ìë™ í†µê³„ ìƒì„±)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ğŸ¯ ì‚¬ìš©ì ì„¤ì • ì˜ì—­ =====\n",
    "\n",
    "# 1. í¬ë¡¤ë§í•  ë„ì‹œëª… ì…ë ¥\n",
    "CITY_NAME = \"ì„œìš¸\"  # ğŸ”¥ğŸ”¥ ë„ì‹œëª… ì…ë ¥ ğŸ”¥ğŸ”¥\n",
    "\n",
    "# 2. ìˆ˜ì§‘í•  ìƒí’ˆ ìˆ˜ ì„¤ì •\n",
    "TARGET_PRODUCTS = 10  # ìˆ˜ì§‘í•  ìƒí’ˆ ìˆ˜\n",
    "\n",
    "# 3. í¬ë¡¤ë§ ë²”ìœ„ ì„¤ì •\n",
    "MAX_PAGES = 3  # ìµœëŒ€ ê²€ìƒ‰í•  í˜ì´ì§€ ìˆ˜\n",
    "\n",
    "# 4. ì´ë¯¸ì§€ ì €ì¥ ì—¬ë¶€\n",
    "SAVE_IMAGES = True  # True: ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ, False: URLë§Œ ì €ì¥\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸš€ KKday í¬ë¡¤ëŸ¬ v1.0 ì‹œì‘\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ===== í™˜ê²½ ì„¤ì • ë° ëª¨ë“ˆ Import =====\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# í˜„ì¬ kkday í´ë”ì—ì„œ src í´ë”ì— ì ‘ê·¼\n",
    "sys.path.append('./src')\n",
    "sys.path.append('.')\n",
    "\n",
    "# KKday í”„ë¡œì íŠ¸ ëª¨ë“ˆ import\n",
    "try:\n",
    "    from src.scraper.crawler import KKdayCrawler, execute_kkday_crawling_system, quick_crawl_test, get_crawling_status\n",
    "    from src.config import CONFIG\n",
    "    from src.utils.file_handler import create_product_data_structure, ensure_directory_structure\n",
    "    print(\"âœ… KKday ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ KKday ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ’¡ src/ í´ë” êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "    raise\n",
    "\n",
    "# ì˜ì¡´ì„± í™•ì¸\n",
    "try:\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    print(\"âœ… Selenium ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ\")\n",
    "except ImportError:\n",
    "    print(\"âŒ Seleniumì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ’¡ í•´ê²°: pip install selenium\")\n",
    "    raise\n",
    "\n",
    "# ===== ì„¤ì • ê²€ì¦ =====\n",
    "print(\"\\nğŸ“‹ í¬ë¡¤ë§ ì„¤ì •:\")\n",
    "print(f\"   ğŸ™ï¸ ë„ì‹œ: {CITY_NAME}\")\n",
    "print(f\"   ğŸ¯ ëª©í‘œ ìƒí’ˆ: {TARGET_PRODUCTS}ê°œ\")\n",
    "print(f\"   ğŸ“„ ìµœëŒ€ í˜ì´ì§€: {MAX_PAGES}ê°œ\")\n",
    "print(f\"   ğŸ“¸ ì´ë¯¸ì§€ ì €ì¥: {'âœ…' if SAVE_IMAGES else 'âŒ'}\")\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ë³´\n",
    "try:\n",
    "    ensure_directory_structure(CITY_NAME)\n",
    "    print(f\"   ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ë³´ ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"   âš ï¸ ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ë³´ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(\"\\nğŸ¯ ì„¤ì • ì™„ë£Œ - í¬ë¡¤ë§ ì‹œì‘ ì¤€ë¹„!\")\n",
    "print(\"ğŸ’¡ ì§„í–‰ìƒí™©ì€ ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ğŸš€ ë©”ì¸ í¬ë¡¤ë§ ì‹¤í–‰ =====\n",
    "print(f\"ğŸš€ '{CITY_NAME}' í¬ë¡¤ë§ ì‹œì‘!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# í¬ë¡¤ë§ ì‹œì‘ ì‹œê°„ ê¸°ë¡\n",
    "start_time = datetime.now()\n",
    "print(f\"â° ì‹œì‘ ì‹œê°„: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# KKday í¬ë¡¤ëŸ¬ ìƒì„± ë° ì‹¤í–‰\n",
    "crawler = None\n",
    "crawling_success = False\n",
    "\n",
    "try:\n",
    "    # 1. KKday í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”\n",
    "    print(f\"\\nğŸ—ï¸ KKday í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”...\")\n",
    "    crawler = KKdayCrawler(city_name=CITY_NAME)\n",
    "    \n",
    "    # 2. ì „ì²´ í¬ë¡¤ë§ ì‹¤í–‰\n",
    "    print(f\"\\nğŸ¯ ì „ì²´ í¬ë¡¤ë§ ì‹¤í–‰ (ìµœëŒ€ {MAX_PAGES}í˜ì´ì§€, {TARGET_PRODUCTS}ê°œ ìƒí’ˆ)\")\n",
    "    crawling_success = crawler.run_full_crawling(\n",
    "        max_pages=MAX_PAGES,\n",
    "        max_products=TARGET_PRODUCTS\n",
    "    )\n",
    "    \n",
    "    if crawling_success:\n",
    "        print(\"\\nğŸ‰ í¬ë¡¤ë§ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ!\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ í¬ë¡¤ë§ì´ ì™„ë£Œë˜ì—ˆì§€ë§Œ ì¼ë¶€ ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nâ¹ï¸ ì‚¬ìš©ìê°€ í¬ë¡¤ë§ì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    crawling_success = False\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    crawling_success = False\n",
    "\n",
    "finally:\n",
    "    # í¬ë¡¤ë§ ì¢…ë£Œ ì‹œê°„ ê¸°ë¡\n",
    "    end_time = datetime.now()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(f\"\\nâ° ì¢…ë£Œ ì‹œê°„: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"â±ï¸ ì´ ì†Œìš” ì‹œê°„: {duration}\")\n",
    "    \n",
    "    # í¬ë¡¤ëŸ¬ í†µê³„ ì¶œë ¥ (í¬ë¡¤ëŸ¬ê°€ ìˆëŠ” ê²½ìš°)\n",
    "    if crawler and hasattr(crawler, 'stats'):\n",
    "        print(f\"\\nğŸ“Š í¬ë¡¤ë§ í†µê³„:\")\n",
    "        stats = crawler.stats\n",
    "        print(f\"   â€¢ ì „ì²´ ì²˜ë¦¬: {stats.get('total_processed', 0)}ê°œ\")\n",
    "        print(f\"   â€¢ ì„±ê³µ: {stats.get('success_count', 0)}ê°œ\")\n",
    "        print(f\"   â€¢ ì‹¤íŒ¨: {stats.get('error_count', 0)}ê°œ\")\n",
    "        print(f\"   â€¢ ê±´ë„ˆëœ€: {stats.get('skip_count', 0)}ê°œ\")\n",
    "        \n",
    "        if stats.get('total_processed', 0) > 0:\n",
    "            success_rate = (stats.get('success_count', 0) / stats.get('total_processed', 1)) * 100\n",
    "            print(f\"   â€¢ ì„±ê³µë¥ : {success_rate:.1f}%\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"ğŸ í¬ë¡¤ë§ ì‹¤í–‰ ë‹¨ê³„ ì™„ë£Œ\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ğŸ“Š í¬ë¡¤ë§ ê²°ê³¼ ë¶„ì„ =====\n",
    "print(f\"ğŸ“Š '{CITY_NAME}' í¬ë¡¤ë§ ê²°ê³¼ ë¶„ì„\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # 1. í¬ë¡¤ë§ ìƒíƒœ ì¡°íšŒ\n",
    "    print(\"\\nğŸ” í¬ë¡¤ë§ ìƒíƒœ ì¡°íšŒ...\")\n",
    "    status_summary = get_crawling_status(CITY_NAME)\n",
    "    \n",
    "    # 2. CSV íŒŒì¼ ë¶„ì„\n",
    "    print(\"\\nğŸ“‹ CSV ë°ì´í„° ë¶„ì„...\")\n",
    "    \n",
    "    # CSV íŒŒì¼ ê²½ë¡œ í™•ì¸\n",
    "    csv_files = []\n",
    "    data_dir = f\"data/{CITY_NAME}\"\n",
    "    \n",
    "    if os.path.exists(data_dir):\n",
    "        for file in os.listdir(data_dir):\n",
    "            if file.endswith('.csv') and 'kkday' in file.lower():\n",
    "                csv_files.append(os.path.join(data_dir, file))\n",
    "    \n",
    "    if csv_files:\n",
    "        print(f\"   ğŸ“„ ë°œê²¬ëœ CSV íŒŒì¼: {len(csv_files)}ê°œ\")\n",
    "        \n",
    "        # pandasë¡œ CSV ë¶„ì„ (ì„¤ì¹˜ë˜ì–´ ìˆë‹¤ë©´)\n",
    "        try:\n",
    "            import pandas as pd\n",
    "            \n",
    "            # ê°€ì¥ ìµœê·¼ CSV íŒŒì¼ ì„ íƒ\n",
    "            latest_csv = max(csv_files, key=os.path.getmtime)\n",
    "            print(f\"   ğŸ“Š ë¶„ì„ íŒŒì¼: {os.path.basename(latest_csv)}\")\n",
    "            \n",
    "            df = pd.read_csv(latest_csv, encoding='utf-8-sig')\n",
    "            \n",
    "            print(f\"\\nğŸ“ˆ ë°ì´í„° í†µê³„:\")\n",
    "            print(f\"   â€¢ ì´ ìƒí’ˆ ìˆ˜: {len(df)}ê°œ\")\n",
    "            print(f\"   â€¢ CSV ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}ê°œ\")\n",
    "            print(f\"   â€¢ íŒŒì¼ í¬ê¸°: {os.path.getsize(latest_csv):,} bytes\")\n",
    "            \n",
    "            # í•„ìˆ˜ í•„ë“œ ì™„ì„±ë„ í™•ì¸\n",
    "            essential_fields = ['ìƒí’ˆëª…', 'ê°€ê²©', 'í‰ì ', 'URL', 'ìˆœìœ„']\n",
    "            print(f\"\\nâœ… í•„ìˆ˜ í•„ë“œ ì™„ì„±ë„:\")\n",
    "            \n",
    "            for field in essential_fields:\n",
    "                if field in df.columns:\n",
    "                    valid_count = len(df[df[field].notna() & (df[field] != '') & (df[field] != 'ì •ë³´ ì—†ìŒ')])\n",
    "                    completion_rate = (valid_count / len(df)) * 100\n",
    "                    status = \"âœ…\" if completion_rate >= 80 else \"âš ï¸\" if completion_rate >= 50 else \"âŒ\"\n",
    "                    print(f\"   {status} {field}: {completion_rate:.1f}% ({valid_count}/{len(df)})\")\n",
    "            \n",
    "            # ìƒìœ„ 5ê°œ ìƒí’ˆ ë¯¸ë¦¬ë³´ê¸°\n",
    "            if len(df) > 0:\n",
    "                print(f\"\\nğŸ† ìƒìœ„ 5ê°œ ìƒí’ˆ:\")\n",
    "                for i, row in df.head(5).iterrows():\n",
    "                    rank = row.get('ìˆœìœ„', i+1)\n",
    "                    name = row.get('ìƒí’ˆëª…', 'N/A')[:40] + ('...' if len(str(row.get('ìƒí’ˆëª…', ''))) > 40 else '')\n",
    "                    price = row.get('ê°€ê²©', 'N/A')\n",
    "                    rating = row.get('í‰ì ', 'N/A')\n",
    "                    print(f\"   {rank}ìœ„: {name}\")\n",
    "                    print(f\"        ğŸ’° {price} | â­ {rating}\")\n",
    "            \n",
    "            # ê°€ê²© ë¶„í¬ ë¶„ì„\n",
    "            if 'ê°€ê²©' in df.columns:\n",
    "                print(f\"\\nğŸ’° ê°€ê²© ë¶„ì„:\")\n",
    "                try:\n",
    "                    # ê°€ê²©ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ\n",
    "                    prices = df['ê°€ê²©'].astype(str).str.extract(r'([0-9,]+)')[0].str.replace(',', '')\n",
    "                    prices = pd.to_numeric(prices, errors='coerce').dropna()\n",
    "                    \n",
    "                    if len(prices) > 0:\n",
    "                        print(f\"   â€¢ ìµœì €ê°€: {prices.min():,.0f}ì›\")\n",
    "                        print(f\"   â€¢ ìµœê³ ê°€: {prices.max():,.0f}ì›\")\n",
    "                        print(f\"   â€¢ í‰ê· ê°€: {prices.mean():,.0f}ì›\")\n",
    "                        print(f\"   â€¢ ì¤‘ê°„ê°€: {prices.median():,.0f}ì›\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   âš ï¸ ê°€ê²© ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "            \n",
    "            # í‰ì  ë¶„í¬ ë¶„ì„\n",
    "            if 'í‰ì ' in df.columns:\n",
    "                print(f\"\\nâ­ í‰ì  ë¶„ì„:\")\n",
    "                try:\n",
    "                    ratings = df['í‰ì '].astype(str).str.extract(r'([0-9.]+)')[0]\n",
    "                    ratings = pd.to_numeric(ratings, errors='coerce').dropna()\n",
    "                    \n",
    "                    if len(ratings) > 0:\n",
    "                        print(f\"   â€¢ ìµœê³  í‰ì : {ratings.max():.1f}/5.0\")\n",
    "                        print(f\"   â€¢ ìµœì € í‰ì : {ratings.min():.1f}/5.0\")\n",
    "                        print(f\"   â€¢ í‰ê·  í‰ì : {ratings.mean():.2f}/5.0\")\n",
    "                        \n",
    "                        # í‰ì  ë“±ê¸‰ ë¶„í¬\n",
    "                        excellent = len(ratings[ratings >= 4.5])\n",
    "                        good = len(ratings[(ratings >= 4.0) & (ratings < 4.5)])\n",
    "                        average = len(ratings[(ratings >= 3.5) & (ratings < 4.0)])\n",
    "                        below = len(ratings[ratings < 3.5])\n",
    "                        \n",
    "                        print(f\"   â€¢ ìš°ìˆ˜ (4.5+): {excellent}ê°œ ({excellent/len(ratings)*100:.1f}%)\")\n",
    "                        print(f\"   â€¢ ì¢‹ìŒ (4.0+): {good}ê°œ ({good/len(ratings)*100:.1f}%)\")\n",
    "                        print(f\"   â€¢ ë³´í†µ (3.5+): {average}ê°œ ({average/len(ratings)*100:.1f}%)\")\n",
    "                        print(f\"   â€¢ ë¯¸í¡ (3.5-): {below}ê°œ ({below/len(ratings)*100:.1f}%)\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"   âš ï¸ í‰ì  ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"   â„¹ï¸ pandasê°€ ì—†ì–´ ìƒì„¸ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "            print(f\"   ğŸ“Š ê¸°ë³¸ ì •ë³´: CSV íŒŒì¼ {len(csv_files)}ê°œ ìƒì„±\")\n",
    "            \n",
    "    else:\n",
    "        print(\"   âš ï¸ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # 3. ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸\n",
    "    print(f\"\\nğŸ–¼ï¸ ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸...\")\n",
    "    image_dir = f\"images/{CITY_NAME}\"\n",
    "    \n",
    "    if os.path.exists(image_dir):\n",
    "        image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        print(f\"   ğŸ“¸ ì €ì¥ëœ ì´ë¯¸ì§€: {len(image_files)}ê°œ\")\n",
    "        \n",
    "        if image_files:\n",
    "            total_size = sum(os.path.getsize(os.path.join(image_dir, f)) for f in image_files)\n",
    "            print(f\"   ğŸ’¾ ì´ í¬ê¸°: {total_size/1024/1024:.2f} MB\")\n",
    "            \n",
    "            # ì´ë¯¸ì§€ íƒ€ì…ë³„ ë¶„ë¥˜\n",
    "            main_images = [f for f in image_files if '_thumb' not in f]\n",
    "            thumb_images = [f for f in image_files if '_thumb' in f]\n",
    "            print(f\"   ğŸ–¼ï¸ ë©”ì¸ ì´ë¯¸ì§€: {len(main_images)}ê°œ\")\n",
    "            print(f\"   ğŸ” ì¸ë„¤ì¼: {len(thumb_images)}ê°œ\")\n",
    "    else:\n",
    "        print(f\"   ğŸ“¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì—†ìŒ\")\n",
    "    \n",
    "    # 4. í¬ë¡¤ë§ í’ˆì§ˆ í‰ê°€\n",
    "    print(f\"\\nğŸ¯ í¬ë¡¤ë§ í’ˆì§ˆ í‰ê°€:\")\n",
    "    \n",
    "    quality_score = 0\n",
    "    max_score = 5\n",
    "    \n",
    "    if crawling_success:\n",
    "        quality_score += 1\n",
    "        print(f\"   âœ… í¬ë¡¤ë§ ì‹¤í–‰: ì„±ê³µ\")\n",
    "    else:\n",
    "        print(f\"   âŒ í¬ë¡¤ë§ ì‹¤í–‰: ì‹¤íŒ¨\")\n",
    "    \n",
    "    if csv_files:\n",
    "        quality_score += 1\n",
    "        print(f\"   âœ… CSV ìƒì„±: ì„±ê³µ\")\n",
    "    else:\n",
    "        print(f\"   âŒ CSV ìƒì„±: ì‹¤íŒ¨\")\n",
    "    \n",
    "    if 'df' in locals() and len(df) > 0:\n",
    "        quality_score += 1\n",
    "        print(f\"   âœ… ë°ì´í„° ìˆ˜ì§‘: {len(df)}ê°œ ìƒí’ˆ\")\n",
    "        \n",
    "        # í•„ìˆ˜ í•„ë“œ ì™„ì„±ë„ ì²´í¬\n",
    "        if len(df) > 0:\n",
    "            essential_completion = 0\n",
    "            for field in ['ìƒí’ˆëª…', 'ê°€ê²©', 'í‰ì ']:\n",
    "                if field in df.columns:\n",
    "                    valid_count = len(df[df[field].notna() & (df[field] != '')])\n",
    "                    if valid_count / len(df) >= 0.8:\n",
    "                        essential_completion += 1\n",
    "            \n",
    "            if essential_completion >= 2:\n",
    "                quality_score += 1\n",
    "                print(f\"   âœ… ë°ì´í„° í’ˆì§ˆ: ìš°ìˆ˜\")\n",
    "            else:\n",
    "                print(f\"   âš ï¸ ë°ì´í„° í’ˆì§ˆ: ë³´í†µ\")\n",
    "    else:\n",
    "        print(f\"   âŒ ë°ì´í„° ìˆ˜ì§‘: ì‹¤íŒ¨\")\n",
    "    \n",
    "    if SAVE_IMAGES and os.path.exists(image_dir) and len(os.listdir(image_dir)) > 0:\n",
    "        quality_score += 1\n",
    "        print(f\"   âœ… ì´ë¯¸ì§€ ì €ì¥: ì„±ê³µ\")\n",
    "    elif not SAVE_IMAGES:\n",
    "        quality_score += 1\n",
    "        print(f\"   âœ… ì´ë¯¸ì§€ ì„¤ì •: URLë§Œ ì €ì¥ (ì„¤ì •ëŒ€ë¡œ)\")\n",
    "    else:\n",
    "        print(f\"   âŒ ì´ë¯¸ì§€ ì €ì¥: ì‹¤íŒ¨\")\n",
    "    \n",
    "    # ìµœì¢… í’ˆì§ˆ ì ìˆ˜\n",
    "    quality_percentage = (quality_score / max_score) * 100\n",
    "    \n",
    "    if quality_percentage >= 80:\n",
    "        quality_status = \"ğŸ‰ ìš°ìˆ˜\"\n",
    "    elif quality_percentage >= 60:\n",
    "        quality_status = \"ğŸ‘ ì–‘í˜¸\"\n",
    "    elif quality_percentage >= 40:\n",
    "        quality_status = \"âš ï¸ ë³´í†µ\"\n",
    "    else:\n",
    "        quality_status = \"âŒ ë¯¸í¡\"\n",
    "    \n",
    "    print(f\"\\nğŸ† ì¢…í•© í’ˆì§ˆ ì ìˆ˜: {quality_score}/{max_score} ({quality_percentage:.1f}%) {quality_status}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ê²°ê³¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"ğŸ“Š ê²°ê³¼ ë¶„ì„ ì™„ë£Œ\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ ìš”ì•½ =====\n",
    "print(f\"ğŸ‰ KKday í¬ë¡¤ëŸ¬ v1.0 ì‹¤í–‰ ì™„ë£Œ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ìµœì¢… ì‹¤í–‰ ìš”ì•½\n",
    "print(f\"ğŸ“‹ ì‹¤í–‰ ìš”ì•½:\")\n",
    "print(f\"   ğŸ™ï¸ í¬ë¡¤ë§ ë„ì‹œ: {CITY_NAME}\")\n",
    "print(f\"   ğŸ¯ ëª©í‘œ ìƒí’ˆ: {TARGET_PRODUCTS}ê°œ\")\n",
    "print(f\"   ğŸ“„ ìµœëŒ€ í˜ì´ì§€: {MAX_PAGES}ê°œ\")\n",
    "print(f\"   ğŸ“¸ ì´ë¯¸ì§€ ì €ì¥: {'í™œì„±í™”' if SAVE_IMAGES else 'ë¹„í™œì„±í™”'}\")\n",
    "\n",
    "# ì‹¤í–‰ ì‹œê°„\n",
    "if 'start_time' in locals() and 'end_time' in locals():\n",
    "    print(f\"   â±ï¸ ì‹¤í–‰ ì‹œê°„: {end_time - start_time}\")\n",
    "\n",
    "# ì„±ê³µ/ì‹¤íŒ¨ ìƒíƒœ\n",
    "if crawling_success:\n",
    "    print(f\"   âœ… í¬ë¡¤ë§ ìƒíƒœ: ì„±ê³µ\")\n",
    "else:\n",
    "    print(f\"   âš ï¸ í¬ë¡¤ë§ ìƒíƒœ: ë¶€ë¶„ ì„±ê³µ ë˜ëŠ” ì‹¤íŒ¨\")\n",
    "\n",
    "# ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´\n",
    "print(f\"\\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "print(f\"   1ï¸âƒ£ ìˆ˜ì§‘ëœ CSV ë°ì´í„° í™•ì¸ ë° ê²€í† \")\n",
    "print(f\"   2ï¸âƒ£ ì´ë¯¸ì§€ íŒŒì¼ í’ˆì§ˆ í™•ì¸ (ë‹¤ìš´ë¡œë“œëœ ê²½ìš°)\")\n",
    "print(f\"   3ï¸âƒ£ ë°ì´í„° í›„ì²˜ë¦¬ ë° ë¶„ì„\")\n",
    "print(f\"   4ï¸âƒ£ ë‹¤ë¥¸ ë„ì‹œ í¬ë¡¤ë§ (CITY_NAME ë³€ê²½ í›„ ì¬ì‹¤í–‰)\")\n",
    "\n",
    "# íŒŒì¼ ìœ„ì¹˜ ì•ˆë‚´\n",
    "print(f\"\\nğŸ“ ìƒì„±ëœ íŒŒì¼ ìœ„ì¹˜:\")\n",
    "print(f\"   ğŸ“„ CSV: data/{CITY_NAME}/\")\n",
    "print(f\"   ğŸ–¼ï¸ ì´ë¯¸ì§€: images/{CITY_NAME}/\")\n",
    "print(f\"   ğŸ“Š ë­í‚¹: ranking_data/ (í•´ë‹¹í•˜ëŠ” ê²½ìš°)\")\n",
    "\n",
    "# ë¬¸ì œ í•´ê²° ì•ˆë‚´\n",
    "if not crawling_success:\n",
    "    print(f\"\\nğŸ”§ ë¬¸ì œ í•´ê²°:\")\n",
    "    print(f\"   â€¢ ì¸í„°ë„· ì—°ê²° í™•ì¸\")\n",
    "    print(f\"   â€¢ Chrome ë¸Œë¼ìš°ì € ë° ChromeDriver ë²„ì „ í™•ì¸\")\n",
    "    print(f\"   â€¢ ë°©í™”ë²½/ë³´ì•ˆ í”„ë¡œê·¸ë¨ ì„¤ì • í™•ì¸\")\n",
    "    print(f\"   â€¢ ë‹¤ë¥¸ ë„ì‹œëª…ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ì‹œë„\")\n",
    "    print(f\"   â€¢ TARGET_PRODUCTSë¥¼ ë” ì ì€ ìˆ˜ë¡œ ì„¤ì •\")\n",
    "\n",
    "print(f\"\\nğŸš€ KKday í¬ë¡¤ëŸ¬ë¥¼ ì´ìš©í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤!\")\n",
    "print(f\"={'*'*70}\")\n",
    "\n",
    "# ê°„ë‹¨í•œ í†µê³„ ì¶œë ¥ (ê°€ëŠ¥í•œ ê²½ìš°)\n",
    "if 'crawler' in locals() and crawler and hasattr(crawler, 'stats'):\n",
    "    stats = crawler.stats\n",
    "    success_count = stats.get('success_count', 0)\n",
    "    total_processed = stats.get('total_processed', 0)\n",
    "    \n",
    "    if total_processed > 0:\n",
    "        print(f\"\\nğŸŠ ìµœì¢… ì„±ê³¼: {success_count}/{total_processed} ìƒí’ˆ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì§‘!\")\n",
    "        success_rate = (success_count / total_processed) * 100\n",
    "        print(f\"ğŸ“ˆ ì„±ê³µë¥ : {success_rate:.1f}%\")\n",
    "        \n",
    "        if success_rate >= 80:\n",
    "            print(f\"ğŸ‰ ìš°ìˆ˜í•œ ì„±ê³¼ì…ë‹ˆë‹¤!\")\n",
    "        elif success_rate >= 60:\n",
    "            print(f\"ğŸ‘ ì–‘í˜¸í•œ ê²°ê³¼ì…ë‹ˆë‹¤!\")\n",
    "        else:\n",
    "            print(f\"ğŸ’ª ë‹¤ìŒë²ˆì—” ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ìœ„í•´ ì„¤ì •ì„ ì¡°ì •í•´ë³´ì„¸ìš”!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}