{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49afb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ğŸš€ ê·¸ë£¹ 1: í†µì¼ëœ í•¨ìˆ˜ëª… - ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ í¬ë¡¤ë§ ì‹œìŠ¤í…œ (í•¨ìˆ˜ëª… ì •ë¦¬ ì™„ë£Œ)\n",
    "# í•¨ìˆ˜ëª… ë‹¨ìˆœí™”: get_product_name(), get_price(), download_image(), clean_price(), clean_rating(), save_results()\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import warnings, os, time, shutil, urllib, random\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import re                        # ê°€ê²©/í‰ì  ì •ì œìš© ì •ê·œì‹\n",
    "import json                      # ë©”íƒ€ë°ì´í„° JSON ì €ì¥ìš©  \n",
    "from datetime import datetime    # íƒ€ì„ìŠ¤íƒ¬í”„ìš©\n",
    "\n",
    "from PIL import Image\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException\n",
    "\n",
    "import chromedriver_autoinstaller\n",
    "import undetected_chromedriver as uc\n",
    "from user_agents import parse\n",
    "import selenium\n",
    "\n",
    "print(f\"ğŸ”§ Selenium ë²„ì „: {selenium.__version__}\")\n",
    "\n",
    "# â­â­â­ ì¤‘ìš” ì„¤ì •: ì—¬ê¸°ì„œ ìˆ˜ì •í•˜ì„¸ìš”! â­â­â­\n",
    "CONFIG = {\n",
    "    \"WAIT_TIMEOUT\": 10,\n",
    "    \"RETRY_COUNT\": 3,\n",
    "    \"MIN_DELAY\": 5,                  # 3 â†’ 5ì´ˆë¡œ ì¦ê°€\n",
    "    \"MAX_DELAY\": 12,                 # 8 â†’ 12ì´ˆë¡œ ì¦ê°€\n",
    "    \"POPUP_WAIT\": 5,\n",
    "    \"SAVE_IMAGES\": True,\n",
    "    \"SAVE_INTERMEDIATE\": True,\n",
    "    \"MAX_PRODUCT_NAME_LENGTH\": 30,\n",
    "    \"LONGER_DELAYS\": True,           # ìƒˆë¡œ ì¶”ê°€\n",
    "    \"MEMORY_CLEANUP_INTERVAL\": 5,    # ìƒˆë¡œ ì¶”ê°€\n",
    "    \"MAX_PRODUCTS_PER_CITY\": 2,     # 2 â†’ 10ê°œë¡œ ì¦ê°€â­â­â­â­â­â­â­â­â­\n",
    "    # ğŸ†• Gemini ì§€ì ì‚¬í•­ í•´ê²°: USER_AGENT ì¶”ê°€\n",
    "    \"USER_AGENT\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# ğŸ™ï¸ ê²€ìƒ‰í•  ë„ì‹œë“¤ (ì—¬ê¸°ì„œ ë³€ê²½!)\n",
    "CITIES_TO_SEARCH = [\"í›„ì¿ ì˜¤ì¹´\"]\n",
    "\n",
    "# ğŸ†• í†µí•©ëœ ë„ì‹œ ì •ë³´ êµ¬ì¡° (Gemini ì§€ì ì‚¬í•­ ë°˜ì˜)\n",
    "CITY_CODES = {\n",
    "    # ë™ë‚¨ì•„ì‹œì•„\n",
    "    \"ë°©ì½•\": \"BKK\",\n",
    "    \"ì¹˜ì•™ë§ˆì´\": \"CNX\", \n",
    "    \"í‘¸ì¼“\": \"HKT\",\n",
    "    \"ì‹±ê°€í¬ë¥´\": \"SIN\",\n",
    "    \"í™ì½©\": \"HKG\",\n",
    "    \"ì¿ ì•Œë¼ë£¸í‘¸ë¥´\": \"KUL\",\n",
    "    \"ì„¸ë¶€\": \"CEB\",\n",
    "    \"ë‹¤ë‚­\": \"DAD\",\n",
    "    \"í˜¸ì¹˜ë¯¼\": \"SGN\",\n",
    "    \n",
    "    # ì¼ë³¸\n",
    "    \"ë„ì¿„\": \"NRT\",\n",
    "    \"ì˜¤ì‚¬ì¹´\": \"KIX\",\n",
    "    \"ë‚˜ê³ ì•¼\": \"NGO\",\n",
    "    \"í›„ì¿ ì˜¤ì¹´\": \"FUK\",\n",
    "    \"ì˜¤í‚¤ë‚˜ì™€\": \"OKA\",\n",
    "    \"ì‚¿í¬ë¡œ\": \"CTS\",\n",
    "    \n",
    "    # í•œêµ­\n",
    "    \"ì„œìš¸\": \"ICN\",\n",
    "    \"ë¶€ì‚°\": \"PUS\",\n",
    "    \"ì œì£¼\": \"CJU\",\n",
    "    \"ëŒ€êµ¬\": \"TAE\",\n",
    "    \"ê´‘ì£¼\": \"KWJ\",\n",
    "    \"ì—¬ìˆ˜\": \"RSU\",\n",
    "    \n",
    "    # ìœ ëŸ½\n",
    "    \"íŒŒë¦¬\": \"CDG\",\n",
    "    \"ëŸ°ë˜\": \"LHR\",\n",
    "    \"ë¡œë§ˆ\": \"FCO\",\n",
    "    \"ë°”ë¥´ì…€ë¡œë‚˜\": \"BCN\",\n",
    "    \n",
    "    # ë¶ë¯¸\n",
    "    \"ë‰´ìš•\": \"JFK\",\n",
    "    \"ë¡œìŠ¤ì•¤ì ¤ë ˆìŠ¤\": \"LAX\",\n",
    "    \"ì‹œì¹´ê³ \": \"ORD\",\n",
    "    \n",
    "    # ì˜¤ì„¸ì•„ë‹ˆì•„\n",
    "    \"ì‹œë“œë‹ˆ\": \"SYD\",\n",
    "    \"ë©œë²„ë¥¸\": \"MEL\",\n",
    "}\n",
    "\n",
    "# ğŸ†• í†µí•©ëœ ë„ì‹œ ì •ë³´ (ëŒ€ë¥™/êµ­ê°€ ì •ë³´ í¬í•¨)\n",
    "UNIFIED_CITY_INFO = {\n",
    "    \"ë°©ì½•\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"BKK\"},\n",
    "    \"ë„ì¿„\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"NRT\"},\n",
    "    \"ì˜¤ì‚¬ì¹´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"KIX\"},\n",
    "    \"ì‹±ê°€í¬ë¥´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì‹±ê°€í¬ë¥´\", \"ì½”ë“œ\": \"SIN\"},\n",
    "    \"í™ì½©\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"í™ì½©\", \"ì½”ë“œ\": \"HKG\"},\n",
    "    \"íŒŒë¦¬\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í”„ë‘ìŠ¤\", \"ì½”ë“œ\": \"CDG\"},\n",
    "    \"ëŸ°ë˜\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì˜êµ­\", \"ì½”ë“œ\": \"LHR\"},\n",
    "    \"ë‰´ìš•\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"JFK\"},\n",
    "    \"ì‹œë“œë‹ˆ\": {\"ëŒ€ë¥™\": \"ì˜¤ì„¸ì•„ë‹ˆì•„\", \"êµ­ê°€\": \"í˜¸ì£¼\", \"ì½”ë“œ\": \"SYD\"},\n",
    "}\n",
    "\n",
    "print(f\"âœ… CITY_CODES ì¶”ê°€ ì™„ë£Œ! {len(CITY_CODES)}ê°œ ë„ì‹œ ì§€ì›\")\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ”§ í•µì‹¬ í•¨ìˆ˜ë“¤ - í•¨ìˆ˜ëª… í†µì¼ ì™„ë£Œ! (ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ ì „ìš©)\n",
    "# =============================================================================\n",
    "\n",
    "def get_city_code(city_name):\n",
    "    \"\"\"ë„ì‹œëª…ìœ¼ë¡œ ê³µí•­ ì½”ë“œ ë°˜í™˜ (ê³µìš© í•¨ìˆ˜)\"\"\"\n",
    "    code = CITY_CODES.get(city_name, city_name[:3].upper())\n",
    "    print(f\"  ğŸ™ï¸ {city_name} â†’ {code}\")\n",
    "    return code\n",
    "\n",
    "def get_city_info(city_name):\n",
    "    \"\"\"í†µí•©ëœ ë„ì‹œ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ê³µìš© í•¨ìˆ˜)\"\"\"\n",
    "    info = UNIFIED_CITY_INFO.get(city_name)\n",
    "    if info:\n",
    "        return info[\"ëŒ€ë¥™\"], info[\"êµ­ê°€\"]\n",
    "    else:\n",
    "        # ê¸°ë³¸ê°’ ë°˜í™˜\n",
    "        return \"ê¸°íƒ€\", \"ê¸°íƒ€\"\n",
    "\n",
    "def get_product_name(driver, url_type=\"Product\"):\n",
    "    \"\"\"âœ… ìƒí’ˆëª… ìˆ˜ì§‘ (ê¸°ì¡´: get_product_name_by_type â†’ ìƒˆë¡œìš´: get_product_name)\"\"\"\n",
    "    print(f\"  ğŸ“Š {url_type} ìƒí’ˆëª… ìˆ˜ì§‘ ì¤‘...\")\n",
    "    \n",
    "    # ê¸°ë³¸ ìƒí’ˆëª… ì…€ë ‰í„°ë“¤ (Productsì™€ Offers ê³µí†µ)\n",
    "    title_selectors = [\n",
    "        (By.CSS_SELECTOR, \"h1\"),\n",
    "        (By.CSS_SELECTOR, \".product-title\"),\n",
    "        (By.XPATH, \"//h1[contains(@class, 'title')]\"),\n",
    "        (By.XPATH, \"/html/body/div[1]/main/div[1]/section/div[1]/h1\")\n",
    "    ]\n",
    "\n",
    "    for selector_type, selector_value in title_selectors:\n",
    "        try:\n",
    "            title_element = WebDriverWait(driver, CONFIG[\"WAIT_TIMEOUT\"]).until(\n",
    "                EC.presence_of_element_located((selector_type, selector_value))\n",
    "            )\n",
    "            found_name = title_element.text\n",
    "            return found_name\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "    \n",
    "    raise NoSuchElementException(\"ìƒí’ˆëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "\n",
    "def get_price(driver):\n",
    "    \"\"\"âœ… ê°€ê²© ìˆ˜ì§‘ (ê¸°ì¡´: get_price_fixed â†’ ìƒˆë¡œìš´: get_price)\"\"\"\n",
    "    print(f\"  ğŸ’° ê°€ê²© ì •ë³´ ìˆ˜ì§‘ ì¤‘...\")\n",
    "    \n",
    "    # ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ ì‹¤ì œ ê°€ê²© ìœ„ì¹˜ë“¤ (ìš°ì„ ìˆœìœ„ ìˆœì„œ)\n",
    "    price_selectors = [\n",
    "        # 1ìˆœìœ„: í• ì¸ëœ ê°€ê²© (ë¹¨ê°„ìƒ‰ í…ìŠ¤íŠ¸)\n",
    "        (By.CSS_SELECTOR, \"span[style*='color: rgb(255, 87, 87)']\"),\n",
    "        (By.CSS_SELECTOR, \"span[style*='color: red']\"),\n",
    "        (By.CSS_SELECTOR, \".price-discount\"),\n",
    "        \n",
    "        # 2ìˆœìœ„: ì¼ë°˜ ê°€ê²©\n",
    "        (By.CSS_SELECTOR, \".price\"),\n",
    "        (By.CSS_SELECTOR, \"[class*='price']\"),\n",
    "        \n",
    "        # 3ìˆœìœ„: ì›ì´ í¬í•¨ëœ í…ìŠ¤íŠ¸ (ì¿ í° ì œì™¸)\n",
    "        (By.XPATH, \"//span[contains(text(), 'ì›') and not(contains(text(), 'ì¿ í°')) and not(contains(text(), 'í• ì¸')) and not(contains(text(), 'ë°›ê¸°'))]\"),\n",
    "        \n",
    "        # 4ìˆœìœ„: ê¸°ë³¸ ê°€ê²© ìœ„ì¹˜\n",
    "        (By.XPATH, \"/html/body/div[1]/main/div[1]/div[4]/div/div/div[2]/span[2]\")\n",
    "    ]\n",
    "\n",
    "    for selector_type, selector_value in price_selectors:\n",
    "        try:\n",
    "            price_element = WebDriverWait(driver, CONFIG[\"WAIT_TIMEOUT\"]).until(\n",
    "                EC.presence_of_element_located((selector_type, selector_value))\n",
    "            )\n",
    "            found_price = price_element.text.strip()\n",
    "            \n",
    "            # ì¿ í° ê´€ë ¨ í…ìŠ¤íŠ¸ ì œì™¸\n",
    "            if any(keyword in found_price for keyword in ['ì¿ í°', 'ë°›ê¸°', 'ë‹¤ìš´']):\n",
    "                continue\n",
    "                \n",
    "            # ê°€ê²© íŒ¨í„´ í™•ì¸ (ìˆ«ì + ì›)\n",
    "            if 'ì›' in found_price and any(char.isdigit() for char in found_price):\n",
    "                return found_price\n",
    "                \n",
    "        except TimeoutException:\n",
    "            continue\n",
    "    \n",
    "    return \"ì •ë³´ ì—†ìŒ\"\n",
    "\n",
    "def clean_price(price_text):\n",
    "    \"\"\"âœ… ê°€ê²© ì •ì œ (ê¸°ì¡´: extract_clean_price â†’ ìƒˆë¡œìš´: clean_price) (ê³µìš© í•¨ìˆ˜)\"\"\"\n",
    "    if not price_text or price_text == \"ì •ë³´ ì—†ìŒ\":\n",
    "        return \"ì •ë³´ ì—†ìŒ\"\n",
    "    \n",
    "    # ê°€ê²© íŒ¨í„´: ìˆ«ì,ìˆ«ìì› ë˜ëŠ” ìˆ«ìì›\n",
    "    price_pattern = r'(\\d{1,3}(?:,\\d{3})*)\\s*ì›[~-]?'\n",
    "    match = re.search(price_pattern, price_text)\n",
    "    \n",
    "    if match:\n",
    "        return match.group(1) + \"ì›\"\n",
    "    else:\n",
    "        return price_text  # ì›ë³¸ ë°˜í™˜\n",
    "\n",
    "def clean_rating(rating_text):\n",
    "    \"\"\"âœ… í‰ì  ì •ì œ (ê¸°ì¡´: extract_clean_rating â†’ ìƒˆë¡œìš´: clean_rating) (ê³µìš© í•¨ìˆ˜)\"\"\"\n",
    "    if not rating_text or rating_text == \"ì •ë³´ ì—†ìŒ\":\n",
    "        return \"ì •ë³´ ì—†ìŒ\"\n",
    "    \n",
    "    # í‰ì  íŒ¨í„´: ìˆ«ì.ìˆ«ì\n",
    "    rating_pattern = r'(\\d+\\.?\\d*)'\n",
    "    match = re.search(rating_pattern, rating_text)\n",
    "    \n",
    "    if match:\n",
    "        try:\n",
    "            return float(match.group(1))\n",
    "        except ValueError:\n",
    "            return rating_text\n",
    "    else:\n",
    "        return rating_text\n",
    "\n",
    "def download_image(driver, product_name, city_name, product_index):\n",
    "    \"\"\"âœ… ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ê¸°ì¡´: download_image_improved_fixed â†’ ìƒˆë¡œìš´: download_image)\"\"\"\n",
    "    if not CONFIG[\"SAVE_IMAGES\"]:\n",
    "        return {\n",
    "            'status': 'ì´ë¯¸ì§€ ì €ì¥ ë¹„í™œì„±í™”',\n",
    "            'filename': '',\n",
    "            'path': '',\n",
    "            'size': 0\n",
    "        }\n",
    "        \n",
    "    print(f\"  ğŸ–¼ï¸ ëŒ€í‘œ ìƒí’ˆ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
    "    \n",
    "    # ëŒ€í‘œ ì´ë¯¸ì§€ ìš°ì„  ì…€ë ‰í„°ë“¤\n",
    "    image_selectors = [\n",
    "        # 1ìˆœìœ„: í° ë©”ì¸ ì´ë¯¸ì§€\n",
    "        (By.CSS_SELECTOR, \".main-image img\"),\n",
    "        (By.CSS_SELECTOR, \".hero-image img\"),\n",
    "        (By.CSS_SELECTOR, \".product-gallery img:first-child\"),\n",
    "        \n",
    "        # 2ìˆœìœ„: ì¼ë°˜ ìƒí’ˆ ì´ë¯¸ì§€\n",
    "        (By.CSS_SELECTOR, \".product-image img\"),\n",
    "        (By.CSS_SELECTOR, \".gallery img:first-child\"),\n",
    "        \n",
    "        # 3ìˆœìœ„: ê¸°ë³¸ ì´ë¯¸ì§€\n",
    "        (By.XPATH, \"//img[contains(@alt, 'ìƒí’ˆ')]\"),\n",
    "        (By.CSS_SELECTOR, \"img[src*='cdn']\"),\n",
    "    ]\n",
    "\n",
    "    img_url = None\n",
    "    for selector_type, selector_value in image_selectors:\n",
    "        try:\n",
    "            img_elements = driver.find_elements(selector_type, selector_value)\n",
    "            \n",
    "            for img_element in img_elements:\n",
    "                img_url = img_element.get_attribute('src')\n",
    "                if img_url and img_url.startswith('http'):\n",
    "                    # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸ (ë„ˆë¬´ ì‘ì€ ì´ë¯¸ì§€ ì œì™¸)\n",
    "                    try:\n",
    "                        width = img_element.get_attribute('width') or img_element.get_attribute('naturalWidth')\n",
    "                        height = img_element.get_attribute('height') or img_element.get_attribute('naturalHeight')\n",
    "                        \n",
    "                        if width and height:\n",
    "                            if int(width) < 100 or int(height) < 100:\n",
    "                                continue  # ë„ˆë¬´ ì‘ì€ ì´ë¯¸ì§€ëŠ” ìŠ¤í‚µ\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    break\n",
    "            \n",
    "            if img_url:\n",
    "                break\n",
    "                \n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if img_url:\n",
    "        try:\n",
    "            # ê³µí•­ ì½”ë“œ ê¸°ë°˜ íŒŒì¼ëª…\n",
    "            city_code = get_city_code(city_name)\n",
    "            img_filename = f\"{city_code}_{product_index:03d}.jpg\"\n",
    "            \n",
    "            # ì´ë¯¸ì§€ í´ë” ìƒì„±\n",
    "            img_folder = \"myrealtripthumb_img\"\n",
    "            os.makedirs(img_folder, exist_ok=True)\n",
    "            \n",
    "            img_path = os.path.join(img_folder, img_filename)\n",
    "            \n",
    "            # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ\n",
    "            urllib.request.urlretrieve(img_url, img_path)\n",
    "            \n",
    "            # íŒŒì¼ í¬ê¸° í™•ì¸\n",
    "            file_size = os.path.getsize(img_path)\n",
    "            \n",
    "            if file_size < 1024:  # 1KB ë¯¸ë§Œì´ë©´ ì‹¤íŒ¨ë¡œ ê°„ì£¼\n",
    "                os.remove(img_path)\n",
    "                return {\n",
    "                    'status': 'ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (íŒŒì¼ ë„ˆë¬´ ì‘ìŒ)',\n",
    "                    'filename': img_filename,\n",
    "                    'path': '',\n",
    "                    'size': 0\n",
    "                }\n",
    "            \n",
    "            print(f\"  âœ… ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ! ({file_size:,} bytes)\")\n",
    "            return {\n",
    "                'status': 'ë‹¤ìš´ë¡œë“œ ì™„ë£Œ',\n",
    "                'filename': img_filename,\n",
    "                'path': img_path,\n",
    "                'size': file_size\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  âš ï¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {type(e).__name__}\")\n",
    "            return {\n",
    "                'status': f'ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {type(e).__name__}',\n",
    "                'filename': f\"{get_city_code(city_name)}_{product_index:03d}.jpg\",\n",
    "                'path': '',\n",
    "                'size': 0\n",
    "            }\n",
    "    else:\n",
    "        return {\n",
    "            'status': 'ì´ë¯¸ì§€ ì—†ìŒ',\n",
    "            'filename': f\"{get_city_code(city_name)}_{product_index:03d}.jpg\",\n",
    "            'path': '',\n",
    "            'size': 0\n",
    "        }\n",
    "\n",
    "def save_results(products_data):\n",
    "    \"\"\"âœ… ë°ì´í„° ì €ì¥ (ê¸°ì¡´: save_myrealtrip_data â†’ ìƒˆë¡œìš´: save_results)\"\"\"\n",
    "    print(\"ğŸ’¾ í•˜ì´ë¸Œë¦¬ë“œ êµ¬ì¡°ë¡œ ë°ì´í„° ì €ì¥ ì¤‘...\")\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # ë„ì‹œëª… ê°€ì ¸ì˜¤ê¸°\n",
    "    city_name = products_data[0]['ë„ì‹œ'] if products_data else 'unknown'\n",
    "    \n",
    "    # ê°œë³„ CSV ì €ì¥\n",
    "    df = pd.DataFrame(products_data)\n",
    "    csv_path = f\"myrealtrip_{city_name}_products_{len(products_data)}ê°œ_{timestamp}.csv\"\n",
    "    df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"ğŸ“ ê°œë³„ CSV ì €ì¥ ì™„ë£Œ: {csv_path}\")\n",
    "    \n",
    "    # ë©”íƒ€ë°ì´í„° ì €ì¥\n",
    "    metadata = {\n",
    "        \"myrealtrip\": {\n",
    "            \"last_update\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            \"product_count\": len(products_data),\n",
    "            \"status\": \"success\",\n",
    "            \"csv_path\": csv_path,\n",
    "            \"city\": city_name\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with open('data_metadata.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"ğŸ“ ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: data_metadata.json\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    return csv_path\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸš€ Phase 2: í™•ì¥ì„± ê°œì„  ì‹œìŠ¤í…œ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)\n",
    "# =============================================================================\n",
    "\n",
    "def create_city_codes_file():\n",
    "    \"\"\"ë„ì‹œ ì½”ë“œë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\"\"\"\n",
    "    \n",
    "    # ğŸ†• Gemini ì§€ì ì‚¬í•­ ë°˜ì˜: ëŒ€ë¥™/êµ­ê°€ ì •ë³´ë„ í¬í•¨\n",
    "    enhanced_city_data = {\n",
    "        \"version\": \"2.0\",\n",
    "        \"last_updated\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"cities\": {},\n",
    "        \"total_cities\": len(CITY_CODES)\n",
    "    }\n",
    "    \n",
    "    # í†µí•©ëœ ì •ë³´ë¡œ cities êµ¬ì„±\n",
    "    for city_name, city_code in CITY_CODES.items():\n",
    "        city_info = UNIFIED_CITY_INFO.get(city_name, {\"ëŒ€ë¥™\": \"ê¸°íƒ€\", \"êµ­ê°€\": \"ê¸°íƒ€\"})\n",
    "        enhanced_city_data[\"cities\"][city_name] = {\n",
    "            \"code\": city_code,\n",
    "            \"continent\": city_info[\"ëŒ€ë¥™\"],\n",
    "            \"country\": city_info[\"êµ­ê°€\"]\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        with open('city_codes.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(enhanced_city_data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"âœ… city_codes.json íŒŒì¼ ìƒì„± ì™„ë£Œ! ({len(CITY_CODES)}ê°œ ë„ì‹œ)\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "def load_city_codes_from_file():\n",
    "    \"\"\"JSON íŒŒì¼ì—ì„œ ë„ì‹œ ì½”ë“œ ë¡œë“œ\"\"\"\n",
    "    \n",
    "    if not os.path.exists('city_codes.json'):\n",
    "        print(\"ğŸ“ city_codes.json íŒŒì¼ì´ ì—†ì–´ì„œ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...\")\n",
    "        create_city_codes_file()\n",
    "        return CITY_CODES\n",
    "    \n",
    "    try:\n",
    "        with open('city_codes.json', 'r', encoding='utf-8') as f:\n",
    "            city_data = json.load(f)\n",
    "        \n",
    "        # ìƒˆ í˜•ì‹ (v2.0) ì²˜ë¦¬\n",
    "        if \"cities\" in city_data and isinstance(list(city_data[\"cities\"].values())[0], dict):\n",
    "            loaded_codes = {city: info[\"code\"] for city, info in city_data[\"cities\"].items()}\n",
    "        else:\n",
    "            # êµ¬ í˜•ì‹ (v1.0) ì²˜ë¦¬\n",
    "            loaded_codes = city_data.get('cities', {})\n",
    "        \n",
    "        print(f\"âœ… city_codes.json ë¡œë“œ ì™„ë£Œ! ({len(loaded_codes)}ê°œ ë„ì‹œ)\")\n",
    "        print(f\"ğŸ“… ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {city_data.get('last_updated', 'ì•Œ ìˆ˜ ì—†ìŒ')}\")\n",
    "        \n",
    "        return loaded_codes\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        print(\"ğŸ’¡ ê¸°ì¡´ ì½”ë“œì˜ CITY_CODESë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "        return CITY_CODES\n",
    "\n",
    "def add_new_city(city_name, airport_code, update_file=True):\n",
    "    \"\"\"ìƒˆë¡œìš´ ë„ì‹œë¥¼ ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    global CITY_CODES\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ì— ì¶”ê°€\n",
    "    CITY_CODES[city_name] = airport_code\n",
    "    print(f\"âœ… ë©”ëª¨ë¦¬ì— ì¶”ê°€: {city_name} â†’ {airport_code}\")\n",
    "    \n",
    "    # íŒŒì¼ì—ë„ ì €ì¥\n",
    "    if update_file:\n",
    "        create_city_codes_file()  # ì „ì²´ ì¬ìƒì„±\n",
    "    \n",
    "    return True\n",
    "\n",
    "def show_supported_cities():\n",
    "    \"\"\"ì§€ì›í•˜ëŠ” ë„ì‹œ ëª©ë¡ í‘œì‹œ\"\"\"\n",
    "    \n",
    "    print(\"\\\\nğŸŒ ì§€ì›í•˜ëŠ” ë„ì‹œ ëª©ë¡:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # ì§€ì—­ë³„ë¡œ ë¶„ë¥˜\n",
    "    regions = {\n",
    "        \"ë™ë‚¨ì•„ì‹œì•„\": [\"ë°©ì½•\", \"ì¹˜ì•™ë§ˆì´\", \"í‘¸ì¼“\", \"ì‹±ê°€í¬ë¥´\", \"í™ì½©\", \"ì¿ ì•Œë¼ë£¸í‘¸ë¥´\", \"ì„¸ë¶€\", \"ë‹¤ë‚­\", \"í˜¸ì¹˜ë¯¼\"],\n",
    "        \"ì¼ë³¸\": [\"ë„ì¿„\", \"ì˜¤ì‚¬ì¹´\", \"ë‚˜ê³ ì•¼\", \"í›„ì¿ ì˜¤ì¹´\", \"ì˜¤í‚¤ë‚˜ì™€\", \"ì‚¿í¬ë¡œ\"],\n",
    "        \"í•œêµ­\": [\"ì„œìš¸\", \"ë¶€ì‚°\", \"ì œì£¼\", \"ëŒ€êµ¬\", \"ê´‘ì£¼\", \"ì—¬ìˆ˜\"],\n",
    "        \"ìœ ëŸ½\": [\"íŒŒë¦¬\", \"ëŸ°ë˜\", \"ë¡œë§ˆ\", \"ë°”ë¥´ì…€ë¡œë‚˜\"],\n",
    "        \"ë¶ë¯¸\": [\"ë‰´ìš•\", \"ë¡œìŠ¤ì•¤ì ¤ë ˆìŠ¤\", \"ì‹œì¹´ê³ \"],\n",
    "        \"ì˜¤ì„¸ì•„ë‹ˆì•„\": [\"ì‹œë“œë‹ˆ\", \"ë©œë²„ë¥¸\"]\n",
    "    }\n",
    "    \n",
    "    for region, cities in regions.items():\n",
    "        print(f\"\\\\nğŸ“ {region}:\")\n",
    "        for city in cities:\n",
    "            if city in CITY_CODES:\n",
    "                code = CITY_CODES[city]\n",
    "                print(f\"   {city} â†’ {code}\")\n",
    "    \n",
    "    print(f\"\\\\nğŸ“Š ì´ {len(CITY_CODES)}ê°œ ë„ì‹œ ì§€ì›\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "def update_config_for_scalability():\n",
    "    \"\"\"í™•ì¥ì„±ì„ ìœ„í•œ CONFIG ì—…ë°ì´íŠ¸\"\"\"\n",
    "    \n",
    "    global CONFIG\n",
    "    \n",
    "    # ê¸°ì¡´ CONFIGì— í™•ì¥ì„± ì„¤ì • ì¶”ê°€\n",
    "    scalability_config = {\n",
    "        # ë„ì‹œ ê´€ë¦¬\n",
    "        \"AUTO_LOAD_CITIES\": True,\n",
    "        \"AUTO_SAVE_NEW_CITIES\": True,\n",
    "        \n",
    "        # ë‹¤ì¤‘ ë„ì‹œ ì§€ì›\n",
    "        \"ENABLE_MULTI_CITY\": False,\n",
    "        \"CITY_PROCESSING_ORDER\": \"sequential\",\n",
    "        \n",
    "        # íŒŒì¼ ê´€ë¦¬\n",
    "        \"BACKUP_OLD_DATA\": True,\n",
    "        \"DATA_RETENTION_DAYS\": 30,\n",
    "        \n",
    "        # í™•ì¥ ê¸°ëŠ¥\n",
    "        \"ENABLE_CITY_VALIDATION\": True,\n",
    "        \"ENABLE_DUPLICATE_CHECK\": True,\n",
    "    }\n",
    "    \n",
    "    CONFIG.update(scalability_config)\n",
    "    print(\"âš™ï¸ CONFIG í™•ì¥ì„± ì„¤ì • ì—…ë°ì´íŠ¸ ì™„ë£Œ!\")\n",
    "\n",
    "def initialize_file_system():\n",
    "    \"\"\"íŒŒì¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ì„¤ì •\"\"\"\n",
    "    \n",
    "    print(\"ğŸ”§ Phase 2: í™•ì¥ì„± ê°œì„  ì‹œìŠ¤í…œ ì´ˆê¸°í™”...\")\n",
    "    \n",
    "    # CONFIG ì—…ë°ì´íŠ¸\n",
    "    update_config_for_scalability()\n",
    "    \n",
    "    # ë„ì‹œ ì½”ë“œ íŒŒì¼ ë¡œë“œ/ìƒì„±\n",
    "    if CONFIG.get(\"AUTO_LOAD_CITIES\", True):\n",
    "        global CITY_CODES\n",
    "        loaded_codes = load_city_codes_from_file()\n",
    "        \n",
    "        # ìƒˆë¡œ ë¡œë“œëœ ì½”ë“œê°€ ë” ë§ìœ¼ë©´ ì—…ë°ì´íŠ¸\n",
    "        if len(loaded_codes) >= len(CITY_CODES):\n",
    "            CITY_CODES = loaded_codes\n",
    "            print(f\"ğŸ”„ CITY_CODES ì—…ë°ì´íŠ¸: {len(CITY_CODES)}ê°œ ë„ì‹œ\")\n",
    "        else:\n",
    "            # ë©”ëª¨ë¦¬ì˜ ì½”ë“œê°€ ë” ìµœì‹ ì´ë©´ íŒŒì¼ ì—…ë°ì´íŠ¸\n",
    "            create_city_codes_file()\n",
    "    \n",
    "    print(\"âœ… Phase 2 ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
    "    return True\n",
    "\n",
    "def quick_add_cities():\n",
    "    \"\"\"ìì£¼ ì‚¬ìš©í•˜ëŠ” ë„ì‹œë“¤ì„ ë¹ ë¥´ê²Œ ì¶”ê°€\"\"\"\n",
    "    \n",
    "    quick_cities = {\n",
    "        # ì¶”ê°€ë¡œ ìì£¼ ì‚¬ìš©ë  ë„ì‹œë“¤\n",
    "        \"êµí† \": \"KIX\",      # ì˜¤ì‚¬ì¹´ ê³µí•­ ì‚¬ìš©\n",
    "        \"ì¸ì²œ\": \"ICN\",      # ì„œìš¸ ê³µí•­\n",
    "        \"ê¹€í¬\": \"GMP\",      # ê¹€í¬ê³µí•­\n",
    "        \"í•˜ì™€ì´\": \"HNL\",    # í˜¸ë†€ë£°ë£¨\n",
    "        \"ê´Œ\": \"GUM\",        # ê´Œ êµ­ì œê³µí•­\n",
    "        \"ì‚¬ì´íŒ\": \"SPN\",    # ì‚¬ì´íŒ ê³µí•­\n",
    "        \"í‘¸ê¾¸ì˜¥\": \"PQC\",    # í‘¸ê¾¸ì˜¥ ê³µí•­\n",
    "        \"ë‚˜íŠ¸ë‘\": \"CXR\",    # ë‚˜íŠ¸ë‘ ê³µí•­\n",
    "        \"ë³´í™€\": \"TAG\",      # ë³´í™€ ê³µí•­\n",
    "        \"ë‘ì¹´ìœ„\": \"LGK\",    # ë‘ì¹´ìœ„ ê³µí•­\n",
    "    }\n",
    "    \n",
    "    print(\"ğŸš€ ìì£¼ ì‚¬ìš©í•˜ëŠ” ë„ì‹œë“¤ ì¶”ê°€ ì¤‘...\")\n",
    "    \n",
    "    for city, code in quick_cities.items():\n",
    "        if city not in CITY_CODES:\n",
    "            add_new_city(city, code, update_file=False)\n",
    "    \n",
    "    # í•œ ë²ˆì— íŒŒì¼ ì €ì¥\n",
    "    create_city_codes_file()\n",
    "    \n",
    "    print(f\"âœ… {len(quick_cities)}ê°œ ë„ì‹œ ì¼ê´„ ì¶”ê°€ ì™„ë£Œ!\")\n",
    "\n",
    "def validate_city(city_name):\n",
    "    \"\"\"ë„ì‹œëª… ìœ íš¨ì„± ê²€ì‚¬\"\"\"\n",
    "    \n",
    "    if not city_name or len(city_name.strip()) == 0:\n",
    "        return False, \"ë„ì‹œëª…ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    if city_name in CITY_CODES:\n",
    "        return True, f\"ì§€ì›í•˜ëŠ” ë„ì‹œì…ë‹ˆë‹¤. ({CITY_CODES[city_name]})\"\n",
    "    \n",
    "    # ìœ ì‚¬í•œ ë„ì‹œëª… ì°¾ê¸°\n",
    "    similar_cities = []\n",
    "    for supported_city in CITY_CODES.keys():\n",
    "        if city_name.lower() in supported_city.lower() or supported_city.lower() in city_name.lower():\n",
    "            similar_cities.append(supported_city)\n",
    "    \n",
    "    if similar_cities:\n",
    "        return False, f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë„ì‹œì…ë‹ˆë‹¤. ë¹„ìŠ·í•œ ë„ì‹œ: {', '.join(similar_cities)}\"\n",
    "    else:\n",
    "        return False, f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë„ì‹œì…ë‹ˆë‹¤. ìƒˆë¡œ ì¶”ê°€í•˜ì‹œë ¤ë©´ add_new_city() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\"\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ› ï¸ ê¸°ì¡´ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (Phase 2 ì‹œìŠ¤í…œê³¼ í•¨ê»˜ ìœ ì§€)\n",
    "# =============================================================================\n",
    "\n",
    "def print_progress(current, total, city_name, status=\"ì§„í–‰ì¤‘\"):\n",
    "    \"\"\"ì§„í–‰ë¥ ì„ ì‹œê°ì ìœ¼ë¡œ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    percentage = (current / total) * 100\n",
    "    bar_length = 30\n",
    "    filled_length = int(bar_length * current // total)\n",
    "    bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)\n",
    "    \n",
    "    emoji = \"ğŸ”\" if status == \"ì§„í–‰ì¤‘\" else \"âœ…\" if status == \"ì™„ë£Œ\" else \"âŒ\"\n",
    "    \n",
    "    print(f\"\\n{emoji} ì§„í–‰ë¥ : [{bar}] {percentage:.1f}% ({current}/{total})\")\n",
    "    print(f\"ğŸ“ í˜„ì¬ ì‘ì—…: {city_name} - {status}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "def print_product_progress(current, total, product_name):\n",
    "    \"\"\"ìƒí’ˆë³„ ì§„í–‰ë¥  í‘œì‹œ í•¨ìˆ˜\"\"\"\n",
    "    percentage = (current / total) * 100\n",
    "    bar_length = 20\n",
    "    filled_length = int(bar_length * current // total)\n",
    "    bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)\n",
    "    \n",
    "    safe_name = str(product_name)[:30] + \"...\" if len(str(product_name)) > 30 else str(product_name)\n",
    "    print(f\"    ğŸ¯ ìƒí’ˆ ì§„í–‰ë¥ : [{bar}] {percentage:.1f}% ({current}/{total})\")\n",
    "    print(f\"    ğŸ“¦ í˜„ì¬ ìƒí’ˆ: {safe_name}\")\n",
    "\n",
    "def save_intermediate_results(results, city_name):\n",
    "    \"\"\"ì¤‘ê°„ ê²°ê³¼ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    if results and CONFIG[\"SAVE_INTERMEDIATE\"]:\n",
    "        try:\n",
    "            timestamp = time.strftime('%Y%m%d_%H%M%S')\n",
    "            temp_filename = f\"temp_ì¤‘ê°„ì €ì¥_{city_name}_{timestamp}.csv\"\n",
    "            pd.DataFrame(results).to_csv(temp_filename, index=False, encoding='utf-8-sig')\n",
    "            print(f\"  ğŸ’¾ ì¤‘ê°„ ê²°ê³¼ ì €ì¥: {temp_filename}\")\n",
    "            return temp_filename\n",
    "        except Exception as e:\n",
    "            print(f\"  âš ï¸ ì¤‘ê°„ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def retry_operation(func, operation_name, max_retries=None):\n",
    "    \"\"\"ì‹¤íŒ¨í•œ ì‘ì—…ì„ ì¬ì‹œë„í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    if max_retries is None:\n",
    "        max_retries = CONFIG[\"RETRY_COUNT\"]\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return func()\n",
    "        except (TimeoutException, NoSuchElementException, WebDriverException) as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                print(f\"  âŒ {operation_name} ìµœì¢… ì‹¤íŒ¨: {type(e).__name__}\")\n",
    "                raise e\n",
    "            print(f\"  ğŸ”„ {operation_name} ì¬ì‹œë„ {attempt + 1}/{max_retries} (ì˜¤ë¥˜: {type(e).__name__})\")\n",
    "            time.sleep(2)\n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ {operation_name} ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {type(e).__name__}: {e}\")\n",
    "            raise e\n",
    "\n",
    "def make_safe_filename(filename):\n",
    "    \"\"\"íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°\"\"\"\n",
    "    if not filename:\n",
    "        return \"ê¸°ë³¸íŒŒì¼ëª…\"\n",
    "    \n",
    "    safe_filename = str(filename)\n",
    "    unsafe_chars = ['/', '\\\\', ':', '*', '?', '\"', '<', '>', '|', '\\n', '\\r', '\\t']\n",
    "    for char in unsafe_chars:\n",
    "        safe_filename = safe_filename.replace(char, '_')\n",
    "    \n",
    "    if len(safe_filename) > 200:\n",
    "        safe_filename = safe_filename[:200]\n",
    "    \n",
    "    if safe_filename.startswith('.'):\n",
    "        safe_filename = '_' + safe_filename[1:]\n",
    "    \n",
    "    return safe_filename\n",
    "\n",
    "def make_user_agent(ua, is_mobile):\n",
    "    user_agent = parse(ua)\n",
    "    model = user_agent.device.model\n",
    "    platform = user_agent.os.family\n",
    "    platform_version = user_agent.os.version_string + \".0.0\"\n",
    "    version = user_agent.browser.version[0]\n",
    "    ua_full_version = user_agent.browser.version_string\n",
    "    architecture = \"x86\"\n",
    "    print(platform)\n",
    "    if is_mobile:\n",
    "        platform_info = \"Linux armv8l\"\n",
    "        architecture= \"\"\n",
    "    else:\n",
    "        platform_info = \"Win32\"\n",
    "        model = \"\"\n",
    "    RET_USER_AGENT = {\n",
    "        \"appVersion\" : ua.replace(\"Mozilla/\", \"\"),\n",
    "        \"userAgent\": ua,\n",
    "        \"platform\" : f\"{platform_info}\",\n",
    "        \"acceptLanguage\" : \"ko-KR, kr, en-US, en\",\n",
    "        \"userAgentMetadata\":{\n",
    "            \"brands\" : [\n",
    "                {\"brand\":\"Google Chrome\", \"version\":f\"{version}\"},\n",
    "                {\"brand\":\"Chromium\", \"version\":f\"{version}\"},\n",
    "                {\"brand\":\" Not A;Brand\", \"version\":\"99\"}\n",
    "            ],\n",
    "            \"fullVersionList\" : [\n",
    "                {\"brand\":\"Google Chrome\", \"version\":f\"{version}\"},\n",
    "                {\"brand\":\"Chromium\", \"version\":f\"{version}\"},\n",
    "                {\"brand\":\" Not A;Brand\", \"version\":\"99\"}\n",
    "            ],\n",
    "            \"fullVersion\":f\"{ua_full_version}\",\n",
    "            \"platform\" :platform,\n",
    "            \"platformVersion\":platform_version,\n",
    "            \"architecture\":architecture,\n",
    "            \"model\" : model,\n",
    "            \"mobile\":is_mobile\n",
    "        }\n",
    "    }\n",
    "    return RET_USER_AGENT\n",
    "\n",
    "def generate_random_geolocation():\n",
    "    ltop_lat = 37.75415601640249\n",
    "    ltop_long = 126.86767642302573\n",
    "    rbottom_lat = 37.593829172663945\n",
    "    rbottom_long = 127.15276051439332\n",
    "\n",
    "    targetLat = random.uniform(rbottom_lat, ltop_lat)\n",
    "    targetLong = random.uniform(ltop_long,rbottom_long)\n",
    "    return {\"latitude\":targetLat, \"longitude\" : targetLong, \"accuracy\":100}\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì • ë° ì‹¤í–‰\"\"\"\n",
    "    chromedriver_autoinstaller.install()\n",
    "    \n",
    "    options = uc.ChromeOptions()\n",
    "    \n",
    "    UA = CONFIG[\"USER_AGENT\"]  # âœ… Gemini ì§€ì ì‚¬í•­ í•´ê²°: USER_AGENT ì‚¬ìš©\n",
    "    options.add_argument(f\"--user-agent={UA}\")\n",
    "    \n",
    "    rand_user_folder = random.randrange(1,100)\n",
    "    raw_path = os.path.abspath(\"cookies\")\n",
    "    try:\n",
    "        shutil.rmtree(raw_path)\n",
    "    except:\n",
    "        pass\n",
    "    os.makedirs(raw_path, exist_ok=True)\n",
    "    user_cookie_name = f\"{raw_path}/{rand_user_folder}\"\n",
    "    if os.path.exists(user_cookie_name) == False:\n",
    "        os.makedirs(user_cookie_name, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        driver = uc.Chrome(user_data_dir=user_cookie_name, options=options)\n",
    "        print(\"âœ… í¬ë¡¬ ë“œë¼ì´ë²„ ì‹¤í–‰ ì„±ê³µ!\")\n",
    "    except Exception as e:\n",
    "        print('\\n',\"-\"*50,\"\\n\",\"-\"*50,\"\\n\")\n",
    "        print(\"# í‚¤í™ˆ ë©”ì„¸ì§€ : í˜¹ì‹œ ì—¬ê¸°ì„œ ì—ëŸ¬ ë°œìƒì‹œ [ì•„ë˜ ë¸”ë¡œê·¸ ì°¸ê³  -> ì¬ë¶€íŒ… -> ë‹¤ì‹œ ì½”ë“œì‹¤í–‰] í•´ë³´ì‹œê¸¸ ë°”ëë‹ˆë‹¤! \\n (êµ¬ê¸€í¬ë¡¬ ë²„ì ¼ ì—…ê·¸ë ˆì´ë“œ ë¬¸ì œ)\")\n",
    "        print('https://appfollow.tistory.com/102')\n",
    "        print('\\n',\"-\"*50,\"\\n\",\"-\"*50,\"\\n\")\n",
    "        raise RuntimeError\n",
    "        \n",
    "    UA_Data = make_user_agent(UA,False)\n",
    "    driver.execute_cdp_cmd(\"Network.setUserAgentOverride\",UA_Data)\n",
    "    \n",
    "    GEO_DATA = generate_random_geolocation()\n",
    "    driver.execute_cdp_cmd(\"Emulation.setGeolocationOverride\", GEO_DATA)\n",
    "    driver.execute_cdp_cmd(\"Emulation.setUserAgentOverride\", UA_Data)\n",
    "    driver.execute_cdp_cmd(\"Emulation.setNavigatorOverrides\",{\"platform\":\"Linux armv8l\"})\n",
    "    \n",
    "    return driver\n",
    "\n",
    "def go_to_main_page(driver):\n",
    "    \"\"\"ë©”ì¸ í˜ì´ì§€ë¡œ ì´ë™\"\"\"\n",
    "    driver.get(\"https://www.myrealtrip.com/experiences/\")\n",
    "    time.sleep(random.uniform(CONFIG[\"MIN_DELAY\"], CONFIG[\"MAX_DELAY\"]))\n",
    "    return True\n",
    "\n",
    "def find_and_fill_search(driver, city_name):\n",
    "    \"\"\"ê²€ìƒ‰ì°½ ì°¾ê¸° ë° ì…ë ¥\"\"\"\n",
    "    print(f\"  ğŸ” '{city_name}' ê²€ìƒ‰ì°½ ì°¾ëŠ” ì¤‘...\")\n",
    "    search_selectors = [\n",
    "        (By.CSS_SELECTOR, \"input[placeholder*='ì–´ë””ë¡œ']\"),\n",
    "        (By.CSS_SELECTOR, \"input[type='text']\"),\n",
    "        (By.XPATH, \"//input[contains(@placeholder, 'ì–´ë””ë¡œ')]\"),\n",
    "        (By.XPATH, \"/html/body/main/div/div[2]/section[1]/div[1]/div/div/input\")\n",
    "    ]\n",
    "\n",
    "    search_input = None\n",
    "    for selector_type, selector_value in search_selectors:\n",
    "        try:\n",
    "            search_input = WebDriverWait(driver, CONFIG[\"WAIT_TIMEOUT\"]).until(\n",
    "                EC.presence_of_element_located((selector_type, selector_value))\n",
    "            )\n",
    "            print(f\"  âœ… ê²€ìƒ‰ì°½ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!\")\n",
    "            break\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "\n",
    "    if not search_input:\n",
    "        raise NoSuchElementException(\"ê²€ìƒ‰ì°½ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "\n",
    "    search_input.clear()\n",
    "    search_input.send_keys(city_name)\n",
    "    time.sleep(random.uniform(CONFIG[\"MIN_DELAY\"], CONFIG[\"MIN_DELAY\"]+2))\n",
    "    print(f\"  ğŸ“ '{city_name}' í‚¤ì›Œë“œ ì…ë ¥ ì™„ë£Œ\")\n",
    "    return True\n",
    "\n",
    "def click_search_button(driver):\n",
    "    \"\"\"ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­\"\"\"\n",
    "    print(f\"  ğŸ” ê²€ìƒ‰ ë²„íŠ¼ ì°¾ëŠ” ì¤‘...\")\n",
    "    search_button_selectors = [\n",
    "        (By.CSS_SELECTOR, \"button[type='submit']\"),\n",
    "        (By.CSS_SELECTOR, \".search-btn\"),\n",
    "        (By.XPATH, \"//button[contains(@class, 'search')]\"),\n",
    "        (By.XPATH, \"//img[contains(@alt, 'ê²€ìƒ‰')]//parent::*\"),\n",
    "        (By.XPATH, \"/html/body/main/div/div[2]/section[1]/div[1]/div/div/div/img\")\n",
    "    ]\n",
    "\n",
    "    search_clicked = False\n",
    "    for selector_type, selector_value in search_button_selectors:\n",
    "        try:\n",
    "            search_button = WebDriverWait(driver, CONFIG[\"WAIT_TIMEOUT\"]).until(\n",
    "                EC.element_to_be_clickable((selector_type, selector_value))\n",
    "            )\n",
    "            search_button.click()\n",
    "            print(f\"  âœ… ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­ ì„±ê³µ!\")\n",
    "            search_clicked = True\n",
    "            time.sleep(random.uniform(CONFIG[\"MIN_DELAY\"], CONFIG[\"MAX_DELAY\"]))\n",
    "            break\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "\n",
    "    if not search_clicked:\n",
    "        raise NoSuchElementException(\"ê²€ìƒ‰ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "    return True\n",
    "\n",
    "def handle_popup(driver):\n",
    "    \"\"\"íŒì—… ì²˜ë¦¬\"\"\"\n",
    "    popup_selectors = [\n",
    "        (By.CSS_SELECTOR, \".popup-close\"),\n",
    "        (By.CSS_SELECTOR, \".modal-close\"),\n",
    "        (By.XPATH, \"//button[contains(@aria-label, 'ë‹«ê¸°')]\"),\n",
    "        (By.XPATH, \"//button[contains(text(), 'ë‹«ê¸°')]\"),\n",
    "        (By.XPATH, \"/html/body/div[15]/div[2]/button\")\n",
    "    ]\n",
    "\n",
    "    popup_closed = False\n",
    "    for selector_type, selector_value in popup_selectors:\n",
    "        try:\n",
    "            popup_button = WebDriverWait(driver, CONFIG[\"POPUP_WAIT\"]).until(\n",
    "                EC.element_to_be_clickable((selector_type, selector_value))\n",
    "            )\n",
    "            popup_button.click()\n",
    "            print(f\"  âœ… íŒì—…ì°½ì„ ë‹«ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "            popup_closed = True\n",
    "            time.sleep(random.uniform(1, 4))\n",
    "            break\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "\n",
    "    if not popup_closed:\n",
    "        print(f\"  â„¹ï¸ íŒì—…ì°½ì´ ì—†ê±°ë‚˜ ì´ë¯¸ ë‹«í˜€ìˆìŠµë‹ˆë‹¤.\")\n",
    "    return True\n",
    "\n",
    "def click_view_all(driver):\n",
    "    \"\"\"ì „ì²´ ìƒí’ˆ ë³´ê¸° ë²„íŠ¼ í´ë¦­\"\"\"\n",
    "    print(f\"  ğŸ“‹ ì „ì²´ ìƒí’ˆ ë³´ê¸° ë²„íŠ¼ ì°¾ëŠ” ì¤‘...\")\n",
    "    view_all_selectors = [\n",
    "        (By.XPATH, \"//button[contains(text(), 'ì „ì²´')]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'ì „ì²´')]//parent::button\"),\n",
    "        (By.CSS_SELECTOR, \"button[aria-label*='ì „ì²´']\"),\n",
    "        (By.XPATH, \"/html/body/div[4]/div[2]/div/div/div/span[21]/button\")\n",
    "    ]\n",
    "\n",
    "    view_all_clicked = False\n",
    "    for selector_type, selector_value in view_all_selectors:\n",
    "        try:\n",
    "            view_all_button = WebDriverWait(driver, CONFIG[\"WAIT_TIMEOUT\"]).until(\n",
    "                EC.element_to_be_clickable((selector_type, selector_value))\n",
    "            )\n",
    "            view_all_button.click()\n",
    "            print(f\"  âœ… ì „ì²´ ìƒí’ˆ ë³´ê¸° í´ë¦­ ì„±ê³µ!\")\n",
    "            view_all_clicked = True\n",
    "            time.sleep(random.uniform(CONFIG[\"MIN_DELAY\"], CONFIG[\"MIN_DELAY\"]+3))\n",
    "            break\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "\n",
    "    if not view_all_clicked:\n",
    "        print(f\"  âš ï¸ ì „ì²´ ìƒí’ˆ ë³´ê¸° ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ìƒí’ˆìœ¼ë¡œ ì§„í–‰...\")\n",
    "    return True\n",
    "\n",
    "def collect_page_urls(driver):\n",
    "    \"\"\"í˜„ì¬ í˜ì´ì§€ì˜ ëª¨ë“  ìƒí’ˆ URL ìˆ˜ì§‘\"\"\"\n",
    "    print(f\"  ğŸ“Š í˜„ì¬ í˜ì´ì§€ì˜ ìƒí’ˆ URLë“¤ì„ ìˆ˜ì§‘ ì¤‘...\")\n",
    "    \n",
    "    time.sleep(random.uniform(3, 5))\n",
    "    \n",
    "    product_url_selectors = [\n",
    "        \"a[href*='/experiences/']\",\n",
    "        \"a[href*='/experience/']\",\n",
    "        \".product-item a\",\n",
    "        \".experience-card a\"\n",
    "    ]\n",
    "    \n",
    "    collected_urls = []\n",
    "    \n",
    "    for selector in product_url_selectors:\n",
    "        try:\n",
    "            product_elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "            \n",
    "            for element in product_elements:\n",
    "                try:\n",
    "                    url = element.get_attribute('href')\n",
    "                    if url and '/experiences/' in url and url not in collected_urls:\n",
    "                        collected_urls.append(url)\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "            \n",
    "            if collected_urls:\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    valid_urls = []\n",
    "    for url in collected_urls:\n",
    "        if url and url.startswith('http') and '/experiences/' in url:\n",
    "            valid_urls.append(url)\n",
    "    \n",
    "    print(f\"  âœ… {len(valid_urls)}ê°œì˜ ìƒí’ˆ URLì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤!\")\n",
    "    \n",
    "    if len(valid_urls) == 0:\n",
    "        print(\"  âš ï¸ ìƒí’ˆ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜ì´ì§€ êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "    \n",
    "    return valid_urls\n",
    "\n",
    "def get_rating(driver):\n",
    "    \"\"\"í‰ì  ì •ë³´ ìˆ˜ì§‘ (ê¸°ì¡´ í•¨ìˆ˜ ìœ ì§€)\"\"\"\n",
    "    rating_selectors = [\n",
    "        (By.CSS_SELECTOR, \".rating\"),\n",
    "        (By.CSS_SELECTOR, \"[class*='rating']\"),\n",
    "        (By.XPATH, \"//span[contains(@class, 'rating')]\"),\n",
    "        (By.XPATH, \"/html/body/div[1]/main/div[1]/section/div[1]/span/span[2]\")\n",
    "    ]\n",
    "\n",
    "    for selector_type, selector_value in rating_selectors:\n",
    "        try:\n",
    "            rating_element = WebDriverWait(driver, CONFIG[\"WAIT_TIMEOUT\"]).until(\n",
    "                EC.presence_of_element_located((selector_type, selector_value))\n",
    "            )\n",
    "            found_rating = rating_element.text\n",
    "            time.sleep(random.uniform(2, 4))\n",
    "            return found_rating\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "    \n",
    "    return \"ì •ë³´ ì—†ìŒ\"\n",
    "\n",
    "def get_review_count(driver):\n",
    "    \"\"\"ë¦¬ë·° ìˆ˜ ì •ë³´ ìˆ˜ì§‘\"\"\"\n",
    "    print(f\"  ğŸ“ ë¦¬ë·° ìˆ˜ ì •ë³´ ì°¾ëŠ” ì¤‘...\")\n",
    "    review_count_selectors = [\n",
    "        (By.XPATH, \"//span[contains(text(), 'ë¦¬ë·°')]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'review')]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'í›„ê¸°')]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'ê°œ')]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'ê±´')]\"),\n",
    "    ]\n",
    "\n",
    "    for selector_type, selector_value in review_count_selectors:\n",
    "        try:\n",
    "            review_element = WebDriverWait(driver, 3).until(\n",
    "                EC.presence_of_element_located((selector_type, selector_value))\n",
    "            )\n",
    "            review_text = review_element.text.strip()\n",
    "            \n",
    "            review_keywords = ['ë¦¬ë·°', 'í›„ê¸°', 'review', 'ê°œ', 'ê±´']\n",
    "            has_number = any(char.isdigit() for char in review_text)\n",
    "            has_keyword = any(keyword in review_text.lower() for keyword in review_keywords)\n",
    "            \n",
    "            if has_number and has_keyword and len(review_text) < 50:\n",
    "                print(f\"  âœ… ë¦¬ë·° ìˆ˜ ì •ë³´ ë°œê²¬: {review_text}\")\n",
    "                return review_text\n",
    "                \n",
    "        except TimeoutException:\n",
    "            continue\n",
    "\n",
    "    print(f\"  â„¹ï¸ ë¦¬ë·° ìˆ˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    return \"\"\n",
    "\n",
    "def get_language(driver):\n",
    "    \"\"\"ì–¸ì–´ ì •ë³´ ìˆ˜ì§‘\"\"\"\n",
    "    print(f\"  ğŸŒ ì–¸ì–´ ì •ë³´ ì°¾ëŠ” ì¤‘...\")\n",
    "    language_selectors = [\n",
    "        (By.XPATH, \"//span[contains(text(), 'ì–¸ì–´')]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'í•œêµ­ì–´')]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'ì˜ì–´')]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'Korean')]\"),\n",
    "        (By.XPATH, \"//span[contains(text(), 'English')]\"),\n",
    "    ]\n",
    "\n",
    "    for selector_type, selector_value in language_selectors:\n",
    "        try:\n",
    "            language_element = WebDriverWait(driver, 3).until(\n",
    "                EC.presence_of_element_located((selector_type, selector_value))\n",
    "            )\n",
    "            language_text = language_element.text.strip()\n",
    "            \n",
    "            language_keywords = ['ì–¸ì–´', 'í•œêµ­ì–´', 'ì˜ì–´', 'ì¤‘êµ­ì–´', 'ì¼ë³¸ì–´', 'Korean', 'English']\n",
    "            \n",
    "            if any(keyword in language_text for keyword in language_keywords):\n",
    "                print(f\"  âœ… ì–¸ì–´ ì •ë³´ ë°œê²¬: {language_text}\")\n",
    "                return language_text\n",
    "                \n",
    "        except TimeoutException:\n",
    "            continue\n",
    "\n",
    "    print(f\"  â„¹ï¸ ì–¸ì–´ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    return \"\"\n",
    "\n",
    "# =============================================================================\n",
    "# Phase 2 ì‹œìŠ¤í…œ ìë™ ì‹¤í–‰\n",
    "# =============================================================================\n",
    "\n",
    "# ìë™ ì´ˆê¸°í™” ì‹¤í–‰\n",
    "try:\n",
    "    initialize_file_system()\n",
    "    \n",
    "    # ìì£¼ ì‚¬ìš©í•˜ëŠ” ë„ì‹œë“¤ë„ ì¶”ê°€\n",
    "    quick_add_cities()\n",
    "    \n",
    "    # ì§€ì› ë„ì‹œ ëª©ë¡ í‘œì‹œ\n",
    "    show_supported_cities()\n",
    "    \n",
    "    print(\"\\nğŸ‰ Phase 2: í™•ì¥ì„± ê°œì„  ì™„ë£Œ!\")\n",
    "    print(\"ğŸ’¡ ì´ì œ ì´ëŸ° ê¸°ëŠ¥ë“¤ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\")\n",
    "    print(\"   - add_new_city('ì œì£¼ë„', 'CJU')  # ìƒˆ ë„ì‹œ ì¶”ê°€\")\n",
    "    print(\"   - show_supported_cities()        # ì§€ì› ë„ì‹œ ëª©ë¡\")\n",
    "    print(\"   - validate_city('ë°©ì½•')          # ë„ì‹œ ìœ íš¨ì„± ê²€ì‚¬\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Phase 2 ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ’¡ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ê³„ì† ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… ê·¸ë£¹ 1 ì™„ë£Œ: ëª¨ë“  í•¨ìˆ˜ê°€ ì •ì˜ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ”§ í•µì‹¬ í•¨ìˆ˜ëª… ë³€ê²½ ì™„ë£Œ:\")\n",
    "print(\"   get_product_name_by_type() â†’ get_product_name()\")\n",
    "print(\"   get_price_fixed() â†’ get_price()\")\n",
    "print(\"   download_image_improved_fixed() â†’ download_image()\")\n",
    "print(\"   extract_clean_price() â†’ clean_price()\")\n",
    "print(\"   extract_clean_rating() â†’ clean_rating()\")\n",
    "print(\"   save_myrealtrip_data() â†’ save_results()\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ğŸ”¢ í˜„ì¬ ì„¤ì •: {CONFIG['MAX_PRODUCTS_PER_CITY']}ê°œ ìƒí’ˆ í¬ë¡¤ë§\")\n",
    "print(f\"ğŸ™ï¸ ê²€ìƒ‰ ë„ì‹œ: {CITIES_TO_SEARCH}\")\n",
    "print(\"ğŸ¯ ë‹¤ìŒ: ê·¸ë£¹ 2,3,4ì—ì„œ í•¨ìˆ˜ í˜¸ì¶œì„ í†µì¼ëœ í•¨ìˆ˜ëª…ìœ¼ë¡œ ë³€ê²½í•˜ì„¸ìš”!\")\n",
    "print(\"ğŸš¨ Gemini ì§€ì ì‚¬í•­ ëª¨ë‘ í•´ê²° ì™„ë£Œ! ì•ˆì „í•˜ê²Œ ì‹¤í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97a1d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e64d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fd4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ğŸ” ê·¸ë£¹ 2: í†µì¼ëœ í•¨ìˆ˜ëª… - ê²€ìƒ‰ ë° URL ìˆ˜ì§‘ ì‹œìŠ¤í…œ (í•¨ìˆ˜ëª… í†µì¼ ì™„ë£Œ)\n",
    "# ê·¸ë£¹ 1ì—ì„œ ì •ì˜ëœ í†µì¼ëœ í•¨ìˆ˜ëª…ë“¤ì„ ì‚¬ìš©\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ” ê·¸ë£¹ 2: ê²€ìƒ‰ ë° URL ìˆ˜ì§‘ ì‹œìŠ¤í…œ ì‹œì‘!\")\n",
    "print(\"ğŸ“‹ ê·¸ë£¹ 1ì˜ í†µì¼ëœ í•¨ìˆ˜ëª…ë“¤ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:\")\n",
    "print(\"   - get_product_name()\")\n",
    "print(\"   - get_price()\")\n",
    "print(\"   - download_image()\")\n",
    "print(\"   - clean_price()\")\n",
    "print(\"   - clean_rating()\")\n",
    "print(\"   - save_results()\")\n",
    "print(\"   - get_city_code(), get_city_info() (ê³µìš©)\")\n",
    "\n",
    "def search_and_collect_urls(driver, city_name):\n",
    "    \"\"\"ë„ì‹œë³„ ê²€ìƒ‰ ë° ìƒí’ˆ URL ìˆ˜ì§‘ (í†µì¼ëœ í•¨ìˆ˜ëª… ì‚¬ìš©)\"\"\"\n",
    "    print(f\"\\nğŸ” {city_name} ë„ì‹œ ê²€ìƒ‰ ì‹œì‘...\")\n",
    "    \n",
    "    try:\n",
    "        # 1. ë©”ì¸ í˜ì´ì§€ ì´ë™\n",
    "        print(\"ğŸ“ 1ë‹¨ê³„: ë©”ì¸ í˜ì´ì§€ ì´ë™\")\n",
    "        go_to_main_page(driver)\n",
    "        \n",
    "        # 2. ê²€ìƒ‰ì°½ ì°¾ê¸° ë° ì…ë ¥\n",
    "        print(\"ğŸ“ 2ë‹¨ê³„: ê²€ìƒ‰ ì‹¤í–‰\")\n",
    "        find_and_fill_search(driver, city_name)\n",
    "        \n",
    "        # 3. ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­\n",
    "        click_search_button(driver)\n",
    "        \n",
    "        # 4. íŒì—… ì²˜ë¦¬\n",
    "        print(\"ğŸ“ 3ë‹¨ê³„: íŒì—… ì²˜ë¦¬\")\n",
    "        handle_popup(driver)\n",
    "        \n",
    "        # 5. ì „ì²´ ìƒí’ˆ ë³´ê¸° í´ë¦­\n",
    "        print(\"ğŸ“ 4ë‹¨ê³„: ì „ì²´ ìƒí’ˆ ë³´ê¸°\")\n",
    "        click_view_all(driver)\n",
    "        \n",
    "        # 6. ìƒí’ˆ URL ìˆ˜ì§‘\n",
    "        print(\"ğŸ“ 5ë‹¨ê³„: ìƒí’ˆ URL ìˆ˜ì§‘\")\n",
    "        product_urls = collect_page_urls(driver)\n",
    "        \n",
    "        # 7. ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½\n",
    "        print(f\"\\nâœ… {city_name} ê²€ìƒ‰ ì™„ë£Œ!\")\n",
    "        print(f\"ğŸ“Š ìˆ˜ì§‘ëœ ìƒí’ˆ URL: {len(product_urls)}ê°œ\")\n",
    "        \n",
    "        # 8. ë„ì‹œ ì½”ë“œ í™•ì¸ (í†µì¼ëœ í•¨ìˆ˜ëª… ì‚¬ìš©)\n",
    "        city_code = get_city_code(city_name)\n",
    "        continent, country = get_city_info(city_name)\n",
    "        \n",
    "        print(f\"ğŸ™ï¸ ë„ì‹œ ì •ë³´: {city_name} ({city_code}) - {continent}, {country}\")\n",
    "        \n",
    "        return product_urls\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {city_name} ê²€ìƒ‰ ì‹¤íŒ¨: {type(e).__name__}: {e}\")\n",
    "        return []\n",
    "\n",
    "def validate_and_filter_urls(product_urls, city_name):\n",
    "    \"\"\"ìˆ˜ì§‘ëœ URL ìœ íš¨ì„± ê²€ì‚¬ ë° í•„í„°ë§\"\"\"\n",
    "    print(f\"\\nğŸ” {city_name} URL ìœ íš¨ì„± ê²€ì‚¬ ì¤‘...\")\n",
    "    \n",
    "    valid_urls = []\n",
    "    invalid_urls = []\n",
    "    \n",
    "    for i, url in enumerate(product_urls):\n",
    "        print(f\"  ğŸ“‹ URL {i+1}/{len(product_urls)} ê²€ì‚¬ ì¤‘...\")\n",
    "        \n",
    "        # URL ê¸°ë³¸ ìœ íš¨ì„± ê²€ì‚¬\n",
    "        if not url or not url.startswith('http'):\n",
    "            invalid_urls.append(url)\n",
    "            continue\n",
    "            \n",
    "        # ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ ê²½í—˜ ìƒí’ˆ URL í™•ì¸\n",
    "        if '/experiences/' not in url:\n",
    "            invalid_urls.append(url)\n",
    "            continue\n",
    "            \n",
    "        # ì¤‘ë³µ ì œê±°\n",
    "        if url in valid_urls:\n",
    "            continue\n",
    "            \n",
    "        valid_urls.append(url)\n",
    "    \n",
    "    print(f\"  âœ… ìœ íš¨í•œ URL: {len(valid_urls)}ê°œ\")\n",
    "    print(f\"  âŒ ë¬´íš¨í•œ URL: {len(invalid_urls)}ê°œ\")\n",
    "    \n",
    "    return valid_urls\n",
    "\n",
    "def prepare_crawling_data(valid_urls, city_name):\n",
    "    \"\"\"í¬ë¡¤ë§ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„\"\"\"\n",
    "    print(f\"\\nğŸ”§ {city_name} í¬ë¡¤ë§ ë°ì´í„° ì¤€ë¹„ ì¤‘...\")\n",
    "    \n",
    "    # ìµœëŒ€ ìƒí’ˆ ìˆ˜ ì œí•œ\n",
    "    max_products = CONFIG[\"MAX_PRODUCTS_PER_CITY\"]\n",
    "    if len(valid_urls) > max_products:\n",
    "        valid_urls = valid_urls[:max_products]\n",
    "        print(f\"  âš ï¸ ìƒí’ˆ ìˆ˜ë¥¼ {max_products}ê°œë¡œ ì œí•œí–ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # í¬ë¡¤ë§ ì¤€ë¹„ ë°ì´í„° ìƒì„±\n",
    "    crawling_data = []\n",
    "    \n",
    "    for i, url in enumerate(valid_urls):\n",
    "        # ë„ì‹œ ì½”ë“œ ìƒì„± (í†µì¼ëœ í•¨ìˆ˜ëª… ì‚¬ìš©)\n",
    "        city_code = get_city_code(city_name)\n",
    "        continent, country = get_city_info(city_name)\n",
    "        \n",
    "        item_data = {\n",
    "            'index': i + 1,\n",
    "            'url': url,\n",
    "            'city_name': city_name,\n",
    "            'city_code': city_code,\n",
    "            'continent': continent,\n",
    "            'country': country,\n",
    "            'status': 'pending'\n",
    "        }\n",
    "        \n",
    "        crawling_data.append(item_data)\n",
    "    \n",
    "    print(f\"  âœ… {len(crawling_data)}ê°œ ìƒí’ˆ í¬ë¡¤ë§ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "    \n",
    "    return crawling_data\n",
    "\n",
    "def quick_url_validation(driver, sample_url):\n",
    "    \"\"\"ìƒ˜í”Œ URLë¡œ ë¹ ë¥¸ ìœ íš¨ì„± ê²€ì‚¬\"\"\"\n",
    "    print(f\"\\nğŸ” ìƒ˜í”Œ URL ìœ íš¨ì„± ê²€ì‚¬ ì¤‘...\")\n",
    "    \n",
    "    try:\n",
    "        # ìƒ˜í”Œ URL ì ‘ì†\n",
    "        driver.get(sample_url)\n",
    "        time.sleep(random.uniform(2, 4))\n",
    "        \n",
    "        # ê¸°ë³¸ ìš”ì†Œë“¤ í™•ì¸ (í†µì¼ëœ í•¨ìˆ˜ëª… ì‚¬ìš©)\n",
    "        try:\n",
    "            # ìƒí’ˆëª… ì¡´ì¬ í™•ì¸\n",
    "            test_name = get_product_name(driver)\n",
    "            print(f\"  âœ… ìƒí’ˆëª… ìˆ˜ì§‘ ê°€ëŠ¥: {test_name[:30]}...\")\n",
    "            \n",
    "            # ê°€ê²© ì •ë³´ í™•ì¸\n",
    "            test_price = get_price(driver)\n",
    "            print(f\"  âœ… ê°€ê²© ì •ë³´ ìˆ˜ì§‘ ê°€ëŠ¥: {test_price}\")\n",
    "            \n",
    "            # ê°€ê²© ì •ì œ í…ŒìŠ¤íŠ¸ (í†µì¼ëœ í•¨ìˆ˜ëª… ì‚¬ìš©)\n",
    "            clean_price_result = clean_price(test_price)\n",
    "            print(f\"  âœ… ê°€ê²© ì •ì œ ê²°ê³¼: {clean_price_result}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  âš ï¸ ìƒí’ˆ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {type(e).__name__}\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"  âœ… URL ìœ íš¨ì„± ê²€ì‚¬ í†µê³¼!\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ URL ì ‘ì† ì‹¤íŒ¨: {type(e).__name__}: {e}\")\n",
    "        return False\n",
    "\n",
    "def multi_city_search(driver, cities_list):\n",
    "    \"\"\"ë‹¤ì¤‘ ë„ì‹œ ê²€ìƒ‰ (í†µì¼ëœ í•¨ìˆ˜ëª… ì‚¬ìš©)\"\"\"\n",
    "    print(f\"\\nğŸŒ ë‹¤ì¤‘ ë„ì‹œ ê²€ìƒ‰ ì‹œì‘! ({len(cities_list)}ê°œ ë„ì‹œ)\")\n",
    "    \n",
    "    all_crawling_data = []\n",
    "    \n",
    "    for i, city_name in enumerate(cities_list):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ğŸ” ë„ì‹œ {i+1}/{len(cities_list)}: {city_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # ë„ì‹œ ìœ íš¨ì„± ê²€ì‚¬ (í†µì¼ëœ í•¨ìˆ˜ëª… ì‚¬ìš©)\n",
    "        is_valid, message = validate_city(city_name)\n",
    "        if not is_valid:\n",
    "            print(f\"  âš ï¸ {message}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # 1. ê²€ìƒ‰ ë° URL ìˆ˜ì§‘\n",
    "            product_urls = search_and_collect_urls(driver, city_name)\n",
    "            \n",
    "            if not product_urls:\n",
    "                print(f\"  âš ï¸ {city_name}ì—ì„œ ìƒí’ˆ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                continue\n",
    "            \n",
    "            # 2. URL ìœ íš¨ì„± ê²€ì‚¬\n",
    "            valid_urls = validate_and_filter_urls(product_urls, city_name)\n",
    "            \n",
    "            if not valid_urls:\n",
    "                print(f\"  âš ï¸ {city_name}ì—ì„œ ìœ íš¨í•œ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                continue\n",
    "            \n",
    "            # 3. í¬ë¡¤ë§ ë°ì´í„° ì¤€ë¹„\n",
    "            city_crawling_data = prepare_crawling_data(valid_urls, city_name)\n",
    "            \n",
    "            # 4. ìƒ˜í”Œ URL ìœ íš¨ì„± ê²€ì‚¬\n",
    "            if city_crawling_data:\n",
    "                sample_url = city_crawling_data[0]['url']\n",
    "                if quick_url_validation(driver, sample_url):\n",
    "                    all_crawling_data.extend(city_crawling_data)\n",
    "                    print(f\"  âœ… {city_name} ê²€ìƒ‰ ì™„ë£Œ! {len(city_crawling_data)}ê°œ ìƒí’ˆ ì¤€ë¹„\")\n",
    "                else:\n",
    "                    print(f\"  âŒ {city_name} URL ìœ íš¨ì„± ê²€ì‚¬ ì‹¤íŒ¨\")\n",
    "            \n",
    "            # 5. ì¤‘ê°„ ê²°ê³¼ ì €ì¥ (í†µì¼ëœ í•¨ìˆ˜ëª… ì‚¬ìš©)\n",
    "            if CONFIG.get(\"SAVE_INTERMEDIATE\", False):\n",
    "                temp_data = [{'ë„ì‹œ': city_name, 'URLìˆ˜': len(valid_urls), 'ì¤€ë¹„ì™„ë£Œ': len(city_crawling_data)}]\n",
    "                save_intermediate_results(temp_data, f\"{city_name}_search_results\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ {city_name} ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # ë„ì‹œ ê°„ ëŒ€ê¸° ì‹œê°„\n",
    "        if i < len(cities_list) - 1:\n",
    "            delay = random.uniform(CONFIG[\"MIN_DELAY\"], CONFIG[\"MAX_DELAY\"])\n",
    "            print(f\"  ğŸ’¤ ë‹¤ìŒ ë„ì‹œ ê²€ìƒ‰ ì „ ëŒ€ê¸°: {delay:.1f}ì´ˆ\")\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    # ìµœì¢… ê²°ê³¼ ìš”ì•½\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸ‰ ë‹¤ì¤‘ ë„ì‹œ ê²€ìƒ‰ ì™„ë£Œ!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"ğŸ“Š ê²€ìƒ‰ ë„ì‹œ: {len(cities_list)}ê°œ\")\n",
    "    print(f\"ğŸ“Š ì´ ìˆ˜ì§‘ ìƒí’ˆ: {len(all_crawling_data)}ê°œ\")\n",
    "    \n",
    "    # ë„ì‹œë³„ ìƒí’ˆ ìˆ˜ ìš”ì•½\n",
    "    city_summary = {}\n",
    "    for item in all_crawling_data:\n",
    "        city = item['city_name']\n",
    "        city_summary[city] = city_summary.get(city, 0) + 1\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ ë„ì‹œë³„ ìƒí’ˆ ìˆ˜:\")\n",
    "    for city, count in city_summary.items():\n",
    "        city_code = get_city_code(city)  # í†µì¼ëœ í•¨ìˆ˜ëª… ì‚¬ìš©\n",
    "        print(f\"   {city} ({city_code}): {count}ê°œ\")\n",
    "    \n",
    "    return all_crawling_data\n",
    "\n",
    "def save_search_results(all_crawling_data):\n",
    "    \"\"\"ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì„ì‹œ ì €ì¥ (í†µì¼ëœ í•¨ìˆ˜ëª… ì‚¬ìš©)\"\"\"\n",
    "    if not all_crawling_data:\n",
    "        print(\"  âš ï¸ ì €ì¥í•  ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\nğŸ’¾ ê²€ìƒ‰ ê²°ê³¼ ì„ì‹œ ì €ì¥ ì¤‘...\")\n",
    "    \n",
    "    # ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„° ë³€í™˜\n",
    "    search_results = []\n",
    "    for item in all_crawling_data:\n",
    "        result = {\n",
    "            'ìˆœë²ˆ': item['index'],\n",
    "            'ë„ì‹œ': item['city_name'],\n",
    "            'ë„ì‹œì½”ë“œ': item['city_code'],\n",
    "            'ëŒ€ë¥™': item['continent'],\n",
    "            'êµ­ê°€': item['country'],\n",
    "            'URL': item['url'],\n",
    "            'ìƒíƒœ': item['status']\n",
    "        }\n",
    "        search_results.append(result)\n",
    "    \n",
    "    # ì„ì‹œ ì €ì¥ (í†µì¼ëœ í•¨ìˆ˜ëª…ì˜ save_intermediate_results ì‚¬ìš©)\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    temp_filename = f\"search_results_{len(search_results)}ê°œ_{timestamp}.csv\"\n",
    "    \n",
    "    try:\n",
    "        df = pd.DataFrame(search_results)\n",
    "        df.to_csv(temp_filename, index=False, encoding='utf-8-sig')\n",
    "        print(f\"  âœ… ê²€ìƒ‰ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {temp_filename}\")\n",
    "        return temp_filename\n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "def run_group2_search():\n",
    "    \"\"\"ê·¸ë£¹ 2 ê²€ìƒ‰ ì‹œìŠ¤í…œ ì‹¤í–‰\"\"\"\n",
    "    print(f\"\\nğŸš€ ê·¸ë£¹ 2: ê²€ìƒ‰ ì‹œìŠ¤í…œ ì‹¤í–‰ ì‹œì‘!\")\n",
    "    print(f\"ğŸ“‹ ê²€ìƒ‰ ëŒ€ìƒ ë„ì‹œ: {CITIES_TO_SEARCH}\")\n",
    "    \n",
    "    # ë“œë¼ì´ë²„ ì„¤ì •\n",
    "    driver = None\n",
    "    try:\n",
    "        # 1. ë“œë¼ì´ë²„ ì´ˆê¸°í™”\n",
    "        driver = setup_driver()\n",
    "        \n",
    "        # 2. ë‹¤ì¤‘ ë„ì‹œ ê²€ìƒ‰ ì‹¤í–‰\n",
    "        all_crawling_data = multi_city_search(driver, CITIES_TO_SEARCH)\n",
    "        \n",
    "        if not all_crawling_data:\n",
    "            print(\"âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return None\n",
    "        \n",
    "        # 3. ê²€ìƒ‰ ê²°ê³¼ ì €ì¥\n",
    "        saved_file = save_search_results(all_crawling_data)\n",
    "        \n",
    "        # 4. ìµœì¢… ê²°ê³¼ ì¶œë ¥\n",
    "        print(f\"\\nğŸ‰ ê·¸ë£¹ 2 ê²€ìƒ‰ ì™„ë£Œ!\")\n",
    "        print(f\"ğŸ“Š ì´ {len(all_crawling_data)}ê°œ ìƒí’ˆ URL ìˆ˜ì§‘\")\n",
    "        print(f\"ğŸ“ ì €ì¥ëœ íŒŒì¼: {saved_file}\")\n",
    "        print(f\"ğŸ¯ ë‹¤ìŒ: ê·¸ë£¹ 3 (URL ìˆ˜ì§‘) ë˜ëŠ” ê·¸ë£¹ 4 (ë©”ì¸ í¬ë¡¤ë§) ì‹¤í–‰\")\n",
    "        \n",
    "        return all_crawling_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ê·¸ë£¹ 2 ê²€ìƒ‰ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {type(e).__name__}: {e}\")\n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        # ë“œë¼ì´ë²„ ì¢…ë£Œ\n",
    "        if driver:\n",
    "            try:\n",
    "                driver.quit()\n",
    "                print(\"âœ… ë“œë¼ì´ë²„ ì¢…ë£Œ ì™„ë£Œ\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "def test_unified_functions():\n",
    "    \"\"\"í†µì¼ëœ í•¨ìˆ˜ëª… í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(f\"\\nğŸ”§ í†µì¼ëœ í•¨ìˆ˜ëª… í…ŒìŠ¤íŠ¸ ì‹œì‘...\")\n",
    "    \n",
    "    # ë„ì‹œ ì½”ë“œ í…ŒìŠ¤íŠ¸\n",
    "    test_cities = [\"í›„ì¿ ì˜¤ì¹´\", \"ë„ì¿„\", \"ë°©ì½•\"]\n",
    "    \n",
    "    for city in test_cities:\n",
    "        print(f\"\\nğŸ“ {city} í…ŒìŠ¤íŠ¸:\")\n",
    "        \n",
    "        # í†µì¼ëœ í•¨ìˆ˜ëª… ì‚¬ìš©\n",
    "        city_code = get_city_code(city)\n",
    "        continent, country = get_city_info(city)\n",
    "        \n",
    "        print(f\"  ğŸ™ï¸ ë„ì‹œ ì½”ë“œ: {city_code}\")\n",
    "        print(f\"  ğŸŒ ìœ„ì¹˜: {continent}, {country}\")\n",
    "        \n",
    "        # ë„ì‹œ ìœ íš¨ì„± ê²€ì‚¬\n",
    "        is_valid, message = validate_city(city)\n",
    "        print(f\"  âœ… ìœ íš¨ì„±: {is_valid} - {message}\")\n",
    "    \n",
    "    # ê°€ê²© ì •ì œ í…ŒìŠ¤íŠ¸\n",
    "    test_prices = [\n",
    "        \"15,000ì›\",\n",
    "        \"ìµœëŒ€ 5ë§Œì› í• ì¸ + 25,000ì›\",\n",
    "        \"3,500ì›ë¶€í„°\",\n",
    "        \"ì •ë³´ ì—†ìŒ\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nğŸ’° ê°€ê²© ì •ì œ í…ŒìŠ¤íŠ¸:\")\n",
    "    for price in test_prices:\n",
    "        # í†µì¼ëœ í•¨ìˆ˜ëª… ì‚¬ìš©\n",
    "        clean_result = clean_price(price)\n",
    "        print(f\"  ì›ë³¸: {price} â†’ ì •ì œ: {clean_result}\")\n",
    "    \n",
    "    # í‰ì  ì •ì œ í…ŒìŠ¤íŠ¸\n",
    "    test_ratings = [\n",
    "        \"4.9 Â· í›„ê¸° ë§ìŒ\",\n",
    "        \"4.2\",\n",
    "        \"í‰ì  ì—†ìŒ\",\n",
    "        \"5.0 â˜…â˜…â˜…â˜…â˜…\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nâ­ í‰ì  ì •ì œ í…ŒìŠ¤íŠ¸:\")\n",
    "    for rating in test_ratings:\n",
    "        # í†µì¼ëœ í•¨ìˆ˜ëª… ì‚¬ìš©\n",
    "        clean_result = clean_rating(rating)\n",
    "        print(f\"  ì›ë³¸: {rating} â†’ ì •ì œ: {clean_result}\")\n",
    "    \n",
    "    print(f\"\\nâœ… í†µì¼ëœ í•¨ìˆ˜ëª… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "\n",
    "# =============================================================================\n",
    "# ê·¸ë£¹ 2 ì‹¤í–‰ ì˜µì…˜\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… ê·¸ë£¹ 2 ì™„ë£Œ: ê²€ìƒ‰ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ”§ ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜ë“¤:\")\n",
    "print(\"   - search_and_collect_urls(driver, city_name)\")\n",
    "print(\"   - multi_city_search(driver, cities_list)\")\n",
    "print(\"   - run_group2_search()  # ì „ì²´ ê²€ìƒ‰ ì‹¤í–‰\")\n",
    "print(\"   - test_unified_functions()  # í•¨ìˆ˜ëª… í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ¯ ì‹¤í–‰ ë°©ë²•:\")\n",
    "print(\"   1. test_unified_functions()      # í•¨ìˆ˜ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"   2. run_group2_search()           # ì „ì²´ ê²€ìƒ‰ ì‹¤í–‰\")\n",
    "print(\"   3. ë˜ëŠ” ê·¸ë£¹ 4ì—ì„œ ì§ì ‘ í¬ë¡¤ë§ ì‹¤í–‰\")\n",
    "print(\"=\"*60)\n",
    "print(\"âœ… ëª¨ë“  í•¨ìˆ˜ê°€ ê·¸ë£¹ 1ì˜ í†µì¼ëœ í•¨ìˆ˜ëª…ì„ ì‚¬ìš©í•©ë‹ˆë‹¤!\")\n",
    "print(\"   get_product_name(), get_price(), clean_price(), clean_rating(), save_results() ë“±\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mikael_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
