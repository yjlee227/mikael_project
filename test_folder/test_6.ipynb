{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aa0a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##í´ë¡œë“œì½”ë“œ í´ë”í˜¸ì¶œ\n",
    "#cd \"/mnt/c/Users/redsk/OneDrive/ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—/mikael_project\"\n",
    "#cd \"/mnt/c/Users/redsk/OneDrive/ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—/mikael_project/test_folder\"\n",
    "#  ì´ì „ ëŒ€í™”ì—ì„œ ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ í¬ë¡¤ë§ ì‹œìŠ¤í…œì„ ê°œë°œí–ˆì—ˆëŠ”ë°,  test_folder/README.mdë¥¼ ì½ê³  í˜„ì¬ ìƒí™©ì„ íŒŒì•…í•´ì„œ4ìˆœìœ„ í˜ì´ì§€ë„¤ì´ì…˜ ìë™í™” ì‘ì—…ë¶€í„° ì´ì–´ì„œ ì§„í–‰í•´ì¤˜.\n",
    "#ğŸ’¡ í•µì‹¬ í¬ì¸íŠ¸\n",
    "#âœ… README.md íŒŒì¼: ëª¨ë“  ì§„í–‰ ìƒí™©ê³¼ ë‹¤ìŒ ì‘ì—…ì´ ê¸°ë¡ë˜ì–´ ìˆìŒ\n",
    "#âœ… test_6.ipynb: í˜„ì¬ ì‘ì—… ì¤‘ì¸ ë©”ì¸ íŒŒì¼\n",
    "#âœ… í˜„ì¬ ìƒíƒœ: ë°ì´í„° ì—°ì†ì„± ì™„ì „ í•´ê²° ì™„ë£Œ, 4ìˆœìœ„ ëŒ€ê¸°ì¤‘"
   ]
  },
  {
   "cell_type": "code",
   "id": "e5bc9fba",
   "metadata": {},
   "outputs": [],
   "source": "################r ê²€ì¦ì™„ë£Œ #################\n# =============================================================================\n# ğŸš€ ê·¸ë£¹ 1: í†µì¼ëœ í•¨ìˆ˜ëª… - ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ í¬ë¡¤ë§ ì‹œìŠ¤í…œ (ë¦¬íŒ©í† ë§ ì™„ë£Œ)\n# - ë„ì‹œ ì •ë³´ë¥¼ UNIFIED_CITY_INFOë¡œ í†µí•©í•˜ì—¬ ë‹¨ì¼ ì†ŒìŠ¤ë¡œ ê´€ë¦¬\n# =============================================================================\n\nimport pandas as pd\nimport warnings, os, time, shutil, urllib, random\nwarnings.filterwarnings(action='ignore')\n\nimport re                        # ê°€ê²©/í‰ì  ì •ì œìš© ì •ê·œì‹\nimport json                      # ë©”íƒ€ë°ì´í„° JSON ì €ì¥ìš©\nfrom datetime import datetime    # íƒ€ì„ìŠ¤íƒ¬í”„ìš©\n\nfrom PIL import Image\nfrom selenium.webdriver.chrome.service import Service as ChromeService\nfrom webdriver_manager.chrome import ChromeDriverManager\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.webdriver import ActionChains\n\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException\n\nimport chromedriver_autoinstaller\nimport undetected_chromedriver as uc\nfrom user_agents import parse\nimport selenium\n\nprint(f\"ğŸ”§ Selenium ë²„ì „: {selenium.__version__}\")\n\n# â­â­â­ ì¤‘ìš” ì„¤ì •: ì—¬ê¸°ì„œ ìˆ˜ì •í•˜ì„¸ìš”! â­â­â­\nCONFIG = {\n    \"WAIT_TIMEOUT\": 10,\n    \"RETRY_COUNT\": 3,\n    \"MIN_DELAY\": 5,                  # 3 â†’ 5ì´ˆë¡œ ì¦ê°€\n    \"MAX_DELAY\": 12,                 # 8 â†’ 12ì´ˆë¡œ ì¦ê°€\n    \"POPUP_WAIT\": 5,\n    \"SAVE_IMAGES\": True,\n    \"SAVE_INTERMEDIATE\": True,\n    \"MAX_PRODUCT_NAME_LENGTH\": 30,\n    \"LONGER_DELAYS\": True,           # ìƒˆë¡œ ì¶”ê°€\n    \"MEMORY_CLEANUP_INTERVAL\": 5,    # ìƒˆë¡œ ì¶”ê°€\n    \"MAX_PRODUCTS_PER_CITY\": 1,     #â­â­â­â­â­â­â­â­â­#\n    # ğŸ†• Gemini ì§€ì ì‚¬í•­ í•´ê²°: USER_AGENT ì¶”ê°€\n    \"USER_AGENT\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\"\n}\n\n# ğŸ™ï¸ ê²€ìƒ‰í•  ë„ì‹œë“¤ (ì—¬ê¸°ì„œ ë³€ê²½!)\nCITIES_TO_SEARCH = [\"í‘¸ì¼“\"]\n\n# =============================================================================\n# ğŸ“ [ìµœì¢… ìˆ˜ì •ë³¸] ë‹¨ì¼ ì •ë³´ ì†ŒìŠ¤ ë° ë¦¬íŒ©í† ë§ëœ í•¨ìˆ˜\n# =============================================================================\n\n# ëª¨ë“  ë„ì‹œì˜ ìƒì„¸ ì •ë³´ê°€ í¬í•¨ëœ ë”•ì…”ë„ˆë¦¬ (ìµœì¢… í™•ì¥ë³¸)\nUNIFIED_CITY_INFO = {\n    # ë™ë‚¨ì•„ì‹œì•„\n    \"ë°©ì½•\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"BKK\"},\n    \"ì•„ìœ íƒ€ì•¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"BKK\"}, # ë°©ì½• ê³µí•­ ì‚¬ìš©\n    \"ì¹˜ì•™ë§ˆì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"CNX\"},\n    \"ë¹ ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"CNX\"}, # ì¹˜ì•™ë§ˆì´ ê³µí•­ ì‚¬ìš©\n    \"ì¹˜ì•™ë¼ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"CEI\"},\n    \"í‘¸ì¼“\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"HKT\"},\n    \"í”¼í”¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"KBV\"}, # í¬ë¼ë¹„ ê³µí•­ ì‚¬ìš©\n    \"í¬ë¼ë¹„\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"KBV\"},\n    \"í›„ì•„íŒ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"íƒœêµ­\", \"ì½”ë“œ\": \"HHQ\"},\n    \"ì‹±ê°€í¬ë¥´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì‹±ê°€í¬ë¥´\", \"ì½”ë“œ\": \"SIN\"},\n    \"í™ì½©\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"í™ì½©\", \"ì½”ë“œ\": \"HKG\"},\n    \"ì¿ ì•Œë¼ë£¸í‘¸ë¥´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë§ë ˆì´ì‹œì•„\", \"ì½”ë“œ\": \"KUL\"},\n    \"ì½”íƒ€í‚¤ë‚˜ë°œë£¨\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë§ë ˆì´ì‹œì•„\", \"ì½”ë“œ\": \"BKI\"},\n    \"í˜ë‚­\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë§ë ˆì´ì‹œì•„\", \"ì½”ë“œ\": \"PEN\"},\n    \"ë‘ì¹´ìœ„\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë§ë ˆì´ì‹œì•„\", \"ì½”ë“œ\": \"LGK\"},\n    \"ì„¸ë¶€\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"í•„ë¦¬í•€\", \"ì½”ë“œ\": \"CEB\"},\n    \"ë³´í™€\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"í•„ë¦¬í•€\", \"ì½”ë“œ\": \"TAG\"},\n    \"ë§ˆë‹ë¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"í•„ë¦¬í•€\", \"ì½”ë“œ\": \"MNL\"},\n    \"ë³´ë¼ì¹´ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"í•„ë¦¬í•€\", \"ì½”ë“œ\": \"MPH\"}, # ì¹´í‹°í´ë€ ê³µí•­\n    \"ë‹¤ë‚­\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"DAD\"},\n    \"í˜¸ì´ì•ˆ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"DAD\"}, # ë‹¤ë‚­ ê³µí•­ ì‚¬ìš©\n    \"í›„ì—\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"HUI\"},\n    \"í˜¸ì¹˜ë¯¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"SGN\"},\n    \"ë¬´ì´ë„¤\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"SGN\"}, # í˜¸ì¹˜ë¯¼ ê³µí•­ ì‚¬ìš©\n    \"í‘¸ê¾¸ì˜¥\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"PQC\"},\n    \"ë‚˜íŠ¸ë‘\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"CXR\"},\n    \"í•˜ë…¸ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"HAN\"},\n    \"ë‹¬ë\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë² íŠ¸ë‚¨\", \"ì½”ë“œ\": \"DLI\"},\n    \"ë°œë¦¬\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¸ë„ë„¤ì‹œì•„\", \"ì½”ë“œ\": \"DPS\"},\n    \"í”„ë†ˆíœ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ìº„ë³´ë””ì•„\", \"ì½”ë“œ\": \"PNH\"}, #ì•„ì§ ìƒí’ˆì—†ìŒ 25.0723\n    \"ì‹œì— ë¦½\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ìº„ë³´ë””ì•„\", \"ì½”ë“œ\": \"REP\"}, #ì•„ì§ ìƒí’ˆì—†ìŒ 25.0723\n    \"ì”¨ì— ë¦½\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ìº„ë³´ë””ì•„\", \"ì½”ë“œ\": \"REP\"}, # ì‹œì— ë¦½ ë™ì˜ì–´, #ì•„ì§ ìƒí’ˆì—†ìŒ 25.0723\n    \"ë¹„ì—”í‹°ì•ˆ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë¼ì˜¤ìŠ¤\", \"ì½”ë“œ\": \"VTE\"},\n    \"ë°©ë¹„ì—¥\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë¼ì˜¤ìŠ¤\", \"ì½”ë“œ\": \"VTE\"}, # ë¹„ì—”í‹°ì•ˆ ê³µí•­ ì‚¬ìš©\n    \"ë£¨ì•™í”„ë¼ë°©\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë¼ì˜¤ìŠ¤\", \"ì½”ë“œ\": \"LPQ\"},\n\n    # ë™ë¶ì•„ì‹œì•„\n    \"ë„ì¿„\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"NRT\"},\n    \"ì˜¤ì‚¬ì¹´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"KIX\"},\n    \"êµí† \": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"KIX\"}, # ì˜¤ì‚¬ì¹´ ê³µí•­ ì‚¬ìš©\n    \"ë‚˜ê³ ì•¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"NGO\"},\n    \"í›„ì¿ ì˜¤ì¹´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"FUK\"},\n    \"ë²³í‘¸\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"OIT\"}, # ì˜¤ì´íƒ€ ê³µí•­ ì‚¬ìš©\n    \"ì˜¤ì´íƒ€\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"OIT\"},\n    \"êµ¬ë§ˆëª¨í† \": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"KMJ\"},\n    \"ì˜¤í‚¤ë‚˜ì™€\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"OKA\"},\n    \"ë¯¸ì•¼ì½”ì§€ë§ˆ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"MMY\"},\n    \"ì‚¿í¬ë¡œ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¼ë³¸\", \"ì½”ë“œ\": \"CTS\"},\n    \"íƒ€ì´ë² ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€ë§Œ\", \"ì½”ë“œ\": \"TPE\"},\n    \"ìƒí•˜ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¤‘êµ­\", \"ì½”ë“œ\": \"PVG\"},\n    \"ë² ì´ì§•\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¤‘êµ­\", \"ì½”ë“œ\": \"PEK\"},\n    \"í•˜ì´ë‚œ(ì‹¼ì•¼)\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¤‘êµ­\", \"ì½”ë“œ\": \"SYX\"},\n    \"ë§ˆì¹´ì˜¤\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë§ˆì¹´ì˜¤\", \"ì½”ë“œ\": \"MFM\"},\n    \n    # ë‚¨ì•„ì‹œì•„\n    \"ë‰´ë¸ë¦¬\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¸ë„\", \"ì½”ë“œ\": \"DEL\"},\n    \"ë­„ë°”ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì¸ë„\", \"ì½”ë“œ\": \"BOM\"},\n    \"ì¹´íŠ¸ë§Œë‘\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë„¤íŒ”\", \"ì½”ë“œ\": \"KTM\"},\n    \"í¬ì¹´ë¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ë„¤íŒ”\", \"ì½”ë“œ\": \"PKR\"},\n\n    # í•œêµ­\n    \"ì„œìš¸\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"ICN\"},\n    \"ë¶€ì‚°\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"PUS\"},\n    \"ì œì£¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"CJU\"},\n    \"ëŒ€êµ¬\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"TAE\"},\n    \"ê´‘ì£¼\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"KWJ\"},\n    \"ì—¬ìˆ˜\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"RSU\"},\n    \"ì¸ì²œ\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"ICN\"},\n    \"ê¹€í¬\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ëŒ€í•œë¯¼êµ­\", \"ì½”ë“œ\": \"GMP\"},\n\n    # ìœ ëŸ½\n    \"íŒŒë¦¬\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í”„ë‘ìŠ¤\", \"ì½”ë“œ\": \"CDG\"},\n    \"ëŸ°ë˜\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì˜êµ­\", \"ì½”ë“œ\": \"LHR\"},\n    \"ë”ë¸”ë¦°\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì•„ì¼ëœë“œ\", \"ì½”ë“œ\": \"DUB\"},\n    \"ë¡œë§ˆ\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"FCO\"},\n    \"í”¼ë Œì²´\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"FLR\"},\n    \"ë² ë„¤ì¹˜ì•„\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"VCE\"},\n    \"ë°€ë¼ë…¸\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì´íƒˆë¦¬ì•„\", \"ì½”ë“œ\": \"MXP\"},\n    \"ë°”ë¥´ì…€ë¡œë‚˜\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤í˜ì¸\", \"ì½”ë“œ\": \"BCN\"},\n    \"ë§ˆë“œë¦¬ë“œ\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤í˜ì¸\", \"ì½”ë“œ\": \"MAD\"},\n    \"ì„¸ë¹„ì•¼\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤í˜ì¸\", \"ì½”ë“œ\": \"SVQ\"},\n    \"ê·¸ë¼ë‚˜ë‹¤\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤í˜ì¸\", \"ì½”ë“œ\": \"GRX\"},\n    \"ì´ë¹„ì\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤í˜ì¸\", \"ì½”ë“œ\": \"IBZ\"},\n    \"ë¦¬ìŠ¤ë³¸\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í¬ë¥´íˆ¬ê°ˆ\", \"ì½”ë“œ\": \"LIS\"},\n    \"í¬ë¥´íˆ¬\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í¬ë¥´íˆ¬ê°ˆ\", \"ì½”ë“œ\": \"OPO\"},\n    \"í”„ë¼í•˜\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì²´ì½”\", \"ì½”ë“œ\": \"PRG\"},\n    \"ë¹„ì—”ë‚˜\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ì˜¤ìŠ¤íŠ¸ë¦¬ì•„\", \"ì½”ë“œ\": \"VIE\"},\n    \"ì·¨ë¦¬íˆ\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤ìœ„ìŠ¤\", \"ì½”ë“œ\": \"ZRH\"},\n    \"ì¸í„°ë¼ì¼„\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤ìœ„ìŠ¤\", \"ì½”ë“œ\": \"ZRH\"}, # ì·¨ë¦¬íˆ ê³µí•­ ì‚¬ìš©\n    \"ì•”ìŠ¤í…Œë¥´ë‹´\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ë„¤ëœë€ë“œ\", \"ì½”ë“œ\": \"AMS\"},\n    \"ë¸Œë¤¼ì…€\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ë²¨ê¸°ì—\", \"ì½”ë“œ\": \"BRU\"},\n    \"ë®Œí—¨\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ë…ì¼\", \"ì½”ë“œ\": \"MUC\"},\n    \"ë² ë¥¼ë¦°\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ë…ì¼\", \"ì½”ë“œ\": \"BER\"},\n    \"í”„ë‘í¬í‘¸ë¥´íŠ¸\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ë…ì¼\", \"ì½”ë“œ\": \"FRA\"},\n    \"ë¶€ë‹¤í˜ìŠ¤íŠ¸\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í—ê°€ë¦¬\", \"ì½”ë“œ\": \"BUD\"},\n    \"ë°”ë¥´ìƒ¤ë°”\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í´ë€ë“œ\", \"ì½”ë“œ\": \"WAW\"},\n    \"í¬ë¼ì¿ í”„\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í´ë€ë“œ\", \"ì½”ë“œ\": \"KRK\"},\n    \"ì•„í…Œë„¤\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ê·¸ë¦¬ìŠ¤\", \"ì½”ë“œ\": \"ATH\"},\n    \"ì‚°í† ë¦¬ë‹ˆ\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ê·¸ë¦¬ìŠ¤\", \"ì½”ë“œ\": \"JTR\"},\n    \"ìê·¸ë ˆë¸Œ\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í¬ë¡œì•„í‹°ì•„\", \"ì½”ë“œ\": \"ZAG\"},\n    \"ë‘ë¸Œë¡œë¸Œë‹ˆí¬\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í¬ë¡œì•„í‹°ì•„\", \"ì½”ë“œ\": \"DBV\"},\n    \"ì½”íœí•˜ê²\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ë´ë§ˆí¬\", \"ì½”ë“œ\": \"CPH\"},\n    \"ìŠ¤í†¡í™€ë¦„\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ìŠ¤ì›¨ë´\", \"ì½”ë“œ\": \"ARN\"},\n    \"ì˜¤ìŠ¬ë¡œ\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"ë…¸ë¥´ì›¨ì´\", \"ì½”ë“œ\": \"OSL\"},\n    \"í—¬ì‹±í‚¤\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í•€ë€ë“œ\", \"ì½”ë“œ\": \"HEL\"},\n    \"ì´ìŠ¤íƒ„ë¶ˆ\": {\"ëŒ€ë¥™\": \"ìœ ëŸ½\", \"êµ­ê°€\": \"í„°í‚¤\", \"ì½”ë“œ\": \"IST\"},\n\n    # ë¶ë¯¸\n    \"ë‰´ìš•\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"JFK\"},\n    \"ë¡œìŠ¤ì•¤ì ¤ë ˆìŠ¤\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"LAX\"},\n    \"ì‹œì¹´ê³ \": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"ORD\"},\n    \"í•˜ì™€ì´\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"HNL\"},\n    \"ìƒŒí”„ë€ì‹œìŠ¤ì½”\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"SFO\"},\n    \"ë¼ìŠ¤ë² ì´ê±°ìŠ¤\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"LAS\"},\n    \"ì›Œì‹±í„´ D.C.\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"IAD\"},\n    \"ë³´ìŠ¤í„´\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"BOS\"},\n    \"ì‹œì• í‹€\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë¯¸êµ­\", \"ì½”ë“œ\": \"SEA\"},\n    \"ë°´ì¿ ë²„\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ìºë‚˜ë‹¤\", \"ì½”ë“œ\": \"YVR\"},\n    \"í† ë¡ í† \": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ìºë‚˜ë‹¤\", \"ì½”ë“œ\": \"YYZ\"},\n    \"ì¹¸ì¿¤\": {\"ëŒ€ë¥™\": \"ë¶ë¯¸\", \"êµ­ê°€\": \"ë©•ì‹œì½”\", \"ì½”ë“œ\": \"CUN\"},\n\n    # ì˜¤ì„¸ì•„ë‹ˆì•„\n    \"ì‹œë“œë‹ˆ\": {\"ëŒ€ë¥™\": \"ì˜¤ì„¸ì•„ë‹ˆì•„\", \"êµ­ê°€\": \"í˜¸ì£¼\", \"ì½”ë“œ\": \"SYD\"},\n    \"ë©œë²„ë¥¸\": {\"ëŒ€ë¥™\": \"ì˜¤ì„¸ì•„ë‹ˆì•„\", \"êµ­ê°€\": \"í˜¸ì£¼\", \"ì½”ë“œ\": \"MEL\"},\n    \"ê´Œ\": {\"ëŒ€ë¥™\": \"ì˜¤ì„¸ì•„ë‹ˆì•„\", \"êµ­ê°€\": \"ê´Œ\", \"ì½”ë“œ\": \"GUM\"},\n    \"ì‚¬ì´íŒ\": {\"ëŒ€ë¥™\": \"ì˜¤ì„¸ì•„ë‹ˆì•„\", \"êµ­ê°€\": \"ë¶ë§ˆë¦¬ì•„ë‚˜ ì œë„\", \"ì½”ë“œ\": \"SPN\"},\n    \"ì˜¤í´ëœë“œ\": {\"ëŒ€ë¥™\": \"ì˜¤ì„¸ì•„ë‹ˆì•„\", \"êµ­ê°€\": \"ë‰´ì§ˆëœë“œ\", \"ì½”ë“œ\": \"AKL\"},\n    \n    # ì¤‘ë™\n    \"ë‘ë°”ì´\": {\"ëŒ€ë¥™\": \"ì•„ì‹œì•„\", \"êµ­ê°€\": \"ì•„ëì—ë¯¸ë¦¬íŠ¸\", \"ì½”ë“œ\": \"DXB\"},\n}\n\n\n\nprint(f\"âœ… UNIFIED_CITY_INFO ë¡œë“œ ì™„ë£Œ! {len(UNIFIED_CITY_INFO)}ê°œ ë„ì‹œ ì§€ì›\")\n\n# =============================================================================\n# ğŸ”§ í•µì‹¬ í•¨ìˆ˜ë“¤ - ë‹¨ì¼ ì •ë³´ ì†ŒìŠ¤(UNIFIED_CITY_INFO) ì‚¬ìš©\n# =============================================================================\n\ndef get_city_code(city_name):\n    \"\"\"ë„ì‹œëª…ìœ¼ë¡œ ê³µí•­ ì½”ë“œ ë°˜í™˜ (UNIFIED_CITY_INFO ì‚¬ìš©)\"\"\"\n    info = UNIFIED_CITY_INFO.get(city_name)\n    if info:\n        code = info.get(\"ì½”ë“œ\", city_name[:3].upper())\n        return code\n    return city_name[:3].upper()\n\ndef get_city_info(city_name):\n    \"\"\"í†µí•©ëœ ë„ì‹œ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì‚¬ì „ ì •ì˜ëœ ê°’ë§Œ ì‚¬ìš©)\"\"\"\n    info = UNIFIED_CITY_INFO.get(city_name)\n    if info:\n        return info[\"ëŒ€ë¥™\"], info[\"êµ­ê°€\"]\n    else:\n        # ì •ì˜ë˜ì§€ ì•Šì€ ë„ì‹œì— ëŒ€í•œ ê¸°ë³¸ê°’\n        return \"ê¸°íƒ€\", \"ê¸°íƒ€\"\n\ndef get_product_name(driver, url_type=\"Product\"):\n    \"\"\"âœ… ìƒí’ˆëª… ìˆ˜ì§‘ (ê¸°ì¡´: get_product_name_by_type â†’ ìƒˆë¡œìš´: get_product_name)\"\"\"\n    print(f\"  ğŸ“Š {url_type} ìƒí’ˆëª… ìˆ˜ì§‘ ì¤‘...\")\n    \n    title_selectors = [\n        (By.CSS_SELECTOR, \"h1\"),\n        (By.CSS_SELECTOR, \".product-title\"),\n        (By.XPATH, \"//h1[contains(@class, 'title')]\"),\n        (By.XPATH, \"/html/body/div[1]/main/div[1]/section/div[1]/h1\")\n    ]\n\n    for selector_type, selector_value in title_selectors:\n        try:\n            title_element = WebDriverWait(driver, CONFIG[\"WAIT_TIMEOUT\"]).until(\n                EC.presence_of_element_located((selector_type, selector_value))\n            )\n            found_name = title_element.text\n            return found_name\n        except TimeoutException:\n            continue\n    \n    raise NoSuchElementException(\"ìƒí’ˆëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n\ndef get_price(driver):\n    \"\"\"âœ… ê°€ê²© ìˆ˜ì§‘ - ìˆ˜ì •ëœ ë²„ì „ (ì˜ëª»ëœ í…ìŠ¤íŠ¸ í•„í„°ë§ ê°•í™”)\"\"\"\n    print(f\"  ğŸ’° ê°€ê²© ì •ë³´ ìˆ˜ì§‘ ì¤‘...\")\n    \n    # ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ ì‹¤ì œ ê°€ê²© ì…€ë ‰í„°ë“¤\n    price_selectors = [\n        (By.CSS_SELECTOR, \"span[style*='color: rgb(255, 87, 87)']\"),\n        (By.CSS_SELECTOR, \"span[style*='color: rgb(255, 71, 71)']\"),\n        (By.CSS_SELECTOR, \"span[style*='color: red']\"),\n        (By.CSS_SELECTOR, \".text-red\"),\n        (By.CSS_SELECTOR, \".price\"),\n        (By.CSS_SELECTOR, \"[class*='price']\"),\n        # ë” êµ¬ì²´ì ì¸ XPath\n        (By.XPATH, \"//span[contains(text(), 'ì›~') and contains(text(), ',') and string-length(text()) < 30]\"),\n        (By.XPATH, \"//span[contains(text(), 'ì›-') and contains(text(), ',') and string-length(text()) < 30]\"),\n        (By.XPATH, \"//span[contains(text(), ',') and contains(text(), 'ì›') and not(contains(text(), 'ì¸ì›')) and not(contains(text(), 'ìµœì†Œ'))]\"),\n    ]\n\n    for selector_type, selector_value in price_selectors:\n        try:\n            price_elements = driver.find_elements(selector_type, selector_value)\n            \n            for price_element in price_elements:\n                found_price = price_element.text.strip()\n                \n                if not found_price:\n                    continue\n                \n                # ğŸ”¥ ê°•ë ¥í•œ í•„í„°ë§: ê°€ê²©ì´ ì•„ë‹Œ í…ìŠ¤íŠ¸ë“¤ ì œì™¸\n                invalid_keywords = [\n                    'ì¿ í°', 'ë°›ê¸°', 'ë‹¤ìš´', 'í• ì¸', 'ì ë¦½', 'í¬ì¸íŠ¸',\n                    'ìµœì†Œ', 'ì¸ì›', 'ëª…', 'ìµœëŒ€', 'ì„ íƒ', 'ì˜µì…˜',\n                    'ì˜ˆì•½', 'ì‹ ì²­', 'ë¬¸ì˜', 'ìƒë‹´', 'í™•ì¸', 'ëª…ë¶€í„°',\n                    'ì‹œê°„', 'ì¼ì •', 'ì½”ìŠ¤', 'íˆ¬ì–´', 'ì—¬í–‰', 'ë¶€í„°',\n                    'ì–¸ì–´', 'ê°€ì´ë“œ', 'í¬í•¨', 'ë¶ˆí¬í•¨', 'ì´ìƒ',\n                    'ì·¨ì†Œ', 'í™˜ë¶ˆ', 'ë³€ê²½', 'ì•ˆë‚´', 'ëª¨ì§‘'\n                ]\n                \n                if any(keyword in found_price for keyword in invalid_keywords):\n                    continue\n                \n                # ê¸¸ì´ ì œí•œ (ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ ì œì™¸)\n                if len(found_price) > 30:\n                    continue\n                \n                # ê°€ê²© íŒ¨í„´ í™•ì¸\n                import re\n                price_patterns = [\n                    r'\\d{1,3}(?:,\\d{3})+ì›[~-]?',  # 10,000ì›~ í˜•íƒœ\n                    r'\\d+,\\d+ì›[~-]?',             # ê°„ë‹¨í•œ ì²œë‹¨ìœ„ êµ¬ë¶„\n                    r'\\d{4,}ì›[~-]?',              # 10000ì›~ í˜•íƒœ\n                ]\n                \n                is_valid_price = any(re.search(pattern, found_price) for pattern in price_patterns)\n                \n                if is_valid_price and 'ì›' in found_price:\n                    print(f\"    âœ… ìœ íš¨í•œ ê°€ê²© ë°œê²¬: '{found_price}'\")\n                    return found_price\n                    \n        except Exception:\n            continue\n    \n    print(f\"    âŒ ê°€ê²© ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n    return \"ì •ë³´ ì—†ìŒ\"\n\ndef clean_price(price_text):\n    \"\"\"âœ… ê°€ê²© ì •ì œ (ê¸°ì¡´: extract_clean_price â†’ ìƒˆë¡œìš´: clean_price) (ê³µìš© í•¨ìˆ˜)\"\"\"\n    if not price_text or price_text == \"ì •ë³´ ì—†ìŒ\":\n        return \"ì •ë³´ ì—†ìŒ\"\n    \n    price_pattern = r'(\\d{1,3}(?:,\\d{3})*)\\s*ì›[~-]?'\n    match = re.search(price_pattern, price_text)\n    \n    if match:\n        return match.group(1) + \"ì›\"\n    else:\n        return price_text\n\ndef clean_rating(rating_text):\n    \"\"\"âœ… í‰ì  ì •ì œ (ê¸°ì¡´: extract_clean_rating â†’ ìƒˆë¡œìš´: clean_rating) (ê³µìš© í•¨ìˆ˜)\"\"\"\n    if not rating_text or rating_text == \"ì •ë³´ ì—†ìŒ\":\n        return \"ì •ë³´ ì—†ìŒ\"\n    \n    rating_pattern = r'(\\d+\\.?\\d*)'\n    match = re.search(rating_pattern, rating_text)\n    \n    if match:\n        try:\n            return float(match.group(1))\n        except ValueError:\n            return rating_text\n    else:\n        return rating_text\n\n\ndef download_image(driver, product_name, city_name, image_number):\n    \"\"\"âœ… ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ - ê³„ì¸µ êµ¬ì¡° ì €ì¥ (ì „ì—­ ë²ˆí˜¸ ì‚¬ìš©ìœ¼ë¡œ ìˆ˜ì •)\"\"\"\n    if not CONFIG[\"SAVE_IMAGES\"]:\n        return {\n            'status': 'ì´ë¯¸ì§€ ì €ì¥ ë¹„í™œì„±í™”',\n            'filename': '',\n            'path': '',\n            'relative_path': '',\n            'size': 0\n        }\n        \n    print(f\"  ğŸ–¼ï¸ ëŒ€í‘œ ìƒí’ˆ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n    \n    # ë” ê´‘ë²”ìœ„í•œ ì´ë¯¸ì§€ ì…€ë ‰í„°ë“¤\n    image_selectors = [\n        (By.CSS_SELECTOR, \".main-image img\"),\n        (By.CSS_SELECTOR, \".hero-image img\"),\n        (By.CSS_SELECTOR, \".product-image img\"),\n        (By.CSS_SELECTOR, \".product-gallery img:first-child\"),\n        (By.CSS_SELECTOR, \".gallery img:first-child\"),\n        (By.CSS_SELECTOR, \".image-gallery img:first-child\"),\n        (By.CSS_SELECTOR, \".slider img:first-child\"),\n        (By.XPATH, \"//img[@width and @height and (@width > '200' or @height > '200')]\"),\n        (By.XPATH, \"//img[contains(@src, 'large') or contains(@src, 'big') or contains(@src, 'main')]\"),\n        (By.CSS_SELECTOR, \"img[src*='cdn']\"),\n        (By.CSS_SELECTOR, \"img[src*='cloudfront']\"),\n        (By.CSS_SELECTOR, \"img[src*='amazonaws']\"),\n        (By.XPATH, \"(//img[contains(@src, 'http') and not(contains(@src, 'icon')) and not(contains(@src, 'logo'))])[1]\"),\n        (By.XPATH, \"//img[contains(@alt, 'ìƒí’ˆ') or contains(@alt, 'íˆ¬ì–´') or contains(@alt, 'ì—¬í–‰')]\"),\n    ]\n\n    img_url = None\n    for selector_type, selector_value in image_selectors:\n        try:\n            img_elements = driver.find_elements(selector_type, selector_value)\n            for img_element in img_elements:\n                try:\n                    img_url = img_element.get_attribute('src')\n                    if not img_url or not img_url.startswith('http'):\n                        continue\n                    exclude_patterns = ['logo', 'icon', 'banner', 'ad', 'avatar', 'profile', 'button', 'arrow', 'star', 'thumb', 'small', 'mini']\n                    if any(pattern in img_url.lower() for pattern in exclude_patterns):\n                        continue\n                    try:\n                        size = img_element.size\n                        if size and (size.get('width', 0) < 100 or size.get('height', 0) < 100):\n                            continue\n                    except:\n                        pass\n                    print(f\"    âœ… ì´ë¯¸ì§€ URL ë°œê²¬: {img_url[:50]}...\")\n                    break\n                except Exception:\n                    continue\n            if img_url:\n                break\n        except Exception:\n            continue\n\n    # â­ï¸ í•µì‹¬ ìˆ˜ì •: íŒŒì¼ëª…ì„ image_number(ì „ì—­ ì¹´ìš´í„°) ê¸°ì¤€ìœ¼ë¡œ ìƒì„±\n    city_code = get_city_code(city_name)\n    img_filename = f\"{city_code}_{image_number:03d}.jpg\"\n\n    if not img_url:\n        print(f\"    âŒ ì´ë¯¸ì§€ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n        return {\n            'status': 'ì´ë¯¸ì§€ URL ì—†ìŒ',\n            'filename': img_filename,\n            'path': '',\n            'relative_path': '',\n            'size': 0\n        }\n\n    # ğŸ—ï¸ ê³„ì¸µ êµ¬ì¡° í´ë” ìƒì„± ë° ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ\n    try:\n        import urllib.request\n        import os\n        \n        # ë„ì‹œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n        continent, country = get_city_info(city_name)\n        \n        # ğŸ“ ê³„ì¸µ êµ¬ì¡° í´ë” ê²½ë¡œ ìƒì„±: myrealtripthumb_img/ëŒ€ë¥™/êµ­ê°€/ë„ì‹œ/\n        base_folder = \"myrealtripthumb_img\"\n        hierarchical_folder = os.path.join(base_folder, continent, country, city_name)\n        \n        # í´ë” ìƒì„± (ê³„ì¸µ êµ¬ì¡°)\n        os.makedirs(hierarchical_folder, exist_ok=True)\n        print(f\"    ğŸ“ ê³„ì¸µ í´ë” ìƒì„±: {hierarchical_folder}\")\n        \n        # ì „ì²´ íŒŒì¼ ê²½ë¡œ\n        img_path = os.path.join(hierarchical_folder, img_filename)\n        \n        # ìƒëŒ€ ê²½ë¡œ (CSVì— ì €ì¥ìš©)\n        relative_path = os.path.join(continent, country, city_name, img_filename)\n        \n        # User-Agent ì¶”ê°€ë¡œ ë‹¤ìš´ë¡œë“œ ì„±ê³µë¥  ë†’ì´ê¸°\n        req = urllib.request.Request(\n            img_url,\n            headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n        )\n        \n        with urllib.request.urlopen(req, timeout=10) as response:\n            with open(img_path, 'wb') as f:\n                f.write(response.read())\n        \n        file_size = os.path.getsize(img_path)\n        \n        if file_size < 1024:\n            os.remove(img_path)\n            print(f\"    âŒ ì´ë¯¸ì§€ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤ ({file_size} bytes)\")\n            return {\n                'status': 'íŒŒì¼ ë„ˆë¬´ ì‘ìŒ',\n                'filename': img_filename,\n                'path': '',\n                'relative_path': '',\n                'size': 0\n            }\n        \n        print(f\"    âœ… ê³„ì¸µ êµ¬ì¡° ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ! ({file_size:,} bytes)\")\n        print(f\"    ğŸ“ ì €ì¥ ìœ„ì¹˜: {relative_path}\")\n        \n        return {\n            'status': 'ë‹¤ìš´ë¡œë“œ ì™„ë£Œ',\n            'filename': img_filename,\n            'path': img_path,\n            'relative_path': relative_path,\n            'size': file_size\n        }\n        \n    except Exception as e:\n        print(f\"    âš ï¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {type(e).__name__}: {e}\")\n        return {\n            'status': f'ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {type(e).__name__}',\n            'filename': img_filename,\n            'path': '',\n            'relative_path': '',\n            'size': 0\n        }\n    else:\n        return {\n            'status': 'ì´ë¯¸ì§€ ì—†ìŒ',\n            'filename': f\"{get_city_code(city_name)}_{product_index:03d}.jpg\",\n            'path': '',\n            'size': 0\n        }\n\ndef save_results(products_data):\n    \"\"\"âœ… ë°ì´í„° ì €ì¥ (ê¸°ì¡´: save_myrealtrip_data â†’ ìƒˆë¡œìš´: save_results)\"\"\"\n    print(\"ğŸ’¾ í•˜ì´ë¸Œë¦¬ë“œ êµ¬ì¡°ë¡œ ë°ì´í„° ì €ì¥ ì¤‘...\")\n    \n    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n    \n    city_name = products_data[0]['ë„ì‹œ'] if products_data else 'unknown'\n    \n    df = pd.DataFrame(products_data)\n    csv_path = f\"myrealtrip_{city_name}_products_{len(products_data)}ê°œ_{timestamp}.csv\"\n    df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n    \n    print(f\"ğŸ“ ê°œë³„ CSV ì €ì¥ ì™„ë£Œ: {csv_path}\")\n    \n    metadata = {\n        \"myrealtrip\": {\n            \"last_update\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n            \"product_count\": len(products_data),\n            \"status\": \"success\",\n            \"csv_path\": csv_path,\n            \"city\": city_name\n        }\n    }\n    \n    try:\n        with open('config/data_metadata.json', 'w', encoding='utf-8') as f:\n            json.dump(metadata, f, ensure_ascii=False, indent=2)\n        print(f\"ğŸ“ ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: config/data_metadata.json\")\n    except Exception as e:\n        print(f\"âš ï¸ ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}\")\n    \n    return csv_path\n\n# =============================================================================\n# ğŸ”„ 1ìˆœìœ„: ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶• (ë°ì´í„° ì—°ì†ì„± í™•ë³´)\n# =============================================================================\n\ndef load_crawler_state():\n    \"\"\"í¬ë¡¤ë§ ìƒíƒœ ë¡œë“œ (config/crawler_meta.jsonì—ì„œ)\"\"\"\n    config_dir = \"config\"\n    state_file = os.path.join(config_dir, \"crawler_meta.json\")\n    urls_file = os.path.join(config_dir, \"completed_urls.log\")\n    \n    # config í´ë” ìƒì„±\n    os.makedirs(config_dir, exist_ok=True)\n    \n    # ê¸°ë³¸ ìƒíƒœ\n    default_state = {\n        \"total_collected_count\": 0,\n        \"last_crawled_page\": 1,\n        \"current_session_start\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n        \"last_updated\": datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n    }\n    \n    # ìƒíƒœ íŒŒì¼ ë¡œë“œ\n    if os.path.exists(state_file):\n        try:\n            with open(state_file, 'r', encoding='utf-8') as f:\n                state = json.load(f)\n            print(f\"âœ… ìƒíƒœ íŒŒì¼ ë¡œë“œ: {state['total_collected_count']}ê°œ ìˆ˜ì§‘ ì™„ë£Œ\")\n        except Exception as e:\n            print(f\"âš ï¸ ìƒíƒœ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}, ê¸°ë³¸ê°’ ì‚¬ìš©\")\n            state = default_state\n    else:\n        state = default_state\n        print(\"ğŸ†• ìƒˆë¡œìš´ í¬ë¡¤ë§ ì„¸ì…˜ ì‹œì‘\")\n    \n    # ì™„ë£Œëœ URL ëª©ë¡ ë¡œë“œ\n    completed_urls = set()\n    if os.path.exists(urls_file):\n        try:\n            with open(urls_file, 'r', encoding='utf-8') as f:\n                completed_urls = set(line.strip() for line in f if line.strip())\n            print(f\"âœ… ì™„ë£Œëœ URL {len(completed_urls)}ê°œ ë¡œë“œ\")\n        except Exception as e:\n            print(f\"âš ï¸ URL íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n    \n    return state, completed_urls\n\ndef save_crawler_state(state, new_url=None):\n    \"\"\"í¬ë¡¤ë§ ìƒíƒœ ì €ì¥ (ì¦‰ì‹œ ì €ì¥)\"\"\"\n    config_dir = \"config\"\n    state_file = os.path.join(config_dir, \"crawler_meta.json\")\n    urls_file = os.path.join(config_dir, \"completed_urls.log\")\n    \n    # ìƒíƒœ ì—…ë°ì´íŠ¸\n    state[\"last_updated\"] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n    \n    try:\n        # ìƒíƒœ íŒŒì¼ ì €ì¥\n        with open(state_file, 'w', encoding='utf-8') as f:\n            json.dump(state, f, ensure_ascii=False, indent=2)\n        \n        # ìƒˆ URLì´ ìˆìœ¼ë©´ ì¶”ê°€\n        if new_url:\n            with open(urls_file, 'a', encoding='utf-8') as f:\n                f.write(new_url + '\\n')\n            state[\"total_collected_count\"] += 1\n        \n        return True\n    except Exception as e:\n        print(f\"âŒ ìƒíƒœ ì €ì¥ ì‹¤íŒ¨: {e}\")\n        return False\n\ndef save_batch_data(batch_results, city_name):\n    \"\"\"ë°°ì¹˜ ë°ì´í„° ì €ì¥ (ë„ì‹œë³„/êµ­ê°€ë³„ ëª¨ë‘ ì¶”ê°€(append) ëª¨ë“œ)\"\"\"\n    if not batch_results:\n        return None\n    \n    try:\n        continent, country = get_city_info(city_name)\n        \n        data_dir = os.path.join(\"data\", continent, country, city_name)\n        os.makedirs(data_dir, exist_ok=True)\n        \n        df = pd.DataFrame(batch_results)\n\n        # 1. ë„ì‹œë³„ CSV (ë°ì´í„° ì—°ì†ì„±ì„ ìœ„í•´ ì¶”ê°€ ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •)\n        city_csv = os.path.join(data_dir, f\"myrealtrip_{city_name}_products.csv\")\n        if os.path.exists(city_csv):\n            df.to_csv(city_csv, mode='a', header=False, index=False, encoding='utf-8-sig')\n        else:\n            df.to_csv(city_csv, mode='w', header=True, index=False, encoding='utf-8-sig')\n\n        # 2. êµ­ê°€ë³„ í†µí•© CSV (ê¸°ì¡´ ì¶”ê°€ ë°©ì‹ ìœ ì§€)\n        country_dir = os.path.join(\"data\", continent, country)\n        os.makedirs(country_dir, exist_ok=True)\n        country_csv = os.path.join(country_dir, f\"{country}_myrealtrip_products_all.csv\")\n        if os.path.exists(country_csv):\n            df.to_csv(country_csv, mode='a', header=False, index=False, encoding='utf-8-sig')\n        else:\n            df.to_csv(country_csv, mode='w', header=True, index=False, encoding='utf-8-sig')\n\n        print(f\"âœ… ë°°ì¹˜ ë°ì´í„° ì €ì¥ ì™„ë£Œ:\")\n        print(f\"   ğŸ“ ë„ì‹œë³„: {city_csv}\")\n        print(f\"   ğŸ“ êµ­ê°€ë³„: {country_csv}\")\n        \n        return {\n            \"city_csv\": city_csv,\n            \"country_csv\": country_csv,\n            \"data_count\": len(batch_results)\n        }\n        \n    except Exception as e:\n        print(f\"âŒ ë°°ì¹˜ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}\")\n        return None\n\ndef filter_new_urls(all_urls, completed_urls):\n    \"\"\"ì™„ë£Œë˜ì§€ ì•Šì€ ìƒˆë¡œìš´ URLë§Œ í•„í„°ë§\"\"\"\n    new_urls = [url for url in all_urls if url not in completed_urls]\n    \n    print(f\"ğŸ” URL í•„í„°ë§ ê²°ê³¼:\")\n    print(f\"   ğŸ“Š ì „ì²´ URL: {len(all_urls)}ê°œ\")\n    print(f\"   âœ… ì™„ë£Œëœ URL: {len(completed_urls)}ê°œ\")\n    print(f\"   ğŸ†• ìƒˆë¡œìš´ URL: {len(new_urls)}ê°œ\")\n    \n    return new_urls\n\ndef create_image_filename(total_count, city_name):\n    \"\"\"ì´ ìˆ˜ì§‘ ê°œìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì´ë¯¸ì§€ íŒŒì¼ëª… ìƒì„±\"\"\"\n    city_code = get_city_code(city_name)\n    return f\"{city_code}_{total_count:03d}.jpg\"\n\n# =============================================================================\n# ğŸš€ Phase 2: í™•ì¥ì„± ê°œì„  ì‹œìŠ¤í…œ (ë¦¬íŒ©í† ë§ëœ ë²„ì „)\n# =============================================================================\n\ndef create_city_codes_file():\n    \"\"\"ë„ì‹œ ì½”ë“œë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥ (UNIFIED_CITY_INFO ê¸°ë°˜)\"\"\"\n    enhanced_city_data = {\n        \"version\": \"3.0\",\n        \"last_updated\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n        \"cities\": {},\n        \"total_cities\": len(UNIFIED_CITY_INFO)\n    }\n\n    for city_name, info in UNIFIED_CITY_INFO.items():\n        enhanced_city_data[\"cities\"][city_name] = {\n            \"code\": info.get(\"ì½”ë“œ\", \"N/A\"),\n            \"continent\": info.get(\"ëŒ€ë¥™\", \"ê¸°íƒ€\"),\n            \"country\": info.get(\"êµ­ê°€\", \"ê¸°íƒ€\")\n        }\n    \n    try:\n        with open('config/city_codes.json', 'w', encoding='utf-8') as f:\n            json.dump(enhanced_city_data, f, ensure_ascii=False, indent=2)\n        print(f\"âœ… config/city_codes.json íŒŒì¼ ìƒì„± ì™„ë£Œ! ({len(UNIFIED_CITY_INFO)}ê°œ ë„ì‹œ)\")\n        return True\n    except Exception as e:\n        print(f\"âŒ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}\")\n        return False\n\ndef load_city_codes_from_file():\n    \"\"\"JSON íŒŒì¼ì—ì„œ ë„ì‹œ ì½”ë“œ ë¡œë“œ (UNIFIED_CITY_INFOì™€ ë™ê¸°í™”)\"\"\"\n    if not os.path.exists('config/city_codes.json'):\n        print(\"ğŸ“ config/city_codes.json íŒŒì¼ì´ ì—†ì–´ì„œ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...\")\n        create_city_codes_file()\n    \n    try:\n        with open('config/city_codes.json', 'r', encoding='utf-8') as f:\n            city_data = json.load(f)\n        \n        loaded_cities = city_data.get(\"cities\", {})\n        \n        for city, info in loaded_cities.items():\n            if city not in UNIFIED_CITY_INFO:\n                 UNIFIED_CITY_INFO[city] = {\n                     \"ëŒ€ë¥™\": info.get(\"continent\"),\n                     \"êµ­ê°€\": info.get(\"country\"),\n                     \"ì½”ë“œ\": info.get(\"code\")\n                 }\n        \n        print(f\"âœ… config/city_codes.json ë¡œë“œ ë° ë™ê¸°í™” ì™„ë£Œ! ({len(UNIFIED_CITY_INFO)}ê°œ ë„ì‹œ)\")\n        print(f\"ğŸ“… ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {city_data.get('last_updated', 'ì•Œ ìˆ˜ ì—†ìŒ')}\")\n        \n    except Exception as e:\n        print(f\"âš ï¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n        print(\"ğŸ’¡ ì½”ë“œì˜ UNIFIED_CITY_INFOë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n\ndef add_new_city(city_name, airport_code, continent=\"ê¸°íƒ€\", country=\"ê¸°íƒ€\", update_file=True):\n    \"\"\"ìƒˆë¡œìš´ ë„ì‹œë¥¼ UNIFIED_CITY_INFOì— ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜\"\"\"\n    global UNIFIED_CITY_INFO\n    \n    if city_name not in UNIFIED_CITY_INFO:\n        UNIFIED_CITY_INFO[city_name] = {\n            \"ëŒ€ë¥™\": continent,\n            \"êµ­ê°€\": country,\n            \"ì½”ë“œ\": airport_code\n        }\n        print(f\"âœ… ë©”ëª¨ë¦¬ì— ì¶”ê°€: {city_name} â†’ {airport_code} ({continent}, {country})\")\n        if update_file:\n            create_city_codes_file()\n        return True\n    else:\n        print(f\"ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ë„ì‹œì…ë‹ˆë‹¤: {city_name}\")\n        return False\n\ndef show_supported_cities():\n    \"\"\"ì§€ì›í•˜ëŠ” ë„ì‹œ ëª©ë¡ í‘œì‹œ (UNIFIED_CITY_INFO ê¸°ë°˜)\"\"\"\n    print(\"\\nğŸŒ ì§€ì›í•˜ëŠ” ë„ì‹œ ëª©ë¡:\")\n    print(\"=\"*50)\n    \n    cities_by_continent = {}\n    for city, info in UNIFIED_CITY_INFO.items():\n        continent = info.get(\"ëŒ€ë¥™\", \"ê¸°íƒ€\")\n        if continent not in cities_by_continent:\n            cities_by_continent[continent] = []\n        cities_by_continent[continent].append(city)\n\n    for continent, cities in sorted(cities_by_continent.items()):\n        print(f\"\\nğŸ“ {continent}:\")\n        for city in sorted(cities):\n            code = UNIFIED_CITY_INFO[city].get(\"ì½”ë“œ\", \"N/A\")\n            print(f\"   {city} â†’ {code}\")\n    \n    print(f\"\\nğŸ“Š ì´ {len(UNIFIED_CITY_INFO)}ê°œ ë„ì‹œ ì§€ì›\")\n    print(\"=\"*50)\n\ndef validate_city(city_name):\n    \"\"\"ë„ì‹œëª… ìœ íš¨ì„± ê²€ì‚¬ (UNIFIED_CITY_INFO ê¸°ë°˜)\"\"\"\n    if not city_name or len(city_name.strip()) == 0:\n        return False, \"ë„ì‹œëª…ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\"\n    \n    if city_name in UNIFIED_CITY_INFO:\n        code = UNIFIED_CITY_INFO[city_name].get(\"ì½”ë“œ\", \"N/A\")\n        return True, f\"ì§€ì›í•˜ëŠ” ë„ì‹œì…ë‹ˆë‹¤. ({code})\"\n    \n    similar_cities = [c for c in UNIFIED_CITY_INFO if city_name.lower() in c.lower() or c.lower() in city_name.lower()]\n    \n    if similar_cities:\n        return False, f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë„ì‹œì…ë‹ˆë‹¤. ë¹„ìŠ·í•œ ë„ì‹œ: {', '.join(similar_cities)}\"\n    else:\n        return False, f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë„ì‹œì…ë‹ˆë‹¤. ìƒˆë¡œ ì¶”ê°€í•˜ì‹œë ¤ë©´ add_new_city() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\"\n\ndef update_config_for_scalability():\n    \"\"\"í™•ì¥ì„±ì„ ìœ„í•œ CONFIG ì—…ë°ì´íŠ¸\"\"\"\n    global CONFIG\n    \n    scalability_config = {\n        \"AUTO_LOAD_CITIES\": True,\n        \"AUTO_SAVE_NEW_CITIES\": True,\n        \"ENABLE_MULTI_CITY\": False,\n        \"CITY_PROCESSING_ORDER\": \"sequential\",\n        \"BACKUP_OLD_DATA\": True,\n        \"DATA_RETENTION_DAYS\": 30,\n        \"ENABLE_CITY_VALIDATION\": True,\n        \"ENABLE_DUPLICATE_CHECK\": True,\n    }\n    \n    CONFIG.update(scalability_config)\n    print(\"âš™ï¸ CONFIG í™•ì¥ì„± ì„¤ì • ì—…ë°ì´íŠ¸ ì™„ë£Œ!\")\n\ndef initialize_file_system():\n    \"\"\"íŒŒì¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ì„¤ì • (ë¦¬íŒ©í† ë§ëœ ë²„ì „)\"\"\"\n    print(\"ğŸ”§ Phase 2: í™•ì¥ì„± ê°œì„  ì‹œìŠ¤í…œ ì´ˆê¸°í™”...\")\n    \n    update_config_for_scalability()\n    \n    if CONFIG.get(\"AUTO_LOAD_CITIES\", True):\n        load_city_codes_from_file()\n    \n    print(\"âœ… Phase 2 ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!\")\n    return True\n\n# =============================================================================\n# ğŸ› ï¸ ê¸°ì¡´ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (Phase 2 ì‹œìŠ¤í…œê³¼ í•¨ê»˜ ìœ ì§€)\n# =============================================================================\n\ndef print_progress(current, total, city_name, status=\"ì§„í–‰ì¤‘\"):\n    \"\"\"ì§„í–‰ë¥ ì„ ì‹œê°ì ìœ¼ë¡œ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n    percentage = (current / total) * 100\n    bar_length = 30\n    filled_length = int(bar_length * current // total)\n    bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)\n    \n    emoji = \"ğŸ”\" if status == \"ì§„í–‰ì¤‘\" else \"âœ…\" if status == \"ì™„ë£Œ\" else \"âŒ\"\n    \n    print(f\"\\n{emoji} ì§„í–‰ë¥ : [{bar}] {percentage:.1f}% ({current}/{total})\")\n    print(f\"ğŸ“ í˜„ì¬ ì‘ì—…: {city_name} - {status}\")\n    print(\"-\" * 50)\n\ndef print_product_progress(current, total, product_name):\n    \"\"\"ìƒí’ˆë³„ ì§„í–‰ë¥  í‘œì‹œ í•¨ìˆ˜\"\"\"\n    percentage = (current / total) * 100\n    bar_length = 20\n    filled_length = int(bar_length * current // total)\n    bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)\n    \n    safe_name = str(product_name)[:30] + \"...\" if len(str(product_name)) > 30 else str(product_name)\n    print(f\"    ğŸ¯ ìƒí’ˆ ì§„í–‰ë¥ : [{bar}] {percentage:.1f}% ({current}/{total})\")\n    print(f\"    ğŸ“¦ í˜„ì¬ ìƒí’ˆ: {safe_name}\")\n\ndef save_intermediate_results(results, city_name):\n    \"\"\"ì¤‘ê°„ ê²°ê³¼ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜\"\"\"\n    if results and CONFIG[\"SAVE_INTERMEDIATE\"]:\n        try:\n            timestamp = time.strftime('%Y%m%d_%H%M%S')\n            temp_filename = f\"temp_ì¤‘ê°„ì €ì¥_{city_name}_{timestamp}.csv\"\n            pd.DataFrame(results).to_csv(temp_filename, index=False, encoding='utf-8-sig')\n            print(f\"  ğŸ’¾ ì¤‘ê°„ ê²°ê³¼ ì €ì¥: {temp_filename}\")\n            return temp_filename\n        except Exception as e:\n            print(f\"  âš ï¸ ì¤‘ê°„ ì €ì¥ ì‹¤íŒ¨: {e}\")\n            return None\n    return None\n\ndef retry_operation(func, operation_name, max_retries=None):\n    \"\"\"ì‹¤íŒ¨í•œ ì‘ì—…ì„ ì¬ì‹œë„í•˜ëŠ” í•¨ìˆ˜\"\"\"\n    if max_retries is None:\n        max_retries = CONFIG[\"RETRY_COUNT\"]\n    \n    for attempt in range(max_retries):\n        try:\n            return func()\n        except (TimeoutException, NoSuchElementException, WebDriverException) as e:\n            if attempt == max_retries - 1:\n                print(f\"  âŒ {operation_name} ìµœì¢… ì‹¤íŒ¨: {type(e).__name__}\")\n                raise e\n            print(f\"  ğŸ”„ {operation_name} ì¬ì‹œë„ {attempt + 1}/{max_retries} (ì˜¤ë¥˜: {type(e).__name__})\")\n            time.sleep(2)\n        except Exception as e:\n            print(f\"  âŒ {operation_name} ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {type(e).__name__}: {e}\")\n            raise e\n\ndef make_safe_filename(filename):\n    \"\"\"íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°\"\"\"\n    if not filename:\n        return \"ê¸°ë³¸íŒŒì¼ëª…\"\n    \n    safe_filename = str(filename)\n    unsafe_chars = ['/', '\\\\', ':', '*', '?', '\"', '<', '>', '|', '\\n', '\\r', '\\t']\n    for char in unsafe_chars:\n        safe_filename = safe_filename.replace(char, '_')\n    \n    if len(safe_filename) > 200:\n        safe_filename = safe_filename[:200]\n    \n    if safe_filename.startswith('.'):\n        safe_filename = '_' + safe_filename[1:]\n    \n    return safe_filename\n\ndef make_user_agent(ua, is_mobile):\n    user_agent = parse(ua)\n    model = user_agent.device.model\n    platform = user_agent.os.family\n    platform_version = user_agent.os.version_string + \".0.0\"\n    version = user_agent.browser.version[0]\n    ua_full_version = user_agent.browser.version_string\n    architecture = \"x86\"\n    print(platform)\n    if is_mobile:\n        platform_info = \"Linux armv8l\"\n        architecture= \"\"\n    else:\n        platform_info = \"Win32\"\n        model = \"\"\n    RET_USER_AGENT = {\n        \"appVersion\" : ua.replace(\"Mozilla/\", \"\"),\n        \"userAgent\": ua,\n        \"platform\" : f\"{platform_info}\",\n        \"acceptLanguage\" : \"ko-KR, kr, en-US, en\",\n        \"userAgentMetadata\":{\n            \"brands\" : [\n                {\"brand\":\"Google Chrome\", \"version\":f\"{version}\"},\n                {\"brand\":\"Chromium\", \"version\":f\"{version}\"},\n                {\"brand\":\" Not A;Brand\", \"version\":\"99\"}\n            ],\n            \"fullVersionList\" : [\n                {\"brand\":\"Google Chrome\", \"version\":f\"{version}\"},\n                {\"brand\":\"Chromium\", \"version\":f\"{version}\"},\n                {\"brand\":\" Not A;Brand\", \"version\":\"99\"}\n            ],\n            \"fullVersion\":f\"{ua_full_version}\",\n            \"platform\" :platform,\n            \"platformVersion\":platform_version,\n            \"architecture\":architecture,\n            \"model\" : model,\n            \"mobile\":is_mobile\n        }\n    }\n    return RET_USER_AGENT\n\ndef generate_random_geolocation():\n    ltop_lat = 37.75415601640249\n    ltop_long = 126.86767642302573\n    rbottom_lat = 37.593829172663945\n    rbottom_long = 127.15276051439332\n\n    targetLat = random.uniform(rbottom_lat, ltop_lat)\n    targetLong = random.uniform(ltop_long,rbottom_long)\n    return {\"latitude\":targetLat, \"longitude\" : targetLong, \"accuracy\":100}\n\ndef setup_driver():\n    \"\"\"í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì • ë° ì‹¤í–‰\"\"\"\n    chromedriver_autoinstaller.install()\n    \n    options = uc.ChromeOptions()\n    \n    UA = CONFIG[\"USER_AGENT\"]\n    options.add_argument(f\"--user-agent={UA}\")\n    \n    rand_user_folder = random.randrange(1,100)\n    raw_path = os.path.abspath(\"cookies\")\n    try:\n        # shutil.rmtree(raw_path) # í´ë” ì‚­ì œ ë°©ì§€ë¥¼ ìœ„í•´ ì´ ì¤„ì„ ì£¼ì„ ì²˜ë¦¬\n        pass\n    except:\n        pass\n    os.makedirs(raw_path, exist_ok=True)\n    user_cookie_name = f\"{raw_path}/{rand_user_folder}\"\n    if os.path.exists(user_cookie_name) == False:\n        os.makedirs(user_cookie_name, exist_ok=True)\n    \n    try:\n        driver = uc.Chrome(user_data_dir=user_cookie_name, options=options)\n        print(\"âœ… í¬ë¡¬ ë“œë¼ì´ë²„ ì‹¤í–‰ ì„±ê³µ!\")\n    except Exception as e:\n        print('\\\\n',\"-\"*50,\"\\\\n\",\"-\"*50,\"\\\\n\")\n        print(\"# í‚¤í™ˆ ë©”ì„¸ì§€ : í˜¹ì‹œ ì—¬ê¸°ì„œ ì—ëŸ¬ ë°œìƒì‹œ [ì•„ë˜ ë¸”ë¡œê·¸ ì°¸ê³  -> ì¬ë¶€íŒ… -> ë‹¤ì‹œ ì½”ë“œì‹¤í–‰] í•´ë³´ì‹œê¸¸ ë°”ëë‹ˆë‹¤! \\\\n (êµ¬ê¸€í¬ë¡¬ ë²„ì ¼ ì—…ê·¸ë ˆì´ë“œ ë¬¸ì œ)\")\n        print('https://appfollow.tistory.com/102')\n        print('\\\\n',\"-\"*50,\"\\\\n\",\"-\"*50,\"\\\\n\")\n        raise RuntimeError\n        \n    UA_Data = make_user_agent(UA,False)\n    driver.execute_cdp_cmd(\"Network.setUserAgentOverride\",UA_Data)\n    \n    GEO_DATA = generate_random_geolocation()\n    driver.execute_cdp_cmd(\"Emulation.setGeolocationOverride\", GEO_DATA)\n    driver.execute_cdp_cmd(\"Emulation.setUserAgentOverride\", UA_Data)\n    driver.execute_cdp_cmd(\"Emulation.setNavigatorOverrides\",{\"platform\":\"Linux armv8l\"})\n    \n    return driver\n\ndef go_to_main_page(driver):\n    \"\"\"ë©”ì¸ í˜ì´ì§€ë¡œ ì´ë™\"\"\"\n    driver.get(\"https://www.myrealtrip.com/experiences/\")\n    time.sleep(random.uniform(CONFIG[\"MIN_DELAY\"], CONFIG[\"MAX_DELAY\"]))\n    return True\n\ndef find_and_fill_search(driver, city_name):\n    \"\"\"ê²€ìƒ‰ì°½ ì°¾ê¸° ë° ì…ë ¥\"\"\"\n    print(f\"  ğŸ” '{city_name}' ê²€ìƒ‰ì°½ ì°¾ëŠ” ì¤‘...\")\n    search_selectors = [\n        (By.CSS_SELECTOR, \"input[placeholder*='ì–´ë””ë¡œ']\"),\n        (By.CSS_SELECTOR, \"input[type='text']\"),\n        (By.XPATH, \"//input[contains(@placeholder, 'ì–´ë””ë¡œ')]\"),\n        (By.XPATH, \"/html/body/main/div/div[2]/section[1]/div[1]/div/div/input\")\n    ]\n\n    search_input = None\n    for selector_type, selector_value in search_selectors:\n        try:\n            search_input = WebDriverWait(driver, CONFIG[\"WAIT_TIMEOUT\"]).until(\n                EC.presence_of_element_located((selector_type, selector_value))\n            )\n            print(f\"  âœ… ê²€ìƒ‰ì°½ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!\")\n            break\n        except TimeoutException:\n            continue\n\n    if not search_input:\n        raise NoSuchElementException(\"ê²€ìƒ‰ì°½ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n\n    search_input.clear()\n    search_input.send_keys(city_name)\n    time.sleep(random.uniform(CONFIG[\"MIN_DELAY\"], CONFIG[\"MIN_DELAY\"]+2))\n    print(f\"  ğŸ“ '{city_name}' í‚¤ì›Œë“œ ì…ë ¥ ì™„ë£Œ\")\n    return True\n\ndef click_search_button(driver):\n    \"\"\"ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­\"\"\"\n    print(f\"  ğŸ” ê²€ìƒ‰ ë²„íŠ¼ ì°¾ëŠ” ì¤‘...\")\n    search_button_selectors = [\n        (By.CSS_SELECTOR, \"button[type='submit']\"),\n        (By.CSS_SELECTOR, \".search-btn\"),\n        (By.XPATH, \"//button[contains(@class, 'search')]\"),\n        (By.XPATH, \"//img[contains(@alt, 'ê²€ìƒ‰')]//parent::*\"),\n        (By.XPATH, \"/html/body/main/div/div[2]/section[1]/div[1]/div/div/div/img\")\n    ]\n\n    search_clicked = False\n    for selector_type, selector_value in search_button_selectors:\n        try:\n            search_button = WebDriverWait(driver, CONFIG[\"WAIT_TIMEOUT\"]).until(\n                EC.element_to_be_clickable((selector_type, selector_value))\n            )\n            search_button.click()\n            print(f\"  âœ… ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­ ì„±ê³µ!\")\n            search_clicked = True\n            time.sleep(random.uniform(CONFIG[\"MIN_DELAY\"], CONFIG[\"MAX_DELAY\"]))\n            break\n        except TimeoutException:\n            continue\n\n    if not search_clicked:\n        raise NoSuchElementException(\"ê²€ìƒ‰ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n    return True\n\ndef handle_popup(driver):\n    \"\"\"íŒì—… ì²˜ë¦¬\"\"\"\n    popup_selectors = [\n        (By.CSS_SELECTOR, \".popup-close\"),\n        (By.CSS_SELECTOR, \".modal-close\"),\n        (By.XPATH, \"//button[contains(@aria-label, 'ë‹«ê¸°')]\"),\n        (By.XPATH, \"//button[contains(text(), 'ë‹«ê¸°')]\"),\n        (By.XPATH, \"/html/body/div[15]/div[2]/button\")\n    ]\n\n    popup_closed = False\n    for selector_type, selector_value in popup_selectors:\n        try:\n            popup_button = WebDriverWait(driver, CONFIG[\"POPUP_WAIT\"]).until(\n                EC.element_to_be_clickable((selector_type, selector_value))\n            )\n            popup_button.click()\n            print(f\"  âœ… íŒì—…ì°½ì„ ë‹«ì•˜ìŠµë‹ˆë‹¤.\")\n            popup_closed = True\n            time.sleep(random.uniform(1, 4))\n            break\n        except TimeoutException:\n            continue\n\n    if not popup_closed:\n        print(f\"  â„¹ï¸ íŒì—…ì°½ì´ ì—†ê±°ë‚˜ ì´ë¯¸ ë‹«í˜€ìˆìŠµë‹ˆë‹¤.\")\n    return True\n\ndef click_view_all(driver):\n    \"\"\"ì „ì²´ ìƒí’ˆ ë³´ê¸° ë²„íŠ¼ í´ë¦­ (ì•ˆì •ì„± ê°•í™”)\"\"\"\n    print(f\"  ğŸ“‹ ì „ì²´ ìƒí’ˆ ë³´ê¸° ë²„íŠ¼ ì°¾ëŠ” ì¤‘...\")\n    \n    view_all_selectors = [\n        (By.XPATH, \"//button[contains(text(), 'ì „ì²´')]\"),\n        (By.XPATH, \"//span[contains(text(), 'ì „ì²´')]//parent::button\"),\n        (By.CSS_SELECTOR, \"button[aria-label*='ì „ì²´']\"),\n        (By.XPATH, \"/html/body/div[4]/div[2]/div/div/div/span[21]/button\")\n    ]\n\n    view_all_clicked = False\n    for selector_type, selector_value in view_all_selectors:\n        try:\n            view_all_button = WebDriverWait(driver, CONFIG[\"WAIT_TIMEOUT\"]).until(\n                EC.element_to_be_clickable((selector_type, selector_value))\n            )\n            driver.execute_script(\"arguments[0].click();\", view_all_button)\n            \n            print(f\"  âœ… ì „ì²´ ìƒí’ˆ ë³´ê¸° í´ë¦­ ì„±ê³µ!\")\n            view_all_clicked = True\n            time.sleep(random.uniform(CONFIG[\"MIN_DELAY\"], CONFIG[\"MIN_DELAY\"]+3))\n            break\n        except TimeoutException:\n            continue\n\n    if not view_all_clicked:\n        print(f\"  âš ï¸ ì „ì²´ ìƒí’ˆ ë³´ê¸° ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ìƒí’ˆìœ¼ë¡œ ì§„í–‰...\")\n        \n    return True\n\ndef collect_page_urls(driver):\n    \"\"\"í˜„ì¬ í˜ì´ì§€ì˜ ëª¨ë“  ìƒí’ˆ URL ìˆ˜ì§‘\"\"\"\n    print(f\"  ğŸ“Š í˜„ì¬ í˜ì´ì§€ì˜ ìƒí’ˆ URLë“¤ì„ ìˆ˜ì§‘ ì¤‘...\")\n    \n    time.sleep(random.uniform(3, 5))\n    \n    product_url_selectors = [\n        \"a[href*='/experiences/']\",\n        \"a[href*='/experience/']\",\n        \".product-item a\",\n        \".experience-card a\"\n    ]\n    \n    collected_urls = []\n    \n    for selector in product_url_selectors:\n        try:\n            product_elements = driver.find_elements(By.CSS_SELECTOR, selector)\n            \n            for element in product_elements:\n                try:\n                    url = element.get_attribute('href')\n                    if url and '/experiences/' in url and url not in collected_urls:\n                        collected_urls.append(url)\n                except Exception as e:\n                    continue\n            \n            if collected_urls:\n                break\n                \n        except Exception as e:\n            continue\n    \n    valid_urls = []\n    for url in collected_urls:\n        if url and url.startswith('http') and '/experiences/' in url:\n            valid_urls.append(url)\n    \n    print(f\"  âœ… {len(valid_urls)}ê°œì˜ ìƒí’ˆ URLì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤!\")\n    \n    if len(valid_urls) == 0:\n        print(\"  âš ï¸ ìƒí’ˆ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜ì´ì§€ êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n    \n    return valid_urls\n\ndef get_rating(driver):\n    \"\"\"í‰ì  ì •ë³´ ìˆ˜ì§‘ (ê¸°ì¡´ í•¨ìˆ˜ ìœ ì§€)\"\"\"\n    rating_selectors = [\n        (By.CSS_SELECTOR, \".rating\"),\n        (By.CSS_SELECTOR, \"[class*='rating']\"),\n        (By.XPATH, \"//span[contains(@class, 'rating')]\"),\n        (By.XPATH, \"/html/body/div[1]/main/div[1]/section/div[1]/span/span[2]\")\n    ]\n\n    for selector_type, selector_value in rating_selectors:\n        try:\n            rating_element = WebDriverWait(driver, CONFIG[\"WAIT_TIMEOUT\"]).until(\n                EC.presence_of_element_located((selector_type, selector_value))\n            )\n            found_rating = rating_element.text\n            time.sleep(random.uniform(2, 4))\n            return found_rating\n        except TimeoutException:\n            continue\n    \n    return \"ì •ë³´ ì—†ìŒ\"\n\ndef get_review_count(driver):\n    \"\"\"ë¦¬ë·° ìˆ˜ ì •ë³´ ìˆ˜ì§‘\"\"\"\n    print(f\"  ğŸ“ ë¦¬ë·° ìˆ˜ ì •ë³´ ì°¾ëŠ” ì¤‘...\")\n    review_count_selectors = [\n        (By.XPATH, \"//span[contains(text(), 'ë¦¬ë·°')]\"),\n        (By.XPATH, \"//span[contains(text(), 'review')]\"),\n        (By.XPATH, \"//span[contains(text(), 'í›„ê¸°')]\"),\n        (By.XPATH, \"//span[contains(text(), 'ê°œ')]\"),\n        (By.XPATH, \"//span[contains(text(), 'ê±´')]\"),\n    ]\n\n    for selector_type, selector_value in review_count_selectors:\n        try:\n            review_element = WebDriverWait(driver, 3).until(\n                EC.presence_of_element_located((selector_type, selector_value))\n            )\n            review_text = review_element.text.strip()\n            \n            review_keywords = ['ë¦¬ë·°', 'í›„ê¸°', 'review', 'ê°œ', 'ê±´']\n            has_number = any(char.isdigit() for char in review_text)\n            has_keyword = any(keyword in review_text.lower() for keyword in review_keywords)\n            \n            if has_number and has_keyword and len(review_text) < 50:\n                print(f\"  âœ… ë¦¬ë·° ìˆ˜ ì •ë³´ ë°œê²¬: {review_text}\")\n                return review_text\n                \n        except TimeoutException:\n            continue\n\n    print(f\"  â„¹ï¸ ë¦¬ë·° ìˆ˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n    return \"\"\n\ndef get_language(driver):\n    \"\"\"ì–¸ì–´ ì •ë³´ ìˆ˜ì§‘ - ìˆ˜ì •ëœ ë²„ì „ (í›„ê¸° ë‚´ìš© ì œì™¸)\"\"\"\n    print(f\"  ğŸŒ ì–¸ì–´ ì •ë³´ ì°¾ëŠ” ì¤‘...\")\n    \n    # ì–¸ì–´ ì •ë³´ê°€ ìˆì„ ê°€ëŠ¥ì„±ì´ ë†’ì€ ì…€ë ‰í„°ë“¤\n    language_selectors = [\n        # ì–¸ì–´ ì„¹ì…˜ ì§ì ‘ íƒ€ê²ŸíŒ…\n        (By.XPATH, \"//dt[contains(text(), 'ì–¸ì–´')]/following-sibling::dd\"),\n        (By.XPATH, \"//span[contains(@class, 'language')]\"),\n        (By.XPATH, \"//div[contains(@class, 'language')]//span\"),\n        # ì§§ì€ ì–¸ì–´ í…ìŠ¤íŠ¸ë§Œ (í›„ê¸° ì œì™¸)\n        (By.XPATH, \"//span[contains(text(), 'í•œêµ­ì–´') and string-length(text()) < 20]\"),\n        (By.XPATH, \"//span[contains(text(), 'ì˜ì–´') and string-length(text()) < 20]\"),\n        (By.XPATH, \"//span[contains(text(), 'ì¤‘êµ­ì–´') and string-length(text()) < 20]\"),\n        (By.XPATH, \"//span[contains(text(), 'ì¼ë³¸ì–´') and string-length(text()) < 20]\"),\n        (By.XPATH, \"//span[contains(text(), 'Korean') and string-length(text()) < 20]\"),\n        (By.XPATH, \"//span[contains(text(), 'English') and string-length(text()) < 20]\"),\n        # ì–¸ì–´ ì•„ì´ì½˜ ê·¼ì²˜ì˜ í…ìŠ¤íŠ¸\n        (By.XPATH, \"//i[contains(@class, 'language')]/following-sibling::span\"),\n    ]\n\n    for selector_type, selector_value in language_selectors:\n        try:\n            language_elements = driver.find_elements(selector_type, selector_value)\n            \n            for language_element in language_elements:\n                language_text = language_element.text.strip()\n                \n                if not language_text:\n                    continue\n                \n                # ğŸ”¥ ê°•ë ¥í•œ í•„í„°ë§: í›„ê¸°ë‚˜ ê¸´ í…ìŠ¤íŠ¸ ì œì™¸\n                # ê¸¸ì´ ì œí•œ (ì–¸ì–´ ì •ë³´ëŠ” ë³´í†µ ì§§ìŒ)\n                if len(language_text) > 50:\n                    continue\n                \n                # í›„ê¸° ê´€ë ¨ í‚¤ì›Œë“œ ì œì™¸\n                review_keywords = [\n                    'í›„ê¸°', 'ë¦¬ë·°', 'í‰ê°€', 'ë³„ì ', 'ì¶”ì²œ', 'ë§Œì¡±',\n                    'ì—¬í–‰', 'íˆ¬ì–´', 'ê²½í—˜', 'ì¢‹ì•˜', 'ë‚˜ë¹´', 'ìµœê³ ',\n                    'ë‹¤ìŒì—', 'ë˜', 'ì¬ë°©ë¬¸', 'ì¹œì ˆ', 'ì„œë¹„ìŠ¤',\n                    'ê°€ê²©', 'ì‹œê°„', 'ì¼ì •', 'ì½”ìŠ¤', 'ê°€ì´ë“œ',\n                    'ì˜ˆì•½', 'ì‹ ì²­', 'ë¬¸ì˜', 'í™•ì¸', 'ì·¨ì†Œ'\n                ]\n                \n                if any(keyword in language_text for keyword in review_keywords):\n                    continue\n                \n                # ì–¸ì–´ í‚¤ì›Œë“œ í™•ì¸\n                language_keywords = [\n                    'ì–¸ì–´', 'í•œêµ­ì–´', 'ì˜ì–´', 'ì¤‘êµ­ì–´', 'ì¼ë³¸ì–´', \n                    'Korean', 'English', 'Chinese', 'Japanese',\n                    'ê°€ëŠ¥', 'ì§€ì›', 'ì œê³µ'\n                ]\n                \n                if any(keyword in language_text for keyword in language_keywords):\n                    print(f\"    âœ… ì–¸ì–´ ì •ë³´ ë°œê²¬: {language_text}\")\n                    return language_text\n                    \n        except Exception:\n            continue\n\n    print(f\"    â„¹ï¸ ì–¸ì–´ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n    return \"\"\n\n# =============================================================================\n# Phase 2 ì‹œìŠ¤í…œ ìë™ ì‹¤í–‰\n# =============================================================================\n\ntry:\n    initialize_file_system()\n    \n    # quick_add_cities()ëŠ” ëª¨ë“  ë„ì‹œê°€ UNIFIED_CITY_INFOì— í¬í•¨ë˜ì–´ ë” ì´ìƒ í•„ìš” ì—†ìŒ\n    \n    show_supported_cities()\n    \n    print(\"\\nğŸ‰ Phase 2: í™•ì¥ì„± ê°œì„  ì™„ë£Œ!\")\n    print(\"ğŸ’¡ ì´ì œ ì´ëŸ° ê¸°ëŠ¥ë“¤ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\")\n    print(\"   - add_new_city('ì œì£¼ë„', 'CJU', 'ì•„ì‹œì•„', 'ëŒ€í•œë¯¼êµ­')  # ìƒˆ ë„ì‹œ ì¶”ê°€\")\n    print(\"   - show_supported_cities()        # ì§€ì› ë„ì‹œ ëª©ë¡\")\n    print(\"   - validate_city('ë°©ì½•')          # ë„ì‹œ ìœ íš¨ì„± ê²€ì‚¬\")\n    \nexcept Exception as e:\n    print(f\"âŒ Phase 2 ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n    print(\"ğŸ’¡ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ê³„ì† ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"âœ… ê·¸ë£¹ 1 ì™„ë£Œ: ëª¨ë“  í•¨ìˆ˜ê°€ ì •ì˜ë˜ì—ˆìŠµë‹ˆë‹¤!\")\nprint(\"=\"*60)\nprint(\"ğŸ”§ í•µì‹¬ í•¨ìˆ˜ëª… ë³€ê²½ ì™„ë£Œ:\")\nprint(\"   get_product_name_by_type() â†’ get_product_name()\")\nprint(\"   get_price_fixed() â†’ get_price()\")\nprint(\"   download_image_improved_fixed() â†’ download_image()\")\nprint(\"   extract_clean_price() â†’ clean_price()\")\nprint(\"   extract_clean_rating() â†’ clean_rating()\")\nprint(\"   save_myrealtrip_data() â†’ save_results()\")\nprint(\"=\"*60)\nprint(\"ğŸ”„ 1ìˆœìœ„: ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ ì¶”ê°€ ì™„ë£Œ!\")\nprint(\"   - load_crawler_state()     # í¬ë¡¤ë§ ìƒíƒœ ë¡œë“œ\")\nprint(\"   - save_crawler_state()     # í¬ë¡¤ë§ ìƒíƒœ ì €ì¥\")\nprint(\"   - save_batch_data()        # ë°°ì¹˜ ë°ì´í„° ì €ì¥\")\nprint(\"   - filter_new_urls()        # ìƒˆë¡œìš´ URL í•„í„°ë§\")\nprint(\"   - create_image_filename()  # ì´ë¯¸ì§€ íŒŒì¼ëª… ìƒì„±\")\nprint(\"=\"*60)\nprint(f\"ğŸ”¢ í˜„ì¬ ì„¤ì •: {CONFIG['MAX_PRODUCTS_PER_CITY']}ê°œ ìƒí’ˆ í¬ë¡¤ë§\")\nprint(f\"ğŸ™ï¸ ê²€ìƒ‰ ë„ì‹œ: {CITIES_TO_SEARCH}\")\nprint(\"ğŸ¯ ë‹¤ìŒ: ê·¸ë£¹ 2,3,4ì—ì„œ í•¨ìˆ˜ í˜¸ì¶œì„ í†µì¼ëœ í•¨ìˆ˜ëª…ìœ¼ë¡œ ë³€ê²½í•˜ì„¸ìš”!\")\nprint(\"ğŸš¨ Gemini ì§€ì ì‚¬í•­ ëª¨ë‘ í•´ê²° ì™„ë£Œ! ì•ˆì „í•˜ê²Œ ì‹¤í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee34c2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2d9e226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ í¬ë¡¤ë§ ì‹œì‘!\n",
      "ğŸ”„ ê²°ê³¼ ì €ì¥ì†Œ ì´ˆê¸°í™” ì™„ë£Œ\n",
      "âœ… í¬ë¡¬ ë“œë¼ì´ë²„ ì‹¤í–‰ ì„±ê³µ!\n",
      "Windows\n",
      "ğŸ“ ì´ë¯¸ì§€ í´ë” ì¤€ë¹„ ì™„ë£Œ (ê¸°ì¡´ ì´ë¯¸ì§€ ë³´ì¡´): c:\\Users\\redsk\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\mikael_project\\test_folder\\myrealtripthumb_img\n",
      "============================================================\n",
      "ğŸŒ ê·¸ë£¹ 1 ì„¤ì • ë„ì‹œ: í‘¸ì¼“ ê²€ìƒ‰ ì‹œì‘!\n",
      "âš™ï¸  ì„¤ì •: ì¬ì‹œë„ 3íšŒ, íƒ€ì„ì•„ì›ƒ 10ì´ˆ\n",
      "============================================================\n",
      "ğŸ” ì§„í–‰ë¥ : [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0% (0/1)\n",
      "ğŸ“ í˜„ì¬ ì‘ì—…: í‘¸ì¼“ - ì§„í–‰ì¤‘\n",
      "--------------------------------------------------\n",
      "  ğŸŒ ëŒ€ë¥™: ì•„ì‹œì•„ | êµ­ê°€: íƒœêµ­\n",
      "  ğŸ“± ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ ë©”ì¸ í˜ì´ì§€ ì´ë™ ì¤‘...\n",
      "  âœ… ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ í˜ì´ì§€ ì—´ê¸° ì™„ë£Œ\n",
      "  ğŸ” 'í‘¸ì¼“' ê²€ìƒ‰ì°½ ì°¾ëŠ” ì¤‘...\n",
      "  âœ… ê²€ìƒ‰ì°½ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!\n",
      "  ğŸ“ 'í‘¸ì¼“' í‚¤ì›Œë“œ ì…ë ¥ ì™„ë£Œ\n",
      "  ğŸ” ê²€ìƒ‰ ë²„íŠ¼ ì°¾ëŠ” ì¤‘...\n",
      "  âœ… ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­ ì„±ê³µ!\n",
      "  âœ… íŒì—…ì°½ì„ ë‹«ì•˜ìŠµë‹ˆë‹¤.\n",
      "  ğŸ“‹ ì „ì²´ ìƒí’ˆ ë³´ê¸° ë²„íŠ¼ ì°¾ëŠ” ì¤‘...\n",
      "  âœ… ì „ì²´ ìƒí’ˆ ë³´ê¸° í´ë¦­ ì„±ê³µ!\n",
      "\n",
      "âœ… ê·¸ë£¹ 2 ì™„ë£Œ: í‘¸ì¼“ ê²€ìƒ‰ ì„±ê³µ!\n",
      "ğŸ¯ í˜„ì¬ ìƒíƒœ: í‘¸ì¼“ ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ì— ìˆìŠµë‹ˆë‹¤\n",
      "ğŸš€ ë‹¤ìŒ: ê·¸ë£¹ 3ì„ ì‹¤í–‰í•˜ì—¬ URL ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ ê·¸ë£¹ 2: ë„ì‹œ í•˜ë“œì½”ë”© í•´ê²° - ë“œë¼ì´ë²„ ì‹¤í–‰ + ë„ì‹œ ê²€ìƒ‰\n",
    "# (ì´ ì…€ì„ ì‹¤í–‰í•˜ë©´ ë¸Œë¼ìš°ì €ê°€ ì—´ë¦¬ê³  ê·¸ë£¹ 1ì—ì„œ ì„¤ì •í•œ ë„ì‹œ ê²€ìƒ‰ê¹Œì§€ ì™„ë£Œë©ë‹ˆë‹¤)\n",
    "\n",
    "print(\"ğŸ”„ ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ í¬ë¡¤ë§ ì‹œì‘!\")\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥ì†Œ ì´ˆê¸°í™”\n",
    "all_results = []\n",
    "print(\"ğŸ”„ ê²°ê³¼ ì €ì¥ì†Œ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "\n",
    "# í¬ë¡¬ ë“œë¼ì´ë²„ ì‹¤í–‰\n",
    "try:\n",
    "    driver = setup_driver()\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë“œë¼ì´ë²„ ì„¤ì • ì‹¤íŒ¨: {e}\")\n",
    "    print(\"âš ï¸ ê·¸ë£¹ 1ì„ ë¨¼ì € ì‹¤í–‰í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”!\")\n",
    "\n",
    "# âœ… ìˆ˜ì •: Windows ê²½ë¡œ ì²˜ë¦¬ ë¬¸ì œ í•´ê²° - ì¸ë„¤ì¼ í´ë” ìƒì„± (ê¸°ì¡´ ì´ë¯¸ì§€ ë³´ì¡´)\n",
    "if CONFIG[\"SAVE_IMAGES\"]:\n",
    "    img_folder_path = os.path.join(os.path.abspath(\"\"), \"myrealtripthumb_img\")\n",
    "    # âœ… ìˆ˜ì •: ê¸°ì¡´ ì´ë¯¸ì§€ ì‚­ì œ ì½”ë“œ ì œê±° (ë°ì´í„° ì—°ì†ì„± í™•ë³´)\n",
    "    # shutil.rmtree(img_folder_path)  # ì´ ì¤„ì„ ì œê±°í•˜ì—¬ ê¸°ì¡´ ì´ë¯¸ì§€ ë³´ì¡´\n",
    "    os.makedirs(img_folder_path, exist_ok=True)\n",
    "    print(f\"ğŸ“ ì´ë¯¸ì§€ í´ë” ì¤€ë¹„ ì™„ë£Œ (ê¸°ì¡´ ì´ë¯¸ì§€ ë³´ì¡´): {img_folder_path}\")\n",
    "\n",
    "# ğŸ†• ê·¸ë£¹ 1 ì„¤ì •ì—ì„œ ë„ì‹œ ê°€ì ¸ì˜¤ê¸°\n",
    "if not CITIES_TO_SEARCH:\n",
    "    print(\"âŒ CITIES_TO_SEARCHê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!\")\n",
    "    print(\"ğŸ’¡ ê·¸ë£¹ 1ì—ì„œ CITIES_TO_SEARCH = ['ë„ì‹œëª…']ì„ ì„¤ì •í•˜ì„¸ìš”!\")\n",
    "    raise ValueError(\"ê²€ìƒ‰í•  ë„ì‹œê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤\")\n",
    "\n",
    "city_name = CITIES_TO_SEARCH[0]  # ğŸ†• ì²« ë²ˆì§¸ ë„ì‹œ ì‚¬ìš©\n",
    "continent, country = get_city_info(city_name)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"ğŸŒ ê·¸ë£¹ 1 ì„¤ì • ë„ì‹œ: {city_name} ê²€ìƒ‰ ì‹œì‘!\")\n",
    "print(f\"âš™ï¸  ì„¤ì •: ì¬ì‹œë„ {CONFIG['RETRY_COUNT']}íšŒ, íƒ€ì„ì•„ì›ƒ {CONFIG['WAIT_TIMEOUT']}ì´ˆ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"ğŸ” ì§„í–‰ë¥ : [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0% (0/1)\")\n",
    "print(f\"ğŸ“ í˜„ì¬ ì‘ì—…: {city_name} - ì§„í–‰ì¤‘\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  ğŸŒ ëŒ€ë¥™: {continent} | êµ­ê°€: {country}\")\n",
    "\n",
    "try:\n",
    "    # 1. ë©”ì¸ í˜ì´ì§€ë¡œ ì´ë™\n",
    "    print(\"  ğŸ“± ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ ë©”ì¸ í˜ì´ì§€ ì´ë™ ì¤‘...\")\n",
    "    retry_operation(\n",
    "        lambda: go_to_main_page(driver), \n",
    "        \"ë©”ì¸ í˜ì´ì§€ ì´ë™\"\n",
    "    )\n",
    "    print(f\"  âœ… ë§ˆì´ë¦¬ì–¼íŠ¸ë¦½ í˜ì´ì§€ ì—´ê¸° ì™„ë£Œ\")\n",
    "    \n",
    "    # 2. ê²€ìƒ‰ì°½ ì°¾ê¸° ë° ì…ë ¥ (ğŸ†• ë™ì  ë„ì‹œëª… ì‚¬ìš©)\n",
    "    retry_operation(\n",
    "        lambda: find_and_fill_search(driver, city_name), \n",
    "        f\"{city_name} ê²€ìƒ‰ì°½ ì…ë ¥\"\n",
    "    )\n",
    "\n",
    "    # 3. ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­\n",
    "    retry_operation(\n",
    "        lambda: click_search_button(driver), \n",
    "        \"ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­\"\n",
    "    )\n",
    "\n",
    "    # 4. íŒì—… ì²˜ë¦¬ (ì„ íƒì‚¬í•­)\n",
    "    try:\n",
    "        handle_popup(driver)\n",
    "    except Exception as e:\n",
    "        print(f\"  â„¹ï¸ íŒì—… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {type(e).__name__}\")\n",
    "\n",
    "    # 5. ì „ì²´ ìƒí’ˆ ë³´ê¸° í´ë¦­ (ì„ íƒì‚¬í•­)\n",
    "    try:\n",
    "        click_view_all(driver)\n",
    "    except Exception as e:\n",
    "        print(f\"  â„¹ï¸ ì „ì²´ ìƒí’ˆ ë³´ê¸° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {type(e).__name__}\")\n",
    "\n",
    "    print(f\"\\nâœ… ê·¸ë£¹ 2 ì™„ë£Œ: {city_name} ê²€ìƒ‰ ì„±ê³µ!\")\n",
    "    print(f\"ğŸ¯ í˜„ì¬ ìƒíƒœ: {city_name} ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ì— ìˆìŠµë‹ˆë‹¤\")\n",
    "    print(\"ğŸš€ ë‹¤ìŒ: ê·¸ë£¹ 3ì„ ì‹¤í–‰í•˜ì—¬ URL ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”!\")\n",
    "    \n",
    "except TimeoutException as e:\n",
    "    print(f\"  â° {city_name}: í˜ì´ì§€ ë¡œë”© ì‹œê°„ ì´ˆê³¼\")\n",
    "    print(f\"  ğŸ“ ìœ„ì¹˜: {continent} > {country} > {city_name}\")\n",
    "    print(\"âŒ ê·¸ë£¹ 2 ì‹¤íŒ¨: ì‹œê°„ ì´ˆê³¼\")\n",
    "    \n",
    "except NoSuchElementException as e:\n",
    "    print(f\"  ğŸ” {city_name}: í•„ìš”í•œ ì›¹ ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ\")\n",
    "    print(f\"  ğŸ“ ìœ„ì¹˜: {continent} > {country} > {city_name}\")\n",
    "    print(\"âŒ ê·¸ë£¹ 2 ì‹¤íŒ¨: ìš”ì†Œ ì—†ìŒ\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  âŒ {city_name}: ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ - {type(e).__name__}: {e}\")\n",
    "    print(\"âŒ ê·¸ë£¹ 2 ì‹¤íŒ¨: ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜\")\n",
    "    print(\"ğŸ’¡ ê·¸ë£¹ 1ì„ ë¨¼ì € ì‹¤í–‰í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”!\")\n",
    "    print(f\"ğŸ’¡ CITIES_TO_SEARCHì— '{city_name}'ì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc18562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27b994d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ê·¸ë£¹ 3: URL ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ ì‹œì‘! (24ê°œ ì™„ì „ ìˆ˜ì§‘ ë²„ì „)\n",
      "==================================================\n",
      "ğŸ“Š í˜„ì¬ í˜ì´ì§€ì—ì„œ 24ê°œ ìƒí’ˆ/ì˜¤í¼ URL ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "  ğŸ” Productsì™€ Offers URL ëª¨ë‘ ìˆ˜ì§‘ ì¤‘...\n",
      "  ğŸ“Š ì „ì²´ ë§í¬ ìˆ˜: 52ê°œ\n",
      "  âœ… Products URL: 18ê°œ\n",
      "  âœ… Offers URL: 6ê°œ\n",
      "  ğŸ‰ ì´ ìˆ˜ì§‘: 24ê°œ\n",
      "\n",
      "ğŸ‰ URL ìˆ˜ì§‘ ì„±ê³µ!\n",
      "ğŸ“ˆ ì´ 24ê°œì˜ ìƒí’ˆ/ì˜¤í¼ URLì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!\n",
      "ğŸ”¢ ì„¤ì •ëœ í¬ë¡¤ë§ ê°œìˆ˜: 2ê°œ\n",
      "ğŸ¯ ì‹¤ì œ í¬ë¡¤ë§í•  ê°œìˆ˜: 2ê°œ\n",
      "\n",
      "ğŸ“‹ ìˆ˜ì§‘ëœ URL ëª©ë¡:\n",
      "--------------------------------------------------------------------------------\n",
      "   1. ğŸ›ï¸ Product: https://experiences.myrealtrip.com/products/3446452\n",
      "   2. ğŸ›ï¸ Product: https://experiences.myrealtrip.com/products/3446456\n",
      "   3. ğŸ›ï¸ Product: https://experiences.myrealtrip.com/products/3147846\n",
      "   4. ğŸ›ï¸ Product: https://experiences.myrealtrip.com/products/3446495\n",
      "   5. ğŸ›ï¸ Product: https://experiences.myrealtrip.com/products/3442583\n",
      "   6. ğŸ›ï¸ Product: https://experiences.myrealtrip.com/products/3887414\n",
      "   7. ğŸ›ï¸ Product: https://experiences.myrealtrip.com/products/3887426\n",
      "   8. ğŸ›ï¸ Product: https://experiences.myrealtrip.com/products/3446446\n",
      "   9. ğŸ›ï¸ Product: https://experiences.myrealtrip.com/products/3446422\n",
      "  10. ğŸ›ï¸ Product: https://experiences.myrealtrip.com/products/3509020\n",
      "  11. ğŸ›ï¸ Product: https://experiences.myrealtrip.com/products/3446488\n",
      "  12. ğŸ›ï¸ Product: https://experiences.myrealtrip.com/products/3887486\n",
      "  13. ğŸ›ï¸ Product: https://experiences.myrealtrip.com/products/3446476\n",
      "  14. ğŸ›ï¸ Product: https://experiences.myrealtrip.com/products/3887491\n",
      "  15. ğŸ›ï¸ Product: https://experiences.myrealtrip.com/products/3887408\n",
      "  16. ğŸ›ï¸ Product: https://experiences.myrealtrip.com/products/4234615\n",
      "  17. ğŸ›ï¸ Product: https://experiences.myrealtrip.com/products/3508999\n",
      "  18. ğŸ›ï¸ Product: https://experiences.myrealtrip.com/products/3508945\n",
      "  19. ğŸ·ï¸ Offer: https://www.myrealtrip.com/offers/120576\n",
      "  20. ğŸ·ï¸ Offer: https://www.myrealtrip.com/offers/148629\n",
      "  21. ğŸ·ï¸ Offer: https://www.myrealtrip.com/offers/124943\n",
      "  22. ğŸ·ï¸ Offer: https://www.myrealtrip.com/offers/148630\n",
      "  23. ğŸ·ï¸ Offer: https://www.myrealtrip.com/offers/72582\n",
      "  24. ğŸ·ï¸ Offer: https://www.myrealtrip.com/offers/148769\n",
      "\n",
      "ğŸ” URL ìœ íš¨ì„± ì²´í¬:\n",
      "  âœ… Products: 18ê°œ\n",
      "  âœ… Offers: 6ê°œ\n",
      "  ğŸ¯ ì´ ìœ íš¨ URL: 24ê°œ\n",
      "\n",
      "ğŸš€ URL ìˆ˜ì§‘ ëŒ€ì„±ê³µ! ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤!\n",
      "âœ… ê·¸ë£¹ 3 ì™„ë£Œ: 24ê°œ URL ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ ì„±ê³µ\n",
      "ğŸ¯ ë‹¤ìŒ: ê·¸ë£¹ 4ë¥¼ ì‹¤í–‰í•˜ì—¬ 24ê°œ ìƒí’ˆ/ì˜¤í¼ í¬ë¡¤ë§ì„ ì‹œì‘í•˜ì„¸ìš”!\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” ê·¸ë£¹ 3: URL ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ (24ê°œ ì™„ì „ ìˆ˜ì§‘ ë²„ì „)\n",
    "# (ì´ ì…€ì„ ì‹¤í–‰í•˜ë©´ í˜„ì¬ í˜ì´ì§€ì—ì„œ Products + Offers 24ê°œ URLì„ ëª¨ë‘ ìˆ˜ì§‘í•©ë‹ˆë‹¤)\n",
    "\n",
    "print(\"ğŸ” ê·¸ë£¹ 3: URL ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ ì‹œì‘! (24ê°œ ì™„ì „ ìˆ˜ì§‘ ë²„ì „)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def collect_all_24_urls(driver):\n",
    "    print(f\"  ğŸ” Productsì™€ Offers URL ëª¨ë‘ ìˆ˜ì§‘ ì¤‘...\")\n",
    "    \n",
    "    # í˜ì´ì§€ ë¡œë”© ì™„ë£Œ ëŒ€ê¸°\n",
    "    time.sleep(5)\n",
    "    \n",
    "    all_links = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "    print(f\"  ğŸ“Š ì „ì²´ ë§í¬ ìˆ˜: {len(all_links)}ê°œ\")\n",
    "    \n",
    "    products_urls = []\n",
    "    offers_urls = []\n",
    "    \n",
    "    for link in all_links:\n",
    "        try:\n",
    "            href = link.get_attribute('href')\n",
    "            if href:\n",
    "                if 'experiences.myrealtrip.com/products/' in href:\n",
    "                    if href not in products_urls:\n",
    "                        products_urls.append(href)\n",
    "                elif 'myrealtrip.com/offers/' in href:\n",
    "                    if href not in offers_urls:\n",
    "                        offers_urls.append(href)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # ë‘ ë¦¬ìŠ¤íŠ¸ í•©ì¹˜ê¸° (products ë¨¼ì €, offers ë‚˜ì¤‘ì—)\n",
    "    all_urls = products_urls + offers_urls\n",
    "    \n",
    "    print(f\"  âœ… Products URL: {len(products_urls)}ê°œ\")\n",
    "    print(f\"  âœ… Offers URL: {len(offers_urls)}ê°œ\")\n",
    "    print(f\"  ğŸ‰ ì´ ìˆ˜ì§‘: {len(all_urls)}ê°œ\")\n",
    "    \n",
    "    return all_urls\n",
    "\n",
    "try:\n",
    "    # 24ê°œ URL ìˆ˜ì§‘ ì‹¤í–‰\n",
    "    print(\"ğŸ“Š í˜„ì¬ í˜ì´ì§€ì—ì„œ 24ê°œ ìƒí’ˆ/ì˜¤í¼ URL ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    collected_urls = collect_all_24_urls(driver)\n",
    "    \n",
    "    if collected_urls:\n",
    "        print(f\"\\nğŸ‰ URL ìˆ˜ì§‘ ì„±ê³µ!\")\n",
    "        print(f\"ğŸ“ˆ ì´ {len(collected_urls)}ê°œì˜ ìƒí’ˆ/ì˜¤í¼ URLì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!\")\n",
    "        \n",
    "        # ì„¤ì •ëœ ê°œìˆ˜ì™€ ë¹„êµ\n",
    "        max_products = CONFIG['MAX_PRODUCTS_PER_CITY']\n",
    "        will_crawl = min(len(collected_urls), max_products)\n",
    "        \n",
    "        print(f\"ğŸ”¢ ì„¤ì •ëœ í¬ë¡¤ë§ ê°œìˆ˜: {max_products}ê°œ\")\n",
    "        print(f\"ğŸ¯ ì‹¤ì œ í¬ë¡¤ë§í•  ê°œìˆ˜: {will_crawl}ê°œ\")\n",
    "        \n",
    "        print(f\"\\nğŸ“‹ ìˆ˜ì§‘ëœ URL ëª©ë¡:\")\n",
    "        print(\"-\" * 80)\n",
    "        for i, url in enumerate(collected_urls, 1):\n",
    "            url_type = \"ğŸ›ï¸ Product\" if \"/products/\" in url else \"ğŸ·ï¸ Offer\"\n",
    "            print(f\"  {i:2d}. {url_type}: {url}\")\n",
    "        \n",
    "        # URL ìœ íš¨ì„± ì²´í¬\n",
    "        print(f\"\\nğŸ” URL ìœ íš¨ì„± ì²´í¬:\")\n",
    "        products_count = sum(1 for url in collected_urls if '/products/' in url)\n",
    "        offers_count = sum(1 for url in collected_urls if '/offers/' in url)\n",
    "        \n",
    "        print(f\"  âœ… Products: {products_count}ê°œ\")\n",
    "        print(f\"  âœ… Offers: {offers_count}ê°œ\")\n",
    "        print(f\"  ğŸ¯ ì´ ìœ íš¨ URL: {products_count + offers_count}ê°œ\")\n",
    "        \n",
    "        if len(collected_urls) >= 20:\n",
    "            print(\"\\nğŸš€ URL ìˆ˜ì§‘ ëŒ€ì„±ê³µ! ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤!\")\n",
    "            print(\"âœ… ê·¸ë£¹ 3 ì™„ë£Œ: 24ê°œ URL ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ ì„±ê³µ\")\n",
    "            print(\"ğŸ¯ ë‹¤ìŒ: ê·¸ë£¹ 4ë¥¼ ì‹¤í–‰í•˜ì—¬ 24ê°œ ìƒí’ˆ/ì˜¤í¼ í¬ë¡¤ë§ì„ ì‹œì‘í•˜ì„¸ìš”!\")\n",
    "        else:\n",
    "            print(\"\\nâš ï¸ ìˆ˜ì§‘ëœ URLì´ ì˜ˆìƒë³´ë‹¤ ì ìŠµë‹ˆë‹¤.\")\n",
    "            \n",
    "    else:\n",
    "        print(\"âŒ URL ìˆ˜ì§‘ ì‹¤íŒ¨: ìƒí’ˆ/ì˜¤í¼ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "        print(\"ğŸ’¡ ì¶”ê°€ ë””ë²„ê¹…:\")\n",
    "        \n",
    "        # ë””ë²„ê¹… ì •ë³´\n",
    "        try:\n",
    "            page_source = driver.page_source\n",
    "            products_count = page_source.count('experiences.myrealtrip.com/products/')\n",
    "            offers_count = page_source.count('myrealtrip.com/offers/')\n",
    "            print(f\"   ğŸ“„ í˜ì´ì§€ ì†ŒìŠ¤ì—ì„œ products íŒ¨í„´: {products_count}íšŒ\")\n",
    "            print(f\"   ğŸ“„ í˜ì´ì§€ ì†ŒìŠ¤ì—ì„œ offers íŒ¨í„´: {offers_count}íšŒ\")\n",
    "            \n",
    "        except Exception as debug_error:\n",
    "            print(f\"   âŒ ë””ë²„ê¹… ì‹¤íŒ¨: {debug_error}\")\n",
    "        \n",
    "        print(\"ğŸ”„ ê·¸ë£¹ 2ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•´ë³´ì„¸ìš”!\")\n",
    "        \n",
    "except NameError as e:\n",
    "    print(f\"âŒ ë³€ìˆ˜ ì˜¤ë¥˜: {e}\")\n",
    "    print(\"ğŸ’¡ ê·¸ë£¹ 1ê³¼ ê·¸ë£¹ 2ë¥¼ ë¨¼ì € ì‹¤í–‰í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ URL ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {type(e).__name__}: {e}\")\n",
    "    print(\"ğŸ’¡ ê°€ëŠ¥í•œ í•´ê²°ì±…:\")\n",
    "    print(\"   1. ê·¸ë£¹ 2ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸\")\n",
    "    print(\"   2. ë¸Œë¼ìš°ì €ê°€ ë°©ì½• ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ì— ìˆëŠ”ì§€ í™•ì¸\")\n",
    "    print(\"   3. ì¸í„°ë„· ì—°ê²° ìƒíƒœ í™•ì¸\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b05f0cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ê·¸ë£¹ 3-1: ì •ì°° ë° ë¶„ì„ ì‹œì‘!\n",
      "==================================================\n",
      "ğŸ” í‘¸ì¼“ í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„ ì¤‘...\n",
      "  ğŸ” í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„ ì¤‘...\n",
      "    âœ… ì´ ìƒí’ˆ ìˆ˜ ë°œê²¬: 423ê°œ\n",
      "\n",
      "ğŸ“‹ í¬ë¡¤ë§ ê³„íš ìˆ˜ë¦½ ì¤‘...\n",
      "\n",
      "ğŸ” === ì •ì°° ì™„ë£Œ ë³´ê³ ì„œ ===\n",
      "ğŸ“ ë„ì‹œ: í‘¸ì¼“\n",
      "ğŸ“Š ë°œê²¬ëœ ì´ ìƒí’ˆ ìˆ˜: 423ê°œ\n",
      "ğŸ“„ ì´ í˜ì´ì§€ ìˆ˜: 1í˜ì´ì§€\n",
      "ğŸ“‹ í˜ì´ì§€ë‹¹ ìƒí’ˆ ìˆ˜: 24ê°œ\n",
      "ğŸ”„ í˜ì´ì§€ë„¤ì´ì…˜ ê°€ëŠ¥: âŒ ì•„ë‹ˆì˜¤\n",
      "â±ï¸ ì˜ˆìƒ ì†Œìš” ì‹œê°„: 1.0ë¶„\n",
      "ğŸ¯ í¬ë¡¤ë§ ì „ëµ: ë‹¨ì¼ í˜ì´ì§€\n",
      "ğŸ“¦ ì‹¤ì œ ìˆ˜ì§‘ ì˜ˆì •: 2ê°œ\n",
      "==================================================\n",
      "âš ï¸ í˜ì´ì§€ë„¤ì´ì…˜ì´ ì œí•œì ì…ë‹ˆë‹¤. í˜„ì¬ í˜ì´ì§€ë§Œ í¬ë¡¤ë§ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
      "  ğŸ” ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ì‘ë™ì„± í™•ì¸ ì¤‘...\n",
      "    âŒ ì‘ë™ ê°€ëŠ¥í•œ ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "âš ï¸ í˜ì´ì§€ë„¤ì´ì…˜ ì œí•œìœ¼ë¡œ í˜„ì¬ í˜ì´ì§€ë§Œ í¬ë¡¤ë§ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
      "\n",
      "âœ… ê·¸ë£¹ 3-1 ì™„ë£Œ: ì •ì°° ë° ë¶„ì„ ì™„ë£Œ!\n",
      "\n",
      "==================================================\n",
      "âœ… ê·¸ë£¹ 3-1 ì •ì°° ë‹¨ê³„ ì™„ë£Œ!\n",
      "ğŸ”§ ì œê³µëœ ê¸°ëŠ¥:\n",
      "   - analyze_pagination(): í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„\n",
      "   - check_next_button(): ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ í™•ì¸\n",
      "   - generate_crawling_plan(): í¬ë¡¤ë§ ê³„íš ìˆ˜ë¦½\n",
      "   - report_reconnaissance_results(): ì •ì°° ê²°ê³¼ ë³´ê³ \n",
      "   - collect_page_urls_enhanced(): ê°œì„ ëœ URL ìˆ˜ì§‘\n"
     ]
    }
   ],
   "source": [
    "#ê·¸ë£¹ 3-1 \n",
    "# =================================================================\n",
    "# ğŸš€ ê·¸ë£¹ 3 ê°œì„ : ì •ì°° ë° ê³„íš ìˆ˜ë¦½ ë‹¨ê³„ (ì •ì˜ + ì‹¤í–‰)\n",
    "# =================================================================\n",
    "\n",
    "def analyze_pagination(driver):\n",
    "    \"\"\"í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„ - ì´ í˜ì´ì§€ ìˆ˜, ìƒí’ˆ ìˆ˜ íŒŒì•…\"\"\"\n",
    "    print(f\"  ğŸ” í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„ ì¤‘...\")\n",
    "    \n",
    "    try:\n",
    "        # í˜ì´ì§€ ë¡œë”© ì™„ë£Œ ëŒ€ê¸°\n",
    "        time.sleep(3)\n",
    "        \n",
    "        # ì´ ìƒí’ˆ ìˆ˜ ì°¾ê¸°\n",
    "        total_products = 0\n",
    "        total_selectors = [\n",
    "            \"//span[contains(text(), 'ì´') and contains(text(), 'ê°œ')]\",\n",
    "            \"//span[contains(text(), 'ì „ì²´') and contains(text(), 'ê°œ')]\", \n",
    "            \"//div[contains(@class, 'total') or contains(@class, 'count')]//span\",\n",
    "            \"//span[contains(text(), 'ê²°ê³¼')]\",\n",
    "        ]\n",
    "        \n",
    "        for selector in total_selectors:\n",
    "            try:\n",
    "                elements = driver.find_elements(By.XPATH, selector)\n",
    "                for element in elements:\n",
    "                    text = element.text.strip()\n",
    "                    if 'ê°œ' in text and any(char.isdigit() for char in text):\n",
    "                        # ìˆ«ì ì¶”ì¶œ\n",
    "                        import re\n",
    "                        numbers = re.findall(r'\\d+', text)\n",
    "                        if numbers:\n",
    "                            total_products = int(numbers[0])\n",
    "                            print(f\"    âœ… ì´ ìƒí’ˆ ìˆ˜ ë°œê²¬: {total_products}ê°œ\")\n",
    "                            break\n",
    "                if total_products > 0:\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ì°¾ê¸°\n",
    "        total_pages = 1\n",
    "        has_next_button = False\n",
    "        \n",
    "        # ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ì°¾ê¸°\n",
    "        next_button_selectors = [\n",
    "            \"//button[contains(@aria-label, 'ë‹¤ìŒ')]\",\n",
    "            \"//button[contains(text(), 'ë‹¤ìŒ')]\",\n",
    "            \"//a[contains(@aria-label, 'ë‹¤ìŒ')]\", \n",
    "            \"//a[contains(text(), 'ë‹¤ìŒ')]\",\n",
    "            \"//button[contains(@class, 'next')]\",\n",
    "            \"//a[contains(@class, 'next')]\",\n",
    "            \".pagination .next\",\n",
    "            \".pager .next\"\n",
    "        ]\n",
    "        \n",
    "        for selector in next_button_selectors:\n",
    "            try:\n",
    "                if selector.startswith('//'):\n",
    "                    elements = driver.find_elements(By.XPATH, selector)\n",
    "                else:\n",
    "                    elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                    \n",
    "                for element in elements:\n",
    "                    if element.is_enabled() and element.is_displayed():\n",
    "                        has_next_button = True\n",
    "                        print(f\"    âœ… 'ë‹¤ìŒ í˜ì´ì§€' ë²„íŠ¼ ë°œê²¬!\")\n",
    "                        break\n",
    "                if has_next_button:\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # í˜ì´ì§€ ë²ˆí˜¸ ì°¾ê¸° (ì´ í˜ì´ì§€ ìˆ˜ ì¶”ì •)\n",
    "        page_number_selectors = [\n",
    "            \"//button[contains(@class, 'page') or contains(@class, 'pagination')]//span\",\n",
    "            \"//a[contains(@class, 'page') or contains(@class, 'pagination')]//span\",\n",
    "            \".pagination button span\",\n",
    "            \".pager a span\"\n",
    "        ]\n",
    "        \n",
    "        max_page = 1\n",
    "        for selector in page_number_selectors:\n",
    "            try:\n",
    "                if selector.startswith('//'):\n",
    "                    elements = driver.find_elements(By.XPATH, selector)\n",
    "                else:\n",
    "                    elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                    \n",
    "                for element in elements:\n",
    "                    text = element.text.strip()\n",
    "                    if text.isdigit():\n",
    "                        page_num = int(text)\n",
    "                        max_page = max(max_page, page_num)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        total_pages = max_page\n",
    "        \n",
    "        # í˜ì´ì§€ë‹¹ ìƒí’ˆ ìˆ˜ ì¶”ì • (í˜„ì¬ í˜ì´ì§€ ê¸°ì¤€)\n",
    "        products_per_page = 24  # ê¸°ë³¸ê°’\n",
    "        if total_products > 0 and total_pages > 0:\n",
    "            products_per_page = min(24, total_products // total_pages + (1 if total_products % total_pages > 0 else 0))\n",
    "        \n",
    "        return {\n",
    "            'total_products': total_products,\n",
    "            'total_pages': total_pages, \n",
    "            'products_per_page': products_per_page,\n",
    "            'has_next_button': has_next_button,\n",
    "            'is_pagination_available': has_next_button or total_pages > 1\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    âŒ í˜ì´ì§€ë„¤ì´ì…˜ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "        return {\n",
    "            'total_products': 0,\n",
    "            'total_pages': 1,\n",
    "            'products_per_page': 24,\n",
    "            'has_next_button': False,\n",
    "            'is_pagination_available': False\n",
    "        }\n",
    "\n",
    "def check_next_button(driver):\n",
    "    \"\"\"ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ì‘ë™ í™•ì¸\"\"\"\n",
    "    print(f\"  ğŸ” ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ì‘ë™ì„± í™•ì¸ ì¤‘...\")\n",
    "    \n",
    "    next_button_selectors = [\n",
    "        \"//button[contains(@aria-label, 'ë‹¤ìŒ') and not(@disabled)]\",\n",
    "        \"//button[contains(text(), 'ë‹¤ìŒ') and not(@disabled)]\",\n",
    "        \"//a[contains(@aria-label, 'ë‹¤ìŒ')]\",\n",
    "        \"//a[contains(text(), 'ë‹¤ìŒ')]\",\n",
    "        \"//button[contains(@class, 'next') and not(@disabled)]\",\n",
    "        \"//a[contains(@class, 'next')]\"\n",
    "    ]\n",
    "    \n",
    "    for selector in next_button_selectors:\n",
    "        try:\n",
    "            element = driver.find_element(By.XPATH, selector)\n",
    "            if element.is_enabled() and element.is_displayed():\n",
    "                # í´ë¦­ ê°€ëŠ¥í•œì§€ í™•ì¸ (ì‹¤ì œë¡œ í´ë¦­í•˜ì§€ëŠ” ì•ŠìŒ)\n",
    "                try:\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView(true);\", element)\n",
    "                    print(f\"    âœ… ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì´ ì‘ë™ ê°€ëŠ¥í•©ë‹ˆë‹¤!\")\n",
    "                    return True\n",
    "                except:\n",
    "                    continue\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    print(f\"    âŒ ì‘ë™ ê°€ëŠ¥í•œ ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    return False\n",
    "\n",
    "def generate_crawling_plan(pagination_info, city_name):\n",
    "    \"\"\"í¬ë¡¤ë§ ê³„íš ìƒì„± ë° ë³´ê³ \"\"\"\n",
    "    print(f\"\\nğŸ“‹ í¬ë¡¤ë§ ê³„íš ìˆ˜ë¦½ ì¤‘...\")\n",
    "    \n",
    "    plan = {\n",
    "        'city': city_name,\n",
    "        'total_products': pagination_info['total_products'],\n",
    "        'total_pages': pagination_info['total_pages'],\n",
    "        'products_per_page': pagination_info['products_per_page'],\n",
    "        'pagination_available': pagination_info['is_pagination_available'],\n",
    "        'estimated_time_minutes': 0,\n",
    "        'recommended_batch_size': CONFIG['MAX_PRODUCTS_PER_CITY'],\n",
    "        'strategy': 'ë‹¨ì¼ í˜ì´ì§€'\n",
    "    }\n",
    "    \n",
    "    # ì˜ˆìƒ ì†Œìš” ì‹œê°„ ê³„ì‚° (ìƒí’ˆë‹¹ ì•½ 30ì´ˆ ì¶”ì •)\n",
    "    products_to_crawl = min(pagination_info['total_products'], CONFIG['MAX_PRODUCTS_PER_CITY'])\n",
    "    plan['estimated_time_minutes'] = products_to_crawl * 0.5  # ìƒí’ˆë‹¹ 30ì´ˆ\n",
    "    \n",
    "    # ì „ëµ ê²°ì •\n",
    "    if pagination_info['is_pagination_available'] and pagination_info['total_pages'] > 1:\n",
    "        plan['strategy'] = 'ë‹¤ì¤‘ í˜ì´ì§€ ìˆœíšŒ'\n",
    "        if pagination_info['total_products'] > CONFIG['MAX_PRODUCTS_PER_CITY']:\n",
    "            plan['strategy'] += f\" (ìµœëŒ€ {CONFIG['MAX_PRODUCTS_PER_CITY']}ê°œ ì œí•œ)\"\n",
    "    \n",
    "    return plan\n",
    "\n",
    "def report_reconnaissance_results(plan):\n",
    "    \"\"\"ì •ì°° ê²°ê³¼ ë³´ê³ \"\"\"\n",
    "    print(f\"\\nğŸ” === ì •ì°° ì™„ë£Œ ë³´ê³ ì„œ ===\")\n",
    "    print(f\"ğŸ“ ë„ì‹œ: {plan['city']}\")\n",
    "    print(f\"ğŸ“Š ë°œê²¬ëœ ì´ ìƒí’ˆ ìˆ˜: {plan['total_products']}ê°œ\")\n",
    "    print(f\"ğŸ“„ ì´ í˜ì´ì§€ ìˆ˜: {plan['total_pages']}í˜ì´ì§€\")\n",
    "    print(f\"ğŸ“‹ í˜ì´ì§€ë‹¹ ìƒí’ˆ ìˆ˜: {plan['products_per_page']}ê°œ\")\n",
    "    print(f\"ğŸ”„ í˜ì´ì§€ë„¤ì´ì…˜ ê°€ëŠ¥: {'âœ… ì˜ˆ' if plan['pagination_available'] else 'âŒ ì•„ë‹ˆì˜¤'}\")\n",
    "    print(f\"â±ï¸ ì˜ˆìƒ ì†Œìš” ì‹œê°„: {plan['estimated_time_minutes']:.1f}ë¶„\")\n",
    "    print(f\"ğŸ¯ í¬ë¡¤ë§ ì „ëµ: {plan['strategy']}\")\n",
    "    print(f\"ğŸ“¦ ì‹¤ì œ ìˆ˜ì§‘ ì˜ˆì •: {min(plan['total_products'], plan['recommended_batch_size'])}ê°œ\")\n",
    "    print(f\"=\" * 50)\n",
    "    \n",
    "    if plan['pagination_available']:\n",
    "        print(f\"ğŸš€ ê·¸ë£¹ 4ì—ì„œ ì „ì²´ í¬ë¡¤ë§ì„ ì‹œì‘í•˜ì„¸ìš”!\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"âš ï¸ í˜ì´ì§€ë„¤ì´ì…˜ì´ ì œí•œì ì…ë‹ˆë‹¤. í˜„ì¬ í˜ì´ì§€ë§Œ í¬ë¡¤ë§ ê°€ëŠ¥í•©ë‹ˆë‹¤.\")\n",
    "        return False\n",
    "\n",
    "# ê¸°ì¡´ collect_all_24_urls í•¨ìˆ˜ ê°œì„ \n",
    "def collect_page_urls_enhanced(driver):\n",
    "    \"\"\"ê°œì„ ëœ URL ìˆ˜ì§‘ + í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ í¬í•¨\"\"\"\n",
    "    print(f\"  ğŸ” ê°œì„ ëœ URL ìˆ˜ì§‘ ì‹œì‘...\")\n",
    "    \n",
    "    # ê¸°ì¡´ URL ìˆ˜ì§‘ ë¡œì§\n",
    "    collected_urls = collect_all_24_urls(driver)\n",
    "    \n",
    "    # í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„\n",
    "    pagination_info = analyze_pagination(driver)\n",
    "    \n",
    "    return collected_urls, pagination_info\n",
    "\n",
    "# =================================================================\n",
    "# ğŸ¯ ì •ì°° ì‹¤í–‰ ë¶€ë¶„\n",
    "# =================================================================\n",
    "\n",
    "print(\"ğŸ” ê·¸ë£¹ 3-1: ì •ì°° ë° ë¶„ì„ ì‹œì‘!\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    # ê·¸ë£¹ 1ì—ì„œ ì„¤ì •ëœ ë„ì‹œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "    if not CITIES_TO_SEARCH:\n",
    "        print(\"âŒ CITIES_TO_SEARCHê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!\")\n",
    "        raise ValueError(\"ê²€ìƒ‰í•  ë„ì‹œê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤\")\n",
    "\n",
    "    city_name = CITIES_TO_SEARCH[0]\n",
    "    \n",
    "    print(f\"ğŸ” {city_name} í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„ ì¤‘...\")\n",
    "    \n",
    "    # ì •ì°° ì‹¤í–‰\n",
    "    pagination_info = analyze_pagination(driver)\n",
    "    plan = generate_crawling_plan(pagination_info, city_name)\n",
    "    can_proceed = report_reconnaissance_results(plan)\n",
    "    \n",
    "    # ì¶”ê°€ ë¶„ì„\n",
    "    button_working = check_next_button(driver)\n",
    "    \n",
    "    if can_proceed and button_working:\n",
    "        print(\"\\nğŸš€ ëª¨ë“  ì •ì°° ì™„ë£Œ! ê·¸ë£¹ 4ì—ì„œ í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ í˜ì´ì§€ë„¤ì´ì…˜ ì œí•œìœ¼ë¡œ í˜„ì¬ í˜ì´ì§€ë§Œ í¬ë¡¤ë§ ê°€ëŠ¥í•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    print(\"\\nâœ… ê·¸ë£¹ 3-1 ì™„ë£Œ: ì •ì°° ë° ë¶„ì„ ì™„ë£Œ!\")\n",
    "    \n",
    "except NameError as e:\n",
    "    print(f\"âŒ ë³€ìˆ˜ ì˜¤ë¥˜: {e}\")\n",
    "    print(\"ğŸ’¡ ê·¸ë£¹ 1, 2, 3ì„ ë¨¼ì € ì‹¤í–‰í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì •ì°° ì¤‘ ì˜¤ë¥˜: {type(e).__name__}: {e}\")\n",
    "    print(\"ğŸ’¡ ë¸Œë¼ìš°ì €ê°€ í‘¸ì¼“ ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"âœ… ê·¸ë£¹ 3-1 ì •ì°° ë‹¨ê³„ ì™„ë£Œ!\")\n",
    "print(\"ğŸ”§ ì œê³µëœ ê¸°ëŠ¥:\")\n",
    "print(\"   - analyze_pagination(): í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ë¶„ì„\")\n",
    "print(\"   - check_next_button(): ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ í™•ì¸\") \n",
    "print(\"   - generate_crawling_plan(): í¬ë¡¤ë§ ê³„íš ìˆ˜ë¦½\")\n",
    "print(\"   - report_reconnaissance_results(): ì •ì°° ê²°ê³¼ ë³´ê³ \")\n",
    "print(\"   - collect_page_urls_enhanced(): ê°œì„ ëœ URL ìˆ˜ì§‘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "facc2c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ê·¸ë£¹ 4: ìƒíƒœ ê´€ë¦¬ + ë¸Œë¼ìš°ì € ì¬ë¶€íŒ… í¬ë¡¤ë§ ì‹œì‘!\n",
      "================================================================================\n",
      "ğŸ”„ ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ ë¡œë“œ ì¤‘...\n",
      "âœ… ìƒíƒœ íŒŒì¼ ë¡œë“œ: 1ê°œ ìˆ˜ì§‘ ì™„ë£Œ\n",
      "âœ… ì™„ë£Œëœ URL 2ê°œ ë¡œë“œ\n",
      "ğŸ” URL ì¤‘ë³µ ì²´í¬ ë° í•„í„°ë§ ì¤‘...\n",
      "ğŸ” URL í•„í„°ë§ ê²°ê³¼:\n",
      "   ğŸ“Š ì „ì²´ URL: 24ê°œ\n",
      "   âœ… ì™„ë£Œëœ URL: 2ê°œ\n",
      "   ğŸ†• ìƒˆë¡œìš´ URL: 22ê°œ\n",
      "ğŸ“Š ê·¸ë£¹ 1 ì„¤ì •ê°’: 1ê°œ ìƒí’ˆ\n",
      "ğŸ†• ìƒˆë¡œìš´ URL: 22ê°œ\n",
      "ğŸ¯ ì‹¤ì œ í¬ë¡¤ë§ ëŒ€ìƒ: 1ê°œ ìƒí’ˆ\n",
      "ğŸŒ ìœ„ì¹˜: ì•„ì‹œì•„ > íƒœêµ­ > í‘¸ì¼“\n",
      "âœˆï¸ ê³µí•­ ì½”ë“œ: HKT\n",
      "ğŸ“ ì´ë¯¸ì§€ ì €ì¥ ê¸°ë³¸ ê²½ë¡œ: myrealtripthumb_img/ì•„ì‹œì•„/íƒœêµ­/í‘¸ì¼“/\n",
      "ğŸ›¡ï¸ ë¸Œë¼ìš°ì € ì¬ë¶€íŒ…: 12ê°œë§ˆë‹¤ ì•ˆì „ ì¬ì‹œì‘ ì˜ˆì •\n",
      "================================================================================\n",
      "    ğŸ¯ ìƒí’ˆ ì§„í–‰ë¥ : [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100.0% (1/1)\n",
      "    ğŸ“¦ í˜„ì¬ ìƒí’ˆ: ìƒí’ˆ 1\n",
      "    ğŸ”— ìƒí’ˆ 1 URLë¡œ ì´ë™ ì¤‘: https://experiences.myrealtrip.com/products/3147846\n",
      "  ğŸ“Š Product ìƒí’ˆëª… ìˆ˜ì§‘ ì¤‘...\n",
      "  ğŸ’° ê°€ê²© ì •ë³´ ìˆ˜ì§‘ ì¤‘...\n",
      "    âœ… ìœ íš¨í•œ ê°€ê²© ë°œê²¬: '89,000ì›~'\n",
      "  ğŸ“ ë¦¬ë·° ìˆ˜ ì •ë³´ ì°¾ëŠ” ì¤‘...\n",
      "  âœ… ë¦¬ë·° ìˆ˜ ì •ë³´ ë°œê²¬: í›„ê¸° 106ê°œ\n",
      "  ğŸŒ ì–¸ì–´ ì •ë³´ ì°¾ëŠ” ì¤‘...\n",
      "    âœ… ì–¸ì–´ ì •ë³´ ë°œê²¬: ê¸°íƒ€, í•œêµ­ì–´\n",
      "  ğŸ–¼ï¸ ëŒ€í‘œ ìƒí’ˆ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...\n",
      "    âœ… ì´ë¯¸ì§€ URL ë°œê²¬: https://dry7pvlp22cox.cloudfront.net/mrt-images-pr...\n",
      "    ğŸ“ ê³„ì¸µ í´ë” ìƒì„±: myrealtripthumb_img\\ì•„ì‹œì•„\\íƒœêµ­\\í‘¸ì¼“\n",
      "    âœ… ê³„ì¸µ êµ¬ì¡° ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ! (153,556 bytes)\n",
      "    ğŸ“ ì €ì¥ ìœ„ì¹˜: ì•„ì‹œì•„\\íƒœêµ­\\í‘¸ì¼“\\HKT_002.jpg\n",
      "    ğŸ‰ ìƒí’ˆ 1 ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ: ğŸ¤¿[ë“œë¡ í¬í•¨/í‘¸ì¼“ì˜ ëª°ë””ë¸Œ!] ë¼ì°¨ì„¬+ë°”ë‚˜ë‚˜ë¹„ì¹˜ ìŠ¤í”¼ë“œ...\n",
      "    ğŸ’¾ ë°°ì¹˜ ë°ì´í„° ì €ì¥ ì¤‘... (1ê°œ)\n",
      "âœ… ë°°ì¹˜ ë°ì´í„° ì €ì¥ ì™„ë£Œ:\n",
      "   ğŸ“ ë„ì‹œë³„: data\\ì•„ì‹œì•„\\íƒœêµ­\\í‘¸ì¼“\\myrealtrip_í‘¸ì¼“_products.csv\n",
      "   ğŸ“ êµ­ê°€ë³„: data\\ì•„ì‹œì•„\\íƒœêµ­\\íƒœêµ­_myrealtrip_products_all.csv\n",
      "    âœ… ë°°ì¹˜ ì €ì¥ ì™„ë£Œ: 1ê°œ\n",
      "\n",
      "ğŸ‰ ë¸Œë¼ìš°ì € ì¬ë¶€íŒ… í¬ë¡¤ë§ ì™„ë£Œ!\n",
      "ğŸ“Š ì´ ì²˜ë¦¬ëœ ìƒí’ˆ: 2ê°œ\n",
      "ğŸ“ ë°ì´í„° ì €ì¥ ìœ„ì¹˜: data/ì•„ì‹œì•„/íƒœêµ­/í‘¸ì¼“/\n",
      "ğŸ“ ì´ë¯¸ì§€ ì €ì¥ ìœ„ì¹˜: myrealtripthumb_img/ì•„ì‹œì•„/íƒœêµ­/í‘¸ì¼“/\n",
      "ğŸ”§ ìƒíƒœ íŒŒì¼: config/crawler_meta.json\n",
      "ğŸ“ ì™„ë£Œ URL ë¡œê·¸: config/completed_urls.log\n",
      "ğŸ›¡ï¸ ë¸Œë¼ìš°ì € ì¬ë¶€íŒ…: ì•ˆì „ì„± ê·¹ëŒ€í™” ì™„ë£Œ\n",
      "\n",
      "ğŸ¯ ë¸Œë¼ìš°ì € ì¬ë¶€íŒ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n",
      "ğŸ’¡ ì•ˆì •ì„±ì´ í™•ì¸ë˜ë©´ 4ìˆœìœ„ í˜ì´ì§€ë„¤ì´ì…˜ì—ì„œ í™œìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "## ê·¸ë£¹ 4: ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ ì ìš© + ë¸Œë¼ìš°ì € ì¬ë¶€íŒ… (í…ŒìŠ¤íŠ¸ ë²„ì „)\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸš€ ê·¸ë£¹ 4: ìµœì¢… ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥ (ìƒíƒœ ê´€ë¦¬ + ë¸Œë¼ìš°ì € ì¬ë¶€íŒ…)\n",
    "# - ê²€ì¦ì™„ë£Œëœ ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ + ë¸Œë¼ìš°ì € ì¬ë¶€íŒ… ê¸°ëŠ¥ ì¶”ê°€\n",
    "# - 10-15ê°œë§ˆë‹¤ ì•ˆì „í•œ ë¸Œë¼ìš°ì € ì¬ì‹œì‘ìœ¼ë¡œ ì•ˆì •ì„± ê·¹ëŒ€í™”\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸš€ ê·¸ë£¹ 4: ìƒíƒœ ê´€ë¦¬ + ë¸Œë¼ìš°ì € ì¬ë¶€íŒ… í¬ë¡¤ë§ ì‹œì‘!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ğŸ›¡ï¸ ì•ˆì „í•œ ë¸Œë¼ìš°ì € ì¬ì‹œì‘ í•¨ìˆ˜\n",
    "def safe_browser_restart():\n",
    "    \"\"\"ì•ˆì „í•œ ë¸Œë¼ìš°ì € ì¬ì‹œì‘ with 3ë²ˆ ì¬ì‹œë„\"\"\"\n",
    "    global driver\n",
    "    \n",
    "    for attempt in range(3):  # 3ë²ˆ ì‹œë„\n",
    "        try:\n",
    "            print(f\"ğŸ”„ ë¸Œë¼ìš°ì € ì¬ì‹œì‘ ì‹œë„ {attempt+1}/3...\")\n",
    "            \n",
    "            # 1ë‹¨ê³„: ì•ˆì „í•œ ì¢…ë£Œ\n",
    "            if 'driver' in globals() and driver:\n",
    "                driver.quit()\n",
    "                driver = None\n",
    "            \n",
    "            # 2ë‹¨ê³„: ëŒ€ê¸° ë° ì •ë¦¬\n",
    "            wait_time = random.uniform(5, 10)\n",
    "            print(f\"â° {wait_time:.1f}ì´ˆ ëŒ€ê¸° ì¤‘...\")\n",
    "            time.sleep(wait_time)\n",
    "            \n",
    "            # 3ë‹¨ê³„: ìƒˆ ë¸Œë¼ìš°ì € ì‹œì‘\n",
    "            print(\"ğŸš€ ìƒˆ ë¸Œë¼ìš°ì € ì‹œì‘ ì¤‘...\")\n",
    "            driver = setup_driver()\n",
    "            \n",
    "            # 4ë‹¨ê³„: ë™ì‘ ê²€ì¦\n",
    "            print(\"ğŸ” ë¸Œë¼ìš°ì € ë™ì‘ ê²€ì¦ ì¤‘...\")\n",
    "            driver.get(\"https://www.myrealtrip.com/\")\n",
    "            time.sleep(2)\n",
    "            \n",
    "            print(\"âœ… ë¸Œë¼ìš°ì € ì¬ì‹œì‘ ì„±ê³µ!\")\n",
    "            return True, \"ì¬ì‹œì‘ ì„±ê³µ\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì¬ì‹œì‘ ì‹œë„ {attempt+1} ì‹¤íŒ¨: {type(e).__name__}: {e}\")\n",
    "            if attempt == 2:  # ë§ˆì§€ë§‰ ì‹œë„\n",
    "                print(\"ğŸš¨ ë¸Œë¼ìš°ì € ì¬ì‹œì‘ ìµœì¢… ì‹¤íŒ¨!\")\n",
    "                return False, f\"ì¬ì‹œì‘ ë¶ˆê°€: {e}\"\n",
    "            print(f\"ğŸ”„ {3-attempt-1}ì´ˆ í›„ ì¬ì‹œë„...\")\n",
    "            time.sleep(3)  # ë‹¤ìŒ ì‹œë„ ì „ ëŒ€ê¸°\n",
    "    \n",
    "    return False, \"ìµœì¢… ì‹¤íŒ¨\"\n",
    "\n",
    "def return_to_current_page():\n",
    "    \"\"\"í‘¸ì¼“ ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ë¡œ ë³µê·€\"\"\"\n",
    "    try:\n",
    "        print(\"ğŸ”„ í‘¸ì¼“ ìƒí’ˆ ëª©ë¡ í˜ì´ì§€ë¡œ ë³µê·€ ì¤‘...\")\n",
    "        driver.get(\"https://www.myrealtrip.com/offers?t=llp&qct=Phuket&qcr=Thailand\")\n",
    "        time.sleep(random.uniform(3, 5))\n",
    "        print(\"âœ… í˜ì´ì§€ ë³µê·€ ì™„ë£Œ\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í˜ì´ì§€ ë³µê·€ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- 1. ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ---\n",
    "print(\"ğŸ”„ ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ ë¡œë“œ ì¤‘...\")\n",
    "crawler_state, completed_urls = load_crawler_state()\n",
    "\n",
    "# ê·¸ë£¹ 1ì—ì„œ ì„¤ì •ëœ ë„ì‹œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "if not CITIES_TO_SEARCH:\n",
    "    print(\"âŒ CITIES_TO_SEARCHê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!\")\n",
    "    raise ValueError(\"ê²€ìƒ‰í•  ë„ì‹œê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤\")\n",
    "\n",
    "city_name = CITIES_TO_SEARCH[0]\n",
    "continent, country = get_city_info(city_name)\n",
    "\n",
    "# ê·¸ë£¹ 3ì—ì„œ ìˆ˜ì§‘í•œ URL ì¤‘ ìƒˆë¡œìš´ URLë§Œ í•„í„°ë§\n",
    "print(\"ğŸ” URL ì¤‘ë³µ ì²´í¬ ë° í•„í„°ë§ ì¤‘...\")\n",
    "new_urls = filter_new_urls(collected_urls, completed_urls)\n",
    "\n",
    "# ì„¤ì •ëœ ê°œìˆ˜ë§Œí¼ë§Œ ì‚¬ìš©\n",
    "urls_to_crawl = new_urls[:CONFIG['MAX_PRODUCTS_PER_CITY']]\n",
    "total_products = len(urls_to_crawl)\n",
    "\n",
    "print(f\"ğŸ“Š ê·¸ë£¹ 1 ì„¤ì •ê°’: {CONFIG['MAX_PRODUCTS_PER_CITY']}ê°œ ìƒí’ˆ\")\n",
    "print(f\"ğŸ†• ìƒˆë¡œìš´ URL: {len(new_urls)}ê°œ\")\n",
    "print(f\"ğŸ¯ ì‹¤ì œ í¬ë¡¤ë§ ëŒ€ìƒ: {total_products}ê°œ ìƒí’ˆ\")\n",
    "print(f\"ğŸŒ ìœ„ì¹˜: {continent} > {country} > {city_name}\")\n",
    "print(f\"âœˆï¸ ê³µí•­ ì½”ë“œ: {get_city_code(city_name)}\")\n",
    "print(f\"ğŸ“ ì´ë¯¸ì§€ ì €ì¥ ê¸°ë³¸ ê²½ë¡œ: myrealtripthumb_img/{continent}/{country}/{city_name}/\")\n",
    "\n",
    "# ğŸ†• ë¸Œë¼ìš°ì € ì¬ë¶€íŒ… ì„¤ì •\n",
    "restart_interval = random.randint(10, 15)  # 10-15ê°œë§ˆë‹¤ ì¬ë¶€íŒ…\n",
    "current_count = 0\n",
    "print(f\"ğŸ›¡ï¸ ë¸Œë¼ìš°ì € ì¬ë¶€íŒ…: {restart_interval}ê°œë§ˆë‹¤ ì•ˆì „ ì¬ì‹œì‘ ì˜ˆì •\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if total_products == 0:\n",
    "    print(\"âœ… ëª¨ë“  URLì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    print(\"ğŸ’¡ ìƒˆë¡œìš´ ìƒí’ˆì„ í¬ë¡¤ë§í•˜ë ¤ë©´ ë‹¤ë¥¸ ë„ì‹œë¥¼ ì„ íƒí•˜ê±°ë‚˜ config/completed_urls.logë¥¼ ì´ˆê¸°í™”í•˜ì„¸ìš”.\")\n",
    "else:\n",
    "    # --- 2. ë°°ì¹˜ ì²˜ë¦¬ìš© ê²°ê³¼ ì €ì¥ì†Œ ---\n",
    "    batch_results = []\n",
    "    batch_size = 5  # 5ê°œì”© ë°°ì¹˜ ì²˜ë¦¬\n",
    "    \n",
    "    # --- 3. ë©”ì¸ í¬ë¡¤ë§ ë£¨í”„ (ìƒíƒœ ê´€ë¦¬ + ë¸Œë¼ìš°ì € ì¬ë¶€íŒ…) ---\n",
    "    for product_index, product_url in enumerate(urls_to_crawl, 1):\n",
    "        current_count += 1  # ğŸ†• ì¹´ìš´íŠ¸ ì¦ê°€\n",
    "        \n",
    "        # ğŸ†• ë¸Œë¼ìš°ì € ì¬ë¶€íŒ… ì²´í¬ (í¬ë¡¤ë§ ì „ì—)\n",
    "        if current_count > restart_interval:\n",
    "            print(f\"\\nğŸ² {current_count-1}ê°œ ì™„ë£Œ! ì•ˆì „í•œ ë¸Œë¼ìš°ì € ì¬ë¶€íŒ…...\")\n",
    "            \n",
    "            # ğŸ›¡ï¸ ì•ˆì „í•œ ì¬ì‹œì‘ ì‹¤í–‰\n",
    "            success, message = safe_browser_restart()\n",
    "            \n",
    "            if success:\n",
    "                # í‘¸ì¼“ í˜ì´ì§€ë¡œ ë³µê·€\n",
    "                if return_to_current_page():\n",
    "                    # ë‹¤ìŒ ì¬ì‹œì‘ ê°„ê²© ìƒˆë¡œ ì„¤ì •\n",
    "                    restart_interval = random.randint(10, 15)\n",
    "                    current_count = 1  # ì¹´ìš´íŠ¸ ë¦¬ì…‹\n",
    "                    print(f\"ğŸ¯ ë‹¤ìŒ ì¬ë¶€íŒ…: {restart_interval}ê°œ í›„\")\n",
    "                    print(\"=\"*50)\n",
    "                else:\n",
    "                    print(\"ğŸš¨ í˜ì´ì§€ ë³µê·€ ì‹¤íŒ¨! ìˆ˜ë™ í™•ì¸ í•„ìš”\")\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"ğŸš¨ ë¸Œë¼ìš°ì € ì¬ì‹œì‘ ì‹¤íŒ¨: {message}\")\n",
    "                print(\"âš ï¸ í˜„ì¬ ë¸Œë¼ìš°ì €ë¡œ ê³„ì† ì§„í–‰í•˜ê±°ë‚˜ ìˆ˜ë™ìœ¼ë¡œ ì¤‘ë‹¨í•˜ì„¸ìš”.\")\n",
    "                # ì¬ì‹œì‘ ì¹´ìš´íŠ¸ëŠ” ë¦¬ì…‹í•˜ì§€ ì•Šê³  ê³„ì† ì§„í–‰\n",
    "                print(\"=\"*50)\n",
    "        \n",
    "        print_product_progress(product_index, total_products, f\"ìƒí’ˆ {product_index}\")\n",
    "        \n",
    "        # ê¸°ë³¸ê°’ ì„¤ì •\n",
    "        product_name, price_raw, price_clean, rating_raw, rating_clean = \"ì •ë³´ ì—†ìŒ\", \"ì •ë³´ ì—†ìŒ\", \"ì •ë³´ ì—†ìŒ\", \"ì •ë³´ ì—†ìŒ\", \"ì •ë³´ ì—†ìŒ\"\n",
    "        review_count, language = \"\", \"\"\n",
    "        img_info = {'status': 'ì²˜ë¦¬ ì•ˆë¨', 'filename': '', 'path': '', 'relative_path': '', 'size': 0}\n",
    "        url_type = \"Product\" if \"/products/\" in product_url else \"Offer\"\n",
    "        \n",
    "        try:\n",
    "            # ê°œë³„ ìƒí’ˆ í˜ì´ì§€ë¡œ ì´ë™\n",
    "            print(f\"    ğŸ”— ìƒí’ˆ {product_index} URLë¡œ ì´ë™ ì¤‘: {product_url}\")\n",
    "            driver.get(product_url)\n",
    "            time.sleep(random.uniform(CONFIG[\"MIN_DELAY\"], CONFIG[\"MAX_DELAY\"]))\n",
    "            \n",
    "            # ê·¸ë£¹ 1ì˜ í•¨ìˆ˜ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ì •ë³´ ìˆ˜ì§‘\n",
    "            product_name = get_product_name(driver, url_type)\n",
    "            price_raw = get_price(driver)\n",
    "            price_clean = clean_price(price_raw)\n",
    "            rating_raw = get_rating(driver)\n",
    "            rating_clean = clean_rating(rating_raw)\n",
    "            review_count = get_review_count(driver)\n",
    "            language = get_language(driver)\n",
    "            \n",
    "            # ìƒíƒœ ê´€ë¦¬ ì´ë¯¸ì§€ íŒŒì¼ëª… ìƒì„±\n",
    "            img_filename = create_image_filename(crawler_state['total_collected_count'] + len(batch_results) + 1, city_name)\n",
    "            \n",
    "            # ê·¸ë£¹ 1ì˜ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜ ì‚¬ìš©\n",
    "            img_info = download_image(driver, product_name, city_name, crawler_state['total_collected_count'] + len(batch_results) + 1)\n",
    "            \n",
    "            # ê²°ê³¼ ì €ì¥ (ë°°ì¹˜ìš©)\n",
    "            result = {\n",
    "                'ë²ˆí˜¸': crawler_state['total_collected_count'] + len(batch_results) + 1,\n",
    "                'ëŒ€ë¥™': continent, 'êµ­ê°€': country, 'ë„ì‹œ': city_name,\n",
    "                'ê³µí•­ì½”ë“œ': get_city_code(city_name), 'ìƒí’ˆë²ˆí˜¸': product_index, 'ìƒí’ˆíƒ€ì…': url_type,\n",
    "                'ìƒí’ˆëª…': product_name, 'ê°€ê²©_ì›ë³¸': price_raw, 'ê°€ê²©_ì •ì œ': price_clean,\n",
    "                'í‰ì _ì›ë³¸': rating_raw, 'í‰ì _ì •ì œ': rating_clean, 'ë¦¬ë·°ìˆ˜': review_count, 'ì–¸ì–´': language,\n",
    "                'ì´ë¯¸ì§€_íŒŒì¼ëª…': img_info.get('filename', ''),\n",
    "                'ì´ë¯¸ì§€_ìƒëŒ€ê²½ë¡œ': img_info.get('relative_path', ''),\n",
    "                'ì´ë¯¸ì§€_ì „ì²´ê²½ë¡œ': img_info.get('path', ''),\n",
    "                'ì´ë¯¸ì§€_ìƒíƒœ': img_info.get('status', ''),\n",
    "                'ì´ë¯¸ì§€_í¬ê¸°': img_info.get('size', 0),\n",
    "                'URL': product_url,\n",
    "                'ìˆ˜ì§‘_ì‹œê°„': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'ìƒíƒœ': 'ì™„ì „ìˆ˜ì§‘'\n",
    "            }\n",
    "            batch_results.append(result)\n",
    "            \n",
    "            # ğŸ”„ ì‹¤ì‹œê°„ ìƒíƒœ ì €ì¥ (URL ì™„ë£Œ ê¸°ë¡)\n",
    "            save_crawler_state(crawler_state, product_url)\n",
    "            \n",
    "            print(f\"    ğŸ‰ ìƒí’ˆ {product_index} ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ: {product_name[:30]}...\")\n",
    "            \n",
    "            # ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì €ì¥ (batch_sizeë§ˆë‹¤ ë˜ëŠ” ë§ˆì§€ë§‰)\n",
    "            if len(batch_results) >= batch_size or product_index == total_products:\n",
    "                print(f\"    ğŸ’¾ ë°°ì¹˜ ë°ì´í„° ì €ì¥ ì¤‘... ({len(batch_results)}ê°œ)\")\n",
    "                batch_save_result = save_batch_data(batch_results, city_name)\n",
    "                \n",
    "                if batch_save_result:\n",
    "                    print(f\"    âœ… ë°°ì¹˜ ì €ì¥ ì™„ë£Œ: {batch_save_result['data_count']}ê°œ\")\n",
    "                    # ë°°ì¹˜ ì €ì¥ í›„ ì´ˆê¸°í™”\n",
    "                    batch_results = []\n",
    "                else:\n",
    "                    print(f\"    âš ï¸ ë°°ì¹˜ ì €ì¥ ì‹¤íŒ¨\")\n",
    "    \n",
    "        except TimeoutException as e:\n",
    "            print(f\"    â° ìƒí’ˆ {product_index} íƒ€ì„ì•„ì›ƒ: ë‹¤ìŒ ìƒí’ˆìœ¼ë¡œ ê³„ì†...\")\n",
    "            # íƒ€ì„ì•„ì›ƒ ìƒí’ˆë„ ê¸°ë¡\n",
    "            error_result = {\n",
    "                'ë²ˆí˜¸': crawler_state['total_collected_count'] + len(batch_results) + 1,\n",
    "                'ëŒ€ë¥™': continent, 'êµ­ê°€': country, 'ë„ì‹œ': city_name,\n",
    "                'ê³µí•­ì½”ë“œ': get_city_code(city_name), 'ìƒí’ˆë²ˆí˜¸': product_index, 'ìƒí’ˆíƒ€ì…': url_type,\n",
    "                'ìƒí’ˆëª…': f\"íƒ€ì„ì•„ì›ƒ_{product_index}\", 'ê°€ê²©_ì›ë³¸': \"ìˆ˜ì§‘ì‹¤íŒ¨\", 'ê°€ê²©_ì •ì œ': \"ìˆ˜ì§‘ì‹¤íŒ¨\",\n",
    "                'í‰ì _ì›ë³¸': \"ìˆ˜ì§‘ì‹¤íŒ¨\", 'í‰ì _ì •ì œ': \"ìˆ˜ì§‘ì‹¤íŒ¨\", 'ë¦¬ë·°ìˆ˜': \"\", 'ì–¸ì–´': \"\",\n",
    "                'ì´ë¯¸ì§€_íŒŒì¼ëª…': \"\", 'ì´ë¯¸ì§€_ìƒëŒ€ê²½ë¡œ': \"\", 'ì´ë¯¸ì§€_ì „ì²´ê²½ë¡œ': \"\",\n",
    "                'ì´ë¯¸ì§€_ìƒíƒœ': \"ì²˜ë¦¬ì‹¤íŒ¨\", 'ì´ë¯¸ì§€_í¬ê¸°': 0, 'URL': product_url,\n",
    "                'ìˆ˜ì§‘_ì‹œê°„': time.strftime('%Y-%m-%d %H:%M:%S'), 'ìƒíƒœ': 'TimeoutException'\n",
    "            }\n",
    "            batch_results.append(error_result)\n",
    "            save_crawler_state(crawler_state, product_url)\n",
    "            continue\n",
    "            \n",
    "        except WebDriverException as e:\n",
    "            print(f\"    ğŸŒ ìƒí’ˆ {product_index} ë¸Œë¼ìš°ì € ì˜¤ë¥˜: {type(e).__name__}\")\n",
    "            print(f\"    ğŸ”§ ì¦‰ì‹œ ë¸Œë¼ìš°ì € ì¬ì‹œì‘ì„ ì‹œë„í•©ë‹ˆë‹¤...\")\n",
    "            \n",
    "            # ğŸ›¡ï¸ ë¸Œë¼ìš°ì € ì˜¤ë¥˜ ì‹œ ì¦‰ì‹œ ì¬ì‹œì‘ ì‹œë„\n",
    "            success, message = safe_browser_restart()\n",
    "            if success:\n",
    "                if return_to_current_page():\n",
    "                    print(f\"    âœ… ì‘ê¸‰ ì¬ì‹œì‘ ì„±ê³µ! ë‹¤ìŒ ìƒí’ˆìœ¼ë¡œ ê³„ì†...\")\n",
    "                    # ì¬ì‹œì‘ ì¹´ìš´íŠ¸ ë¦¬ì…‹\n",
    "                    restart_interval = random.randint(10, 15)\n",
    "                    current_count = 1\n",
    "                else:\n",
    "                    print(f\"    ğŸš¨ í˜ì´ì§€ ë³µê·€ ì‹¤íŒ¨: í¬ë¡¤ë§ ì¤‘ë‹¨\")\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"    ğŸš¨ ì‘ê¸‰ ì¬ì‹œì‘ ì‹¤íŒ¨: {message}\")\n",
    "                print(f\"    â›” í¬ë¡¤ë§ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\")\n",
    "                break\n",
    "                \n",
    "            # ì‹¤íŒ¨ ê¸°ë¡\n",
    "            error_result = {\n",
    "                'ë²ˆí˜¸': crawler_state['total_collected_count'] + len(batch_results) + 1,\n",
    "                'ëŒ€ë¥™': continent, 'êµ­ê°€': country, 'ë„ì‹œ': city_name,\n",
    "                'ê³µí•­ì½”ë“œ': get_city_code(city_name), 'ìƒí’ˆë²ˆí˜¸': product_index, 'ìƒí’ˆíƒ€ì…': url_type,\n",
    "                'ìƒí’ˆëª…': f\"ë¸Œë¼ìš°ì €ì˜¤ë¥˜_{product_index}\", 'ê°€ê²©_ì›ë³¸': \"ìˆ˜ì§‘ì‹¤íŒ¨\", 'ê°€ê²©_ì •ì œ': \"ìˆ˜ì§‘ì‹¤íŒ¨\",\n",
    "                'í‰ì _ì›ë³¸': \"ìˆ˜ì§‘ì‹¤íŒ¨\", 'í‰ì _ì •ì œ': \"ìˆ˜ì§‘ì‹¤íŒ¨\", 'ë¦¬ë·°ìˆ˜': \"\", 'ì–¸ì–´': \"\",\n",
    "                'ì´ë¯¸ì§€_íŒŒì¼ëª…': \"\", 'ì´ë¯¸ì§€_ìƒëŒ€ê²½ë¡œ': \"\", 'ì´ë¯¸ì§€_ì „ì²´ê²½ë¡œ': \"\",\n",
    "                'ì´ë¯¸ì§€_ìƒíƒœ': \"ì²˜ë¦¬ì‹¤íŒ¨\", 'ì´ë¯¸ì§€_í¬ê¸°': 0, 'URL': product_url,\n",
    "                'ìˆ˜ì§‘_ì‹œê°„': time.strftime('%Y-%m-%d %H:%M:%S'), 'ìƒíƒœ': f'WebDriverException'\n",
    "            }\n",
    "            batch_results.append(error_result)\n",
    "            save_crawler_state(crawler_state, product_url)\n",
    "            continue\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    âŒ ìƒí’ˆ {product_index} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__}: {e}\")\n",
    "            \n",
    "            # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ê¸°ë³¸ ì •ë³´ ì €ì¥\n",
    "            error_result = {\n",
    "                'ë²ˆí˜¸': crawler_state['total_collected_count'] + len(batch_results) + 1,\n",
    "                'ëŒ€ë¥™': continent, 'êµ­ê°€': country, 'ë„ì‹œ': city_name,\n",
    "                'ê³µí•­ì½”ë“œ': get_city_code(city_name), 'ìƒí’ˆë²ˆí˜¸': product_index, 'ìƒí’ˆíƒ€ì…': url_type,\n",
    "                'ìƒí’ˆëª…': f\"ì˜¤ë¥˜_{product_index}\", 'ê°€ê²©_ì›ë³¸': \"ìˆ˜ì§‘ì‹¤íŒ¨\", 'ê°€ê²©_ì •ì œ': \"ìˆ˜ì§‘ì‹¤íŒ¨\",\n",
    "                'í‰ì _ì›ë³¸': \"ìˆ˜ì§‘ì‹¤íŒ¨\", 'í‰ì _ì •ì œ': \"ìˆ˜ì§‘ì‹¤íŒ¨\", 'ë¦¬ë·°ìˆ˜': \"\", 'ì–¸ì–´': \"\",\n",
    "                'ì´ë¯¸ì§€_íŒŒì¼ëª…': \"\", 'ì´ë¯¸ì§€_ìƒëŒ€ê²½ë¡œ': \"\", 'ì´ë¯¸ì§€_ì „ì²´ê²½ë¡œ': \"\",\n",
    "                'ì´ë¯¸ì§€_ìƒíƒœ': \"ì²˜ë¦¬ì‹¤íŒ¨\", 'ì´ë¯¸ì§€_í¬ê¸°': 0, 'URL': product_url,\n",
    "                'ìˆ˜ì§‘_ì‹œê°„': time.strftime('%Y-%m-%d %H:%M:%S'), 'ìƒíƒœ': f'ì˜¤ë¥˜({type(e).__name__})'\n",
    "            }\n",
    "            batch_results.append(error_result)\n",
    "            \n",
    "            # ì˜¤ë¥˜ ìƒí’ˆë„ ì™„ë£Œë¡œ ê¸°ë¡ (ë¬´í•œ ì¬ì‹œë„ ë°©ì§€)\n",
    "            save_crawler_state(crawler_state, product_url)\n",
    "            continue\n",
    "    \n",
    "    # --- 4. ë‚¨ì€ ë°°ì¹˜ ë°ì´í„° ì €ì¥ ---\n",
    "    if batch_results:\n",
    "        print(f\"\\nğŸ’¾ ìµœì¢… ë°°ì¹˜ ë°ì´í„° ì €ì¥ ì¤‘... ({len(batch_results)}ê°œ)\")\n",
    "        final_batch_result = save_batch_data(batch_results, city_name)\n",
    "        if final_batch_result:\n",
    "            print(f\"âœ… ìµœì¢… ë°°ì¹˜ ì €ì¥ ì™„ë£Œ: {final_batch_result['data_count']}ê°œ\")\n",
    "    \n",
    "    print(f\"\\nğŸ‰ ë¸Œë¼ìš°ì € ì¬ë¶€íŒ… í¬ë¡¤ë§ ì™„ë£Œ!\")\n",
    "    print(f\"ğŸ“Š ì´ ì²˜ë¦¬ëœ ìƒí’ˆ: {crawler_state['total_collected_count']}ê°œ\")\n",
    "    print(f\"ğŸ“ ë°ì´í„° ì €ì¥ ìœ„ì¹˜: data/{continent}/{country}/{city_name}/\")\n",
    "    print(f\"ğŸ“ ì´ë¯¸ì§€ ì €ì¥ ìœ„ì¹˜: myrealtripthumb_img/{continent}/{country}/{city_name}/\")\n",
    "    print(f\"ğŸ”§ ìƒíƒœ íŒŒì¼: config/crawler_meta.json\")\n",
    "    print(f\"ğŸ“ ì™„ë£Œ URL ë¡œê·¸: config/completed_urls.log\")\n",
    "    print(f\"ğŸ›¡ï¸ ë¸Œë¼ìš°ì € ì¬ë¶€íŒ…: ì•ˆì „ì„± ê·¹ëŒ€í™” ì™„ë£Œ\")\n",
    "\n",
    "print(\"\\nğŸ¯ ë¸Œë¼ìš°ì € ì¬ë¶€íŒ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "print(\"ğŸ’¡ ì•ˆì •ì„±ì´ í™•ì¸ë˜ë©´ 4ìˆœìœ„ í˜ì´ì§€ë„¤ì´ì…˜ì—ì„œ í™œìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mikael_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}