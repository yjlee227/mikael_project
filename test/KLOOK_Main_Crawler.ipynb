{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ KLOOK í†µí•© í¬ë¡¤ëŸ¬ ì‹œìŠ¤í…œ\n",
    "\n",
    "## ğŸ“‹ ì§€ì›í•˜ëŠ” ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤:\n",
    "1. **ê¸°ë³¸ í¬ë¡¤ë§**: ë„ì‹œ ì„ íƒ â†’ íƒ­ë³„ ìˆœì°¨ í¬ë¡¤ë§ (ì „ì²´â†’íˆ¬ì–´â†’í‹°ì¼“â†’êµí†µâ†’ê¸°íƒ€)\n",
    "2. **ë­í‚¹ ê¸°ë°˜ ìˆ˜ì§‘**: ê° íƒ­ë³„ ì‚¬ìš©ì ì„¤ì • ìˆœìœ„ê¹Œì§€ ìˆ˜ì§‘, ì¤‘ë³µ ìë™ ê±´ë„ˆë›°ê¸°\n",
    "3. **ì„¸ì…˜ ì—°ì†ì„±**: ì¤‘ê°„ ì¤‘ë‹¨ í›„ ì´ì–´ì„œ ê³„ì† ê°€ëŠ¥\n",
    "4. **hashlib ê³ ì† ì¤‘ë³µ ì²´í¬**: ì´ë¯¸ í¬ë¡¤ë§í•œ URL ì´ˆê³ ì† ê²€ì‚¬\n",
    "5. **í˜ì´ì§€ë„¤ì´ì…˜**: KLOOK 15ê°œ/í˜ì´ì§€ êµ¬ì¡° ì™„ë²½ ëŒ€ì‘\n",
    "6. **CSV ìë™ ì €ì¥**: 10ê°œë§ˆë‹¤ ìë™ ì €ì¥\n",
    "7. **ğŸ†• ì‚¬ìš©ì ì„¤ì • ê°€ëŠ¥í•œ ìˆ˜ì§‘ ì œí•œ**: 1ê°œ~500ê°œê¹Œì§€ ì›í•˜ëŠ” ê°œìˆ˜ë§Œí¼ ìˆ˜ì§‘\n",
    "8. **ğŸª ê°œë³„ íƒ­ ì„ íƒ**: ì „ì²´/íˆ¬ì–´/í‹°ì¼“/êµí†µ/ê¸°íƒ€ íƒ­ì„ True/Falseë¡œ ê°œë³„ ì„ íƒ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ›ï¸ 1. í¬ë¡¤ë§ ì„¤ì • (ë¨¼ì € ì„¤ì •í•˜ì„¸ìš”!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ KLOOK í¬ë¡¤ëŸ¬ ì„¤ì • (í˜ì´ì§€ë„¤ì´ì…˜ ìˆœìœ„ ì‹œìŠ¤í…œ)\n",
    "print(\"ğŸš€ KLOOK í¬ë¡¤ëŸ¬ ì„¤ì • - í˜ì´ì§€ë„¤ì´ì…˜ ìˆœìœ„ ì‹œìŠ¤í…œ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ğŸ¯ í¬ë¡¤ë§ ì„¤ì • (ì§ì ‘ ìˆ˜ì •í•˜ì„¸ìš”!)\n",
    "CURRENT_CITY = \"êµ¬ë§ˆëª¨í† \"           #ğŸ”¥ğŸ”¥ë„ì‹œ ì…ë ¥ ğŸ”¥ğŸ”¥#\n",
    "\n",
    "# ğŸ†• í˜ì´ì§€ë„¤ì´ì…˜ ì„¤ì • (ìƒˆë¡œìš´ ë°©ì‹)\n",
    "PAGINATION_MODE = True         # í˜ì´ì§€ë„¤ì´ì…˜ ëª¨ë“œ í™œì„±í™”\n",
    "TARGET_PRODUCTS = 15          # ìˆ˜ì§‘í•  ìƒí’ˆ ìˆ˜ (1ìœ„ë¶€í„° ìˆœì°¨ì ìœ¼ë¡œ)\n",
    "MAX_PAGES = 5                 # ìµœëŒ€ í˜ì´ì§€ ìˆ˜\n",
    "RANKING_CONTINUITY = True     # í˜ì´ì§€ ê°„ ìˆœìœ„ ì—°ì†ì„± ìœ ì§€\n",
    "\n",
    "# ê¸°ì¡´ ìˆœìœ„ ê¸°ë°˜ ì„¤ì • (í˜¸í™˜ì„±ìš© - PAGINATION_MODE=Falseì¼ ë•Œë§Œ ì‚¬ìš©)\n",
    "START_RANK = 1\n",
    "END_RANK = 15\n",
    "COLLECT_COUNT = 15\n",
    "\n",
    "# ğŸ“Š ë°ì´í„° ë¶„ë¦¬ ì €ì¥ ì„¤ì •\n",
    "SEPARATE_RANKING_DATA = True   # ë­í‚¹ ì •ë³´ ë³„ë„ ì €ì¥\n",
    "MAINTAIN_CSV_CONTINUITY = True # CSV ë²ˆí˜¸ ì—°ì†ì„± ìœ ì§€\n",
    "MAINTAIN_IMAGE_CONTINUITY = True # ì´ë¯¸ì§€ ë²ˆí˜¸ ì—°ì†ì„± ìœ ì§€\n",
    "\n",
    "# ğŸª íƒ­ ì„¤ì • (í˜ì´ì§€ë„¤ì´ì…˜ì€ ì „ì²´ íƒ­ë§Œ ì§€ì›)\n",
    "TAB_ì „ì²´ = True               # ì „ì²´ íƒ­ (í˜ì´ì§€ë„¤ì´ì…˜ ì „ìš©)\n",
    "TAB_íˆ¬ì–´ì•¡í‹°ë¹„í‹° = False      # íˆ¬ì–´&ì•¡í‹°ë¹„í‹° íƒ­ (ë¹„í™œì„±í™”)\n",
    "TAB_í‹°ì¼“ì…ì¥ê¶Œ = False         # í‹°ì¼“&ì…ì¥ê¶Œ íƒ­ (ë¹„í™œì„±í™”)\n",
    "TAB_êµí†µ = False             # êµí†µ íƒ­ (ë¹„í™œì„±í™”)\n",
    "TAB_ê¸°íƒ€ = False             # ê¸°íƒ€ íƒ­ (ë¹„í™œì„±í™”)\n",
    "\n",
    "# ğŸ® í¬ë¡¤ë§ ëª¨ë“œ ì„ íƒ\n",
    "MODE_PAGINATION = True        # ğŸ†• í˜ì´ì§€ë„¤ì´ì…˜ ìˆœìœ„ ëª¨ë“œ (ì¶”ì²œ)\n",
    "MODE_CLASSIC = False          # ê¸°ì¡´ ë°©ì‹\n",
    "MODE_RESUME = False           # ì´ì–´ì„œ ê³„ì†\n",
    "\n",
    "# ê³ ê¸‰ ì˜µì…˜\n",
    "AUTO_SAVE = True              # 10ê°œë§ˆë‹¤ ìë™ ì €ì¥\n",
    "DOWNLOAD_IMAGES = True        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í™œì„±í™”\n",
    "SAVE_SESSION = True           # ì„¸ì…˜ ìƒíƒœ ì €ì¥\n",
    "VALIDATION_MODE = True        # í¬ë¡¤ë§ í›„ ê²€ì¦ ì‹¤í–‰\n",
    "\n",
    "# ëª¨ë“œ ì²˜ë¦¬\n",
    "if MODE_PAGINATION:\n",
    "    CRAWLING_MODE = \"pagination\"\n",
    "    mode_desc = f\"ğŸ“„ í˜ì´ì§€ë„¤ì´ì…˜ ìˆœìœ„ ëª¨ë“œ ({TARGET_PRODUCTS}ê°œ ìƒí’ˆ, {MAX_PAGES}í˜ì´ì§€)\"\n",
    "    SELECTED_TABS = [\"ì „ì²´\"]\n",
    "elif MODE_CLASSIC:\n",
    "    CRAWLING_MODE = \"classic\"\n",
    "    mode_desc = f\"ğŸ¯ ê¸°ì¡´ ìˆœìœ„ ëª¨ë“œ ({START_RANK}-{END_RANK}ìœ„)\"\n",
    "    SELECTED_TABS = [\"ì „ì²´\"] if TAB_ì „ì²´ else []\n",
    "elif MODE_RESUME:\n",
    "    CRAWLING_MODE = \"resume\"\n",
    "    mode_desc = \"ğŸ”„ ì´ì–´ì„œ ê³„ì†\"\n",
    "else:\n",
    "    CRAWLING_MODE = \"pagination\"  # ê¸°ë³¸ê°’\n",
    "    mode_desc = f\"ğŸ“„ í˜ì´ì§€ë„¤ì´ì…˜ ìˆœìœ„ ëª¨ë“œ (ê¸°ë³¸ê°’)\"\n",
    "    SELECTED_TABS = [\"ì „ì²´\"]\n",
    "\n",
    "print(\"âœ… ì„¤ì • ì™„ë£Œ!\")\n",
    "print(f\"   ğŸŒ ë„ì‹œ: {CURRENT_CITY}\")\n",
    "if MODE_PAGINATION:\n",
    "    print(f\"   ğŸ“„ í˜ì´ì§€ë„¤ì´ì…˜: {TARGET_PRODUCTS}ê°œ ìƒí’ˆ (1ìœ„ë¶€í„° ìˆœì°¨)\")\n",
    "    print(f\"   ğŸ“– ìµœëŒ€ í˜ì´ì§€: {MAX_PAGES}í˜ì´ì§€\")\n",
    "    print(f\"   ğŸ”„ ìˆœìœ„ ì—°ì†ì„±: {'âœ… ë³´ì¥' if RANKING_CONTINUITY else 'âŒ ë¹„ë³´ì¥'}\")\n",
    "    print(f\"   ğŸ“Š ë°ì´í„° ë¶„ë¦¬: {'âœ… ë­í‚¹ë³„ë„ì €ì¥' if SEPARATE_RANKING_DATA else 'âŒ í†µí•©ì €ì¥'}\")\n",
    "else:\n",
    "    print(f\"   ğŸ“Š ìˆœìœ„ ê¸°ë°˜: {START_RANK}ìœ„ ~ {END_RANK}ìœ„\")\n",
    "print(f\"   {mode_desc}\")\n",
    "print(f\"   ğŸ’¾ ìë™ì €ì¥: {AUTO_SAVE}\")\n",
    "print(f\"   ğŸ“¸ ì´ë¯¸ì§€: {DOWNLOAD_IMAGES}\")\n",
    "print(f\"   ğŸ” ê²€ì¦ëª¨ë“œ: {VALIDATION_MODE}\")\n",
    "\n",
    "# ì„¤ì •ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ì •ë¦¬\n",
    "CRAWLING_SETTINGS = {\n",
    "    'city': CURRENT_CITY,\n",
    "    'mode': CRAWLING_MODE,\n",
    "    'pagination_mode': PAGINATION_MODE,\n",
    "    'target_products': TARGET_PRODUCTS if PAGINATION_MODE else END_RANK - START_RANK + 1,\n",
    "    'max_pages': MAX_PAGES,\n",
    "    'ranking_continuity': RANKING_CONTINUITY,\n",
    "    'separate_ranking_data': SEPARATE_RANKING_DATA,\n",
    "    'maintain_continuity': {\n",
    "        'csv': MAINTAIN_CSV_CONTINUITY,\n",
    "        'image': MAINTAIN_IMAGE_CONTINUITY\n",
    "    },\n",
    "    'start_rank': START_RANK,\n",
    "    'end_rank': END_RANK,\n",
    "    'selected_tabs': SELECTED_TABS,\n",
    "    'skip_duplicates': True,\n",
    "    'auto_save': AUTO_SAVE,\n",
    "    'download_images': DOWNLOAD_IMAGES,\n",
    "    'save_session': SAVE_SESSION,\n",
    "    'validation_mode': VALIDATION_MODE\n",
    "}\n",
    "\n",
    "# ì˜ˆìƒ ì‘ì—…ëŸ‰ ê³„ì‚°\n",
    "if MODE_PAGINATION:\n",
    "    total_text = f\"{TARGET_PRODUCTS}ê°œ ìƒí’ˆ (í˜ì´ì§€ë„¤ì´ì…˜)\"\n",
    "    print(f\"   ğŸ“Š ì˜ˆìƒ ì‘ì—…ëŸ‰: {total_text}\")\n",
    "    print(f\"   ğŸ† ìˆœìœ„ ë³´ì¥: 1ìœ„ ~ {TARGET_PRODUCTS}ìœ„ ì •í™•í•œ ìˆœì„œ\")\n",
    "else:\n",
    "    expected = END_RANK - START_RANK + 1\n",
    "    total_text = f\"{expected}ê°œ ìƒí’ˆ (ê¸°ì¡´ë°©ì‹)\"\n",
    "    print(f\"   ğŸ“Š ì˜ˆìƒ ì‘ì—…ëŸ‰: {total_text}\")\n",
    "\n",
    "print(\"\\nğŸ“‹ í˜ì´ì§€ë„¤ì´ì…˜ ìˆœìœ„ ì‹œìŠ¤í…œ íŠ¹ì§•:\")\n",
    "print(\"ğŸ”¹ í˜ì´ì§€ë¥¼ ë„˜ì–´ê°€ë©´ì„œ ìˆœìœ„ ì—°ì†ì„± ìœ ì§€ (1ìœ„â†’2ìœ„â†’3ìœ„â†’...)\")\n",
    "print(\"ğŸ”¹ ë­í‚¹ ì •ë³´ì™€ í¬ë¡¤ë§ ë°ì´í„° ë¶„ë¦¬ ì €ì¥\")\n",
    "print(\"ğŸ”¹ CSV ìˆœì„œì™€ ì‹¤ì œ ìˆœìœ„ëŠ” ë…ë¦½ì  (ë°ì´í„° ê°€ê³µ ì‹œ ë§¤í•‘)\")\n",
    "print(\"ğŸ”¹ ì´ë¯¸ì§€, CSV, ë­í‚¹ ë²ˆí˜¸ì˜ ì—°ì†ì„± ìë™ ë³´ì¥\")\n",
    "print(\"ğŸ”¹ ì¶”í›„ ë°ì´í„° ê°€ê³µ ì‹œ ë­í‚¹ ì •ë³´ í™œìš© ê°€ëŠ¥\")\n",
    "\n",
    "print(\"\\nâ­ï¸ ë‹¤ìŒ ì…€ë“¤ì´ ìë™ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤!\")\n",
    "\n",
    "CRAWLING_READY = True\n",
    "\n",
    "# ì„¤ì • í™•ì¸ í•¨ìˆ˜\n",
    "def get_current_settings():\n",
    "    return CRAWLING_SETTINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ 2. ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ import ë° ì‹œìŠ¤í…œ ì²´í¬ (í˜ì´ì§€ë„¤ì´ì…˜ ì‹œìŠ¤í…œ í¬í•¨)\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# ëª¨ë“ˆ import\n",
    "try:\n",
    "    from klook_modules.control_system import KlookMasterController\n",
    "    from klook_modules.system_utils import setup_driver, check_dependencies, get_system_info\n",
    "    from klook_modules.config import UNIFIED_CITY_INFO, CONFIG\n",
    "    from klook_modules.url_manager import is_url_already_processed, mark_url_as_processed\n",
    "    from klook_modules.tab_selector import execute_integrated_tab_selector_system\n",
    "    from klook_modules.url_collection import collect_urls_with_pagination\n",
    "    from klook_modules.crawler_engine import KlookCrawlerEngine\n",
    "    from klook_modules.ranking_manager import ranking_manager\n",
    "    \n",
    "    # ğŸ†• í˜ì´ì§€ë„¤ì´ì…˜ ì‹œìŠ¤í…œ ëª¨ë“ˆ\n",
    "    from klook_modules.pagination_ranking_system import (\n",
    "        pagination_ranking_system, ranking_data_matcher, continuity_manager\n",
    "    )\n",
    "    from klook_modules.integrated_pagination_crawler import (\n",
    "        IntegratedPaginationCrawler, pagination_crawler_validator\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… ëª¨ë“  ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ!\")\n",
    "    print(\"   ğŸ†• í˜ì´ì§€ë„¤ì´ì…˜ ì‹œìŠ¤í…œ: âœ… ë¡œë“œë¨\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"klook_modules í´ë”ê°€ í˜„ì¬ ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "# ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬\n",
    "print(\"\\nğŸ” ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬...\")\n",
    "dependencies = check_dependencies()\n",
    "missing_deps = [lib for lib, available in dependencies.items() if not available]\n",
    "\n",
    "if missing_deps:\n",
    "    print(f\"âŒ ëˆ„ë½ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬: {', '.join(missing_deps)}\")\n",
    "    print(\"ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install selenium chromedriver-autoinstaller pandas requests beautifulsoup4\")\n",
    "else:\n",
    "    print(\"âœ… ëª¨ë“  ì˜ì¡´ì„± ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "\n",
    "print(f\"\\nğŸŒ ì§€ì› ë„ì‹œ: {len(UNIFIED_CITY_INFO)}ê°œ\")\n",
    "print(f\"ğŸ“Š ì„¤ì • ìƒíƒœ: hashlib={CONFIG.get('USE_HASH_SYSTEM', True)}, V2_URL={CONFIG.get('USE_V2_URL_SYSTEM', True)}\")\n",
    "print(f\"ğŸ† ë­í‚¹ ë§¤ë‹ˆì €: {'âœ… ë¡œë“œë¨' if 'ranking_manager' in locals() else 'âŒ ë¡œë“œ ì‹¤íŒ¨'}\")\n",
    "print(f\"ğŸ“„ í˜ì´ì§€ë„¤ì´ì…˜ ì‹œìŠ¤í…œ: {'âœ… ë¡œë“œë¨' if 'pagination_ranking_system' in locals() else 'âŒ ë¡œë“œ ì‹¤íŒ¨'}\")\n",
    "print(f\"ğŸ’¾ 32ê°œ ì»¬ëŸ¼ êµ¬ì¡°: âœ… ì ìš©ë¨\")\n",
    "print(f\"ğŸ“¸ ë“€ì–¼ ì´ë¯¸ì§€ ì‹œìŠ¤í…œ: âœ… ì ìš©ë¨\")\n",
    "\n",
    "# í˜ì´ì§€ë„¤ì´ì…˜ ì‹œìŠ¤í…œ íŠ¹ì§• ì•ˆë‚´\n",
    "print(f\"\\nğŸ“„ í˜ì´ì§€ë„¤ì´ì…˜ ìˆœìœ„ ì‹œìŠ¤í…œ íŠ¹ì§•:\")\n",
    "print(f\"   ğŸ”¹ í˜ì´ì§€ ê°„ ìˆœìœ„ ì—°ì†ì„± ìë™ ë³´ì¥ (1ìœ„â†’2ìœ„â†’3ìœ„â†’...)\")\n",
    "print(f\"   ğŸ”¹ '>' ë²„íŠ¼ìœ¼ë¡œ ë‹¤ìŒ í˜ì´ì§€ ìë™ ì´ë™\")\n",
    "print(f\"   ğŸ”¹ ë­í‚¹ ì •ë³´ ë³„ë„ ì €ì¥ (ì¶”í›„ ë°ì´í„° ê°€ê³µìš©)\")\n",
    "print(f\"   ğŸ”¹ CSV, ì´ë¯¸ì§€, ë­í‚¹ ë²ˆí˜¸ì˜ ì—°ì†ì„± ìœ ì§€\")\n",
    "print(f\"   ğŸ”¹ í¬ë¡¤ë§ í›„ ìë™ ê²€ì¦ ì‹œìŠ¤í…œ\")\n",
    "\n",
    "print(\"\\nâœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
    "print(\"ğŸ”½ ë‹¤ìŒ ì…€ì—ì„œ í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ 3. ì„¤ì • ì ìš© ë° í¬ë¡¤ë§ ì‹œì‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¤ì • ì ìš© ë° ë“œë¼ì´ë²„ ì¤€ë¹„\n",
    "print(\"ğŸ“Š í¬ë¡¤ë§ ì„¤ì • ì ìš© ì¤‘...\")\n",
    "\n",
    "# 1ë²ˆ ì…€ì—ì„œ ì„¤ì •í•œ ê°’ ê°€ì ¸ì˜¤ê¸°\n",
    "try:\n",
    "    settings = get_current_settings()\n",
    "    \n",
    "    print(\"âœ… ì„¤ì • í™•ì¸:\")\n",
    "    print(f\"   ğŸŒ ë„ì‹œ: {settings['city']}\")\n",
    "    print(f\"   ğŸ“Š ìˆœìœ„: {settings['start_rank']}ìœ„ ~ {settings['end_rank']}ìœ„\")\n",
    "    print(f\"   ğŸ“Š ìµœëŒ€ ìˆ˜ì§‘ ì œí•œ: {settings['max_collect_limit']}ê°œ\")\n",
    "    print(f\"   ğŸ® ëª¨ë“œ: {settings['mode']}\")\n",
    "    if settings['mode'] == 'tab_select':\n",
    "        print(f\"   ğŸª ì„ íƒëœ íƒ­: {', '.join(settings['selected_tabs'])}\")\n",
    "    \n",
    "    # ë“œë¼ì´ë²„ ì„¤ì •\n",
    "    print(\"\\nğŸ”§ í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì • ì¤‘...\")\n",
    "    driver = setup_driver()\n",
    "    \n",
    "    # ê¸€ë¡œë²Œ ë³€ìˆ˜ ì„¤ì • (ë‹¤ë¥¸ ì…€ì—ì„œ ì‚¬ìš©)\n",
    "    CURRENT_CITY = settings['city']\n",
    "    START_RANK = settings['start_rank']\n",
    "    END_RANK = settings['end_rank']\n",
    "    MAX_COLLECT_LIMIT = settings['max_collect_limit']\n",
    "    CRAWLING_MODE = settings['mode']\n",
    "    SELECTED_TABS = settings['selected_tabs']\n",
    "    \n",
    "    print(f\"ğŸ¯ '{CURRENT_CITY}' í¬ë¡¤ë§ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "    print(f\"ğŸ“Š ìˆœìœ„ ë²”ìœ„: {START_RANK}ìœ„ ~ {END_RANK}ìœ„\")\n",
    "    print(f\"ğŸ“Š ìµœëŒ€ ìˆ˜ì§‘ ì œí•œ: {MAX_COLLECT_LIMIT}ê°œ\")\n",
    "    if CRAWLING_MODE == 'tab_select':\n",
    "        print(f\"ğŸª íƒ­ ì„ íƒ ëª¨ë“œ: {len(SELECTED_TABS)}ê°œ íƒ­ ({', '.join(SELECTED_TABS)})\")\n",
    "    print(f\"ğŸ† ë­í‚¹ ë§¤ë‹ˆì €: ì¤‘ë³µ URL ìë™ ì²˜ë¦¬\")\n",
    "    print(f\"ğŸ’¾ 32ê°œ ì»¬ëŸ¼ êµ¬ì¡°: ìë™ ì ìš©\")\n",
    "    print(f\"ğŸ“¸ ë“€ì–¼ ì´ë¯¸ì§€: ë©”ì¸+ì¸ë„¤ì¼ ìë™ ë‹¤ìš´ë¡œë“œ\")\n",
    "    print(\"âœ… ë‹¤ìŒ ì…€ì—ì„œ URL ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤!\")\n",
    "    \n",
    "    # í¬ë¡¤ë§ ì¤€ë¹„ ì™„ë£Œ í”Œë˜ê·¸\n",
    "    DRIVER_READY = True\n",
    "    \n",
    "except RuntimeError as e:\n",
    "    print(f\"âŒ {e}\")\n",
    "    print(\"ğŸ’¡ 1ë²ˆ ì…€ì—ì„œ 'ğŸš€ í¬ë¡¤ë§ ì‹œì‘' ë²„íŠ¼ì„ ë¨¼ì € ëˆŒëŸ¬ì£¼ì„¸ìš”.\")\n",
    "    DRIVER_READY = False\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}\")\n",
    "    DRIVER_READY = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ 4. íƒ­ë³„ ë­í‚¹ ìˆ˜ì§‘ (URL ìˆ˜ì§‘)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ğŸ†• í˜ì´ì§€ë„¤ì´ì…˜ ìˆœìœ„ ê¸°ë°˜ í¬ë¡¤ë§ ì‹¤í–‰\nprint(f\"ğŸ“„ '{CURRENT_CITY}' í˜ì´ì§€ë„¤ì´ì…˜ ìˆœìœ„ í¬ë¡¤ë§ ì‹œì‘!\")\nprint(\"=\" * 70)\n\n# ë“œë¼ì´ë²„ ì¤€ë¹„ ìƒíƒœ í™•ì¸\ntry:\n    if not DRIVER_READY:\n        print(\"âŒ ë“œë¼ì´ë²„ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n        print(\"ğŸ’¡ ì´ì „ ì…€ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n    else:\n        settings = get_current_settings()\n        \n        if settings['pagination_mode']:\n            # ğŸ†• í˜ì´ì§€ë„¤ì´ì…˜ ëª¨ë“œ\n            print(f\"ğŸ“„ í˜ì´ì§€ë„¤ì´ì…˜ ìˆœìœ„ ëª¨ë“œ ì‹¤í–‰\")\n            print(f\"ğŸ¯ ëª©í‘œ: {settings['target_products']}ê°œ ìƒí’ˆ (1ìœ„ë¶€í„° ìˆœì°¨)\")\n            print(f\"ğŸ“– ìµœëŒ€ í˜ì´ì§€: {settings['max_pages']}í˜ì´ì§€\")\n            \n            # 1. KLOOK ë©”ì¸ í˜ì´ì§€ ì´ë™\n            from klook_modules.driver_manager import go_to_main_page, find_and_fill_search, click_search_button\n            \n            print(\"\\nğŸŒ KLOOK ë©”ì¸ í˜ì´ì§€ ì´ë™...\")\n            go_to_main_page(driver)\n            \n            print(f\"ğŸ” '{CURRENT_CITY}' ê²€ìƒ‰ ì¤‘...\")\n            find_and_fill_search(driver, CURRENT_CITY)\n            click_search_button(driver)\n            \n            time.sleep(5)  # ê²€ìƒ‰ ê²°ê³¼ ë¡œë”© ì¶©ë¶„íˆ ëŒ€ê¸°\n            \n            # 2. í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”\n            pagination_crawler = IntegratedPaginationCrawler(driver)\n            \n            # 3. í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ ì‹¤í–‰\n            print(f\"\\nğŸ“„ í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ ì‹œì‘...\")\n            success = pagination_crawler.execute_pagination_crawling(\n                city_name=CURRENT_CITY,\n                target_count=settings['target_products'],\n                max_pages=settings['max_pages']\n            )\n            \n            if success:\n                print(f\"\\nâœ… í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ ì„±ê³µ!\")\n                \n                # 4. ê²€ì¦ ì‹¤í–‰ (ì„¤ì •ì— ë”°ë¼)\n                if settings.get('validation_mode', False):\n                    print(f\"\\nğŸ” í¬ë¡¤ë§ ê²°ê³¼ ê²€ì¦ ì¤‘...\")\n                    \n                    # ìˆœìœ„ ì—°ì†ì„± ê²€ì¦\n                    ranking_ok = pagination_crawler_validator.validate_ranking_continuity(CURRENT_CITY)\n                    \n                    # ë°ì´í„° ì¼ê´€ì„± ê²€ì¦\n                    data_ok = pagination_crawler_validator.validate_data_consistency(CURRENT_CITY)\n                    \n                    # ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±\n                    report_file = pagination_crawler_validator.generate_pagination_report(CURRENT_CITY)\n                    \n                    print(f\"\\nğŸ“Š ê²€ì¦ ê²°ê³¼:\")\n                    print(f\"   ğŸ† ìˆœìœ„ ì—°ì†ì„±: {'âœ… ì™„ë²½' if ranking_ok else 'âš ï¸ ë¬¸ì œ ë°œê²¬'}\")\n                    print(f\"   ğŸ“‹ ë°ì´í„° ì¼ê´€ì„±: {'âœ… ì™„ë²½' if data_ok else 'âš ï¸ ë¬¸ì œ ë°œê²¬'}\")\n                    print(f\"   ğŸ“„ ë¦¬í¬íŠ¸: {report_file}\")\n                \n                CRAWLING_SUCCESS = True\n                \n            else:\n                print(f\"\\nâŒ í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ ì‹¤íŒ¨\")\n                CRAWLING_SUCCESS = False\n        \n        else:\n            # ê¸°ì¡´ ë°©ì‹ (í˜¸í™˜ì„±ìš©)\n            print(f\"ğŸ¯ ê¸°ì¡´ ìˆœìœ„ ëª¨ë“œ ì‹¤í–‰\")\n            print(f\"ğŸ“Š ì„¤ì •ëœ ë²”ìœ„: {settings['start_rank']}ìœ„ ~ {settings['end_rank']}ìœ„\")\n            \n            # ê¸°ì¡´ ì½”ë“œ ì‹¤í–‰...\n            # (ì—¬ê¸°ì— ê¸°ì¡´ì˜ íƒ­ ì„ íƒ ë° URL ìˆ˜ì§‘ ë¡œì§)\n            print(\"âš ï¸ ê¸°ì¡´ ë°©ì‹ì€ ë³„ë„ êµ¬í˜„ í•„ìš”\")\n            CRAWLING_SUCCESS = False\n\nexcept NameError:\n    print(\"âŒ í•„ìš”í•œ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n    print(\"ğŸ’¡ ì´ì „ ì…€ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n    CRAWLING_SUCCESS = False\nexcept Exception as e:\n    print(f\"âŒ í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {e}\")\n    import traceback\n    traceback.print_exc()\n    CRAWLING_SUCCESS = False\n\n# í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½\nif 'CRAWLING_SUCCESS' in locals() and CRAWLING_SUCCESS:\n    print(f\"\\nğŸ‰ '{CURRENT_CITY}' í¬ë¡¤ë§ ì™„ë£Œ!\")\n    print(\"=\" * 50)\n    print(\"ğŸ“Š í˜ì´ì§€ë„¤ì´ì…˜ ìˆœìœ„ ì‹œìŠ¤í…œ ì„±ê³¼:\")\n    print(\"   âœ… ìˆœìœ„ ì—°ì†ì„± ë³´ì¥ (1ìœ„ë¶€í„° ìˆœì°¨ì )\")\n    print(\"   âœ… í˜ì´ì§€ ê°„ ì´ë™ ìë™í™”\")\n    print(\"   âœ… ë­í‚¹ ì •ë³´ ë³„ë„ ì €ì¥\")\n    print(\"   âœ… CSV, ì´ë¯¸ì§€, ë­í‚¹ ë²ˆí˜¸ ì—°ì†ì„± ìœ ì§€\")\n    print(\"   âœ… ìë™ ê²€ì¦ ë° ë¦¬í¬íŠ¸ ìƒì„±\")\n    \n    # ë™ì ìœ¼ë¡œ íŒŒì¼ ê²½ë¡œ ìƒì„±\n    from klook_modules.config import get_city_info\n    continent, country = get_city_info(CURRENT_CITY)\n    \n    print(f\"\\nğŸ“ ìƒì„±ëœ íŒŒì¼:\")\n    print(f\"   ğŸ“Š CSV ë°ì´í„°: data/{continent}/{country}/\")\n    print(f\"   ğŸ† ë­í‚¹ ì •ë³´: ranking_data/\")\n    print(f\"   ğŸ“„ í˜ì´ì§€ë„¤ì´ì…˜ ë¡œê·¸: url_collected/\")\n    print(f\"   ğŸ” ê²€ì¦ ë¦¬í¬íŠ¸: reports/\")\n    \nelse:\n    print(f\"\\nâŒ í¬ë¡¤ë§ ì‹¤íŒ¨ ë˜ëŠ” ë¯¸ì‹¤í–‰\")\n    print(\"ğŸ’¡ ì„¤ì •ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ğŸ§ª í˜ì´ì§€ë„¤ì´ì…˜ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\nprint(\"ğŸ§ª í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ë§ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\")\nprint(\"=\" * 60)\n\n# í…ŒìŠ¤íŠ¸ìš© ì„¤ì • - ì²« ë²ˆì§¸ ì…€ì˜ CURRENT_CITY ì‚¬ìš©\nTEST_CITY = CURRENT_CITY  # ì²« ë²ˆì§¸ ì…€ì˜ ì„¤ì • ì‚¬ìš©\nTEST_TARGET_PRODUCTS = 5  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ 5ê°œë§Œ ìˆ˜ì§‘\nTEST_MAX_PAGES = 2\n\nprint(f\"ğŸ¯ í…ŒìŠ¤íŠ¸ ì„¤ì •:\")\nprint(f\"   ğŸŒ ë„ì‹œ: {TEST_CITY}\")\nprint(f\"   ğŸ“Š ëª©í‘œ ìƒí’ˆ: {TEST_TARGET_PRODUCTS}ê°œ\")\nprint(f\"   ğŸ“„ ìµœëŒ€ í˜ì´ì§€: {TEST_MAX_PAGES}í˜ì´ì§€\")\nprint(f\"   ğŸ† ìˆœìœ„: 1ìœ„ë¶€í„° {TEST_TARGET_PRODUCTS}ìœ„ê¹Œì§€\")\n\ntry:\n    # ë“œë¼ì´ë²„ ì„¤ì •\n    if 'driver' not in locals() or driver is None:\n        print(\"\\nğŸ”§ ë“œë¼ì´ë²„ ì„¤ì • ì¤‘...\")\n        driver = setup_driver()\n    \n    # KLOOK ë©”ì¸ í˜ì´ì§€ ì´ë™\n    from klook_modules.driver_manager import go_to_main_page, find_and_fill_search, click_search_button\n    \n    print(f\"\\nğŸŒ KLOOK ë©”ì¸ í˜ì´ì§€ ì´ë™...\")\n    go_to_main_page(driver)\n    time.sleep(3)\n    \n    print(f\"ğŸ” '{TEST_CITY}' ê²€ìƒ‰ ì¤‘...\")\n    find_and_fill_search(driver, TEST_CITY)\n    click_search_button(driver)\n    time.sleep(5)  # ê²€ìƒ‰ ê²°ê³¼ ë¡œë”© ëŒ€ê¸°\n    \n    # í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”\n    print(f\"\\nğŸš€ í˜ì´ì§€ë„¤ì´ì…˜ í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”...\")\n    pagination_crawler = IntegratedPaginationCrawler(driver)\n    \n    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n    print(f\"\\nğŸ“„ í˜ì´ì§€ë„¤ì´ì…˜ í…ŒìŠ¤íŠ¸ ì‹œì‘!\")\n    print(f\"   ğŸ¯ {TEST_TARGET_PRODUCTS}ê°œ ìƒí’ˆ ìˆ˜ì§‘\")\n    print(f\"   ğŸ“– ìµœëŒ€ {TEST_MAX_PAGES}í˜ì´ì§€ ì²˜ë¦¬\")\n    print(f\"   ğŸ† ìˆœìœ„ ì—°ì†ì„± ë³´ì¥\")\n    \n    test_success = pagination_crawler.execute_pagination_crawling(\n        city_name=TEST_CITY,\n        target_count=TEST_TARGET_PRODUCTS,\n        max_pages=TEST_MAX_PAGES\n    )\n    \n    if test_success:\n        print(f\"\\nâœ… í˜ì´ì§€ë„¤ì´ì…˜ í…ŒìŠ¤íŠ¸ ì„±ê³µ!\")\n        \n        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê²€ì¦\n        print(f\"\\nğŸ” í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê²€ì¦ ì¤‘...\")\n        \n        # ìˆœìœ„ ì—°ì†ì„± ê²€ì¦\n        ranking_ok = pagination_crawler_validator.validate_ranking_continuity(TEST_CITY)\n        \n        # ë°ì´í„° ì¼ê´€ì„± ê²€ì¦\n        data_ok = pagination_crawler_validator.validate_data_consistency(TEST_CITY)\n        \n        # ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±\n        report_file = pagination_crawler_validator.generate_pagination_report(TEST_CITY)\n        \n        print(f\"\\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²€ì¦ ê²°ê³¼:\")\n        print(f\"   ğŸ† ìˆœìœ„ ì—°ì†ì„±: {'âœ… ì™„ë²½' if ranking_ok else 'âš ï¸ ë¬¸ì œ ë°œê²¬'}\")\n        print(f\"   ğŸ“‹ ë°ì´í„° ì¼ê´€ì„±: {'âœ… ì™„ë²½' if data_ok else 'âš ï¸ ë¬¸ì œ ë°œê²¬'}\")\n        if report_file:\n            print(f\"   ğŸ“„ ê²€ì¦ ë¦¬í¬íŠ¸: {report_file}\")\n        \n        # ìƒì„±ëœ íŒŒì¼ í™•ì¸\n        print(f\"\\nğŸ“ ìƒì„±ëœ íŒŒì¼ í™•ì¸:\")\n        \n        # ë™ì ìœ¼ë¡œ city_code ê°€ì ¸ì˜¤ê¸°\n        from klook_modules.config import get_city_code\n        city_code = get_city_code(TEST_CITY)\n        \n        # ë­í‚¹ ë°ì´í„° íŒŒì¼\n        ranking_files = [f for f in os.listdir(\"ranking_data\") if f.startswith(f\"{city_code}_\") and \"pagination\" in f]\n        if ranking_files:\n            print(f\"   ğŸ† ë­í‚¹ ë°ì´í„°: {len(ranking_files)}ê°œ íŒŒì¼\")\n        \n        # URL ìˆ˜ì§‘ ë¡œê·¸\n        url_log_files = [f for f in os.listdir(\"url_collected\") if f.startswith(f\"{city_code}_\")]\n        if url_log_files:\n            print(f\"   ğŸ“ URL ë¡œê·¸: {len(url_log_files)}ê°œ íŒŒì¼\")\n        \n        # CSV ë°ì´í„° í™•ì¸ - ë™ì ìœ¼ë¡œ ê²½ë¡œ êµ¬ì„±\n        from klook_modules.config import get_city_info\n        continent, country = get_city_info(TEST_CITY)\n        csv_path = f\"data/{continent}/{country}/{TEST_CITY}_klook_products_all.csv\"\n        if os.path.exists(csv_path):\n            with open(csv_path, 'r', encoding='utf-8-sig') as f:\n                lines = f.readlines()\n                data_rows = len(lines) - 1  # í—¤ë” ì œì™¸\n            print(f\"   ğŸ“‹ CSV ë°ì´í„°: {data_rows}ê°œ ìƒí’ˆ\")\n        \n        print(f\"\\nğŸ‰ í˜ì´ì§€ë„¤ì´ì…˜ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n        print(f\"   âœ… URL ìˆ˜ì§‘: ì •ìƒ ë™ì‘\")\n        print(f\"   âœ… ìˆœìœ„ ì—°ì†ì„±: ë³´ì¥ë¨\")\n        print(f\"   âœ… ë°ì´í„° ì €ì¥: ì„±ê³µ\")\n        print(f\"   âœ… ê²€ì¦ ì‹œìŠ¤í…œ: ì •ìƒ ë™ì‘\")\n        \n        # ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´\n        print(f\"\\nâ­ï¸ ë‹¤ìŒ ë‹¨ê³„:\")\n        print(f\"   1. ì„¤ì •ì„ í° ê°’ìœ¼ë¡œ ë³€ê²½ (ì˜ˆ: TARGET_PRODUCTS = 15)\")\n        print(f\"   2. ìœ„ì˜ ì„¤ì • ì…€ì—ì„œ PAGINATION_MODE = Trueë¡œ ì„¤ì •\")\n        print(f\"   3. ì „ì²´ í¬ë¡¤ë§ ì…€ ì‹¤í–‰í•˜ì—¬ ì‹¤ì œ í¬ë¡¤ë§ ì§„í–‰\")\n        \n    else:\n        print(f\"\\nâŒ í˜ì´ì§€ë„¤ì´ì…˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨\")\n        print(f\"   ğŸ’¡ ë¡œê·¸ë¥¼ í™•ì¸í•˜ê³  ë¬¸ì œë¥¼ í•´ê²°í•˜ì„¸ìš”\")\n\nexcept Exception as e:\n    print(f\"\\nğŸ’¥ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}\")\n    import traceback\n    traceback.print_exc()\n    print(f\"\\nğŸ’¡ ë¬¸ì œ í•´ê²° ë°©ì•ˆ:\")\n    print(f\"   1. ì´ì „ ì…€ë“¤ì´ ëª¨ë‘ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸\")\n    print(f\"   2. ëª¨ë“ˆ ë¡œë”©ì´ ì •ìƒì¸ì§€ í™•ì¸\")\n    print(f\"   3. ì¸í„°ë„· ì—°ê²° ìƒíƒœ í™•ì¸\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¥ 5. ìƒì„¸ í¬ë¡¤ë§ ì‹¤í–‰ (2ë‹¨ê³„: ë°ì´í„° ìˆ˜ì§‘)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CURRENT_CITY' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ìƒì„¸ í¬ë¡¤ë§ ì‹œì‘\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ”¥ \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mCURRENT_CITY\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m ìƒì„¸ í¬ë¡¤ë§ ì‹œì‘!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# í¬ë¡¤ë§ ì—”ì§„ ì´ˆê¸°í™” (driverë¥¼ ì „ë‹¬í•˜ê³  í†µê³„ ì´ˆê¸°í™”)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CURRENT_CITY' is not defined"
     ]
    }
   ],
   "source": [
    "# ìƒì„¸ í¬ë¡¤ë§ ì‹œì‘\n",
    "print(f\"ğŸ”¥ '{CURRENT_CITY}' ìƒì„¸ í¬ë¡¤ë§ ì‹œì‘!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# í¬ë¡¤ë§ ì—”ì§„ ì´ˆê¸°í™” (driverë¥¼ ì „ë‹¬í•˜ê³  í†µê³„ ì´ˆê¸°í™”)\n",
    "crawler = KlookCrawlerEngine(driver)\n",
    "crawler.reset_stats(CURRENT_CITY)\n",
    "\n",
    "# ì „ì²´ ì§„í–‰ ìƒí™© ì¶”ì \n",
    "total_planned = sum(len(urls) for urls in collected_urls_by_tab.values())\n",
    "total_completed = 0\n",
    "total_duplicated = 0\n",
    "total_failed = 0\n",
    "\n",
    "# ë°°ì¹˜ ì €ì¥ì„ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘\n",
    "batch_data = []\n",
    "batch_size = 10 if settings['auto_save'] else 50\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"ğŸ’¾ 32ê°œ ì»¬ëŸ¼ êµ¬ì¡°: ìë™ ì ìš©\")\n",
    "print(f\"ğŸ“¸ ë“€ì–¼ ì´ë¯¸ì§€ ì‹œìŠ¤í…œ: {'âœ… í™œì„±í™”' if settings.get('download_images', True) else 'âŒ ë¹„í™œì„±í™”'}\")\n",
    "print(f\"ğŸ† ë­í‚¹ ë§¤ë‹ˆì €: ì¤‘ë³µ URL ìŠ¤ë§ˆíŠ¸ ì²˜ë¦¬\")\n",
    "print(f\"ğŸ’¾ ì„¸ì…˜ ì €ì¥: {'âœ… í™œì„±í™”' if settings.get('save_session', True) else 'âŒ ë¹„í™œì„±í™”'}\")\n",
    "print(f\"ğŸ’¾ ìë™ ë°±ì—…: âœ… 20ê°œë§ˆë‹¤ + ìµœì¢… ë°±ì—…\")\n",
    "print(f\"ğŸ¯ ìˆœìœ„ ë§¤í¼: ì‹¤ì œ ìˆœìœ„ì™€ URL ë°°ì—´ ì¸ë±ìŠ¤ ë§¤í•‘\")\n",
    "\n",
    "try:\n",
    "    # íƒ­ë³„ ìˆœì°¨ í¬ë¡¤ë§\n",
    "    for tab_name, urls in collected_urls_by_tab.items():\n",
    "        if not urls:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nğŸª '{tab_name}' íƒ­ í¬ë¡¤ë§ ì‹œì‘ ({len(urls)}ê°œ URL)\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        tab_completed = 0\n",
    "        tab_duplicated = 0\n",
    "        tab_failed = 0\n",
    "        \n",
    "        # ğŸ¯ ì‹¤ì œ ìˆœìœ„ ë§¤í•‘ ì‹œìŠ¤í…œ ì‚¬ìš©\n",
    "        from klook_modules.rank_mapper import rank_mapper\n",
    "        \n",
    "        # ì‹¤ì œ ìˆœìœ„ ë²”ìœ„ì— í•´ë‹¹í•˜ëŠ” URLë“¤ë§Œ ë§¤í•‘\n",
    "        rank_mappings = rank_mapper.map_range_to_actual_ranks(urls, CURRENT_CITY, tab_name, START_RANK, END_RANK)\n",
    "        \n",
    "        print(f\"ğŸ“Š ì‹¤ì œ ìˆœìœ„ ë§¤í•‘: {len(rank_mappings)}ê°œ URL\")\n",
    "        \n",
    "        # URLë³„ ìˆœì°¨ í¬ë¡¤ë§ (ì‹¤ì œ ìˆœìœ„ ê¸°ì¤€)\n",
    "        for mapping in rank_mappings:\n",
    "            url = mapping['url']\n",
    "            actual_rank = mapping['actual_rank']\n",
    "            current_progress = total_completed + tab_completed + 1\n",
    "            \n",
    "            print(f\"\\nğŸ“Š ì§„í–‰ë¥ : {current_progress}/{total_planned} | {tab_name} {actual_rank}ìœ„ (ì‹¤ì œìˆœìœ„)\")\n",
    "            print(f\"ğŸ”— URL: {url[:60]}...\")\n",
    "            \n",
    "            # ë­í‚¹ ë§¤ë‹ˆì € ì¤‘ë³µ ì²´í¬\n",
    "            try:\n",
    "                if not ranking_manager.should_crawl_url(url, CURRENT_CITY):\n",
    "                    print(f\"    ğŸ† ë­í‚¹ ë§¤ë‹ˆì €: ì¤‘ë³µ ì œì™¸ (ë‹¤ë¥¸ íƒ­ì—ì„œ ì´ë¯¸ í¬ë¡¤ë§ë¨)\")\n",
    "                    tab_duplicated += 1\n",
    "                    continue\n",
    "            except Exception as e:\n",
    "                print(f\"    âš ï¸ ë­í‚¹ ë§¤ë‹ˆì € í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "            \n",
    "            # ê¸°ì¡´ ì¤‘ë³µ ì²´í¬ (hashlib ê³ ì† ê²€ì‚¬)\n",
    "            if is_url_already_processed(url, CURRENT_CITY):\n",
    "                print(f\"    ğŸ”„ ì´ë¯¸ ì²˜ë¦¬ë¨ - ì¤‘ë³µ ì œì™¸\")\n",
    "                tab_duplicated += 1\n",
    "                continue\n",
    "            \n",
    "            # ìƒì„¸ í¬ë¡¤ë§ ì‹¤í–‰ (32ê°œ ì»¬ëŸ¼ + ë“€ì–¼ ì´ë¯¸ì§€)\n",
    "            try:\n",
    "                result = crawler.process_single_url(url, CURRENT_CITY, current_progress)\n",
    "                \n",
    "                if result.get('success') and not result.get('skipped'):\n",
    "                    product_data = result.get('product_data', {})\n",
    "                    product_name = product_data.get('ìƒí’ˆëª…', 'N/A')[:30]\n",
    "                    print(f\"    âœ… ì„±ê³µ: {product_name}...\")\n",
    "                    \n",
    "                    # íƒ­ ë° ë­í‚¹ ì •ë³´ ì¶”ê°€ (ì‹¤ì œ ìˆœìœ„ ì‚¬ìš©)\n",
    "                    product_data['íƒ­ëª…'] = tab_name\n",
    "                    product_data['íƒ­ë‚´_ë­í‚¹'] = actual_rank\n",
    "                    \n",
    "                    # 32ê°œ ì»¬ëŸ¼ êµ¬ì¡° í™•ì¸\n",
    "                    column_count = len(product_data.keys())\n",
    "                    print(f\"    ğŸ“Š ë°ì´í„° ì»¬ëŸ¼: {column_count}ê°œ\")\n",
    "                    \n",
    "                    # ë“€ì–¼ ì´ë¯¸ì§€ í™•ì¸\n",
    "                    main_img = product_data.get('ë©”ì¸ì´ë¯¸ì§€_íŒŒì¼ëª…', 'ì •ë³´ ì—†ìŒ')\n",
    "                    thumb_img = product_data.get('ì¸ë„¤ì¼ì´ë¯¸ì§€_íŒŒì¼ëª…', 'ì •ë³´ ì—†ìŒ')\n",
    "                    if main_img != 'ì •ë³´ ì—†ìŒ' and thumb_img != 'ì •ë³´ ì—†ìŒ':\n",
    "                        print(f\"    ğŸ“¸ ë“€ì–¼ ì´ë¯¸ì§€: ë©”ì¸ + ì¸ë„¤ì¼\")\n",
    "                    elif main_img != 'ì •ë³´ ì—†ìŒ':\n",
    "                        print(f\"    ğŸ“¸ ë‹¨ì¼ ì´ë¯¸ì§€: ë©”ì¸ë§Œ\")\n",
    "                    else:\n",
    "                        print(f\"    ğŸ“¸ ì´ë¯¸ì§€: ì—†ìŒ\")\n",
    "                    \n",
    "                    # ë­í‚¹ ë§¤ë‹ˆì €ì— í¬ë¡¤ë§ ì™„ë£Œ í‘œì‹œ\n",
    "                    try:\n",
    "                        ranking_manager.mark_url_crawled(url, CURRENT_CITY)\n",
    "                        print(f\"    ğŸ† ë­í‚¹ ë§¤ë‹ˆì €: í¬ë¡¤ë§ ì™„ë£Œ í‘œì‹œ\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"    âš ï¸ ë­í‚¹ ì™„ë£Œ í‘œì‹œ ì‹¤íŒ¨: {e}\")\n",
    "                    \n",
    "                    # ì„¸ì…˜ ìƒíƒœ ì €ì¥ (ì„¤ì •ì— ë”°ë¼)\n",
    "                    if settings.get('save_session', True):\n",
    "                        try:\n",
    "                            from klook_modules.system_utils import save_crawler_state\n",
    "                            session_data = {\n",
    "                                'city': CURRENT_CITY,\n",
    "                                'start_rank': START_RANK,\n",
    "                                'end_rank': END_RANK,\n",
    "                                'current_tab': tab_name,\n",
    "                                'current_rank': actual_rank,\n",
    "                                'total_completed': total_completed + tab_completed + 1,\n",
    "                                'settings': settings,\n",
    "                                'timestamp': datetime.now().isoformat()\n",
    "                            }\n",
    "                            save_crawler_state(session_data, url)\n",
    "                            print(f\"    ğŸ’¾ ì„¸ì…˜ ìƒíƒœ ì €ì¥ ì™„ë£Œ\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"    âš ï¸ ì„¸ì…˜ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "                    \n",
    "                    tab_completed += 1\n",
    "                    \n",
    "                elif result.get('skipped'):\n",
    "                    print(f\"    ğŸ”„ ì¤‘ë³µ ì œì™¸: {result.get('reason', 'unknown')}\")\n",
    "                    tab_duplicated += 1\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"    âŒ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ìŒ')}\")\n",
    "                    tab_failed += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"    ğŸ’¥ ì˜ˆì™¸ ë°œìƒ: {e}\")\n",
    "                tab_failed += 1\n",
    "            \n",
    "            # ì§„í–‰ ìƒí™© í‘œì‹œ\n",
    "            elapsed = time.time() - start_time\n",
    "            avg_time = elapsed / max(total_completed + tab_completed, 1)\n",
    "            remaining = (total_planned - current_progress) * avg_time\n",
    "            \n",
    "            print(f\"    â±ï¸ ê²½ê³¼: {int(elapsed//60)}ë¶„ | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {int(remaining//60)}ë¶„\")\n",
    "            \n",
    "            # ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€ê¸°\n",
    "            time.sleep(2)\n",
    "        \n",
    "        # íƒ­ ì™„ë£Œ ì •ë¦¬\n",
    "        total_completed += tab_completed\n",
    "        total_duplicated += tab_duplicated\n",
    "        total_failed += tab_failed\n",
    "        \n",
    "        print(f\"\\nâœ… '{tab_name}' íƒ­ ì™„ë£Œ!\")\n",
    "        print(f\"   ì„±ê³µ: {tab_completed}ê°œ | ì¤‘ë³µ ì œì™¸: {tab_duplicated}ê°œ | ì‹¤íŒ¨: {tab_failed}ê°œ\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    # ì¤‘ë‹¨ ì‹œì—ë„ ì„¸ì…˜ ì €ì¥\n",
    "    if settings.get('save_session', True):\n",
    "        try:\n",
    "            from klook_modules.system_utils import save_crawler_state\n",
    "            interrupt_session_data = {\n",
    "                'city': CURRENT_CITY,\n",
    "                'start_rank': START_RANK,\n",
    "                'end_rank': END_RANK,\n",
    "                'total_completed': total_completed,\n",
    "                'settings': settings,\n",
    "                'interrupted': True,\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "            save_crawler_state(interrupt_session_data, \"INTERRUPTED\")\n",
    "            print(\"ğŸ’¾ ì¤‘ë‹¨ ìƒíƒœ ì €ì¥ ì™„ë£Œ - Resume ê¸°ëŠ¥ìœ¼ë¡œ ì´ì–´ì„œ ê³„ì†í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ì¤‘ë‹¨ ìƒíƒœ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "            \n",
    "    # ì¤‘ë‹¨ ì‹œì—ë„ ìµœì¢… ë°±ì—… ì‹¤í–‰ (ê¸°ì¡´ ìë™ ì‹œìŠ¤í…œ ì‚¬ìš©)\n",
    "    try:\n",
    "        print(f\"ğŸ’¾ ì¤‘ë‹¨ ì‹œ ë°±ì—… ì‹¤í–‰...\")\n",
    "        crawler.final_backup(CURRENT_CITY)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ì¤‘ë‹¨ ì‹œ ë°±ì—… ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nğŸ’¥ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# ìµœì¢… ë°±ì—… ì‹¤í–‰ (ê¸°ì¡´ ìë™ ì‹œìŠ¤í…œë§Œ ì‚¬ìš©)\n",
    "try:\n",
    "    print(f\"\\nğŸ’¾ ìµœì¢… ë°±ì—… ì‹¤í–‰ ì¤‘...\")\n",
    "    print(f\"ğŸ“Š í¬ë¡¤ëŸ¬ í†µê³„ í™•ì¸: success_count={crawler.stats['success_count']}\")\n",
    "    crawler.final_backup(CURRENT_CITY)\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ìµœì¢… ë°±ì—… ì‹¤íŒ¨: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(\"\\nğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"ğŸ“Š ìµœì¢… ê²°ê³¼:\")\n",
    "print(f\"   âœ… ì„±ê³µ: {total_completed}ê°œ\")\n",
    "print(f\"   ğŸ”„ ì¤‘ë³µ ì œì™¸: {total_duplicated}ê°œ\")\n",
    "print(f\"   âŒ ì‹¤íŒ¨: {total_failed}ê°œ\")\n",
    "print(f\"   ğŸ“Š ì´ê³„: {total_completed + total_duplicated + total_failed}ê°œ\")\n",
    "print(f\"   â±ï¸ ì†Œìš” ì‹œê°„: {int(total_time//60)}ë¶„ {int(total_time%60)}ì´ˆ\")\n",
    "\n",
    "# ì„±ê³µë¥  ê³„ì‚°\n",
    "if total_completed + total_failed > 0:\n",
    "    success_rate = (total_completed / (total_completed + total_failed)) * 100\n",
    "    print(f\"   ğŸ“ˆ ì„±ê³µë¥ : {success_rate:.1f}%\")\n",
    "\n",
    "# 32ê°œ ì»¬ëŸ¼ êµ¬ì¡° ë° ë“€ì–¼ ì´ë¯¸ì§€ í™•ì¸\n",
    "print(f\"\\nğŸ’¾ 32ê°œ ì»¬ëŸ¼ êµ¬ì¡°: {'âœ… ì ìš©ë¨' if total_completed > 0 else 'âš ï¸ í™•ì¸ í•„ìš”'}\")\n",
    "print(f\"ğŸ“¸ ë“€ì–¼ ì´ë¯¸ì§€ ì‹œìŠ¤í…œ: {'âœ… ì ìš©ë¨' if settings.get('download_images', True) else 'âŒ ë¹„í™œì„±í™”'}\")\n",
    "\n",
    "# ë­í‚¹ ë§¤ë‹ˆì € ìµœì¢… í†µê³„\n",
    "try:\n",
    "    ranking_stats = ranking_manager.get_city_ranking_stats(CURRENT_CITY)\n",
    "    if ranking_stats:\n",
    "        print(f\"ğŸ† ë­í‚¹ ë§¤ë‹ˆì € ìµœì¢… í†µê³„:\")\n",
    "        print(f\"   ì´ URL: {ranking_stats.get('total_urls', 0)}ê°œ\")\n",
    "        print(f\"   ì¤‘ë³µ ì œì™¸: {ranking_stats.get('duplicate_urls', 0)}ê°œ\")\n",
    "        print(f\"   ì²˜ë¦¬ëœ íƒ­: {len(ranking_stats.get('tabs_processed', []))}ê°œ\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ë­í‚¹ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ“ ë°ì´í„° ì €ì¥ ìœ„ì¹˜:\")\n",
    "print(f\"   - CSV: data/{CURRENT_CITY}/\")\n",
    "print(f\"   - ì´ë¯¸ì§€: klook_thumb_img/\")\n",
    "print(f\"   - ë­í‚¹ ë°ì´í„°: ranking_data/\")\n",
    "print(f\"   - ì„¸ì…˜ ìƒíƒœ: crawler_state/\")\n",
    "print(f\"   - ë°±ì—… íŒŒì¼: data/{CURRENT_CITY}/*_backup_*.csv\")\n",
    "print(f\"   - êµ­ê°€ë³„ í†µí•© CSV: ìë™ ìƒì„±ë¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—ºï¸ 6. Sitemap URL ì¶”ê°€ ìˆ˜ì§‘ (ì„ íƒì‚¬í•­)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sitemapì—ì„œ ì¶”ê°€ URL ìˆ˜ì§‘ (ìë™ ì‹¤í–‰)\n",
    "print(\"ğŸ—ºï¸ Sitemapì—ì„œ ì¶”ê°€ URL ìˆ˜ì§‘ (ìë™ ê±´ë„ˆë›°ê¸°)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Run All í˜¸í™˜ì„ ìœ„í•´ ìë™ìœ¼ë¡œ ê±´ë„ˆë›°ê¸°\n",
    "print(\"â­ï¸ Run All ëª¨ë“œ: Sitemap ìˆ˜ì§‘ì„ ìë™ìœ¼ë¡œ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "print(\"ğŸ’¡ í•„ìš”ì‹œ ì´ ì…€ì„ ê°œë³„ ì‹¤í–‰í•˜ì—¬ Sitemap ìˆ˜ì§‘ì„ í™œì„±í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ìˆ˜ë™ ì‹¤í–‰ ëª¨ë“œ (ê°œë³„ ì…€ ì‹¤í–‰ì‹œì—ë§Œ ë™ì‘)\n",
    "if False:  # ê¸°ë³¸ì ìœ¼ë¡œ ë¹„í™œì„±í™”\n",
    "    from klook_modules.url_collection import collect_urls_from_sitemap\n",
    "    \n",
    "    print(f\"\\nğŸ—ºï¸ '{CURRENT_CITY}' Sitemap URL ìˆ˜ì§‘ ì¤‘...\")\n",
    "    \n",
    "    # Sitemap URL ìˆ˜ì§‘\n",
    "    sitemap_urls = collect_urls_from_sitemap(CURRENT_CITY, limit=500)\n",
    "    \n",
    "    if sitemap_urls:\n",
    "        print(f\"ğŸ“Š Sitemapì—ì„œ {len(sitemap_urls)}ê°œ URL ë°œê²¬\")\n",
    "        \n",
    "        # ì¤‘ë³µ ì œê±° (ì´ë¯¸ í¬ë¡¤ë§í•œ URL ì œì™¸)\n",
    "        new_urls = []\n",
    "        for url in sitemap_urls:\n",
    "            if not is_url_already_processed(url, CURRENT_CITY):\n",
    "                new_urls.append(url)\n",
    "        \n",
    "        print(f\"ğŸ†• ìƒˆë¡œìš´ URL: {len(new_urls)}ê°œ\")\n",
    "        \n",
    "        if new_urls:\n",
    "            print(f\"\\n{len(new_urls)}ê°œì˜ ìƒˆë¡œìš´ URLì„ í¬ë¡¤ë§í•©ë‹ˆë‹¤...\")\n",
    "            \n",
    "            sitemap_completed = 0\n",
    "            sitemap_failed = 0\n",
    "            \n",
    "            for i, url in enumerate(new_urls, 1):\n",
    "                print(f\"\\nğŸ“Š ì§„í–‰ë¥ : {i}/{len(new_urls)} | Sitemap URL\")\n",
    "                print(f\"ğŸ”— URL: {url[:60]}...\")\n",
    "                \n",
    "                try:\n",
    "                    # ìˆ˜ì •ëœ í•¨ìˆ˜ í˜¸ì¶œ: process_single_url ì‚¬ìš©\n",
    "                    result = crawler.process_single_url(url, CURRENT_CITY, f\"sitemap_{i}\")\n",
    "                    \n",
    "                    if result.get('success') and not result.get('skipped'):\n",
    "                        product_data = result.get('product_data', {})\n",
    "                        product_name = product_data.get('ìƒí’ˆëª…', 'N/A')[:30]\n",
    "                        print(f\"    âœ… ì„±ê³µ: {product_name}...\")\n",
    "                        \n",
    "                        sitemap_completed += 1\n",
    "                        \n",
    "                    elif result.get('skipped'):\n",
    "                        print(f\"    â­ï¸ ê±´ë„ˆë›°ê¸°: {result.get('reason', 'unknown')}\")\n",
    "                    else:\n",
    "                        print(f\"    âŒ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ìŒ')}\")\n",
    "                        sitemap_failed += 1\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"    ğŸ’¥ ì˜ˆì™¸: {e}\")\n",
    "                    sitemap_failed += 1\n",
    "                \n",
    "                time.sleep(1)\n",
    "            \n",
    "            print(f\"\\nâœ… Sitemap í¬ë¡¤ë§ ì™„ë£Œ!\")\n",
    "            print(f\"   ì„±ê³µ: {sitemap_completed}ê°œ | ì‹¤íŒ¨: {sitemap_failed}ê°œ\")\n",
    "        else:\n",
    "            print(\"â„¹ï¸ ìƒˆë¡œìš´ URLì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(\"âŒ Sitemapì—ì„œ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š 7. í¬ë¡¤ë§ ê²°ê³¼ ë¶„ì„ ë° ë³´ê³ ì„œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í¬ë¡¤ë§ ê²°ê³¼ ë¶„ì„ ë° ë³´ê³ ì„œ ìƒì„±\n",
    "print(\"ğŸ“Š í¬ë¡¤ë§ ê²°ê³¼ ë¶„ì„ ì¤‘...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    from klook_modules.system_utils import get_hash_stats\n",
    "    from klook_modules.url_manager import get_url_collection_stats\n",
    "    import pandas as pd\n",
    "    \n",
    "    # 1. í•´ì‹œ ì‹œìŠ¤í…œ í†µê³„\n",
    "    hash_stats = get_hash_stats(CURRENT_CITY)\n",
    "    print(f\"ğŸ”’ í•´ì‹œ ì‹œìŠ¤í…œ í†µê³„:\")\n",
    "    print(f\"   ì²˜ë¦¬ëœ URL: {hash_stats.get('processed_count', 0)}ê°œ\")\n",
    "    \n",
    "    # 2. URL ìˆ˜ì§‘ í†µê³„\n",
    "    url_stats = get_url_collection_stats(CURRENT_CITY)\n",
    "    print(f\"\\nğŸ”— URL ìˆ˜ì§‘ í†µê³„:\")\n",
    "    print(f\"   ìˆ˜ì§‘ íŒŒì¼: {url_stats.get('total_files', 0)}ê°œ\")\n",
    "    print(f\"   ì´ URL: {url_stats.get('total_urls', 0)}ê°œ\")\n",
    "    print(f\"   ìµœê·¼ ìˆ˜ì§‘: {url_stats.get('latest_collection', 'N/A')}\")\n",
    "    \n",
    "    # 3. CSV ë°ì´í„° ë¶„ì„ (ìƒˆë¡œìš´ 32ê°œ ì»¬ëŸ¼ êµ¬ì¡°)\n",
    "    from klook_modules.config import get_city_info\n",
    "    continent, country = get_city_info(CURRENT_CITY)\n",
    "    \n",
    "    # ìƒˆë¡œìš´ íŒŒì¼ëª… í˜•ì‹ í™•ì¸\n",
    "    if CURRENT_CITY in [\"ë§ˆì¹´ì˜¤\", \"í™ì½©\", \"ì‹±ê°€í¬ë¥´\"]:\n",
    "        csv_path_new = f\"data/{continent}/{CURRENT_CITY}_klook_products_all.csv\"\n",
    "        csv_path_old = f\"data/{continent}/klook_{CURRENT_CITY}_products.csv\"\n",
    "    else:\n",
    "        csv_path_new = f\"data/{continent}/{country}/{CURRENT_CITY}/{CURRENT_CITY}_klook_products_all.csv\"\n",
    "        csv_path_old = f\"data/{continent}/{country}/{CURRENT_CITY}/klook_{CURRENT_CITY}_products.csv\"\n",
    "    \n",
    "    # ìƒˆ êµ¬ì¡° CSV í™•ì¸\n",
    "    csv_path = csv_path_new if os.path.exists(csv_path_new) else csv_path_old\n",
    "    csv_structure = \"32ê°œ ì»¬ëŸ¼ (ì‹ ê·œ)\" if os.path.exists(csv_path_new) else \"13ê°œ ì»¬ëŸ¼ (ê¸°ì¡´)\"\n",
    "    \n",
    "    if os.path.exists(csv_path):\n",
    "        df = pd.read_csv(csv_path, encoding='utf-8-sig')\n",
    "        \n",
    "        print(f\"\\nğŸ“‹ CSV ë°ì´í„° ë¶„ì„:\")\n",
    "        print(f\"   ì´ ìƒí’ˆ: {len(df)}ê°œ\")\n",
    "        print(f\"   êµ¬ì¡°: {csv_structure}\")\n",
    "        print(f\"   ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}ê°œ\")\n",
    "        print(f\"   íŒŒì¼ ìœ„ì¹˜: {csv_path}\")\n",
    "        \n",
    "        # 32ê°œ ì»¬ëŸ¼ êµ¬ì¡° ìƒì„¸ ë¶„ì„\n",
    "        if len(df.columns) >= 30:  # 32ê°œ ì»¬ëŸ¼ êµ¬ì¡°\n",
    "            print(f\"\\nğŸ’¾ 32ê°œ ì»¬ëŸ¼ êµ¬ì¡° í™•ì¸:\")\n",
    "            \n",
    "            # ê¸°ë³¸ ì •ë³´ ì»¬ëŸ¼\n",
    "            basic_cols = ['ë²ˆí˜¸', 'ë„ì‹œID', 'ìƒí’ˆëª…', 'ê°€ê²©_ì›ë³¸', 'ê°€ê²©_ì •ì œ']\n",
    "            basic_present = [col for col in basic_cols if col in df.columns]\n",
    "            print(f\"   ê¸°ë³¸ ì •ë³´: {len(basic_present)}/{len(basic_cols)}ê°œ\")\n",
    "            \n",
    "            # ì´ë¯¸ì§€ ì»¬ëŸ¼ (8ê°œ)\n",
    "            image_cols = [col for col in df.columns if 'ì´ë¯¸ì§€' in col]\n",
    "            print(f\"   ì´ë¯¸ì§€ ì •ë³´: {len(image_cols)}ê°œ\")\n",
    "            \n",
    "            # ë­í‚¹ ì»¬ëŸ¼\n",
    "            ranking_cols = ['íƒ­ëª…', 'íƒ­ìˆœì„œ', 'íƒ­ë‚´_ë­í‚¹', 'URL_í•´ì‹œ']\n",
    "            ranking_present = [col for col in ranking_cols if col in df.columns]\n",
    "            print(f\"   ë­í‚¹ ì •ë³´: {len(ranking_present)}/{len(ranking_cols)}ê°œ\")\n",
    "            \n",
    "            # ë“€ì–¼ ì´ë¯¸ì§€ í†µê³„\n",
    "            if 'ë©”ì¸ì´ë¯¸ì§€_íŒŒì¼ëª…' in df.columns and 'ì¸ë„¤ì¼ì´ë¯¸ì§€_íŒŒì¼ëª…' in df.columns:\n",
    "                main_images = df[df['ë©”ì¸ì´ë¯¸ì§€_íŒŒì¼ëª…'] != 'ì •ë³´ ì—†ìŒ']\n",
    "                thumb_images = df[df['ì¸ë„¤ì¼ì´ë¯¸ì§€_íŒŒì¼ëª…'] != 'ì •ë³´ ì—†ìŒ']\n",
    "                dual_images = df[(df['ë©”ì¸ì´ë¯¸ì§€_íŒŒì¼ëª…'] != 'ì •ë³´ ì—†ìŒ') & \n",
    "                               (df['ì¸ë„¤ì¼ì´ë¯¸ì§€_íŒŒì¼ëª…'] != 'ì •ë³´ ì—†ìŒ')]\n",
    "                \n",
    "                print(f\"\\nğŸ“¸ ë“€ì–¼ ì´ë¯¸ì§€ í†µê³„:\")\n",
    "                print(f\"   ë©”ì¸ ì´ë¯¸ì§€: {len(main_images)}ê°œ\")\n",
    "                print(f\"   ì¸ë„¤ì¼ ì´ë¯¸ì§€: {len(thumb_images)}ê°œ\")\n",
    "                print(f\"   ë“€ì–¼ ì´ë¯¸ì§€: {len(dual_images)}ê°œ\")\n",
    "        \n",
    "        # íƒ­ë³„ ë¶„ì„\n",
    "        tab_col = 'íƒ­ëª…' if 'íƒ­ëª…' in df.columns else None\n",
    "        if tab_col:\n",
    "            tab_counts = df[tab_col].value_counts()\n",
    "            print(f\"\\nğŸª íƒ­ë³„ ìƒí’ˆ ìˆ˜:\")\n",
    "            for tab, count in tab_counts.items():\n",
    "                print(f\"   {tab}: {count}ê°œ\")\n",
    "        \n",
    "        # ê°€ê²© ë¶„ì„ (êµ¬ ì»¬ëŸ¼/ì‹  ì»¬ëŸ¼ í˜¸í™˜)\n",
    "        price_col = 'ê°€ê²©_ì •ì œ' if 'ê°€ê²©_ì •ì œ' in df.columns else 'ê°€ê²©'\n",
    "        if price_col in df.columns:\n",
    "            valid_prices = df[df[price_col] != 'ì •ë³´ ì—†ìŒ'][price_col]\n",
    "            print(f\"\\nğŸ’° ê°€ê²© ì •ë³´:\")\n",
    "            print(f\"   ê°€ê²© ìˆìŒ: {len(valid_prices)}ê°œ\")\n",
    "            print(f\"   ê°€ê²© ì—†ìŒ: {len(df) - len(valid_prices)}ê°œ\")\n",
    "        \n",
    "        # í‰ì  ë¶„ì„ (êµ¬ ì»¬ëŸ¼/ì‹  ì»¬ëŸ¼ í˜¸í™˜)\n",
    "        rating_col = 'í‰ì _ì •ì œ' if 'í‰ì _ì •ì œ' in df.columns else 'í‰ì '\n",
    "        if rating_col in df.columns:\n",
    "            valid_ratings = df[df[rating_col] != 'ì •ë³´ ì—†ìŒ'][rating_col]\n",
    "            print(f\"\\nâ­ í‰ì  ì •ë³´:\")\n",
    "            print(f\"   í‰ì  ìˆìŒ: {len(valid_ratings)}ê°œ\")\n",
    "            print(f\"   í‰ì  ì—†ìŒ: {len(df) - len(valid_ratings)}ê°œ\")\n",
    "        \n",
    "        # ì¶”ê°€ ì •ë³´ ë¶„ì„ (32ê°œ ì»¬ëŸ¼ êµ¬ì¡°)\n",
    "        if 'í•˜ì´ë¼ì´íŠ¸' in df.columns:\n",
    "            highlights = df[df['í•˜ì´ë¼ì´íŠ¸'] != 'ì •ë³´ ì—†ìŒ']\n",
    "            print(f\"   í•˜ì´ë¼ì´íŠ¸: {len(highlights)}ê°œ\")\n",
    "        \n",
    "        if 'ì–¸ì–´' in df.columns:\n",
    "            languages = df[df['ì–¸ì–´'] != 'ì •ë³´ ì—†ìŒ']\n",
    "            print(f\"   ì–¸ì–´ ì •ë³´: {len(languages)}ê°œ\")\n",
    "        \n",
    "        # ìµœê·¼ í¬ë¡¤ë§ ì‹œê°„\n",
    "        time_col = 'ìˆ˜ì§‘_ì‹œê°„' if 'ìˆ˜ì§‘_ì‹œê°„' in df.columns else 'ìˆ˜ì§‘ì¼ì‹œ'\n",
    "        if time_col in df.columns:\n",
    "            latest_crawl = df[time_col].max()\n",
    "            print(f\"\\nâ° ìµœê·¼ í¬ë¡¤ë§: {latest_crawl}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}\")\n",
    "    \n",
    "    # 4. ë­í‚¹ ë§¤ë‹ˆì € ë¶„ì„\n",
    "    try:\n",
    "        ranking_stats = ranking_manager.get_city_ranking_stats(CURRENT_CITY)\n",
    "        if ranking_stats:\n",
    "            print(f\"\\nğŸ† ë­í‚¹ ë§¤ë‹ˆì € ë¶„ì„:\")\n",
    "            print(f\"   ì´ ê´€ë¦¬ URL: {ranking_stats.get('total_urls', 0)}ê°œ\")\n",
    "            print(f\"   ì¤‘ë³µ ë°œê²¬ URL: {ranking_stats.get('duplicate_urls', 0)}ê°œ\")\n",
    "            print(f\"   ì²˜ë¦¬ëœ íƒ­: {ranking_stats.get('tabs_processed', [])}\")\n",
    "            print(f\"   ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {ranking_stats.get('last_updated', 'N/A')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ë­í‚¹ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # 5. ì´ë¯¸ì§€ í´ë” ë¶„ì„\n",
    "    try:\n",
    "        img_base_folder = \"klook_thumb_img\"\n",
    "        if os.path.exists(img_base_folder):\n",
    "            if CURRENT_CITY in [\"ë§ˆì¹´ì˜¤\", \"í™ì½©\", \"ì‹±ê°€í¬ë¥´\"]:\n",
    "                img_folder = os.path.join(img_base_folder, continent)\n",
    "            else:\n",
    "                img_folder = os.path.join(img_base_folder, continent, country, CURRENT_CITY)\n",
    "            \n",
    "            if os.path.exists(img_folder):\n",
    "                img_files = [f for f in os.listdir(img_folder) if f.endswith('.jpg')]\n",
    "                main_imgs = [f for f in img_files if '_thumb' not in f and '_main' not in f]\n",
    "                thumb_imgs = [f for f in img_files if '_thumb' in f]\n",
    "                \n",
    "                print(f\"\\nğŸ“¸ ì´ë¯¸ì§€ í´ë” ë¶„ì„:\")\n",
    "                print(f\"   í´ë” ìœ„ì¹˜: {img_folder}\")\n",
    "                print(f\"   ì´ ì´ë¯¸ì§€: {len(img_files)}ê°œ\")\n",
    "                print(f\"   ë©”ì¸ ì´ë¯¸ì§€: {len(main_imgs)}ê°œ\")\n",
    "                print(f\"   ì¸ë„¤ì¼: {len(thumb_imgs)}ê°œ\")\n",
    "            else:\n",
    "                print(f\"\\nğŸ“¸ ì´ë¯¸ì§€ í´ë” ì—†ìŒ: {img_folder}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# ì„¸ì…˜ ë³´ê³ ì„œ ìƒì„± (ì—…ë°ì´íŠ¸ëœ ì •ë³´ í¬í•¨)\n",
    "try:\n",
    "    session_report = {\n",
    "        \"city\": CURRENT_CITY,\n",
    "        \"mode\": CRAWLING_MODE,\n",
    "        \"start_rank\": START_RANK,\n",
    "        \"end_rank\": END_RANK,\n",
    "        \"completed_at\": datetime.now().isoformat(),\n",
    "        \"settings\": settings,\n",
    "        \"total_time_minutes\": int(total_time // 60),\n",
    "        \"results\": {\n",
    "            \"completed\": total_completed,\n",
    "            \"skipped\": total_skipped,\n",
    "            \"failed\": total_failed\n",
    "        },\n",
    "        \"system_info\": {\n",
    "            \"column_structure\": \"32ê°œ ì»¬ëŸ¼\",\n",
    "            \"dual_image_system\": settings.get('download_images', True),\n",
    "            \"ranking_manager\": True,\n",
    "            \"hashlib_system\": CONFIG.get('USE_HASH_SYSTEM', True)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # ë³´ê³ ì„œ ì €ì¥\n",
    "    os.makedirs(\"session_reports\", exist_ok=True)\n",
    "    report_filename = f\"session_reports/klook_session_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "    \n",
    "    import json\n",
    "    with open(report_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(session_report, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ ì„¸ì…˜ ë³´ê³ ì„œ ì €ì¥: {report_filename}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ë³´ê³ ì„œ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(\"\\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(f\"ğŸ’¾ 32ê°œ ì»¬ëŸ¼ êµ¬ì¡°: {'âœ… ì ìš©ë¨' if csv_structure == '32ê°œ ì»¬ëŸ¼ (ì‹ ê·œ)' else 'âš ï¸ ê¸°ì¡´ êµ¬ì¡°'}\")\n",
    "print(f\"ğŸ“¸ ë“€ì–¼ ì´ë¯¸ì§€: {'âœ… ì ìš©ë¨' if settings.get('download_images', True) else 'âŒ ë¹„í™œì„±í™”'}\")\n",
    "print(f\"ğŸ† ë­í‚¹ ë§¤ë‹ˆì €: {'âœ… í™œì„±í™”' if 'ranking_manager' in locals() else 'âŒ ë¹„í™œì„±í™”'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§¹ 8. ì‹œìŠ¤í…œ ì •ë¦¬ ë° ì¢…ë£Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œìŠ¤í…œ ì •ë¦¬ ë° ë¸Œë¼ìš°ì € ì¢…ë£Œ\n",
    "print(\"ğŸ§¹ ì‹œìŠ¤í…œ ì •ë¦¬ ì¤‘...\")\n",
    "\n",
    "try:\n",
    "    # í¬ë¡¤ëŸ¬ ì •ë¦¬\n",
    "    if 'crawler' in locals():\n",
    "        crawler.cleanup()\n",
    "        print(\"âœ… í¬ë¡¤ëŸ¬ ì •ë¦¬ ì™„ë£Œ\")\n",
    "    \n",
    "    # ë“œë¼ì´ë²„ ì¢…ë£Œ\n",
    "    if 'driver' in locals():\n",
    "        driver.quit()\n",
    "        print(\"âœ… ë¸Œë¼ìš°ì € ì¢…ë£Œ ì™„ë£Œ\")\n",
    "    \n",
    "    # ë§ˆìŠ¤í„° ì»¨íŠ¸ë¡¤ëŸ¬ ì •ë¦¬\n",
    "    if 'controller' in locals():\n",
    "        controller.cleanup_system()\n",
    "        print(\"âœ… ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "print(\"\\nğŸ‘‹ KLOOK í¬ë¡¤ëŸ¬ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ‰ í¬ë¡¤ë§ ì„¸ì…˜ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(\"ğŸ“ ê²°ê³¼ íŒŒì¼ë“¤ì„ í™•ì¸í•˜ì„¸ìš”:\")\n",
    "print(f\"   - CSV ë°ì´í„°: data/{CURRENT_CITY}/\")\n",
    "print(f\"   - ì„¸ì…˜ ë³´ê³ ì„œ: session_reports/\")\n",
    "print(f\"   - URL ìˆ˜ì§‘ ë¡œê·¸: url_collected/\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ğŸ” ì‹¤ì œ URL ìˆœì„œ í™•ì¸ (ìˆ˜ë™ ì‹¤í–‰ìš©)\nprint(\"ğŸ” ì‹¤ì œ ìˆ˜ì§‘ëœ URL ìˆœì„œ í™•ì¸\")\nprint(\"=\" * 50)\n\n# ë™ì ìœ¼ë¡œ city_code ê°€ì ¸ì˜¤ê¸°\ntry:\n    from klook_modules.config import get_city_code\n    city_code = get_city_code(CURRENT_CITY)\n    \n    # ë™ì ìœ¼ë¡œ êµ¬ì„±ëœ íŒŒì¼ ê²½ë¡œë¡œ URL ë¡œê·¸ í™•ì¸\n    url_log_file = f'url_collected/{city_code}_url_log.txt'\n    \n    with open(url_log_file, 'r', encoding='utf-8') as f:\n        urls = f.readlines()\n    \n    print(f\"ğŸ“Š {CURRENT_CITY} ìˆ˜ì§‘ ê²°ê³¼: {len(urls)}ê°œ URL\")\n    \n    for i, line in enumerate(urls, 1):\n        if '|' in line:\n            timestamp, url = line.strip().split(' | ')\n            # URLì—ì„œ ìƒí’ˆëª… ì¶”ì¶œ\n            product_name = url.split('/')[-1].replace('-', ' ')[:50]\n            print(f\"   {i}ìœ„: {product_name}\")\n    \n    # ì‹¤ì œ KLOOK í˜ì´ì§€ì—ì„œ 1-3ìœ„ì™€ ë¹„êµ (ë™ì  ë„ì‹œëª… ì‚¬ìš©)\n    print(f\"\\nğŸ’¡ ì‹¤ì œ KLOOK {CURRENT_CITY} í˜ì´ì§€ì™€ ë¹„êµí•´ë³´ì„¸ìš”:\")\n    if CURRENT_CITY == \"ë¡œë§ˆ\":\n        print(f\"   1ìœ„: ë°”í‹°ì¹¸ ë°•ë¬¼ê´€ (Vatican Museums)\")  \n        print(f\"   2ìœ„: ì½œë¡œì„¸ì›€ (Colosseum)\")\n        print(f\"   3ìœ„: ë°”í‹°ì¹¸ íˆ¬ì–´ ë˜ëŠ” ë‹¤ë¥¸ ì¸ê¸° ìƒí’ˆ\")\n    elif CURRENT_CITY == \"êµ¬ë§ˆëª¨í† \":\n        print(f\"   1ìœ„: êµ¬ë§ˆëª¨í† ì„± íˆ¬ì–´ (Kumamoto Castle Tour)\")\n        print(f\"   2ìœ„: ì•„ì†Œì‚° íˆ¬ì–´ (Mount Aso Tour)\")\n        print(f\"   3ìœ„: êµ¬ë§ˆëª¨í†  ì˜¨ì²œ ì²´í—˜\")\n    else:\n        print(f\"   í•´ë‹¹ ë„ì‹œì˜ ì£¼ìš” ê´€ê´‘ ìƒí’ˆë“¤ê³¼ ë¹„êµí•´ë³´ì„¸ìš”\")\n    \n    print(f\"\\nâ“ ìœ„ ìˆœì„œê°€ ì‹¤ì œ KLOOK {CURRENT_CITY} í˜ì´ì§€ ìˆœì„œì™€ ì¼ì¹˜í•˜ë‚˜ìš”?\")\n    \nexcept FileNotFoundError:\n    print(f\"âŒ {CURRENT_CITY} URL ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n    print(f\"   íŒŒì¼ ê²½ë¡œ: {url_log_file}\")\n    print(f\"   ğŸ’¡ ë¨¼ì € URL ìˆ˜ì§‘ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\nexcept NameError:\n    print(\"âŒ CURRENT_CITY ë³€ìˆ˜ê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n    print(\"ğŸ’¡ ì²« ë²ˆì§¸ ì…€ì—ì„œ ì„¤ì •ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\nexcept Exception as e:\n    print(f\"âŒ ì˜¤ë¥˜: {e}\")\n\nprint(f\"\\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„:\")\nprint(f\"   1. KLOOK {CURRENT_CITY} í˜ì´ì§€ë¥¼ ì§ì ‘ í™•ì¸\")  \nprint(f\"   2. ì‹¤ì œ 1-3ìœ„ ìˆœì„œì™€ ë¹„êµ\")\nprint(f\"   3. ìˆœì„œê°€ ë‹¤ë¥´ë©´ ì¢Œí‘œ ê¸°ë°˜ ì •ë ¬ êµ¬í˜„\")\nprint(f\"   4. ìˆœì„œê°€ ë§ë‹¤ë©´ í˜„ì¬ ë°©ì‹ ìœ ì§€\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”„ ì´ì–´ì„œ ê³„ì†í•˜ê¸° (Resume ê¸°ëŠ¥)\n",
    "\n",
    "ë§Œì•½ í¬ë¡¤ë§ì´ ì¤‘ê°„ì— ì¤‘ë‹¨ë˜ì—ˆë‹¤ë©´, ë‹¤ìŒ ì…€ì„ ì‹¤í–‰í•˜ì—¬ ì´ì–´ì„œ ê³„ì†í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume ê¸°ëŠ¥ - ì¤‘ë‹¨ëœ ì§€ì ë¶€í„° ì´ì–´ì„œ ê³„ì† (ìë™ ê±´ë„ˆë›°ê¸°)\n",
    "print(\"ğŸ”„ ì´ì–´ì„œ ê³„ì†í•˜ê¸° ê¸°ëŠ¥ (Run All í˜¸í™˜)\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Run All í˜¸í™˜ì„ ìœ„í•´ ìë™ìœ¼ë¡œ ê±´ë„ˆë›°ê¸°\n",
    "print(\"â­ï¸ Run All ëª¨ë“œ: Resume ê¸°ëŠ¥ì„ ìë™ìœ¼ë¡œ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "print(\"ğŸ’¡ í•„ìš”ì‹œ ì´ ì…€ì„ ê°œë³„ ì‹¤í–‰í•˜ì—¬ Resume ê¸°ëŠ¥ì„ í™œì„±í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ìˆ˜ë™ ì‹¤í–‰ ëª¨ë“œ (ê°œë³„ ì…€ ì‹¤í–‰ì‹œì—ë§Œ ë™ì‘)\n",
    "if False:  # ê¸°ë³¸ì ìœ¼ë¡œ ë¹„í™œì„±í™”\n",
    "    try:\n",
    "        from klook_modules.system_utils import load_session_state\n",
    "        \n",
    "        # ì‚¬ìš©ìì—ê²Œ ë„ì‹œëª… ì…ë ¥ ë°›ê¸° (ìˆ˜ë™ ëª¨ë“œì—ì„œë§Œ)\n",
    "        resume_city = input(\"ì´ì–´ì„œ ê³„ì†í•  ë„ì‹œëª…ì„ ì…ë ¥í•˜ì„¸ìš”: \")\n",
    "        \n",
    "        # ì´ì „ ì„¸ì…˜ ìƒíƒœ ë¡œë“œ\n",
    "        session_state = load_session_state(resume_city)\n",
    "        \n",
    "        if session_state:\n",
    "            print(f\"âœ… '{resume_city}' ì´ì „ ì„¸ì…˜ ë°œê²¬!\")\n",
    "            print(f\"ğŸ“Š ì´ì „ ì„¸ì…˜ ì •ë³´: {session_state.get('timestamp', 'N/A')}\")\n",
    "            \n",
    "            # ì„¤ì • ë³µì› (ìˆ˜ì •ëœ ë³€ìˆ˜ëª…)\n",
    "            CURRENT_CITY = resume_city\n",
    "            START_RANK = session_state.get('start_rank', 1)\n",
    "            END_RANK = session_state.get('end_rank', 50)\n",
    "            CRAWLING_MODE = 'resume'\n",
    "            \n",
    "            # ì„¤ì • ë”•ì…”ë„ˆë¦¬ ë³µì›\n",
    "            settings = {\n",
    "                'city': resume_city,\n",
    "                'start_rank': START_RANK,\n",
    "                'end_rank': END_RANK,\n",
    "                'mode': 'resume',\n",
    "                'skip_duplicates': True,\n",
    "                'auto_save': session_state.get('auto_save', True),\n",
    "                'download_images': session_state.get('download_images', True),\n",
    "                'save_session': True\n",
    "            }\n",
    "            \n",
    "            print(f\"ğŸ”„ '{CURRENT_CITY}'ì—ì„œ ì´ì–´ì„œ ê³„ì†í•©ë‹ˆë‹¤...\")\n",
    "            print(f\"ğŸ“Š ë³µì›ëœ ìˆœìœ„ ë²”ìœ„: {START_RANK}ìœ„ ~ {END_RANK}ìœ„\")\n",
    "            print(f\"ğŸ’¾ 32ê°œ ì»¬ëŸ¼ êµ¬ì¡°: âœ… ì ìš©\")\n",
    "            print(f\"ğŸ† ë­í‚¹ ë§¤ë‹ˆì €: âœ… í™œì„±í™”\")\n",
    "            print(\"ìœ„ì˜ '3. í¬ë¡¤ë§ ì‹¤í–‰' ì…€ë¶€í„° ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "        else:\n",
    "            print(f\"âŒ '{resume_city}'ì˜ ì´ì „ ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Resume ê¸°ëŠ¥ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "print(\"âœ… Resume ê¸°ëŠ¥ ì…€ ì™„ë£Œ - ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}