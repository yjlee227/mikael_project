{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ KLOOK í¬ë¡¤ëŸ¬ v2.0\n",
    "## Activity ì¹´í…Œê³ ë¦¬ ì „ìš© ìˆœìœ„ ê¸°ë°˜ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ\n",
    "\n",
    "### ğŸ“‹ ì£¼ìš” ê¸°ëŠ¥:\n",
    "- âœ… Activity ì¹´í…Œê³ ë¦¬ë§Œ ì„ ë³„ ìˆ˜ì§‘ (í˜¸í…”, ë Œí„°ì¹´ ì œì™¸)\n",
    "- âœ… íƒ­ë³„ ìˆœìœ„ ê¸°ë°˜ í¬ë¡¤ë§ (ì „ì²´, íˆ¬ì–´&ì•¡í‹°ë¹„í‹°, í‹°ì¼“&ì…ì¥ê¶Œ, êµí†µ, ê¸°íƒ€)\n",
    "- âœ… ëª©ë¡í˜ì´ì§€ URL ë°±ì—…ìœ¼ë¡œ ì•ˆì •ì  í˜ì´ì§€ë„¤ì´ì…˜\n",
    "- âœ… **ğŸ—ºï¸ Sitemap ê¸°ë°˜ ì¶”ê°€ ìˆ˜ì§‘** (í˜ì´ì§€ë„¤ì´ì…˜ ë³´ì™„)\n",
    "- âœ… **âœ¨ í•˜ì´ë¼ì´íŠ¸ í† ê¸€ ëª¨ë‹¬** (í¼ì¹˜ê¸° ë²„íŠ¼ â†’ ìˆ˜ì§‘ â†’ Xë²„íŠ¼ ë‹«ê¸°)\n",
    "- âœ… **ğŸŒ ì–¸ì–´ ì •ë³´ ìë™ ê°ì§€** (URL/HTML/ë‚´ìš© ê¸°ë°˜)\n",
    "- âœ… **ğŸ¯ ì›ë³¸ ì •êµí•œ ì…€ë ‰í„°** (100% ì‘ë™ ë³´ì¥)\n",
    "- âœ… 3ê°€ì§€ ë…ë¦½ ë°ì´í„° ì €ì¥: CSV, ë­í‚¹JSON, ì´ë¯¸ì§€\n",
    "- âœ… ì—°ì†ì„± ë³´ì¥: 1ìœ„ë¶€í„° ìˆœì°¨ì  ìˆœìœ„ ë§¤ê¹€\n",
    "\n",
    "### ğŸ”¥ **v2.0 ì‹ ê·œ ê¸°ëŠ¥:**\n",
    "- **í† ê¸€ ëª¨ë‹¬ í•˜ì´ë¼ì´íŠ¸**: í¼ì¹˜ê¸° ë²„íŠ¼ í´ë¦­ â†’ í•˜ì´ë¼ì´íŠ¸ ìˆ˜ì§‘ â†’ ìë™ ë‹«ê¸°\n",
    "- **ì–¸ì–´ ì •ë³´ ìˆ˜ì§‘**: í•œêµ­ì–´/ì˜ì–´/ì¼ë³¸ì–´/ì¤‘êµ­ì–´ ìë™ ê°ì§€\n",
    "- **Sitemap ë³´ì™„ ìˆ˜ì§‘**: í˜ì´ì§€ë„¤ì´ì…˜ìœ¼ë¡œ ë†“ì¹œ ìƒí’ˆë“¤ ì¶”ê°€ ìˆ˜ì§‘\n",
    "- **ì›ë³¸ ì…€ë ‰í„° ì ìš©**: KLOOK ì „ìš© ì •êµí•œ ì…€ë ‰í„°ë¡œ ì¶”ì¶œ ì„±ê³µë¥  ê·¹ëŒ€í™”\n",
    "\n",
    "### ğŸ¯ ì‚¬ìš©ë²•:\n",
    "1. **ì•„ë˜ 1ë²ˆ ì…€ì—ì„œ ì„¤ì • ë³€ê²½**\n",
    "2. **Run All ì‹¤í–‰** (ì „ì²´ ìë™ ì‹¤í–‰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸš€ KLOOK í¬ë¡¤ëŸ¬ v2.0 ì‹œì‘\n",
      "======================================================================\n",
      "ğŸ”§ Selenium ë²„ì „: 4.9.1\n",
      "âœ… UNIFIED_CITY_INFO ë¡œë“œ ì™„ë£Œ! ì´ 177ê°œ ë„ì‹œ\n",
      "âœ… config.py ë¡œë“œ ì™„ë£Œ: ê¸°ë³¸ ì„¤ì • ë° ë„ì‹œ ì •ë³´ ì‹œìŠ¤í…œ ì¤€ë¹„!\n",
      "âœ… city_manager.py ë¡œë“œ ì™„ë£Œ: ë„ì‹œ ì •ë³´ ê´€ë¦¬ ì‹œìŠ¤í…œ ì¤€ë¹„!\n",
      "âœ… driver_manager.py ë¡œë“œ ì™„ë£Œ: ë“œë¼ì´ë²„ ê´€ë¦¬ ì‹œìŠ¤í…œ ì¤€ë¹„!\n",
      "âœ… parsers.py ë¡œë“œ ì™„ë£Œ: ë°ì´í„° ì¶”ì¶œ ì‹œìŠ¤í…œ ì¤€ë¹„!\n",
      "file_handler.py ë¡œë“œ ì™„ë£Œ: íŒŒì¼ ì²˜ë¦¬ ì‹œìŠ¤í…œ ì¤€ë¹„!\n",
      "   ë„ì‹œì½”ë“œ ê¸°ë°˜ ì´ë¯¸ì§€ íŒŒì¼ëª…: KMJ_0001.jpg, KMJ_0001_thumb.jpg\n",
      "   êµ­ê°€ë³„ í†µí•© CSV ìë™ ìƒì„± ê¸°ëŠ¥ í¬í•¨ (ë„ì‹œêµ­ê°€ ì œì™¸)\n",
      "âœ… í”„ë¡œì íŠ¸ ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ (ì´ˆê³ ì† ì¤‘ë³µ ì²´í¬ í¬í•¨)\n",
      "âœ… Selenium ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ\n",
      "\n",
      "ğŸ“‹ í¬ë¡¤ë§ ì„¤ì •:\n",
      "   ğŸ¯ ëª©í‘œ ìƒí’ˆ: 3ê°œ\n",
      "   ğŸ™ï¸ ë„ì‹œ: í¬ë¼ë¹„\n",
      "   ğŸ“‘ íƒ­: ì „ì²´\n",
      "   ğŸ“¸ ì´ë¯¸ì§€ ì €ì¥: âœ…\n",
      "   ğŸ“„ ìµœëŒ€ í˜ì´ì§€: 10\n",
      "ğŸŒ ë„ì‹œëª… ì •ê·œí™”: 'í¬ë¼ë¹„' â†’ 'í¬ë¼ë¹„'\n",
      "ğŸŒ ë„ì‹œëª… ì •ê·œí™”: 'í¬ë¼ë¹„' â†’ 'í¬ë¼ë¹„'\n",
      "   âœ… ë„ì‹œ í™•ì¸ ì™„ë£Œ: í¬ë¼ë¹„\n",
      "\n",
      "ğŸ¯ ì„¤ì • ì™„ë£Œ - í¬ë¡¤ë§ ì‹œì‘ ì¤€ë¹„!\n",
      "ğŸ’¡ Sitemap í¬ë¡¤ë§ì´ í•„ìš”í•œ ê²½ìš°:\n",
      "   â†’ KLOOK_sitemap_crawler.ipynb ì‚¬ìš©í•˜ì„¸ìš”\n"
     ]
    }
   ],
   "source": [
    "# ê·¸ë£¹ 1===== ğŸ¯ ì‚¬ìš©ì ì„¤ì • ì˜ì—­ =====\n",
    "\n",
    "# 1. ìˆ˜ì§‘í•  ìƒí’ˆ ìˆ˜ ì„¤ì •\n",
    "TARGET_PRODUCTS = 3  # ìˆ˜ì§‘í•  ìƒí’ˆ ìˆ˜ ì…ë ¥\n",
    "\n",
    "# 2. ë„ì‹œëª… ì…ë ¥\n",
    "CITY_NAME = \"í¬ë¼ë¹„\"  # #ğŸ”¥ğŸ”¥ë„ì‹œ ì…ë ¥ ğŸ”¥ğŸ”¥# #\n",
    "\n",
    "# 3. í¬ë¡¤ë§í•  íƒ­ ì„¤ì • (íƒ­ë³„ ë­í‚¹ ìˆ˜ì§‘ìš©)\n",
    "TARGET_TAB = \"ì „ì²´\"  # ì˜µì…˜: \"ì „ì²´\", \"íˆ¬ì–´&ì•¡í‹°ë¹„í‹°\", \"í‹°ì¼“&ì…ì¥ê¶Œ\", \"êµí†µ\", \"ê¸°íƒ€\"\n",
    "\n",
    "# 4. ì´ë¯¸ì§€ ì €ì¥ ì—¬ë¶€\n",
    "SAVE_IMAGES = True  # True: ì´ë¯¸ì§€ ì €ì¥, False: URLë§Œ ì €ì¥\n",
    "\n",
    "# ===== ì‹œìŠ¤í…œ ì„¤ì • =====\n",
    "MAX_PAGES = 10  # ìµœëŒ€ ê²€ìƒ‰í•  í˜ì´ì§€ ìˆ˜ (ì•ˆì „ì¥ì¹˜)\n",
    "PRODUCTS_PER_PAGE = 15  # KLOOK í˜ì´ì§€ë‹¹ ìƒí’ˆ ìˆ˜ (ì°¸ê³ ìš©)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸš€ KLOOK í¬ë¡¤ëŸ¬ v2.0 ì‹œì‘\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ===== í™˜ê²½ ì„¤ì • ë° ëª¨ë“ˆ Import =====\n",
    "import sys\n",
    "import os\n",
    "# í˜„ì¬ klook í´ë”ì—ì„œ src í´ë”ì— ì ‘ê·¼\n",
    "sys.path.append('./src')\n",
    "\n",
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ëª¨ë“ˆ import\n",
    "try:\n",
    "    from src.config import CONFIG, UNIFIED_CITY_INFO, is_url_processed_fast, mark_url_processed_fast\n",
    "    from src.utils.city_manager import normalize_city_name, is_city_supported\n",
    "    from src.scraper.driver_manager import setup_driver, go_to_main_page, find_and_fill_search, click_search_button, handle_popup, smart_scroll_selector\n",
    "    from src.scraper.parsers import extract_all_product_data\n",
    "    from src.utils.file_handler import create_product_data_structure, save_to_csv_klook, get_dual_image_urls_klook, download_dual_images_klook, auto_create_country_csv_after_crawling, get_next_product_number\n",
    "    print(\"âœ… í”„ë¡œì íŠ¸ ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ (ì´ˆê³ ì† ì¤‘ë³µ ì²´í¬ í¬í•¨)\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ í”„ë¡œì íŠ¸ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ’¡ src/ í´ë” êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "    raise\n",
    "\n",
    "# Selenium import\n",
    "try:\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "    print(\"âœ… Selenium ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ\")\n",
    "except ImportError:\n",
    "    print(\"âŒ Seleniumì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ’¡ í•´ê²°: pip install selenium\")\n",
    "    raise\n",
    "\n",
    "# ===== ì„¤ì • ê²€ì¦ =====\n",
    "print(\"\\nğŸ“‹ í¬ë¡¤ë§ ì„¤ì •:\")\n",
    "print(f\"   ğŸ¯ ëª©í‘œ ìƒí’ˆ: {TARGET_PRODUCTS}ê°œ\")\n",
    "print(f\"   ğŸ™ï¸ ë„ì‹œ: {CITY_NAME}\")\n",
    "print(f\"   ğŸ“‘ íƒ­: {TARGET_TAB}\")\n",
    "print(f\"   ğŸ“¸ ì´ë¯¸ì§€ ì €ì¥: {'âœ…' if SAVE_IMAGES else 'âŒ'}\")\n",
    "print(f\"   ğŸ“„ ìµœëŒ€ í˜ì´ì§€: {MAX_PAGES}\")\n",
    "\n",
    "# ë„ì‹œ ì§€ì› ì—¬ë¶€ í™•ì¸\n",
    "normalized_city = normalize_city_name(CITY_NAME)\n",
    "if not is_city_supported(normalized_city):\n",
    "    print(f\"\\nâŒ ì§€ì›ë˜ì§€ ì•ŠëŠ” ë„ì‹œ: {CITY_NAME}\")\n",
    "    print(\"ğŸ“‹ ì§€ì› ë„ì‹œ ëª©ë¡ (ì¼ë¶€):\")\n",
    "    for city in list(UNIFIED_CITY_INFO.keys())[:10]:\n",
    "        print(f\"   â€¢ {city}\")\n",
    "    raise ValueError(f\"ì§€ì›ë˜ì§€ ì•ŠëŠ” ë„ì‹œ: {CITY_NAME}\")\n",
    "else:\n",
    "    CITY_NAME = normalized_city\n",
    "    print(f\"   âœ… ë„ì‹œ í™•ì¸ ì™„ë£Œ: {CITY_NAME}\")\n",
    "\n",
    "print(\"\\nğŸ¯ ì„¤ì • ì™„ë£Œ - í¬ë¡¤ë§ ì‹œì‘ ì¤€ë¹„!\")\n",
    "print(\"ğŸ’¡ Sitemap í¬ë¡¤ë§ì´ í•„ìš”í•œ ê²½ìš°:\")\n",
    "print(\"   â†’ KLOOK_sitemap_crawler.ipynb ì‚¬ìš©í•˜ì„¸ìš”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ê·¸ë£¹ 2 ===== í•µì‹¬ í•¨ìˆ˜ ì •ì˜ =====\n\ndef select_target_tab(driver, tab_name):\n    \"\"\"ì§€ì •ëœ íƒ­ ì„ íƒ\"\"\"\n    print(f\"ğŸ“‘ '{tab_name}' íƒ­ ì„ íƒ ì¤‘...\")\n    \n    # íƒ­ ì„ íƒì ë§¤í•‘\n    tab_selectors = {\n        \"ì „ì²´\": [\n            \"//button[contains(text(), 'ì „ì²´')]\",\n            \"//a[contains(text(), 'ì „ì²´')]\",\n            \"//div[contains(@class, 'tab') and contains(text(), 'ì „ì²´')]\"\n        ],\n        \"íˆ¬ì–´&ì•¡í‹°ë¹„í‹°\": [\n            \"//button[contains(text(), 'íˆ¬ì–´') or contains(text(), 'ì•¡í‹°ë¹„í‹°')]\",\n            \"//a[contains(text(), 'íˆ¬ì–´') or contains(text(), 'ì•¡í‹°ë¹„í‹°')]\"\n        ],\n        \"í‹°ì¼“&ì…ì¥ê¶Œ\": [\n            \"//button[contains(text(), 'í‹°ì¼“') or contains(text(), 'ì…ì¥ê¶Œ')]\",\n            \"//a[contains(text(), 'í‹°ì¼“') or contains(text(), 'ì…ì¥ê¶Œ')]\"\n        ],\n        \"êµí†µ\": [\n            \"//button[contains(text(), 'êµí†µ')]\",\n            \"//a[contains(text(), 'êµí†µ')]\"\n        ],\n        \"ê¸°íƒ€\": [\n            \"//button[contains(text(), 'ê¸°íƒ€')]\",\n            \"//a[contains(text(), 'ê¸°íƒ€')]\"\n        ]\n    }\n    \n    if tab_name == \"ì „ì²´\":\n        print(\"   â„¹ï¸ ê¸°ë³¸ íƒ­(ì „ì²´) ì‚¬ìš© - ë³„ë„ í´ë¦­ ë¶ˆí•„ìš”\")\n        return True\n    \n    selectors = tab_selectors.get(tab_name, [])\n    \n    for selector in selectors:\n        try:\n            tab_element = driver.find_element(By.XPATH, selector)\n            if tab_element.is_displayed() and tab_element.is_enabled():\n                tab_element.click()\n                time.sleep(2)\n                print(f\"   âœ… '{tab_name}' íƒ­ ì„ íƒ ì™„ë£Œ\")\n                return True\n        except Exception:\n            continue\n    \n    print(f\"   âš ï¸ '{tab_name}' íƒ­ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ - ê¸°ë³¸ íƒ­ ì‚¬ìš©\")\n    return False\n\ndef collect_activity_urls_only(driver):\n    \"\"\"í˜„ì¬ í˜ì´ì§€ì—ì„œ Activity URLë§Œ ìˆœìœ„ëŒ€ë¡œ ìˆ˜ì§‘\"\"\"\n    print(\"Activity URL ìˆ˜ì§‘ ì¤‘...\")\n    \n    # í˜ì´ì§€ ë¡œë”© ì™„ë£Œ ëŒ€ê¸°\n    time.sleep(2)\n    \n    # KLOOK Activity URL íŒ¨í„´\n    activity_selectors = [\n        \"a[href*='/activity/']\",\n        \"a[href*='/ko/activity/']\",\n        \".product-card a\",\n        \".activity-card a\",\n        \"[data-testid*='product'] a\",\n        \".search-result-item a\",\n        \".product-item a\",\n        \".card a[href*='activity']\",\n        \".list-item a[href*='activity']\"\n    ]\n    \n    activity_urls = []\n    \n    for selector in activity_selectors:\n        try:\n            elements = driver.find_elements(By.CSS_SELECTOR, selector)\n            \n            for element in elements:\n                try:\n                    url = element.get_attribute(\"href\")\n                    if url and '/activity/' in url and url.startswith('https://www.klook.com/ko/activity/') and url not in activity_urls:\n                        activity_urls.append(url)\n                            \n                except Exception:\n                    continue\n                    \n        except Exception:\n            continue\n    \n    print(f\"   Activity URL {len(activity_urls)}ê°œ ìˆ˜ì§‘\")\n    return activity_urls[:15]  # í˜ì´ì§€ë‹¹ ìµœëŒ€ 15ê°œ\n\ndef go_to_next_page(driver, current_listing_url):\n    \"\"\"ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™ (í™”ì‚´í‘œ í´ë¦­ or URL ë³€ê²½)\"\"\"\n    print(\"â¡ï¸ ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™...\")\n    \n    # 1ë‹¨ê³„: í™”ì‚´í‘œ í´ë¦­ ì‹œë„\n    arrow_selectors = [\n        \".klk-pagination-next-btn:not(.klk-pagination-next-btn-disabled)\",\n        \"button[class*='pagination-next']:not([disabled])\",\n        \"//button[contains(@aria-label, 'ë‹¤ìŒ')]\",\n        \"//a[contains(@aria-label, 'ë‹¤ìŒ')]\",\n        \"//button[contains(@class, 'next')]\",\n        \"//span[contains(text(), 'ë‹¤ìŒ')]/parent::button\",\n        \".pagination button:last-child\",\n        \"[data-testid*='next']\"\n    ]\n    \n    for selector in arrow_selectors:\n        try:\n            if selector.startswith('//'):\n                buttons = driver.find_elements(By.XPATH, selector)\n            else:\n                buttons = driver.find_elements(By.CSS_SELECTOR, selector)\n            \n            for arrow_button in buttons:\n                try:\n                    if arrow_button.is_displayed() and arrow_button.is_enabled():\n                        # ë²„íŠ¼ì´ ë³´ì´ë„ë¡ ìŠ¤í¬ë¡¤\n                        driver.execute_script(\"arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});\", arrow_button)\n                        time.sleep(1)\n                        \n                        # í´ë¦­ ì „ URL ì €ì¥\n                        url_before_click = driver.current_url\n                        \n                        # í´ë¦­\n                        driver.execute_script(\"arguments[0].click();\", arrow_button)\n                        print(\"   ğŸ–±ï¸ í™”ì‚´í‘œ í´ë¦­ ì™„ë£Œ\")\n                        \n                        # í˜ì´ì§€ ë³€í™” í™•ì¸\n                        time.sleep(3)\n                        new_url = driver.current_url\n                        \n                        if new_url != url_before_click:\n                            print(\"   âœ… í˜ì´ì§€ ì´ë™ ì„±ê³µ!\")\n                            return True, new_url\n                        else:\n                            continue\n                            \n                except Exception:\n                    continue\n                    \n        except Exception:\n            continue\n    \n    # 2ë‹¨ê³„: URL ì§ì ‘ ë³€ê²½\n    print(\"   ğŸ”„ í™”ì‚´í‘œ í´ë¦­ ì‹¤íŒ¨ - URL ì§ì ‘ ë³€ê²½\")\n    try:\n        # í˜„ì¬ í˜ì´ì§€ ë²ˆí˜¸ í™•ì¸\n        if 'page=' in current_listing_url:\n            import re\n            match = re.search(r'page=(\\d+)', current_listing_url)\n            if match:\n                current_page = int(match.group(1))\n                next_page_url = current_listing_url.replace(f'page={current_page}', f'page={current_page + 1}')\n            else:\n                raise Exception(\"í˜ì´ì§€ ë²ˆí˜¸ ì¶”ì¶œ ì‹¤íŒ¨\")\n        else:\n            separator = '&' if '?' in current_listing_url else '?'\n            next_page_url = current_listing_url + f'{separator}page=2'\n        \n        driver.get(next_page_url)\n        time.sleep(5)\n        print(\"ğŸ“œ ë‹¤ìŒ í˜ì´ì§€ ë¡œë”© í›„ ìŠ¤í¬ë¡¤ ì‹¤í–‰...\")\n        smart_scroll_selector(driver)\n        \n        final_url = driver.current_url\n        return True, final_url\n        \n    except Exception as e:\n        print(f\"   âŒ í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨: {e}\")\n        return False, current_listing_url\n\nprint(\"ğŸ”§ í•µì‹¬ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™”...\n",
      "ğŸš€ Chrome ë“œë¼ì´ë²„ ì„¤ì • ì¤‘...\n",
      "   ğŸ­ User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWeb...\n"
     ]
    }
   ],
   "source": [
    "# ê·¸ë£¹ 3 ===== ë“œë¼ì´ë²„ ì´ˆê¸°í™” ë° ê²€ìƒ‰ =====\n",
    "print(\"ğŸš€ Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™”...\")\n",
    "driver = setup_driver()\n",
    "\n",
    "if not driver:\n",
    "    print(\"âŒ ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹¤íŒ¨\")\n",
    "    raise Exception(\"ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹¤íŒ¨\")\n",
    "\n",
    "print(\"âœ… ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì„±ê³µ\")\n",
    "\n",
    "try:\n",
    "    # 1. KLOOK ë©”ì¸ í˜ì´ì§€ ì´ë™\n",
    "    print(\"ğŸŒ KLOOK ë©”ì¸ í˜ì´ì§€ ì´ë™...\")\n",
    "    if not go_to_main_page(driver):\n",
    "        raise Exception(\"ë©”ì¸ í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨\")\n",
    "    \n",
    "    # 2. íŒì—… ì²˜ë¦¬\n",
    "    handle_popup(driver)\n",
    "    \n",
    "    # 3. ë„ì‹œ ê²€ìƒ‰\n",
    "    print(f\"ğŸ” '{CITY_NAME}' ê²€ìƒ‰...\")\n",
    "    search_input = find_and_fill_search(driver, CITY_NAME)\n",
    "    if not search_input:\n",
    "        raise Exception(\"ê²€ìƒ‰ì°½ ì…ë ¥ ì‹¤íŒ¨\")\n",
    "    \n",
    "    # 4. ê²€ìƒ‰ ì‹¤í–‰\n",
    "    if not click_search_button(driver):\n",
    "        raise Exception(\"ê²€ìƒ‰ ì‹¤í–‰ ì‹¤íŒ¨\")\n",
    "    \n",
    "    # 5. ê²€ìƒ‰ ê²°ê³¼ ë¡œë”© ëŒ€ê¸°\n",
    "    time.sleep(5)\n",
    "    print(\"âœ… ê²€ìƒ‰ ì™„ë£Œ - ê²°ê³¼ í˜ì´ì§€ ë„ì°©\")\n",
    "    \n",
    "    # 6. íƒ­ ì„ íƒ\n",
    "    select_target_tab(driver, TARGET_TAB)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # 7. ëª©ë¡ í˜ì´ì§€ URL ì €ì¥ (ë°±ì—…ìš©)\n",
    "    listing_page_url = driver.current_url\n",
    "    print(f\"ğŸ“ ëª©ë¡ í˜ì´ì§€ URL ì €ì¥: {listing_page_url[:60]}...\")\n",
    "    \n",
    "    print(\"ğŸ¯ í¬ë¡¤ë§ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    if driver:\n",
    "        # ë¸Œë¼ìš°ì € ìœ ì§€ë¥¼ ìœ„í•´ driver.quit() ì£¼ì„ ì²˜ë¦¬\n",
    "        pass\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê·¸ë£¹ 4 ===== ë©”ì¸ í¬ë¡¤ë§ ì‹¤í–‰ (ì™„ë²½í•œ ë²ˆí˜¸ ì—°ì†ì„± ë³´ì¥) =====\n",
    "print(f\"ğŸš€ '{CITY_NAME}' {TARGET_TAB} íƒ­ í¬ë¡¤ë§ ì‹œì‘!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥ìš© ë³€ìˆ˜\n",
    "crawled_products = []  # í¬ë¡¤ë§ëœ ìƒí’ˆ ë°ì´í„°\n",
    "ranking_data = []      # ìˆœìœ„ ì •ë³´\n",
    "collected_images = []  # ì´ë¯¸ì§€ ì •ë³´\n",
    "\n",
    "# í¬ë¡¤ë§ ìƒíƒœ ë³€ìˆ˜\n",
    "current_rank = 1\n",
    "current_page = 1\n",
    "total_collected = 0\n",
    "current_listing_url = listing_page_url\n",
    "\n",
    "try:\n",
    "    while total_collected < TARGET_PRODUCTS and current_page <= MAX_PAGES:\n",
    "        print(f\"\\nğŸ“„ {current_page}í˜ì´ì§€ ì²˜ë¦¬ ì¤‘... (ëª©í‘œ: {TARGET_PRODUCTS - total_collected}ê°œ ë‚¨ìŒ)\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # 1. í˜„ì¬ í˜ì´ì§€ì—ì„œ Activity URL ìˆ˜ì§‘\n",
    "        activity_urls = collect_activity_urls_only(driver)\n",
    "\n",
    "        if not activity_urls:\n",
    "            print(\"   âš ï¸ Activity URLì´ ì—†ìŒ - ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™\")\n",
    "            success, current_listing_url = go_to_next_page(driver, current_listing_url)\n",
    "            if not success:\n",
    "                print(\"   âŒ ë” ì´ìƒ í˜ì´ì§€ê°€ ì—†ìŒ\")\n",
    "                break\n",
    "            current_page += 1\n",
    "            continue\n",
    "\n",
    "        print(f\"   ğŸ“Š {current_page}í˜ì´ì§€ì—ì„œ Activity {len(activity_urls)}ê°œ ë°œê²¬\")\n",
    "\n",
    "        # 2. ê° Activity ìˆœì°¨ì ìœ¼ë¡œ í¬ë¡¤ë§\n",
    "        page_products = []  # í˜„ì¬ í˜ì´ì§€ì—ì„œ ìˆ˜ì§‘í•œ ìƒí’ˆë“¤\n",
    "        for i, url in enumerate(activity_urls):\n",
    "            if total_collected >= TARGET_PRODUCTS:\n",
    "                break\n",
    "\n",
    "            print(f\"\\n   ğŸ” {current_rank}ìœ„ í¬ë¡¤ë§ ì¤‘... ({i+1}/{len(activity_urls)})\")\n",
    "            print(f\"      URL: {url[:60]}...\")\n",
    "\n",
    "            # ì´ˆê³ ì† ì¤‘ë³µ ì²´í¬ (íŒŒì¼ ì¡´ì¬ í™•ì¸)\n",
    "            if is_url_processed_fast(url, CITY_NAME):\n",
    "                print(f\"      â­ï¸ {current_rank}ìœ„ ì¤‘ë³µ URL ê±´ë„ˆë›°ê¸°: {url[:50]}...\")\n",
    "                current_rank += 1\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # 2-1. ìƒí’ˆ í˜ì´ì§€ ì´ë™\n",
    "                driver.get(url)\n",
    "                time.sleep(random.uniform(2, 4))\n",
    "                print(\"ğŸ“œ ìƒí’ˆ ìƒì„¸ í˜ì´ì§€ ìŠ¤í¬ë¡¤ ì‹¤í–‰...\")\n",
    "                smart_scroll_selector(driver)\n",
    "\n",
    "\n",
    "                # 2-2. ìƒí’ˆ ë°ì´í„° ì¶”ì¶œ\n",
    "                product_data = extract_all_product_data(driver, url, current_rank, city_name=CITY_NAME)\n",
    "\n",
    "                # ì˜¬ë°”ë¥¸ ë²ˆí˜¸ í• ë‹¹ (CSV ì—°ì†ì„± ë³´ì¥)\n",
    "                next_num = get_next_product_number(CITY_NAME)\n",
    "\n",
    "                # 2-3. ê¸°ë³¸ êµ¬ì¡° ìƒì„± ë° ë³‘í•©\n",
    "                base_data = create_product_data_structure(CITY_NAME, next_num, current_rank)\n",
    "                base_data.update(product_data)\n",
    "                base_data['íƒ­'] = TARGET_TAB\n",
    "\n",
    "                # 2-4. ì´ë¯¸ì§€ ì²˜ë¦¬ (ë„ì‹œì½”ë“œ ê¸°ë°˜ íŒŒì¼ëª… ì ìš©)\n",
    "                try:\n",
    "                    main_img, thumb_img = get_dual_image_urls_klook(driver)\n",
    "                    base_data['ë©”ì¸ì´ë¯¸ì§€'] = main_img or \"ì´ë¯¸ì§€ ì—†ìŒ\"\n",
    "                    base_data['ì¸ë„¤ì¼ì´ë¯¸ì§€'] = thumb_img or \"ì´ë¯¸ì§€ ì—†ìŒ\"\n",
    "\n",
    "                    # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ë„ì‹œì½”ë“œ ê¸°ë°˜ íŒŒì¼ëª…: KMJ_0001.jpg)\n",
    "                    if SAVE_IMAGES and (main_img or thumb_img):\n",
    "                        image_urls = {\"main\": main_img, \"thumb\": thumb_img}\n",
    "                        download_results = download_dual_images_klook(image_urls, next_num, CITY_NAME)\n",
    "\n",
    "                        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ê²°ê³¼ë¥¼ ë°ì´í„°ì— ë°˜ì˜\n",
    "                        if download_results.get(\"main\"):\n",
    "                            base_data['ë©”ì¸ì´ë¯¸ì§€_íŒŒì¼ëª…'] = download_results[\"main\"]\n",
    "                        if download_results.get(\"thumb\"):\n",
    "                            base_data['ì¸ë„¤ì¼ì´ë¯¸ì§€_íŒŒì¼ëª…'] = download_results[\"thumb\"]\n",
    "                except Exception as e:\n",
    "                    print(f\"      âš ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "                    base_data['ë©”ì¸ì´ë¯¸ì§€'] = \"ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨\"\n",
    "                    base_data['ì¸ë„¤ì¼ì´ë¯¸ì§€'] = \"ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨\"\n",
    "\n",
    "                # 2-5. CSV ì €ì¥ (êµ­ê°€ë³„ í†µí•© CSV ìë™ ìƒì„± í¬í•¨)\n",
    "                if save_to_csv_klook(base_data, CITY_NAME):\n",
    "                    page_products.append(base_data)\n",
    "\n",
    "                    # ì´ˆê³ ì† ì¤‘ë³µ ì²´í¬ ë§ˆí‚¹ (ì„±ê³µ ì‹œì—ë§Œ)\n",
    "                    mark_url_processed_fast(url, CITY_NAME, next_num, current_rank)\n",
    "\n",
    "                    # ë­í‚¹ ì •ë³´ ì €ì¥\n",
    "                    ranking_info = {\n",
    "                        \"url\": url,\n",
    "                        \"rank\": current_rank,\n",
    "                        \"tab\": TARGET_TAB,\n",
    "                        \"city\": CITY_NAME,\n",
    "                        \"page\": current_page,\n",
    "                        \"product_number\": next_num,  # ì‹¤ì œ í• ë‹¹ëœ ë²ˆí˜¸ ì €ì¥\n",
    "                        \"collected_at\": datetime.now().isoformat()\n",
    "                    }\n",
    "                    ranking_data.append(ranking_info)\n",
    "                    total_collected += 1\n",
    "                    print(f\"      âœ… {current_rank}ìœ„ ìˆ˜ì§‘ ì™„ë£Œ (ë²ˆí˜¸: {next_num}, ì´ {total_collected}/{TARGET_PRODUCTS})\")\n",
    "                else:\n",
    "                    print(f\"      âŒ {current_rank}ìœ„ ì €ì¥ ì‹¤íŒ¨\")\n",
    "\n",
    "                current_rank += 1\n",
    "\n",
    "                # ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€ê¸°\n",
    "                time.sleep(random.uniform(1, 3))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"      âŒ {current_rank}ìœ„ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}\")\n",
    "                current_rank += 1\n",
    "                continue\n",
    "\n",
    "        # 3. ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™ (ë³µê·€ ì—†ì´ ì§ì ‘ ì§„í–‰)\n",
    "        if total_collected < TARGET_PRODUCTS and current_page < MAX_PAGES:\n",
    "            print(f\"\\nâ¡ï¸ {current_page}í˜ì´ì§€ ì™„ë£Œ - ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™...\")\n",
    "            \n",
    "            # í˜„ì¬ í˜ì´ì§€ì—ì„œ ì§ì ‘ ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™ (ë³µê·€í•˜ì§€ ì•ŠìŒ)\n",
    "            success, new_listing_url = go_to_next_page(driver, current_listing_url)\n",
    "            if success:\n",
    "                current_listing_url = new_listing_url\n",
    "                current_page += 1\n",
    "                time.sleep(3)  # ë‹¤ìŒ í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°\n",
    "                print(f\"   âœ… {current_page}í˜ì´ì§€ ì´ë™ ì™„ë£Œ\")\n",
    "            else:\n",
    "                print(\"   âŒ ë” ì´ìƒ í˜ì´ì§€ê°€ ì—†ìŒ\")\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print(f\"\\nğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ!\")\n",
    "\n",
    "    # êµ­ê°€ë³„ í†µí•© CSV ìë™ ìƒì„±\n",
    "    try:\n",
    "        from src.utils.file_handler import auto_create_country_csv_after_crawling\n",
    "        auto_create_country_csv_after_crawling(CITY_NAME)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ êµ­ê°€ë³„ í†µí•© CSV ìë™ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "finally:\n",
    "    # ë“œë¼ì´ë²„ ì¢…ë£Œ\n",
    "    if driver:\n",
    "        # ë¸Œë¼ìš°ì € ìœ ì§€ë¥¼ ìœ„í•´ driver.quit() ì£¼ì„ ì²˜ë¦¬\n",
    "        print(\"ğŸ”š ë“œë¼ì´ë²„ ì¢…ë£Œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê·¸ë£¹ 5 ==== ë­í‚¹ ë°ì´í„° ì €ì¥ =====\n",
    "if ranking_data:\n",
    "    print(\"ğŸ“Š ë­í‚¹ ë°ì´í„° ì €ì¥ ì¤‘...\")\n",
    "    \n",
    "    # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "    ranking_dir = \"ranking_data\"\n",
    "    os.makedirs(ranking_dir, exist_ok=True)\n",
    "    \n",
    "    # íŒŒì¼ëª… ìƒì„±\n",
    "    from src.config import get_city_code\n",
    "    city_code = get_city_code(CITY_NAME)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    tab_safe = TARGET_TAB.replace(\"&\", \"and\").replace(\" \", \"_\")\n",
    "    filename = f\"{city_code}_{tab_safe}_ranking_{timestamp}.json\"\n",
    "    filepath = os.path.join(ranking_dir, filename)\n",
    "    \n",
    "    # ë­í‚¹ ì •ë³´ êµ¬ì¡°í™”\n",
    "    ranking_summary = {\n",
    "        \"city_name\": CITY_NAME,\n",
    "        \"city_code\": city_code,\n",
    "        \"tab_name\": TARGET_TAB,\n",
    "        \"target_products\": TARGET_PRODUCTS,\n",
    "        \"total_collected\": len(ranking_data),\n",
    "        \"pages_processed\": current_page,\n",
    "        \"collected_at\": datetime.now().isoformat(),\n",
    "        \"ranking_data\": ranking_data\n",
    "    }\n",
    "    \n",
    "    # JSON ì €ì¥\n",
    "    try:\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(ranking_summary, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"âœ… ë­í‚¹ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filepath}\")\n",
    "        print(f\"   ğŸ“Š ì €ì¥ëœ ë­í‚¹: {len(ranking_data)}ê°œ\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë­í‚¹ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "else:\n",
    "    print(\"âš ï¸ ì €ì¥í•  ë­í‚¹ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½ =====\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"ğŸ‰ KLOOK í¬ë¡¤ë§ ì™„ë£Œ - {CITY_NAME} ({TARGET_TAB} íƒ­)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼:\")\n",
    "print(f\"   ğŸ¯ ëª©í‘œ: {TARGET_PRODUCTS}ê°œ\")\n",
    "print(f\"   âœ… ì‹¤ì œ ìˆ˜ì§‘: {total_collected}ê°œ\")\n",
    "print(f\"   ğŸ“„ ì²˜ë¦¬í•œ í˜ì´ì§€: {current_page}ê°œ\")\n",
    "print(f\"   ğŸ† ìˆœìœ„ ë²”ìœ„: 1ìœ„ ~ {current_rank-1}ìœ„\")\n",
    "\n",
    "print(f\"\\nğŸ“ ì €ì¥ëœ íŒŒì¼:\")\n",
    "\n",
    "# CSV íŒŒì¼ í™•ì¸\n",
    "try:\n",
    "    from src.utils.file_handler import get_csv_stats\n",
    "    csv_stats = get_csv_stats(CITY_NAME)\n",
    "    if isinstance(csv_stats, dict) and 'error' not in csv_stats:\n",
    "        print(f\"   ğŸ“„ CSV: {csv_stats.get('total_products', 0)}ê°œ ìƒí’ˆ ì €ì¥ë¨\")\n",
    "        print(f\"   ğŸ’¾ í¬ê¸°: {csv_stats.get('file_size', 0)} bytes\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸ CSV: íŒŒì¼ í™•ì¸ ì‹¤íŒ¨\")\n",
    "except Exception as e:\n",
    "    print(f\"   âŒ CSV ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# ë­í‚¹ íŒŒì¼ í™•ì¸\n",
    "if ranking_data:\n",
    "    print(f\"   ğŸ† ë­í‚¹ JSON: {len(ranking_data)}ê°œ ìˆœìœ„ ì •ë³´ ì €ì¥ë¨\")\n",
    "\n",
    "# ì´ë¯¸ì§€ ì €ì¥ ê²°ê³¼ (klook_img í´ë” ì‚¬ìš©)\n",
    "if SAVE_IMAGES:\n",
    "    image_dir = f\"klook_img/{CITY_NAME}\"\n",
    "    if os.path.exists(image_dir):\n",
    "        image_count = len([f for f in os.listdir(image_dir) if f.endswith('.jpg')])\n",
    "        print(f\"   ğŸ“¸ ì´ë¯¸ì§€: {image_count}ê°œ ì €ì¥ë¨\")\n",
    "    else:\n",
    "        print(f\"   ğŸ“¸ ì´ë¯¸ì§€: ì €ì¥ëœ íŒŒì¼ ì—†ìŒ\")\n",
    "else:\n",
    "    print(f\"   ğŸ“¸ ì´ë¯¸ì§€: URLë§Œ ì €ì¥ (ë‹¤ìš´ë¡œë“œ ì•ˆí•¨)\")\n",
    "\n",
    "print(f\"\\nğŸ¯ ì„±ê³µë¥ : {(total_collected/TARGET_PRODUCTS*100):.1f}%\")\n",
    "\n",
    "if total_collected < TARGET_PRODUCTS:\n",
    "    print(f\"\\nğŸ’¡ ì°¸ê³ ì‚¬í•­:\")\n",
    "    print(f\"   â€¢ ëª©í‘œë³´ë‹¤ ì ê²Œ ìˆ˜ì§‘ëœ ì´ìœ : Activity ìƒí’ˆ ë¶€ì¡± ë˜ëŠ” í˜ì´ì§€ í•œê³„\")\n",
    "    print(f\"   â€¢ í˜¸í…”, ë Œí„°ì¹´ëŠ” ì œì™¸í•˜ê³  Activityë§Œ ìˆ˜ì§‘í•¨\")\n",
    "    print(f\"   â€¢ ë‹¤ë¥¸ íƒ­ì—ì„œ ì¶”ê°€ ìˆ˜ì§‘ì„ ì›í•˜ë©´ TARGET_TABì„ ë³€ê²½í•˜ì—¬ ì¬ì‹¤í–‰\")\n",
    "\n",
    "print(f\"\\nâœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ - ê°€ê³µ ë‹¨ê³„ë¡œ ì§„í–‰ ê°€ëŠ¥!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê·¸ë£¹ 6 ===== ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ì„ íƒì ) =====\n",
    "try:\n",
    "    if ranking_data:\n",
    "        print(\"ğŸ“‹ ìˆ˜ì§‘ëœ ìƒí’ˆ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 5ê°œ):\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for i, item in enumerate(ranking_data[:5]):\n",
    "            print(f\"{item['rank']}ìœ„: {item['url'][:50]}...\")\n",
    "            print(f\"      íƒ­: {item['tab']}, í˜ì´ì§€: {item['page']}\")\n",
    "            print(f\"      ìˆ˜ì§‘ì‹œê°„: {item['collected_at'][:19]}\")\n",
    "            print()\n",
    "        \n",
    "        if len(ranking_data) > 5:\n",
    "            print(f\"... ì™¸ {len(ranking_data) - 5}ê°œ ë”\")\n",
    "    \n",
    "    # CSV íŒŒì¼ì„ pandasë¡œ ì½ì–´ì„œ ë¯¸ë¦¬ë³´ê¸°\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        from src.config import get_city_info\n",
    "        \n",
    "        continent, country = get_city_info(CITY_NAME)\n",
    "        \n",
    "        # CSV íŒŒì¼ ê²½ë¡œ ê²°ì • (ë²”ìš©ì ìœ¼ë¡œ ìˆ˜ì • - ì „ì²´ ëŒ€ë¥™ ì§€ì›)\n",
    "        if CITY_NAME == country:\n",
    "            # ë„ì‹œêµ­ê°€: ëŒ€ë¥™ ì§í•˜ì— ì €ì¥\n",
    "            csv_path = os.path.join(\"data\", continent, f\"klook_{CITY_NAME}_products.csv\")\n",
    "        else:\n",
    "            # ì¼ë°˜ ë„ì‹œ: ëŒ€ë¥™/êµ­ê°€/ë„ì‹œ êµ¬ì¡°\n",
    "            csv_path = os.path.join(\"data\", continent, country, CITY_NAME, f\"klook_{CITY_NAME}_products.csv\")\n",
    "        \n",
    "        if os.path.exists(csv_path):\n",
    "            df = pd.read_csv(csv_path, encoding='utf-8-sig')\n",
    "            print(f\"\\nğŸ“Š CSV ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "            print(f\"   ì»¬ëŸ¼: {list(df.columns)}\")\n",
    "            print(f\"   í–‰ ìˆ˜: {len(df)}\")\n",
    "            \n",
    "            if len(df) > 0:\n",
    "                print(f\"\\nìƒìœ„ 3ê°œ ìƒí’ˆ:\")\n",
    "                for i, row in df.head(3).iterrows():\n",
    "                    print(f\"   {row.get('ìˆœìœ„', i+1)}ìœ„: {row.get('ìƒí’ˆëª…', 'N/A')[:30]}...\")\n",
    "                    print(f\"         ê°€ê²©: {row.get('ê°€ê²©', 'N/A')}, í‰ì : {row.get('í‰ì ', 'N/A')}\")\n",
    "                    \n",
    "                    # ğŸ†• v2.0 ì‹ ê·œ í•„ë“œ ë¯¸ë¦¬ë³´ê¸°\n",
    "                    highlights = row.get('í•˜ì´ë¼ì´íŠ¸', '')\n",
    "                    language = row.get('ì–¸ì–´', '')\n",
    "                    if highlights and highlights != 'ì •ë³´ ì—†ìŒ':\n",
    "                        print(f\"         í•˜ì´ë¼ì´íŠ¸: {highlights[:50]}...\")\n",
    "                    if language and language != 'ì •ë³´ ì—†ìŒ':\n",
    "                        print(f\"         ì–¸ì–´: {language}\")\n",
    "                    print()\n",
    "        else:\n",
    "            print(f\"âš ï¸ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {csv_path}\")\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"â„¹ï¸ pandasê°€ ì—†ì–´ CSV ë¯¸ë¦¬ë³´ê¸°ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ CSV ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ë¯¸ë¦¬ë³´ê¸° ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# ğŸ¯ ë°ì´í„° í’ˆì§ˆ ë¶„ì„\n",
    "try:\n",
    "    if os.path.exists(csv_path) and len(df) > 0:\n",
    "        print(f\"\\nğŸ“ˆ ë°ì´í„° í’ˆì§ˆ ë¶„ì„:\")\n",
    "        \n",
    "        # í•„ìˆ˜ ë°ì´í„° ì™„ì„±ë„ í™•ì¸\n",
    "        essential_fields = ['ìƒí’ˆëª…', 'ê°€ê²©', 'í‰ì ', 'URL']\n",
    "        for field in essential_fields:\n",
    "            if field in df.columns:\n",
    "                valid_count = len(df[df[field].notna() & (df[field] != '') & (df[field] != 'ì •ë³´ ì—†ìŒ') & (df[field] != 'ì¶”ì¶œ ì‹¤íŒ¨')])\n",
    "                completion_rate = (valid_count / len(df)) * 100\n",
    "                print(f\"   {field}: {completion_rate:.1f}% ì™„ì„±ë„ ({valid_count}/{len(df)})\")\n",
    "        \n",
    "        # ğŸ†• v2.0 ì‹ ê·œ í•„ë“œ ì™„ì„±ë„\n",
    "        new_fields = ['í•˜ì´ë¼ì´íŠ¸', 'ì–¸ì–´']\n",
    "        for field in new_fields:\n",
    "            if field in df.columns:\n",
    "                valid_count = len(df[df[field].notna() & (df[field] != '') & (df[field] != 'ì •ë³´ ì—†ìŒ') & (df[field] != 'ì¶”ì¶œ ì‹¤íŒ¨')])\n",
    "                completion_rate = (valid_count / len(df)) * 100\n",
    "                print(f\"   {field} (ì‹ ê·œ): {completion_rate:.1f}% ì™„ì„±ë„ ({valid_count}/{len(df)})\")\n",
    "        \n",
    "        # ì–¸ì–´ë³„ ë¶„í¬ (ì–¸ì–´ í•„ë“œê°€ ìˆë‹¤ë©´)\n",
    "        if 'ì–¸ì–´' in df.columns:\n",
    "            language_counts = df['ì–¸ì–´'].value_counts().head(3)\n",
    "            print(f\"\\nğŸŒ ì–¸ì–´ë³„ ë¶„í¬ (ìƒìœ„ 3ê°œ):\")\n",
    "            for lang, count in language_counts.items():\n",
    "                if lang and lang != 'ì •ë³´ ì—†ìŒ':\n",
    "                    percentage = (count / len(df)) * 100\n",
    "                    print(f\"   {lang}: {count}ê°œ ({percentage:.1f}%)\")\n",
    "        \n",
    "        # ê°€ê²© ë²”ìœ„ ë¶„ì„\n",
    "        if 'ê°€ê²©' in df.columns:\n",
    "            price_data = df['ê°€ê²©'].str.extract(r'(\\d+,?\\d*)', expand=False).str.replace(',', '').astype(float, errors='ignore')\n",
    "            valid_prices = price_data.dropna()\n",
    "            if len(valid_prices) > 0:\n",
    "                print(f\"\\nğŸ’° ê°€ê²© ë¶„í¬:\")\n",
    "                print(f\"   ìµœì €ê°€: {valid_prices.min():,.0f}ì›\")\n",
    "                print(f\"   ìµœê³ ê°€: {valid_prices.max():,.0f}ì›\")\n",
    "                print(f\"   í‰ê· ê°€: {valid_prices.mean():,.0f}ì›\")\n",
    "                print(f\"   ì¤‘ê°„ê°€: {valid_prices.median():,.0f}ì›\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ† ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼:\")\n",
    "print(f\"   ğŸ“Š ì „ì²´ ìƒí’ˆ: {total_collected}ê°œ ìˆ˜ì§‘\")\n",
    "print(f\"   ğŸ¯ ëª©í‘œ ë‹¬ì„±ë¥ : {(total_collected/TARGET_PRODUCTS*100):.1f}%\")\n",
    "print(f\"   ğŸ—ºï¸ Sitemap ë³´ì™„: {'âœ… í™œìš©ë¨' if 'sitemap' in [item.get('source', '') for item in ranking_data] else 'âŒ ë¯¸ì‚¬ìš©'}\")\n",
    "print(f\"   âœ¨ í•˜ì´ë¼ì´íŠ¸ ìˆ˜ì§‘: {'âœ… v2.0 ê¸°ëŠ¥ ì ìš©' if any('í•˜ì´ë¼ì´íŠ¸' in str(item) for item in ranking_data) else 'âŒ ê¸°ë³¸ ìˆ˜ì§‘ë§Œ'}\")\n",
    "print(f\"   ğŸŒ ì–¸ì–´ ì •ë³´ ìˆ˜ì§‘: {'âœ… v2.0 ê¸°ëŠ¥ ì ìš©' if any('ì–¸ì–´' in str(item) for item in ranking_data) else 'âŒ ê¸°ë³¸ ìˆ˜ì§‘ë§Œ'}\")\n",
    "\n",
    "print(f\"\\nğŸš€ KLOOK í¬ë¡¤ëŸ¬ v2.0 ì‹¤í–‰ ì™„ë£Œ! ğŸ‰\")\n",
    "print(f\"   ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„: ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ í™œìš©í•œ ë­í‚¹ ì ìˆ˜ ë¶€ì—¬ ë° ê°€ê²© ë¹„êµ\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mikael_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}